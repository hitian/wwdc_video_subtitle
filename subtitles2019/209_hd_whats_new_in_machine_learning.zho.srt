1
00:00:01,516 --> 0:00:04,500
[音乐]

2
00:00:08,516 --> 0:00:17,546
[掌声]

3
00:00:18,046 --> 0:00:19,896
&gt;&gt; 大家好 欢迎各位

4
00:00:20,656 --> 0:00:22,786
我的名字是 Gaurav 今天

5
00:00:22,786 --> 0:00:24,306
我们要讲的是

6
00:00:24,396 --> 0:00:27,456
机器学习的新功能

7
00:00:29,696 --> 0:00:32,326
成千上万的 App 都在用机器学习

8
00:00:33,356 --> 0:00:36,436
你们正在制作的 App 非常棒

9
00:00:37,006 --> 0:00:39,846
他们涉及到了用户生活的方方面面

10
00:00:40,456 --> 0:00:45,086
医院里 医生正在使用

11
00:00:45,086 --> 0:00:47,326
诸如 Butterfly iQ 这样的 App

12
00:00:47,326 --> 0:00:52,206
来进行实时的医学诊断

13
00:00:52,416 --> 0:00:54,866
体育界 教练正在使用

14
00:00:54,866 --> 0:00:57,646
诸如 HomeCourt 这样的 App

15
00:00:58,576 --> 0:01:02,896
在创造力方面 诸如

16
00:00:58,576 --> 0:01:02,896
在创造力方面 诸如

17
00:01:02,896 --> 0:01:04,936
Pixelmator Pro 这样的 App 帮助其他

18
00:01:04,936 --> 0:01:07,686
用户使用 ML 来增强他们的创造性

19
00:01:08,746 --> 0:01:10,366
这只是其中一些例子

20
00:01:10,576 --> 0:01:12,446
我们想要你们制作的

21
00:01:12,446 --> 0:01:14,746
App 也能成为

22
00:01:14,746 --> 0:01:17,396
这种优秀的 App

23
00:01:17,656 --> 0:01:19,686
所以现在的问题是新功能是什么

24
00:01:20,556 --> 0:01:24,736
那我就开始讲了

25
00:01:25,576 --> 0:01:28,896
我们有很多的材料

26
00:01:28,896 --> 0:01:31,556
所以一次或者两次会议是讲不完的

27
00:01:32,126 --> 0:01:36,856
我们需要十次会议来讲解整个材料

28
00:01:38,316 --> 0:01:39,606
我们还有一个

29
00:01:39,776 --> 0:01:43,216
与机器学习中的设计相交叉的会议

30
00:01:44,556 --> 0:01:47,216
我们也有每日实验室

31
00:01:47,216 --> 0:01:49,496
你可以在这里和 Apple 机器学习

32
00:01:49,496 --> 0:01:51,746
工程师一起相约探讨你的想法

33
00:01:53,116 --> 0:01:55,156
当你在 App 中整合机器学习

34
00:01:55,156 --> 0:01:56,956
我们都在这为你清除任何

35
00:01:56,956 --> 0:02:00,326
你可能遇到的障碍

36
00:01:56,956 --> 0:02:00,326
你可能遇到的障碍

37
00:02:02,876 --> 0:02:04,776
在所有的会议中

38
00:02:04,776 --> 0:02:07,016
你将会看到 我们遵循简单的原则

39
00:02:08,356 --> 0:02:12,976
我们想让机器学习变得越简单越好

40
00:02:12,976 --> 0:02:15,106
我们正全神贯注于做此事

41
00:02:15,736 --> 0:02:17,766
我们希望使其更灵活

42
00:02:17,766 --> 0:02:20,466
以便你可以通过各种任务来完成它

43
00:02:21,436 --> 0:02:22,926
我们希望使其更强大

44
00:02:22,976 --> 0:02:25,506
以便你可以在你的设备上

45
00:02:25,506 --> 0:02:28,136
运行最先进的机器学习模型

46
00:02:28,876 --> 0:02:32,976
机器学习适用于每个人

47
00:02:32,976 --> 0:02:35,036
不管你是研究员

48
00:02:35,036 --> 0:02:37,286
还是一名机器学习的新手

49
00:02:38,776 --> 0:02:40,046
通过在实验室中创建

50
00:02:40,046 --> 0:02:41,236
你可以创建最先进的

51
00:02:41,236 --> 0:02:42,816
以任务为中心的机器学习模型

52
00:02:44,526 --> 0:02:47,286
我们产品的下一大支柱是 Domain API

53
00:02:49,256 --> 0:02:50,746
Domain API 允许你用

54
00:02:50,746 --> 0:02:53,346
Apple 的内置智能和模型

55
00:02:54,266 --> 0:02:55,506
所以你不用担心

56
00:02:55,506 --> 0:02:57,426
收集数据和建造模型了

57
00:02:57,646 --> 0:03:00,296
简单地调用 API 即可完成

58
00:02:57,646 --> 0:03:00,296
简单地调用 API 即可完成

59
00:03:02,696 --> 0:03:04,326
今年 我们正在大力

60
00:03:04,356 --> 0:03:05,806
扩展我们的 Domain API

61
00:03:06,256 --> 0:03:08,676
我们在视觉 文本 语音和声音中

62
00:03:09,106 --> 0:03:13,196
都有 Domain API

63
00:03:13,406 --> 0:03:15,226
现在先让我们来看看

64
00:03:15,276 --> 0:03:16,386
其中的一些 API 

65
00:03:17,146 --> 0:03:19,746
让我们先从视觉开始

66
00:03:20,976 --> 0:03:22,906
视觉允许你推断

67
00:03:23,016 --> 0:03:24,716
图像的内容

68
00:03:26,206 --> 0:03:27,386
今年的新特点之一是

69
00:03:27,386 --> 0:03:29,036
图像显著性

70
00:03:30,096 --> 0:03:31,576
图像显著性可以帮你

71
00:03:31,576 --> 0:03:33,536
识别图像中

72
00:03:33,536 --> 0:03:35,256
最相关的区域

73
00:03:36,106 --> 0:03:40,146
在这个例子中 就是人周围的区域

74
00:03:41,936 --> 0:03:43,056
你可以用它来生成

75
00:03:43,056 --> 0:03:44,996
缩略图或进行图像

76
00:03:44,996 --> 0:03:49,976
裁剪 生成记忆 引导相机等等

77
00:03:50,046 --> 0:03:53,786
今年我们要介绍的另外一个

78
00:03:53,786 --> 0:03:56,126
重要特点是文本识别

79
00:03:57,666 --> 0:03:59,516
现在你可以对文档

80
00:03:59,516 --> 0:04:01,476
进行拍照 执行

81
00:03:59,516 --> 0:04:01,476
进行拍照 执行

82
00:04:01,476 --> 0:04:03,556
透视校正 照明

83
00:04:03,556 --> 0:04:05,566
校正和重新组织

84
00:04:05,616 --> 0:04:06,976
设备上的文本

85
00:04:07,516 --> 0:04:13,986
[掌声]

86
00:04:14,486 --> 0:04:18,666
这是很成功的 但并不是全部

87
00:04:18,666 --> 0:04:19,796
我们有图像内置

88
00:04:19,796 --> 0:04:22,016
分类器 人体探测器 宠物

89
00:04:22,016 --> 0:04:24,036
探测器 我们将

90
00:04:24,036 --> 0:04:27,046
在两个视觉会议中介绍它们

91
00:04:31,036 --> 0:04:33,106
下一个领域是自然语言

92
00:04:33,656 --> 0:04:36,356
就像是你用视觉来

93
00:04:36,356 --> 0:04:38,376
推断图像 你可以用

94
00:04:38,376 --> 0:04:43,076
自然语言来推断文本

95
00:04:43,256 --> 0:04:46,166
今年的新内容是内置的情感分析

96
00:04:46,166 --> 0:04:48,626
所以你可以用一种

97
00:04:48,686 --> 0:04:50,616
尊重隐私的方式在设备上

98
00:04:50,616 --> 0:04:53,216
实时分析文本的情感

99
00:04:53,836 --> 0:04:55,296
所以 举例来说 如果有人

100
00:04:55,296 --> 0:04:56,486
输入这样的文本 我

101
00:04:56,566 --> 0:04:57,926
对第二季结局感到很兴奋

102
00:04:57,926 --> 0:04:59,406
这是一种积极的情感

103
00:05:00,256 --> 0:05:02,656
但是最后有点失落

104
00:05:02,656 --> 0:05:05,406
这又是一个消极的情感

105
00:05:06,056 --> 0:05:08,656
所以你可以实时

106
00:05:08,656 --> 0:05:10,006
提供这种反馈

107
00:05:10,526 --> 0:05:14,516
我们还首次

108
00:05:14,516 --> 0:05:17,386
公开了内置的词嵌入

109
00:05:18,606 --> 0:05:20,096
词嵌入可以让你

110
00:05:20,166 --> 0:05:21,666
找到语义相近的单词

111
00:05:21,666 --> 0:05:23,426
例如 雷暴这个词在语义上

112
00:05:23,426 --> 0:05:25,246
非常接近多云

113
00:05:25,246 --> 0:05:28,406
但是离鞋子和靴子相差甚远

114
00:05:28,896 --> 0:05:31,486
词嵌入的一个重要使用案例是语义搜索

115
00:05:31,486 --> 0:05:35,246
我们接下来给你举一个例子

116
00:05:35,456 --> 0:05:36,546
自然语言将提前在

117
00:05:36,546 --> 0:05:38,446
自然语言框架会议中

118
00:05:38,446 --> 0:05:40,086
进行详细讨论

119
00:05:40,636 --> 0:05:45,836
用户与 App 交互的第三种方式

120
00:05:45,836 --> 0:05:48,426
是通过语言和声音

121
00:05:49,566 --> 0:05:51,076
现在我们有了设备语音

122
00:05:51,106 --> 0:05:52,496
支持 所以你可以在设备上

123
00:05:52,546 --> 0:05:54,986
转录文本

124
00:05:54,986 --> 0:05:56,226
你再也不用依赖

125
00:05:56,226 --> 0:05:59,266
网络连接 我们也

126
00:05:59,266 --> 0:06:01,086
有新的语音分析 API

127
00:05:59,266 --> 0:06:01,086
有新的语音分析 API

128
00:06:01,436 --> 0:06:03,066
它不仅可以告诉你讲话的内容

129
00:06:03,066 --> 0:06:05,926
还可以告诉你讲话的方式

130
00:06:05,926 --> 0:06:07,066
所以你可以区分

131
00:06:07,066 --> 0:06:08,486
一个正常的声音和一个高度

132
00:06:08,576 --> 0:06:09,986
紧张的声音

133
00:06:11,016 --> 0:06:12,916
我们也有一个全新的声音

134
00:06:12,916 --> 0:06:14,396
分析框架 我们会在

135
00:06:14,396 --> 0:06:15,936
Create ML 大会上进行讨论

136
00:06:16,416 --> 0:06:21,496
这些域中的

137
00:06:21,496 --> 0:06:24,146
每一个域都有很多功能

138
00:06:24,146 --> 0:06:25,606
你可以做的另一件事就是

139
00:06:25,606 --> 0:06:27,396
无缝地组合这些域

140
00:06:28,216 --> 0:06:29,246
让我给你们举一个例子

141
00:06:30,026 --> 0:06:33,176
假设你想要构建一个

142
00:06:33,176 --> 0:06:35,566
在图像上进行语义搜索的功能

143
00:06:35,676 --> 0:06:36,896
这是一个非常复杂的功能

144
00:06:36,896 --> 0:06:38,746
因此 如果一个用户搜索

145
00:06:38,746 --> 0:06:41,056
雷暴 你不仅想

146
00:06:41,056 --> 0:06:42,366
向他们提供

147
00:06:42,366 --> 0:06:43,886
雷暴的结果 也想

148
00:06:44,026 --> 0:06:46,716
提供天空和多云的结果

149
00:06:46,836 --> 0:06:49,756
现在 你可以将视觉

150
00:06:49,756 --> 0:06:51,336
和自然语言结合起来

151
00:06:51,336 --> 0:06:53,806
仅需很少的代码就可实现此功能

152
00:06:55,176 --> 0:06:56,206
这就是你将要做的

153
00:06:56,206 --> 0:06:58,146
你将会在你的

154
00:06:58,146 --> 0:07:02,056
图像上运行图像分类器

155
00:06:58,146 --> 0:07:02,056
图像上运行图像分类器

156
00:07:02,056 --> 0:07:03,606
你也可以让它们使用内置的图像

157
00:07:03,606 --> 0:07:05,286
分类器来生成标记

158
00:07:06,016 --> 0:07:08,886
当用户输入

159
00:07:08,936 --> 0:07:10,356
类似雷暴的单词 你

160
00:07:10,356 --> 0:07:11,926
可以使用词嵌入来

161
00:07:11,926 --> 0:07:15,226
生成相似的单词 并找到

162
00:07:15,226 --> 0:07:16,896
与这些标记匹配的图像

163
00:07:17,626 --> 0:07:21,896
而且这不是全部

164
00:07:21,896 --> 0:07:23,756
你还可以将使用

165
00:07:23,756 --> 0:07:24,936
Create ML 和 Domain API   

166
00:07:24,936 --> 0:07:26,746
创建的自定义模型组合在一起

167
00:07:27,036 --> 0:07:28,646
我们将在使用 Core ML 和 ARKit

168
00:07:28,646 --> 0:07:30,686
创建伟大 App 的会议中

169
00:07:30,686 --> 0:07:32,996
展示该示例

170
00:07:33,546 --> 0:07:37,426
总之 Domain API

171
00:07:37,426 --> 0:07:38,766
允许你利用 Apple 

172
00:07:38,896 --> 0:07:40,576
内置智能和模型

173
00:07:40,856 --> 0:07:42,586
使用 API 所以你无需

174
00:07:42,586 --> 0:07:44,266
收据数据并制作模型

175
00:07:44,736 --> 0:07:45,776
今年我们在

176
00:07:45,866 --> 0:07:48,046
视觉自然语言

177
00:07:48,046 --> 0:07:49,976
语音和声音 API 方面有了显著的扩展

178
00:07:56,336 --> 0:07:58,176
现在让我们来谈谈 Core ML 3

179
00:07:58,526 --> 0:08:01,016
我们产品的第三大支柱

180
00:07:58,526 --> 0:08:01,016
我们产品的第三大支柱

181
00:08:03,536 --> 0:08:06,106
现在我们所有的平台都

182
00:08:06,196 --> 0:08:10,156
支持 Core ML

183
00:08:10,216 --> 0:08:11,396
所有工作都在设备上完成

184
00:08:11,396 --> 0:08:13,936
因此可以维护用户的隐私

185
00:08:14,716 --> 0:08:16,686
Core ML 是硬件加速 

186
00:08:16,686 --> 0:08:18,466
所以你可以这样做 你可以用它来

187
00:08:18,466 --> 0:08:19,726
进行实时的机器学习

188
00:08:20,646 --> 0:08:22,586
无需服务器

189
00:08:22,586 --> 0:08:23,656
它总是可用的

190
00:08:24,356 --> 0:08:29,666
Core ML 始终支持

191
00:08:29,666 --> 0:08:31,056
各种机器学习

192
00:08:31,056 --> 0:08:33,006
模型 包括经典的

193
00:08:33,006 --> 0:08:34,566
广义线性模型 树集成

194
00:08:34,566 --> 0:08:35,976
支持向量机

195
00:08:35,976 --> 0:08:40,395
和卷积神经网络

196
00:08:40,395 --> 0:08:43,155
和循环神经网络等网络

197
00:08:46,236 --> 0:08:48,596
Core ML 的新功能是

198
00:08:48,596 --> 0:08:51,046
模型灵活化和模型个性化

199
00:08:51,626 --> 0:08:54,016
所以让我们来看看这些

200
00:08:55,956 --> 0:08:58,226
Core ML 扩展了

201
00:08:58,226 --> 0:09:01,036
对数据神经网络的支持

202
00:08:58,226 --> 0:09:01,036
对数据神经网络的支持

203
00:09:01,036 --> 0:09:03,686
我们增加了对

204
00:09:03,686 --> 0:09:06,106
100 多个神经网络层的支持

205
00:09:07,356 --> 0:09:09,046
这意味着你几乎可以

206
00:09:09,046 --> 0:09:11,186
携带 你可以将

207
00:09:11,186 --> 0:09:13,456
最先进的机器学习

208
00:09:13,456 --> 0:09:15,486
模型带入到你的 App 中

209
00:09:15,486 --> 0:09:16,926
比如 ELMo BERT Wavenet

210
00:09:17,816 --> 0:09:18,586
这是什么意思呢

211
00:09:20,136 --> 0:09:21,716
假设你有一个 App

212
00:09:21,716 --> 0:09:22,906
你想在你的 App 中

213
00:09:22,906 --> 0:09:24,056
集成一个最先进的

214
00:09:24,056 --> 0:09:26,476
问答系统

215
00:09:26,476 --> 0:09:28,156
这样一来 当用户提出一个问题

216
00:09:28,156 --> 0:09:30,606
今年的 WWDC 会有多少次大会

217
00:09:31,196 --> 0:09:33,336
你可以使用 BERT 模型来完成

218
00:09:34,536 --> 0:09:35,796
所以 该模型可以对语句

219
00:09:35,796 --> 0:09:38,116
进行分析并给出反馈

220
00:09:38,146 --> 0:09:43,956
结果答案是超过 100

221
00:09:43,956 --> 0:09:45,286
除了自然语言以外

222
00:09:45,286 --> 0:09:47,756
你还可以运行视觉方面的

223
00:09:47,756 --> 0:09:49,166
最新进展比如

224
00:09:49,166 --> 0:09:51,666
实例分割和音频生成

225
00:09:51,666 --> 0:09:53,256
方面的最新进展

226
00:09:56,876 --> 0:09:58,606
为了充分利用

227
00:09:58,606 --> 0:10:00,216
Core ML 的扩展支持

228
00:09:58,606 --> 0:10:00,216
Core ML 的扩展支持

229
00:10:00,266 --> 0:10:03,556
我们正在更新我们的转换器

230
00:10:03,556 --> 0:10:04,986
因此我们将有一个全新的

231
00:10:04,986 --> 0:10:06,276
TensorFlow Core ML 转换器和

232
00:10:06,276 --> 0:10:09,566
ONNX 支持的 ML 转换器即将推出

233
00:10:10,176 --> 0:10:14,756
我们也在更新我们的模型库

234
00:10:14,756 --> 0:10:16,326
在我们的模型库中

235
00:10:16,366 --> 0:10:18,726
导入一些研究模型

236
00:10:18,726 --> 0:10:21,566
以便你可以立即开始使用它们

237
00:10:22,686 --> 0:10:24,466
因此代表着新模型的 ML 3 

238
00:10:24,466 --> 0:10:27,666
和带有模型库的转换器

239
00:10:28,196 --> 0:10:29,526
可以帮助你将

240
00:10:29,526 --> 0:10:31,316
最前沿的 ML 引入到 App 中

241
00:10:32,216 --> 0:10:34,456
现在 模型个性化是一个很大的特点

242
00:10:35,146 --> 0:10:36,836
所以让我解释一下这是什么

243
00:10:37,336 --> 0:10:39,086
所以到目前为止你可以看到

244
00:10:39,086 --> 0:10:41,106
你已经使用 Create ML 来构建

245
00:10:41,106 --> 0:10:44,006
模型 使用 Core ML 来部署

246
00:10:44,006 --> 0:10:47,616
模型 但是 Core ML 3 的新功能是

247
00:10:47,846 --> 0:10:49,806
设备模型个性化

248
00:10:50,266 --> 0:10:53,236
你可以在设备上微调模型

249
00:10:53,966 --> 0:10:58,196
我们在面部 ID 中

250
00:10:58,196 --> 0:11:00,466
使用这种技术并

251
00:10:58,196 --> 0:11:00,466
使用这种技术并

252
00:11:00,466 --> 0:11:01,276
设置 Watch Face

253
00:11:02,026 --> 0:11:05,536
所以事情就是这样发生的

254
00:11:05,756 --> 0:11:08,506
今天你有了数据 你制作一个

255
00:11:08,566 --> 0:11:11,526
ML 模型 你把它发送到你的

256
00:11:11,736 --> 0:11:13,776
App 中 你的所有用户

257
00:11:13,776 --> 0:11:15,136
都下载了相同的模型

258
00:11:15,706 --> 0:11:19,716
这很棒 因为现在

259
00:11:20,196 --> 0:11:21,986
用户不用上传他们的门户网站

260
00:11:22,346 --> 0:11:24,166
你可以直接拍照

261
00:11:24,646 --> 0:11:25,956
在设备上运行模型

262
00:11:25,956 --> 0:11:31,616
得到诸如狗之类的推理

263
00:11:31,836 --> 0:11:34,126
但是如果你正在尝试

264
00:11:34,126 --> 0:11:35,496
处理一个对于每个用户来说都很独特

265
00:11:35,496 --> 0:11:36,526
的概念 该怎么办

266
00:11:37,096 --> 0:11:38,826
说一说我的狗这个概念吧

267
00:11:39,696 --> 0:11:41,006
你可能希望用户

268
00:11:41,006 --> 0:11:42,866
在图片库中找到他们自己的狗的照片

269
00:11:42,916 --> 0:11:44,456
而不是他们拍的

270
00:11:44,456 --> 0:11:47,216
所有狗的照片

271
00:11:47,336 --> 0:11:49,156
而且每个用户的狗看起来都如此不同

272
00:11:49,156 --> 0:11:50,426
例如 有人可能有

273
00:11:50,486 --> 0:11:51,706
金毛猎犬 有的人可能

274
00:11:52,196 --> 0:11:54,386
有斗牛犬 啊 这就是

275
00:11:54,386 --> 0:11:56,976
我的傻狗

276
00:11:58,976 --> 0:12:01,546
那么 我们应该怎么做呢

277
00:11:58,976 --> 0:12:01,546
那么 我们应该怎么做呢

278
00:12:02,746 --> 0:12:05,106
所以对于用户 1 来说我们想要的

279
00:12:05,106 --> 0:12:06,936
需要的是带有这只狗的

280
00:12:06,936 --> 0:12:09,076
图像分类器 说这是他们的狗

281
00:12:10,286 --> 0:12:12,326
对用户 2 来说 这是英国

282
00:12:12,326 --> 0:12:14,906
斗牛犬 这是第三只狗

283
00:12:18,576 --> 0:12:21,286
所以为了做到这一点 其中一种

284
00:12:21,286 --> 0:12:23,886
方法是使用基于服务器的方法

285
00:12:23,916 --> 0:12:26,126
所以你可能要求

286
00:12:26,636 --> 0:12:32,476
每个用户在云端上传照片

287
00:12:32,476 --> 0:12:34,496
服务器为每个用户生成模型

288
00:12:34,496 --> 0:12:39,466
然后将它们发回来

289
00:12:39,466 --> 0:12:42,606
不幸的是 这种方法存在隐私问题

290
00:12:42,606 --> 0:12:45,006
你的用户可能并不乐意

291
00:12:45,266 --> 0:12:47,236
将他们的照片上传到你的

292
00:12:47,236 --> 0:12:48,496
服务器中 这样你就无法

293
00:12:48,496 --> 0:12:49,516
获得他们的照片

294
00:12:50,606 --> 0:12:51,866
你必须设置服务器

295
00:12:51,916 --> 0:12:53,296
所以需要一些成本

296
00:12:53,846 --> 0:12:56,346
我们假设你有一百万用户

297
00:12:56,346 --> 0:12:58,036
我们也真诚的希望你有

298
00:12:58,036 --> 0:12:59,396
你就必须得制作数百万个

299
00:12:59,396 --> 0:13:00,776
这样的模型 然后随着时间的推移

300
00:12:59,396 --> 0:13:00,776
这样的模型 然后随着时间的推移

301
00:13:00,836 --> 0:13:02,966
来追踪它们

302
00:13:05,176 --> 0:13:07,356
使用 Core ML 3 你就可以

303
00:13:07,356 --> 0:13:09,186
在设备上进行更多个性化设置

304
00:13:09,396 --> 0:13:11,776
所以如果你设备上有

305
00:13:11,776 --> 0:13:13,886
训练数据 你就可以

306
00:13:13,886 --> 0:13:15,906
简单地使用它来微调

307
00:13:15,906 --> 0:13:17,146
设备上的模型

308
00:13:17,946 --> 0:13:23,366
所以你之前使用 LMH

309
00:13:23,366 --> 0:13:27,156
来进行推理 如今你可以

310
00:13:27,156 --> 0:13:28,936
从用户那里获取标签数据反馈

311
00:13:28,936 --> 0:13:30,396
提供一些

312
00:13:30,396 --> 0:13:32,386
训练数据 微调

313
00:13:32,386 --> 0:13:34,276
设备上的模型

314
00:13:35,516 --> 0:13:42,226
[掌声]

315
00:13:42,726 --> 0:13:44,256
每个用户都有一个

316
00:13:44,406 --> 0:13:46,006
个性化模型

317
00:13:48,176 --> 0:13:50,826
我们尊重每个用户的隐私

318
00:13:50,826 --> 0:13:52,696
所以你不必放置服务器

319
00:13:53,386 --> 0:13:56,386
所以 Core ML 3 支持

320
00:13:56,386 --> 0:13:59,326
神经网络的设备个性化

321
00:13:59,786 --> 0:14:01,146
我们也支持近邻

322
00:13:59,786 --> 0:14:01,146
我们也支持近邻

323
00:14:01,276 --> 0:14:03,346
算法 这个可以

324
00:14:03,346 --> 0:14:05,246
晚上在后台进行

325
00:14:08,536 --> 0:14:10,276
因此 为了总结和结束我们的

326
00:14:10,356 --> 0:14:13,046
会议 我们看到 Create ML 这个全新的

327
00:14:13,046 --> 0:14:16,006
App 来构建 ML 模型 我们

328
00:14:16,006 --> 0:14:17,556
在 Domain API 中进行了重大 

329
00:14:17,556 --> 0:14:21,126
扩展 Core ML

330
00:14:21,196 --> 0:14:22,586
也变得更加灵活 现在

331
00:14:22,586 --> 0:14:24,666
支持设备个性化

332
00:14:25,206 --> 0:14:29,016
你可以在我们的开发者网站大会 209

333
00:14:29,016 --> 0:14:30,796
上找到更多信息

334
00:14:30,796 --> 0:14:33,966
我们希望你们

335
00:14:33,996 --> 0:14:36,176
像我们一样对这些技术感兴趣

336
00:14:36,566 --> 0:14:38,226
我期待在实验室见到你

337
00:14:38,366 --> 0:14:38,706
谢谢

338
00:14:39,516 --> 0:14:43,500
[掌声]
