1
00:00:01,176 --> 0:00:04,500
[音乐]

2
00:00:09,516 --> 0:00:15,546
[掌声]

3
00:00:16,046 --> 0:00:16,826
&gt;&gt; 下午好

4
00:00:17,536 --> 0:00:18,636
我叫 Justin

5
00:00:18,756 --> 0:00:20,376
我是 GPU 软件的一名工程师

6
00:00:20,376 --> 0:00:21,976
我要讲的是机器学习的 Metal

7
00:00:24,516 --> 0:00:25,946
今天我们要讨论的是

8
00:00:25,946 --> 0:00:26,896
Metal Performance Shaders

9
00:00:26,896 --> 0:00:28,466
框架 以及我们今年

10
00:00:28,466 --> 0:00:29,796
增加的新的机器学习功能

11
00:00:30,396 --> 0:00:33,096
Metal Performance Shaders 或

12
00:00:33,096 --> 0:00:35,156
MPS 是 GPU 加速的

13
00:00:35,156 --> 0:00:36,626
基元的集合

14
00:00:37,066 --> 0:00:38,006
它让你可以

15
00:00:38,006 --> 0:00:39,356
在 GPU 中利用 Metal

16
00:00:39,356 --> 0:00:40,476
高性能的能力

17
00:00:41,226 --> 0:00:43,326
MPS 为图像处理

18
00:00:43,356 --> 0:00:46,266
线性代数 光线追踪 机器学习

19
00:00:46,266 --> 0:00:48,486
提供内核 

20
00:00:49,066 --> 0:00:51,016
现在 机器学习内核

21
00:00:51,016 --> 0:00:52,826
支持推理和训练

22
00:00:52,826 --> 0:00:54,516
它们在 iOS macOS

23
00:00:54,516 --> 0:00:58,896
tvOS 中得到了优化

24
00:00:59,066 --> 0:01:00,446
MPS 还通过图表 API

25
00:00:59,066 --> 0:01:00,446
MPS 还通过图表 API

26
00:01:00,446 --> 0:01:01,766
为构建神经网络

27
00:01:02,006 --> 0:01:07,646
提供了一个便捷的方式

28
00:01:07,876 --> 0:01:10,326
所以 我们现在可以看到

29
00:01:10,326 --> 0:01:11,826
MPS 是如何适应更大的

30
00:01:11,826 --> 0:01:12,436
Apple ML 生态系统的

31
00:01:13,646 --> 0:01:14,936
你有更高等级的框架

32
00:01:14,936 --> 0:01:17,806
如 Core ML 和 Create ML

33
00:01:17,806 --> 0:01:18,736
它们为你实施自己的网络

34
00:01:18,736 --> 0:01:20,386
提供了一个便捷的方式

35
00:01:20,916 --> 0:01:22,076
但是如果你想要在自己的项目上

36
00:01:22,076 --> 0:01:23,646
多一点弹性和控制

37
00:01:23,646 --> 0:01:25,086
你可以使用如 MPS 的

38
00:01:25,086 --> 0:01:27,186
更低等级框架

39
00:01:29,386 --> 0:01:32,266
今年 我们为机器学习支持

40
00:01:32,266 --> 0:01:33,696
添加了几个新功能

41
00:01:34,816 --> 0:01:36,356
我们增加了内核

42
00:01:36,396 --> 0:01:37,676
来支持比以往更多的网络

43
00:01:39,426 --> 0:01:41,256
我们提升了

44
00:01:41,256 --> 0:01:43,726
已存在的网络的性能

45
00:01:43,726 --> 0:01:47,176
我们也让 MPS 更易使用

46
00:01:47,176 --> 0:01:48,276
现在 随着我们检查这些新特征

47
00:01:48,276 --> 0:01:49,456
知道一些关于

48
00:01:49,456 --> 0:01:50,636
推理和训练如何在

49
00:01:50,636 --> 0:01:52,476
机器学习中运行

50
00:01:53,386 --> 0:01:54,546
是很有用的

51
00:01:54,546 --> 0:01:56,706
所以 让我们简单复习一下这些概念

52
00:01:59,156 --> 0:02:01,136
推理就是

53
00:01:59,156 --> 0:02:01,136
推理就是

54
00:02:01,136 --> 0:02:02,536
将网络运用到一个输入数值的过程

55
00:02:02,536 --> 0:02:04,196
在这个例子中就是个图片

56
00:02:04,196 --> 0:02:06,366
产生一个输出或者猜测它是什么

57
00:02:07,386 --> 0:02:09,066
现在 网络是由

58
00:02:09,066 --> 0:02:10,346
如卷积和神经元激活

59
00:02:10,346 --> 0:02:12,106
等多种功能组成

60
00:02:12,106 --> 0:02:16,456
这些层数都依赖于一组参数

61
00:02:16,696 --> 0:02:18,526
在推理中 这些参数

62
00:02:18,526 --> 0:02:20,246
都是固定的 但是它们的

63
00:02:20,246 --> 0:02:22,746
数值在训练过程中被确定

64
00:02:23,306 --> 0:02:26,266
那么 在训练中发生了什么呢

65
00:02:26,266 --> 0:02:28,146
在训练中 我们给予

66
00:02:28,146 --> 0:02:30,956
网络很多已知对象的图像

67
00:02:31,346 --> 0:02:32,506
训练过程包含

68
00:02:32,506 --> 0:02:34,016
不断地对这些图像进行分类

69
00:02:34,016 --> 0:02:35,926
正如我们所做的

70
00:02:35,926 --> 0:02:38,496
我们更新了我们的参数

71
00:02:38,496 --> 0:02:39,416
每一次网络的迭代

72
00:02:39,786 --> 0:02:40,676
都会产生一套更好的参数

73
00:02:40,736 --> 0:02:42,976
直到我们最终得到一套

74
00:02:42,976 --> 0:02:45,896
让我们能最好地分类图像的参数

75
00:02:46,406 --> 0:02:49,526
在我们停止

76
00:02:49,526 --> 0:02:50,726
训练过程的阶段

77
00:02:50,726 --> 0:02:51,716
我们的参数已经准备好

78
00:02:51,716 --> 0:02:56,036
在推理中使用了 我们来看看

79
00:02:56,036 --> 0:02:57,546
如何运用 MPS 来执行这些想法

80
00:02:58,186 --> 0:02:59,516
我还是想说

81
00:03:00,036 --> 0:03:00,966
与我们刚刚说到的相比

82
00:03:00,966 --> 0:03:02,536
还有更多的推理和训练

83
00:03:02,536 --> 0:03:03,956
所以如果你想要更多细节

84
00:03:04,296 --> 0:03:05,406
你可以看看我们过去几年的

85
00:03:05,406 --> 0:03:06,936
那些演讲

86
00:03:10,026 --> 0:03:11,256
现在 我们今年增加了

87
00:03:11,256 --> 0:03:12,256
几个新的功能

88
00:03:12,256 --> 0:03:13,456
以此来更好地支持

89
00:03:13,456 --> 0:03:14,636
广范围的推理和训练网络

90
00:03:15,556 --> 0:03:16,616
首先 通过支持你推理图表

91
00:03:16,616 --> 0:03:18,576
中的训练图表的隐式创建

92
00:03:18,576 --> 0:03:19,946
我们让你的网络的

93
00:03:19,946 --> 0:03:21,706
图表创建变得更加简单

94
00:03:22,206 --> 0:03:24,316
我们为可分离损耗层

95
00:03:24,316 --> 0:03:26,146
和随机数生成添加了内核

96
00:03:26,146 --> 0:03:28,426
以此来运行

97
00:03:28,426 --> 0:03:31,046
一系列的新网络

98
00:03:31,046 --> 0:03:33,366
我们为如预测和更好地控制 MPS 

99
00:03:33,366 --> 0:03:35,276
使其提升性能等

100
00:03:35,276 --> 0:03:37,276
增加了支持

101
00:03:37,826 --> 0:03:41,056
所以 让我们先从隐式图表创作开始吧

102
00:03:41,586 --> 0:03:44,866
通过隐式图表创作

103
00:03:44,866 --> 0:03:46,526
我们可以隐晦地从我们的推理图表中

104
00:03:46,526 --> 0:03:47,246
创建训练图表

105
00:03:48,466 --> 0:03:49,996
所以 我们先来复习一下

106
00:03:49,996 --> 0:03:52,266
如何为我们的网络创建一个图表

107
00:03:52,426 --> 0:03:54,306
这里我们有一个简单的推理网络

108
00:03:54,526 --> 0:03:55,836
它由一些卷积层组成

109
00:03:55,836 --> 0:03:58,756
一些池化层

110
00:03:58,756 --> 0:04:00,166
最后是一些完全相连的层

111
00:03:58,756 --> 0:04:00,166
最后是一些完全相连的层

112
00:04:00,726 --> 0:04:03,306
所以 我们会通过

113
00:04:03,306 --> 0:04:04,596
为每个层创建节点

114
00:04:04,596 --> 0:04:06,006
来为网络创建一个图表

115
00:04:06,006 --> 0:04:07,556
我们将为

116
00:04:07,556 --> 0:04:09,106
每个卷积层创建一个

117
00:04:09,106 --> 0:04:11,706
卷积节点

118
00:04:11,706 --> 0:04:12,716
每个池化层创建一个

119
00:04:12,716 --> 0:04:14,876
池化节点 然后为完全连接层

120
00:04:14,876 --> 0:04:17,106
创建一个完全连接节点

121
00:04:17,685 --> 0:04:20,315
随着我们的推理图表被定义

122
00:04:20,315 --> 0:04:21,976
我们可以将其拓展为训练图表

123
00:04:25,276 --> 0:04:26,556
我们首先在推理图表的末端

124
00:04:26,556 --> 0:04:28,186
增加一个损耗节点

125
00:04:28,186 --> 0:04:30,616
然后我们在正向节点

126
00:04:30,616 --> 0:04:31,676
增加梯度节点

127
00:04:31,676 --> 0:04:34,946
方向和我们的推理图表正好相反

128
00:04:35,506 --> 0:04:37,256
现在我们可以看看

129
00:04:37,256 --> 0:04:37,806
这个部分的代码

130
00:04:38,606 --> 0:04:39,886
正如之前所说

131
00:04:39,886 --> 0:04:43,306
我们开始先是增加损耗节点

132
00:04:43,306 --> 0:04:44,956
然后增加梯度节点

133
00:04:44,956 --> 0:04:46,546
顺序就和我们之前提到的一样

134
00:04:47,146 --> 0:04:49,996
所以我们可以看到

135
00:04:49,996 --> 0:04:51,876
每一个梯度节点

136
00:04:51,876 --> 0:04:53,676
都可以很容易地从前面的节点中创造出来

137
00:04:53,676 --> 0:04:55,406
但是如果通过隐式

138
00:04:55,406 --> 0:04:56,786
图表创造 这一切会更简单

139
00:04:58,896 --> 0:05:00,116
现在 你一旦通过损耗节点

140
00:04:58,896 --> 0:05:00,116
现在 你一旦通过损耗节点

141
00:05:00,116 --> 0:05:01,046
初始化你的梯度图像

142
00:05:01,046 --> 0:05:03,216
我们可以自动地

143
00:05:03,216 --> 0:05:04,616
创建与推理图表

144
00:05:04,656 --> 0:05:05,946
相匹配的训练图表

145
00:05:07,646 --> 0:05:09,276
和之前一样 我们创建了损耗节点

146
00:05:09,846 --> 0:05:12,526
通过一行代码

147
00:05:12,786 --> 0:05:14,546
我们可以创建我们的训练图表

148
00:05:14,546 --> 0:05:17,126
在这个例子中

149
00:05:17,126 --> 0:05:18,846
我们会从损耗节点创建训练图表

150
00:05:18,846 --> 0:05:19,896
我们将为我们的

151
00:05:19,896 --> 0:05:20,886
资源梯度使用 nil 参数

152
00:05:20,886 --> 0:05:23,226
这将会告知损耗节点

153
00:05:23,226 --> 0:05:24,626
使用其结果

154
00:05:24,626 --> 0:05:25,686
来初始化梯度

155
00:05:26,086 --> 0:05:27,306
但是如果我们想的话

156
00:05:27,306 --> 0:05:27,786
可以使用另一个图像

157
00:05:28,336 --> 0:05:31,736
我们为第二个参数提供零点

158
00:05:31,736 --> 0:05:32,886
这个叫作节点处理器

159
00:05:33,426 --> 0:05:34,476
节点处理器会让你提供一个块

160
00:05:34,476 --> 0:05:36,006
你可以用它来

161
00:05:36,006 --> 0:05:37,526
实施一些自定义的代码

162
00:05:38,036 --> 0:05:39,976
在你的节点创建之后来配置它们

163
00:05:43,766 --> 0:05:44,716
我还想要提到另一个有用的

164
00:05:44,716 --> 0:05:47,176
功能 那就是停止梯度属性

165
00:05:48,116 --> 0:05:49,766
所以 一般来说

166
00:05:49,766 --> 0:05:50,986
当你生成你的训练序列时

167
00:05:50,986 --> 0:05:53,346
你所有的可训练层都会更新它们的权重

168
00:05:54,696 --> 0:05:55,776
在这例子中

169
00:05:55,776 --> 0:05:58,026
这些是卷积和完全连接层

170
00:05:58,556 --> 0:06:00,106
但是在一些例子中

171
00:05:58,556 --> 0:06:00,106
但是在一些例子中

172
00:06:00,106 --> 0:06:01,276
你可能只想更新

173
00:06:01,276 --> 0:06:02,086
网络中某些层的权重

174
00:06:02,086 --> 0:06:04,746
比如说 在转换学习中

175
00:06:05,116 --> 0:06:06,606
现在 在转换学习中

176
00:06:06,606 --> 0:06:07,686
我们将要对很多层

177
00:06:07,686 --> 0:06:09,036
使用事先训练好的权重

178
00:06:09,036 --> 0:06:09,896
我们只想训练

179
00:06:09,896 --> 0:06:10,876
某些层的权重

180
00:06:11,266 --> 0:06:13,666
比如说 最终完全连接层

181
00:06:15,576 --> 0:06:17,016
隐式图表创作同样支持

182
00:06:17,016 --> 0:06:18,266
通过停止梯度属性

183
00:06:18,266 --> 0:06:20,556
为这些网络类型创作图表

184
00:06:21,166 --> 0:06:24,176
所以 为了实现这个

185
00:06:24,176 --> 0:06:25,396
我们应该首先

186
00:06:25,396 --> 0:06:26,856
在那些我们想要更新权重的第一层

187
00:06:27,066 --> 0:06:28,986
设置停止梯度属性

188
00:06:29,956 --> 0:06:30,956
在这个例子中 

189
00:06:30,956 --> 0:06:31,526
就是完全连接层

190
00:06:32,056 --> 0:06:35,156
当图表生成时

191
00:06:35,156 --> 0:06:37,066
后来的梯度节点

192
00:06:37,066 --> 0:06:39,306
都不会被创建

193
00:06:39,886 --> 0:06:42,906
所以正如你们所见

194
00:06:42,906 --> 0:06:44,576
使用隐式图表创作

195
00:06:44,576 --> 0:06:46,726
是一个从你的推理图表

196
00:06:46,726 --> 0:06:47,666
生成训练图表的

197
00:06:47,666 --> 0:06:48,366
非常简单的方法

198
00:06:52,236 --> 0:06:53,496
让我们来看一个

199
00:06:53,496 --> 0:06:55,836
我们增加的用来支持新的网络的功能

200
00:06:56,576 --> 0:06:57,926
可分离损耗内核

201
00:06:59,676 --> 0:07:01,726
所以 早些时候 我们看到了

202
00:06:59,676 --> 0:07:01,726
所以 早些时候 我们看到了

203
00:07:01,726 --> 0:07:04,836
如何使用损耗节点来使用

204
00:07:04,836 --> 0:07:05,276
MPS CNN 损耗

205
00:07:06,316 --> 0:07:07,966
MPS CNN 损耗消耗一个最终图像

206
00:07:07,966 --> 0:07:09,006
这通常都是如 Softmax 层

207
00:07:09,006 --> 0:07:10,456
和 Truth 数据

208
00:07:10,456 --> 0:07:12,116
为了计算梯度数值

209
00:07:12,116 --> 0:07:15,786
以开始反向传播过程的结果

210
00:07:16,476 --> 0:07:18,206
但是还有一些为了

211
00:07:18,206 --> 0:07:19,956
产生一个最终损耗

212
00:07:19,956 --> 0:07:22,456
而使用多重中间损耗数值的网络

213
00:07:22,926 --> 0:07:24,936
为了支持这个

214
00:07:24,986 --> 0:07:26,526
我们增加了分别的正向和

215
00:07:26,526 --> 0:07:27,186
梯度损耗内核

216
00:07:27,656 --> 0:07:29,256
所以 在这里

217
00:07:29,256 --> 0:07:31,256
我们使用了利用正向损耗节点

218
00:07:31,336 --> 0:07:33,506
进行运算的两个损耗数值

219
00:07:33,506 --> 0:07:34,746
然后我们得到了这些结果

220
00:07:34,746 --> 0:07:37,396
将它们加在一起来产生一个最终损耗

221
00:07:38,016 --> 0:07:41,236
现在 我们需要初始化

222
00:07:41,236 --> 0:07:43,286
梯度值来开始反向过程

223
00:07:44,926 --> 0:07:46,446
在它通过损耗节点

224
00:07:46,446 --> 0:07:47,566
隐式发生前

225
00:07:47,566 --> 0:07:49,066
我们需要增加一个初始的梯度内核

226
00:07:49,536 --> 0:07:51,126
这将会生成

227
00:07:51,126 --> 0:07:52,516
一个梯度图像

228
00:07:52,516 --> 0:07:53,716
它将会变成

229
00:07:53,716 --> 0:07:54,996
最终损耗计算的结果权重

230
00:07:55,606 --> 0:07:57,896
所以 随着梯度数值的初始化

231
00:07:57,896 --> 0:07:59,266
我们可以启动

232
00:07:59,266 --> 0:08:00,386
反向过程

233
00:07:59,266 --> 0:08:00,386
反向过程

234
00:08:00,686 --> 0:08:01,706
我们将会为

235
00:08:01,706 --> 0:08:02,736
我们拥有附加梯度的

236
00:08:02,736 --> 0:08:03,806
正向内核使用梯度内核

237
00:08:03,806 --> 0:08:06,586
也为正向损耗内核使用梯度

238
00:08:06,586 --> 0:08:09,706
现在 让我们看看

239
00:08:09,706 --> 0:08:12,726
使用可分离损耗的网络

240
00:08:13,266 --> 0:08:14,196
特别地 我们将看一下

241
00:08:14,196 --> 0:08:15,336
风格转换

242
00:08:15,926 --> 0:08:18,766
风格转换网络

243
00:08:18,766 --> 0:08:20,256
产生了融合

244
00:08:20,256 --> 0:08:23,176
风格和原始图像的图像

245
00:08:24,716 --> 0:08:26,286
我们会看到的模型

246
00:08:26,286 --> 0:08:27,276
是你可以找到并重新创作的

247
00:08:27,276 --> 0:08:28,646
它可以使用 MPS

248
00:08:28,646 --> 0:08:29,986
来实施

249
00:08:31,086 --> 0:08:32,466
在推理中 这个网络

250
00:08:32,466 --> 0:08:34,176
由转换节点构成

251
00:08:34,176 --> 0:08:35,405
如卷积和

252
00:08:35,405 --> 0:08:36,556
实例规范化层

253
00:08:36,556 --> 0:08:38,135
它们的权重构成了

254
00:08:38,135 --> 0:08:40,015
训练的参数

255
00:08:40,775 --> 0:08:42,566
这就是嵌入风格的地方

256
00:08:43,126 --> 0:08:44,766
它通过训练过程

257
00:08:44,866 --> 0:08:45,876
学习到参数内

258
00:08:46,716 --> 0:08:48,596
所以让我们来看看如何训练

259
00:08:49,186 --> 0:08:51,706
现在我们有一个关于网络的概览

260
00:08:53,546 --> 0:08:55,126
作为推理

261
00:08:55,126 --> 0:08:56,306
我们将应用转换器

262
00:08:56,926 --> 0:08:58,496
来生成一个风格化的图像

263
00:08:59,186 --> 0:09:00,216
现在 在这个例子中

264
00:08:59,186 --> 0:09:00,216
现在 在这个例子中

265
00:09:00,216 --> 0:09:02,136
它将是网络目前

266
00:09:02,356 --> 0:09:04,516
关于最好的风格图像的猜测

267
00:09:04,516 --> 0:09:05,956
它结合了风格和内容

268
00:09:06,686 --> 0:09:08,726
因为网络的目标是

269
00:09:08,726 --> 0:09:10,286
匹配期望的风格

270
00:09:10,286 --> 0:09:11,726
和原始图像的内容

271
00:09:11,726 --> 0:09:12,846
我们将需要

272
00:09:12,846 --> 0:09:13,996
两个损耗数值

273
00:09:14,486 --> 0:09:18,116
所以 第一个损耗数值

274
00:09:18,116 --> 0:09:20,166
是由我们称之为风格损耗网络的数据网络

275
00:09:20,166 --> 0:09:21,096
进行计算的

276
00:09:22,316 --> 0:09:23,326
这个损耗数值

277
00:09:23,326 --> 0:09:25,756
将会保证网络收敛在一个结果上

278
00:09:25,756 --> 0:09:27,706
而这个结果会与我们期望的风格很匹配

279
00:09:28,316 --> 0:09:29,666
我们还想要保证

280
00:09:29,666 --> 0:09:32,036
生成的图像还能保持

281
00:09:32,776 --> 0:09:34,366
原始图像的特征

282
00:09:34,496 --> 0:09:35,346
所以 我们要对此

283
00:09:35,346 --> 0:09:36,236
使用第二个损耗网络

284
00:09:36,626 --> 0:09:37,846
那就是内容损耗

285
00:09:38,336 --> 0:09:41,896
我们可以为每个损耗计算

286
00:09:46,416 --> 0:09:48,716
但是让我们更仔细地看看

287
00:09:48,716 --> 0:09:49,766
风格损耗网络

288
00:09:50,786 --> 0:09:51,926
为了计算

289
00:09:51,926 --> 0:09:53,676
风格损耗 我们需要一个

290
00:09:53,916 --> 0:09:55,586
测量图像风格的方法

291
00:09:56,236 --> 0:09:57,086
为了实现这个

292
00:09:57,086 --> 0:09:58,306
我们需要为几个

293
00:09:58,306 --> 0:09:59,936
代表这个图像的中间特征

294
00:09:59,936 --> 0:10:00,976
计算我们所称的格兰姆矩阵

295
00:09:59,936 --> 0:10:00,976
计算我们所称的格兰姆矩阵

296
00:10:01,116 --> 0:10:04,766
今年 格兰姆矩阵计算

297
00:10:04,766 --> 0:10:05,946
在 MPS 中

298
00:10:05,946 --> 0:10:07,596
由正向和梯度内核

299
00:10:07,596 --> 0:10:08,996
本机支持

300
00:10:09,606 --> 0:10:11,476
所以 让我们迅速来看一下 

301
00:10:11,656 --> 0:10:12,686
格兰姆矩阵以及

302
00:10:12,686 --> 0:10:13,116
它是如何运算的

303
00:10:13,666 --> 0:10:15,286
格兰姆矩阵代表了

304
00:10:15,286 --> 0:10:16,626
特征向量间的

305
00:10:16,716 --> 0:10:17,856
非居中的关联

306
00:10:18,396 --> 0:10:20,296
现在 每个特征向量

307
00:10:20,296 --> 0:10:21,296
都是从空间扁平化一个单一的特征通道中的

308
00:10:21,296 --> 0:10:23,926
一个单一的图像所获得的结果

309
00:10:24,536 --> 0:10:26,926
为了创作一个格兰姆矩阵

310
00:10:26,926 --> 0:10:29,146
我们在特征向量间计算点积

311
00:10:29,916 --> 0:10:31,216
我们来看看这是如何使用的

312
00:10:32,036 --> 0:10:34,586
在我们得到格兰姆矩阵前

313
00:10:34,586 --> 0:10:35,906
我们将使用 VGG

314
00:10:35,906 --> 0:10:37,466
图像分类网络

315
00:10:37,466 --> 0:10:38,986
来从我们的风格和

316
00:10:38,986 --> 0:10:41,366
风格化的输入图像来提取特征

317
00:10:41,366 --> 0:10:43,896
现在 正如我们之前描述的

318
00:10:43,896 --> 0:10:45,106
格兰姆矩阵

319
00:10:45,106 --> 0:10:46,526
给了我们特征向量之间的关联

320
00:10:47,586 --> 0:10:48,906
现在 当我们采用这些

321
00:10:48,906 --> 0:10:49,986
从风格提取的特征

322
00:10:49,986 --> 0:10:52,776
这为我们想要应用的

323
00:10:52,776 --> 0:10:54,376
风格提供了真值

324
00:10:54,376 --> 0:10:56,216
我们还要为

325
00:10:56,216 --> 0:10:57,946
关于最好的风格图像的

326
00:10:57,946 --> 0:11:00,496
现存猜测做同样的事情

327
00:10:57,946 --> 0:11:00,496
现存猜测做同样的事情

328
00:11:01,506 --> 0:11:02,706
现在 我们用这两个数值一起

329
00:11:02,706 --> 0:11:06,306
来形成我们的风格损耗

330
00:11:08,916 --> 0:11:10,196
所以 现在让我们看看

331
00:11:10,196 --> 0:11:11,216
我们如何计算两个损耗中的第二个

332
00:11:11,216 --> 0:11:12,746
内容损耗

333
00:11:13,306 --> 0:11:15,326
和之前一样

334
00:11:15,326 --> 0:11:17,576
我们将使用 VGG 提取特征

335
00:11:17,686 --> 0:11:19,026
然后使用这些特征计算损耗

336
00:11:19,026 --> 0:11:21,426
以及我们风格化的图像的特征

337
00:11:22,396 --> 0:11:23,556
网络的最终损耗

338
00:11:23,556 --> 0:11:25,386
将是内容损耗和

339
00:11:25,386 --> 0:11:27,066
风格损耗的总和

340
00:11:28,206 --> 0:11:29,256
所以 现在让我们看看

341
00:11:29,256 --> 0:11:30,966
我们如何使用 MPS 来计算这些数值

342
00:11:30,966 --> 0:11:32,046
和初始化梯度

343
00:11:32,606 --> 0:11:36,086
首先 让我们假设

344
00:11:36,086 --> 0:11:37,426
我们有特征代表

345
00:11:37,426 --> 0:11:38,326
由 VGG 生成

346
00:11:39,306 --> 0:11:40,326
首先 我们要为了

347
00:11:40,326 --> 0:11:42,876
风格和风格化图像

348
00:11:42,946 --> 0:11:44,266
增加格兰姆矩阵计算节点

349
00:11:44,266 --> 0:11:46,376
来计算格兰姆矩阵

350
00:11:49,546 --> 0:11:50,526
我们将把这些结果

351
00:11:50,526 --> 0:11:52,206
注入正向损耗节点

352
00:11:52,806 --> 0:11:54,626
以此来计算我们风格的损耗

353
00:11:55,886 --> 0:11:57,536
这里的源图像是格兰姆矩阵

354
00:11:57,536 --> 0:11:58,626
对我们的网络风格化的图像的

355
00:11:58,626 --> 0:12:00,756
计算结果

356
00:11:58,626 --> 0:12:00,756
计算结果

357
00:12:03,416 --> 0:12:04,646
对于引用风格图像的

358
00:12:04,646 --> 0:12:06,566
格兰姆矩阵

359
00:12:06,566 --> 0:12:07,926
将会用在标签参数中

360
00:12:09,256 --> 0:12:10,126
现在它展示了一个

361
00:12:10,126 --> 0:12:12,096
新的正向损耗内核的重要特征

362
00:12:12,356 --> 0:12:13,656
之前 你必须使用 MPS 状态对象

363
00:12:13,656 --> 0:12:15,276
来传递聚类

364
00:12:15,826 --> 0:12:20,866
但是现在 你可以使用 MPS 图像

365
00:12:21,036 --> 0:12:22,256
现在我们可以使用

366
00:12:22,256 --> 0:12:23,996
风格化的图像和原始图像

367
00:12:24,036 --> 0:12:25,206
来为内容损耗

368
00:12:25,206 --> 0:12:27,326
增加损耗节点

369
00:12:27,326 --> 0:12:28,816
我们可以将其相结合

370
00:12:28,816 --> 0:12:29,686
来获得我们总共的损耗数值

371
00:12:30,276 --> 0:12:32,466
现在我们需要初始化

372
00:12:32,466 --> 0:12:34,066
最终的损耗梯度

373
00:12:34,066 --> 0:12:35,246
来启动反向过程

374
00:12:36,636 --> 0:12:38,256
我们使用

375
00:12:38,256 --> 0:12:39,506
之前提到过的初始化梯度节点

376
00:12:43,236 --> 0:12:44,316
我们之前已经看到了

377
00:12:44,316 --> 0:12:46,316
损耗节点的结果是

378
00:12:46,316 --> 0:12:47,956
如何用来隐式生成训练图表的

379
00:12:48,276 --> 0:12:49,826
这是因为它生成了

380
00:12:49,826 --> 0:12:50,496
初始的梯度

381
00:12:51,266 --> 0:12:52,856
但是现在 正如我之前提到的

382
00:12:52,856 --> 0:12:54,976
通过可分离损耗内核

383
00:12:54,976 --> 0:12:56,326
我们可以使用初始梯度节点

384
00:12:56,326 --> 0:12:57,216
来明确地完成这个

385
00:12:57,586 --> 0:12:58,696
所以 这就是

386
00:12:58,696 --> 0:12:59,976
我们用来生成训练图表的节点

387
00:13:02,536 --> 0:13:03,586
随着图表的生成

388
00:13:03,966 --> 0:13:05,626
我们可以看看

389
00:13:05,626 --> 0:13:07,156
这个网络在活动中做什么

390
00:13:10,836 --> 0:13:12,236
所以 我们可以看到

391
00:13:12,236 --> 0:13:13,876
在 GPU 上运行的使用 MPS 的

392
00:13:13,876 --> 0:13:14,766
风格转换网络

393
00:13:14,766 --> 0:13:17,106
它在拥有 AMD Radeon pro 560

394
00:13:17,176 --> 0:13:20,266
图表卡的 Mac Book Pro 上运行

395
00:13:20,866 --> 0:13:22,986
这个展示了

396
00:13:22,986 --> 0:13:24,336
风格转换训练在运行过程中

397
00:13:24,336 --> 0:13:26,106
在每个迭代的结果

398
00:13:26,576 --> 0:13:28,866
正如你所见

399
00:13:28,866 --> 0:13:30,996
风格在日益增多地被运用

400
00:13:30,996 --> 0:13:31,916
但是图像的内容

401
00:13:31,916 --> 0:13:32,506
却被保留了

402
00:13:32,506 --> 0:13:34,156
我还想提到的是

403
00:13:34,156 --> 0:13:35,746
这些迭代在这个视频中

404
00:13:35,746 --> 0:13:37,776
被加速了

405
00:13:37,776 --> 0:13:38,906
以此来更好地展示

406
00:13:38,906 --> 0:13:40,976
训练网络的进程

407
00:13:47,266 --> 0:13:49,576
所以现在我要看一看

408
00:13:49,576 --> 0:13:50,566
我们今年增加的另一个功能

409
00:13:50,566 --> 0:13:52,146
随机数生成

410
00:13:54,596 --> 0:13:56,016
今年 我们为 MPS 中的

411
00:13:56,016 --> 0:13:57,026
两种随机数生成

412
00:13:57,026 --> 0:13:58,116
增加了支持

413
00:13:58,816 --> 0:13:59,586
我们有一个名为 MTGP32 的

414
00:13:59,586 --> 0:14:01,656
梅森旋转算法的变量

415
00:13:59,586 --> 0:14:01,656
梅森旋转算法的变量

416
00:14:01,656 --> 0:14:03,806
以及一个名为 Philox 的

417
00:14:03,806 --> 0:14:04,416
基于计数的生成器

418
00:14:05,596 --> 0:14:06,676
这些生成器之所以被选择

419
00:14:06,676 --> 0:14:07,806
是因为它们的算法

420
00:14:07,806 --> 0:14:08,706
很适合 GPU 体系结构

421
00:14:08,706 --> 0:14:10,086
它们也会提供

422
00:14:10,086 --> 0:14:12,046
拥有很好的统计属性的

423
00:14:12,046 --> 0:14:13,896
随机数的序列

424
00:14:14,316 --> 0:14:16,566
现在 你们可以使用这些内核

425
00:14:16,566 --> 0:14:18,126
来生成大的使用

426
00:14:18,126 --> 0:14:21,056
缓冲和 GPU 内存的随机数序列

427
00:14:21,626 --> 0:14:22,606
既然在 GPU 内存上

428
00:14:22,606 --> 0:14:24,496
这个结果可用

429
00:14:24,496 --> 0:14:25,476
你可以避免同步大的

430
00:14:25,476 --> 0:14:26,766
射线和 CPU 的数字

431
00:14:27,796 --> 0:14:29,176
生成像这样的随机数

432
00:14:29,696 --> 0:14:30,576
对于机器学习 App

433
00:14:30,576 --> 0:14:32,056
非常重要

434
00:14:32,756 --> 0:14:33,986
它们被要求

435
00:14:33,986 --> 0:14:35,536
比如说 初始化

436
00:14:35,536 --> 0:14:37,636
你用于训练的网络的权重

437
00:14:37,636 --> 0:14:39,376
同时也在训练生成

438
00:14:39,376 --> 0:14:40,836
对抗的网络 或简称为 GAN

439
00:14:40,836 --> 0:14:41,946
创建输入

440
00:14:43,076 --> 0:14:44,016
GAN 是随机数生成器

441
00:14:44,016 --> 0:14:46,366
的一个非常重要的使用例子

442
00:14:46,636 --> 0:14:47,626
你需要在你的训练的

443
00:14:47,626 --> 0:14:50,016
每个迭代

444
00:14:50,016 --> 0:14:50,336
生成随机输入

445
00:14:50,956 --> 0:14:53,576
如果你要从 CPU

446
00:14:53,576 --> 0:14:55,026
同步一个阵列的数字

447
00:14:55,456 --> 0:14:57,186
每一个迭代

448
00:14:57,186 --> 0:14:58,196
都可以训练你的网络

449
00:14:58,236 --> 0:14:59,216
过分昂贵

450
00:15:00,636 --> 0:15:01,946
所以 让我们进一步看看

451
00:15:01,946 --> 0:15:03,206
这些网络和

452
00:15:03,206 --> 0:15:04,346
我们如何使用新的

453
00:15:04,346 --> 0:15:04,866
随机数生成器

454
00:15:07,016 --> 0:15:09,436
生成对抗网络或 GAN

455
00:15:09,436 --> 0:15:10,666
一般都在

456
00:15:10,666 --> 0:15:11,566
两个网络中构建

457
00:15:11,566 --> 0:15:12,706
我们有一个生成器网络

458
00:15:12,706 --> 0:15:13,756
和一个鉴别器网络

459
00:15:14,726 --> 0:15:15,576
我们这里有一个生成器的例子

460
00:15:15,576 --> 0:15:17,416
它只会生成

461
00:15:17,416 --> 0:15:18,526
手写数字的图像

462
00:15:19,106 --> 0:15:21,506
和训练中的

463
00:15:21,506 --> 0:15:22,766
图像分类相似

464
00:15:22,766 --> 0:15:25,876
我们将会提供有手写数字的很多例子的网络

465
00:15:25,876 --> 0:15:27,046
然而 网络并没有试着对它们分类

466
00:15:27,046 --> 0:15:29,236
而是试着从

467
00:15:29,236 --> 0:15:31,296
从随机初始数据集

468
00:15:31,296 --> 0:15:34,676
生成新的图像 以此与训练集

469
00:15:34,676 --> 0:15:35,216
看起来相似

470
00:15:35,746 --> 0:15:39,326
为了执行

471
00:15:39,326 --> 0:15:41,886
训练过程 我们需要

472
00:15:41,886 --> 0:15:43,836
一些决定这些图像

473
00:15:44,236 --> 0:15:45,046
将如何相似的方法

474
00:15:45,626 --> 0:15:46,676
所以 针对这第二个网络

475
00:15:46,806 --> 0:15:48,016
我们将使用

476
00:15:48,016 --> 0:15:48,726
我们称之为鉴别器的东西

477
00:15:50,576 --> 0:15:52,356
正如这个名字所展示的

478
00:15:52,356 --> 0:15:54,426
它将用来鉴别

479
00:15:54,426 --> 0:15:57,056
训练图像和那些

480
00:15:57,056 --> 0:15:58,486
由生成器模拟的图像

481
00:15:59,206 --> 0:16:00,406
在这个例子中

482
00:15:59,206 --> 0:16:00,406
在这个例子中

483
00:16:00,406 --> 0:16:01,416
它表现为图像分类网络

484
00:16:01,416 --> 0:16:02,726
但是只有两个可能性

485
00:16:03,426 --> 0:16:05,496
输入要么是从训练集中的真实的图像

486
00:16:05,496 --> 0:16:06,596
或者它可能是生成的

487
00:16:06,596 --> 0:16:08,016
是一个假图像

488
00:16:08,326 --> 0:16:10,596
所以你们可以看到

489
00:16:10,596 --> 0:16:11,996
这就是鉴别器

490
00:16:11,996 --> 0:16:13,966
正在查询数字

491
00:16:13,966 --> 0:16:15,606
是真还是假

492
00:16:17,946 --> 0:16:19,066
现在 典型的生成器和鉴别器

493
00:16:19,066 --> 0:16:20,916
都是一起训练的

494
00:16:21,646 --> 0:16:23,206
我们训练生成器

495
00:16:23,206 --> 0:16:24,586
来产生更多真实的图像

496
00:16:25,066 --> 0:16:25,626
我们训练鉴别器

497
00:16:25,626 --> 0:16:27,976
来更好地分辨合成的图像

498
00:16:28,186 --> 0:16:29,136
与训练图像

499
00:16:29,876 --> 0:16:31,466
所以 我们这里有一个

500
00:16:31,466 --> 0:16:32,626
针对你的训练网络的

501
00:16:32,626 --> 0:16:33,786
节点的高层次的概览

502
00:16:34,416 --> 0:16:35,706
这就是我们的鉴别器训练

503
00:16:35,706 --> 0:16:36,766
训练网络

504
00:16:37,656 --> 0:16:39,426
它由两个损耗计算组成

505
00:16:39,536 --> 0:16:40,486
所以 我们刚刚谈到的

506
00:16:40,486 --> 0:16:41,626
是关于你在哪里能使用

507
00:16:41,626 --> 0:16:42,486
可分离损耗节点的例子

508
00:16:43,636 --> 0:16:46,176
我们还有一个损耗

509
00:16:46,176 --> 0:16:47,766
通过它我们试图保证

510
00:16:47,766 --> 0:16:48,756
鉴别器正确地

511
00:16:48,756 --> 0:16:50,656
将模拟图像分类为假

512
00:16:50,656 --> 0:16:52,816
我们还有第二个损耗

513
00:16:52,816 --> 0:16:55,356
通过它我们可以训练

514
00:16:55,356 --> 0:16:56,596
鉴别器将从训练集中的真实图像

515
00:16:56,596 --> 0:16:58,546
分类为真

516
00:16:59,086 --> 0:17:02,696
计算完这些分离损耗数值后

517
00:16:59,086 --> 0:17:02,696
计算完这些分离损耗数值后

518
00:17:02,696 --> 0:17:04,346
我们可以使用

519
00:17:04,346 --> 0:17:06,306
一个初始化梯度节点

520
00:17:06,306 --> 0:17:07,256
来初始化你的训练图表

521
00:17:07,866 --> 0:17:10,906
第二 我们在这里有

522
00:17:10,906 --> 0:17:11,856
生成器训练网络

523
00:17:12,516 --> 0:17:13,596
这个稍微简单一点

524
00:17:13,596 --> 0:17:14,856
它只有一个损耗数值

525
00:17:15,756 --> 0:17:18,496
但是在这个例子中

526
00:17:18,496 --> 0:17:20,026
我们使用一个真实的聚类数值

527
00:17:20,026 --> 0:17:21,886
来保证我们的生成器可以生成

528
00:17:21,886 --> 0:17:22,715
鉴别器随后会分类为

529
00:17:22,715 --> 0:17:23,965
真的图像

530
00:17:24,856 --> 0:17:26,016
正如我之前提到的

531
00:17:26,016 --> 0:17:27,076
生成器网络开始时伴随着

532
00:17:27,076 --> 0:17:28,926
一套随机的数据

533
00:17:28,926 --> 0:17:29,806
我们将会使用随机数生成器

534
00:17:29,806 --> 0:17:30,596
来生成这些数

535
00:17:31,256 --> 0:17:32,476
所以 让我们仔细看看

536
00:17:33,196 --> 0:17:34,246
随机数字生成器

537
00:17:34,826 --> 0:17:37,206
现在 随机数生成器内核

538
00:17:37,206 --> 0:17:39,446
属于 MPSMatrix 副框架

539
00:17:39,446 --> 0:17:41,196
它们通过

540
00:17:41,196 --> 0:17:42,506
MPSMatrix 随机类

541
00:17:42,506 --> 0:17:43,866
被接入

542
00:17:44,806 --> 0:17:46,206
所以它们在 MPSMatrix

543
00:17:46,206 --> 0:17:47,356
和 MPSVector 对象上运转

544
00:17:47,356 --> 0:17:48,226
这意味着它们与

545
00:17:48,226 --> 0:17:51,096
metal 缓冲器一起运行

546
00:17:51,096 --> 0:17:53,476
它们也与潜在的生成器一起

547
00:17:53,476 --> 0:17:54,576
支持生成随机整数

548
00:17:54,576 --> 0:17:55,566
或者你可以使用一个

549
00:17:55,566 --> 0:17:57,126
统一的分布来生成浮点值

550
00:17:57,726 --> 0:17:59,996
在这里 我们将为数值在 0 和 1 之间的

551
00:17:59,996 --> 0:18:01,706
统一分配

552
00:17:59,996 --> 0:18:01,706
统一分配

553
00:18:01,706 --> 0:18:04,676
创建一个分配描述符

554
00:18:05,226 --> 0:18:07,896
然后我们将创建我们的生成器

555
00:18:07,896 --> 0:18:12,246
测试合适的数据类型 

556
00:18:12,246 --> 0:18:13,006
然后给它一个初始种子

557
00:18:15,976 --> 0:18:17,366
最后 我们为了保存结果

558
00:18:17,366 --> 0:18:19,276
创建了一个矩阵

559
00:18:19,276 --> 0:18:21,496
我们将运算编码至指令缓冲

560
00:18:21,496 --> 0:18:23,426
所以 现在让我们回到网络

561
00:18:23,426 --> 0:18:25,106
然后看看我们如何使用它

562
00:18:25,756 --> 0:18:27,226
这是生成器网络的

563
00:18:27,226 --> 0:18:27,926
更进一步的视图

564
00:18:27,926 --> 0:18:30,246
我们有一些卷积层

565
00:18:30,466 --> 0:18:31,786
一些 ReLu 层

566
00:18:31,786 --> 0:18:33,026
双曲正切神经元

567
00:18:33,646 --> 0:18:36,256
现在 输入图像将

568
00:18:36,256 --> 0:18:37,706
成为我们随机数生成器的结果

569
00:18:39,046 --> 0:18:40,046
正如我们之前看的

570
00:18:40,046 --> 0:18:41,266
随机数生成器

571
00:18:41,266 --> 0:18:43,406
与矩阵一起运行 但是图表

572
00:18:43,406 --> 0:18:44,416
和所有神经网络内核

573
00:18:44,416 --> 0:18:45,216
都需要图像

574
00:18:45,576 --> 0:18:47,186
所以 我们将使用我们的

575
00:18:47,186 --> 0:18:48,646
MPS 复制内核

576
00:18:49,106 --> 0:18:50,926
来将矩阵上的数据复制至一个图像上

577
00:18:53,436 --> 0:18:54,676
所以 首先我们要创建一个矩阵

578
00:18:54,676 --> 0:18:55,836
来保存我们的随机数值

579
00:18:57,576 --> 0:18:58,996
然后我们会创建一个图像

580
00:18:58,996 --> 0:19:00,606
它将会作为我们网络的输入

581
00:18:58,996 --> 0:19:00,606
它将会作为我们网络的输入

582
00:19:04,616 --> 0:19:05,766
我们将初始化一个

583
00:19:05,766 --> 0:19:07,706
复制内核来运行这个复制

584
00:19:09,246 --> 0:19:10,946
然后我们将编码我们的

585
00:19:10,946 --> 0:19:12,436
随机数字生成器

586
00:19:12,436 --> 0:19:13,386
来生成数值

587
00:19:13,386 --> 0:19:14,446
我们将会编码复制

588
00:19:14,726 --> 0:19:16,556
把它们复制成图像

589
00:19:16,556 --> 0:19:19,556
然后我们会使用图像

590
00:19:20,146 --> 0:19:21,226
编码网络

591
00:19:21,826 --> 0:19:25,376
现在 想要获得关于这个网络

592
00:19:25,376 --> 0:19:27,246
和使用 MPSMatrix 随机数生成器内核

593
00:19:27,246 --> 0:19:28,426
的更多细节

594
00:19:28,426 --> 0:19:30,766
请查看我们网上的文档

595
00:19:30,766 --> 0:19:31,796
这里还有一些代码样例

596
00:19:36,046 --> 0:19:36,766
现在我们增加了一些特征

597
00:19:36,766 --> 0:19:38,296
来帮助提升使用 MPS 的

598
00:19:38,296 --> 0:19:40,336
网络性能和效率

599
00:19:41,136 --> 0:19:42,006
所以 让我们来看看

600
00:19:42,006 --> 0:19:43,396
它们中的一个 预测

601
00:19:43,966 --> 0:19:46,176
通过预测 你可以

602
00:19:46,216 --> 0:19:47,966
有条件地实行 MPS 内核

603
00:19:48,836 --> 0:19:50,376
内核的实施

604
00:19:50,416 --> 0:19:52,196
在存在于 GPU 内存的

605
00:19:52,196 --> 0:19:53,736
数值上被预测

606
00:19:53,736 --> 0:19:54,976
它们在内核实施的时候被引用

607
00:19:58,226 --> 0:19:58,966
所以 让我们看一眼网络

608
00:19:58,966 --> 0:20:01,026
它说明了这个是如何使用的

609
00:19:58,966 --> 0:20:01,026
它说明了这个是如何使用的

610
00:20:01,846 --> 0:20:02,876
这是一个图片说明

611
00:20:03,256 --> 0:20:04,526
这是我们几年前

612
00:20:04,526 --> 0:20:06,336
展示的一个网络

613
00:20:06,336 --> 0:20:07,556
它会使用卷积神经网络

614
00:20:07,556 --> 0:20:08,756
和常返的神经网络

615
00:20:08,756 --> 0:20:11,186
来生成图片说明

616
00:20:13,116 --> 0:20:14,496
卷积网络是

617
00:20:14,496 --> 0:20:15,596
普通的分类网络

618
00:20:15,596 --> 0:20:16,976
在这个例子中 我们会使用 Inception V3

619
00:20:16,976 --> 0:20:18,946
它将会用来从

620
00:20:18,946 --> 0:20:20,136
源图像提取特征

621
00:20:20,666 --> 0:20:23,286
然后我们使用这些特征示意图

622
00:20:23,456 --> 0:20:24,686
我们把它们注入一个

623
00:20:24,686 --> 0:20:26,136
小的以 LSTM 为基础的网络

624
00:20:26,136 --> 0:20:27,226
在那里图片说明从提取的

625
00:20:27,226 --> 0:20:28,196
特征中生成

626
00:20:28,926 --> 0:20:30,026
现在 我们迭代这个网络

627
00:20:30,026 --> 0:20:31,586
来生成图片说明

628
00:20:32,216 --> 0:20:35,856
在这个例子中 我们需要知道

629
00:20:36,646 --> 0:20:38,206
在这个例子中 我们需要

630
00:20:38,206 --> 0:20:39,696
运行以 LSTM 为基础的网络

631
00:20:39,696 --> 0:20:41,486
以获得一些迭代

632
00:20:41,486 --> 0:20:42,676
它将会被修复

633
00:20:42,676 --> 0:20:43,836
我们至少需要一直这样做

634
00:20:43,836 --> 0:20:44,986
直到我们相信这样

635
00:20:44,986 --> 0:20:46,676
可以生成图片说明

636
00:20:47,926 --> 0:20:48,936
在这个例子中 比如说

637
00:20:48,936 --> 0:20:50,566
我们运行 20 次

638
00:20:50,566 --> 0:20:51,046
以 LSTM 为基础的网络

639
00:20:51,586 --> 0:20:53,956
每个迭代通过

640
00:20:53,956 --> 0:20:55,416
在之前的迭代中

641
00:20:55,416 --> 0:20:56,776
为图片说明增加一个新的词

642
00:20:56,776 --> 0:20:57,516
来计算出最好的图片说明

643
00:20:58,046 --> 0:21:00,546
但如果图片说明只要求

644
00:20:58,046 --> 0:21:00,546
但如果图片说明只要求

645
00:21:00,546 --> 0:21:02,896
五个词 那我们需要

646
00:21:02,896 --> 0:21:04,236
运行超过

647
00:21:04,236 --> 0:21:05,326
我们需要的迭代

648
00:21:06,356 --> 0:21:08,906
通过预测 我们可以早点

649
00:21:08,906 --> 0:21:09,656
结束这个执行

650
00:21:09,956 --> 0:21:12,466
在这个例子中 就是在五个单词的图片说明生成之后

651
00:21:13,466 --> 0:21:14,716
所以 让我们看看

652
00:21:14,716 --> 0:21:15,466
如何在 MPS 中使用它

653
00:21:16,206 --> 0:21:17,406
为了实现它 我们首先需要

654
00:21:17,406 --> 0:21:19,476
讨论我们是如何为 MPS 命令

655
00:21:19,476 --> 0:21:22,826
提供预测数值的

656
00:21:22,826 --> 0:21:24,356
针对这个 我们引入了

657
00:21:24,356 --> 0:21:25,236
MPSCommandBuffer

658
00:21:25,776 --> 0:21:29,536
现在 MPSCommandBuffer 

659
00:21:29,536 --> 0:21:30,216
是一个遵循 MTLCommandBuffer 协议的类

660
00:21:30,216 --> 0:21:31,426
但是它增加了

661
00:21:31,426 --> 0:21:32,836
更多一点的弹性

662
00:21:33,656 --> 0:21:34,546
它可以在任何

663
00:21:34,546 --> 0:21:36,506
你正在使用 metal 命令缓冲的地方被使用

664
00:21:36,506 --> 0:21:37,926
正如一个 MTLCommandBuffer

665
00:21:37,926 --> 0:21:39,216
它由 MTLCommandQueue 构建而成

666
00:21:39,216 --> 0:21:42,036
现在 它提供了好几个重要的好处

667
00:21:42,696 --> 0:21:43,776
它允许你预测

668
00:21:43,776 --> 0:21:46,146
MPS 内核的实施

669
00:21:46,146 --> 0:21:47,296
我们之后也会讨论到

670
00:21:47,296 --> 0:21:48,446
随着你编码你的 MPS 工作

671
00:21:48,446 --> 0:21:49,686
你可以简单地运行一些

672
00:21:49,686 --> 0:21:51,436
中间事务

673
00:21:51,436 --> 0:21:52,706
并使用一个名为 commitAndContinue 的方法

674
00:21:52,706 --> 0:21:53,766
但是我们之后再谈这个

675
00:21:54,256 --> 0:21:55,706
首先 让我们看看

676
00:21:55,706 --> 0:21:57,546
如何使用 MPSCommandBuffers

677
00:21:57,546 --> 0:21:58,766
将预测运用到 MPS 内核上

678
00:21:59,216 --> 0:22:01,836
所以一个 MPS 预测对象

679
00:21:59,216 --> 0:22:01,836
所以一个 MPS 预测对象

680
00:22:01,836 --> 0:22:03,146
包含一个 metal 缓冲

681
00:22:03,146 --> 0:22:04,346
这个缓冲内包含了 32 位的

682
00:22:04,346 --> 0:22:05,666
整数预测数值

683
00:22:05,666 --> 0:22:06,096
它们处在偏移位置

684
00:22:07,276 --> 0:22:08,166
随着实施预测

685
00:22:08,166 --> 0:22:09,476
我们在偏移位置

686
00:22:09,476 --> 0:22:10,386
在 metal 缓冲内获得数值

687
00:22:10,576 --> 0:22:12,656
数值 0 代表

688
00:22:12,656 --> 0:22:13,916
我们不想实施这个内核

689
00:22:14,116 --> 0:22:16,336
而非零数值则意味正常实施

690
00:22:16,846 --> 0:22:18,736
在这个图表中

691
00:22:18,736 --> 0:22:19,736
我们通过在偏移位置

692
00:22:19,736 --> 0:22:21,276
将数值设定为 0 

693
00:22:21,276 --> 0:22:22,896
避开了这个内核的实施

694
00:22:23,436 --> 0:22:25,246
这个偏移很重要

695
00:22:25,246 --> 0:22:26,186
它让你可以在

696
00:22:26,186 --> 0:22:27,556
众多 MPS 预测对象中

697
00:22:27,556 --> 0:22:28,986
分享一个单一的 metal 缓冲

698
00:22:28,986 --> 0:22:29,966
这样你就可以

699
00:22:29,966 --> 0:22:30,726
向多个内核发送预测

700
00:22:31,206 --> 0:22:33,326
每个预测数值

701
00:22:33,416 --> 0:22:34,456
将会由一个不同的偏移指定

702
00:22:35,006 --> 0:22:38,106
为了使用一个

703
00:22:38,106 --> 0:22:39,826
预测数值 我们需要把它附加到

704
00:22:39,826 --> 0:22:40,686
MPSCommandBuffer

705
00:22:41,236 --> 0:22:42,576
这种情况下

706
00:22:42,576 --> 0:22:43,826
我们编码到命令缓冲的任何 MPS 内核

707
00:22:43,826 --> 0:22:45,326
都会获得预测数值

708
00:22:45,976 --> 0:22:47,096
让我们看看

709
00:22:47,096 --> 0:22:49,096
我们如何创建一个预测

710
00:22:49,096 --> 0:22:50,156
并在一个 MPSCommandBuffer 上设置

711
00:22:50,706 --> 0:22:53,976
首先 我们创建了

712
00:22:53,976 --> 0:22:56,966
一个 MPSPredicate 对象

713
00:22:57,186 --> 0:22:58,666
我们把预测附加到

714
00:22:58,666 --> 0:22:59,406
我们的 MPSCommandBuffer

715
00:22:59,966 --> 0:23:01,226
现在 我们会编码一个操作

716
00:22:59,966 --> 0:23:01,226
现在 我们会编码一个操作

717
00:23:01,936 --> 0:23:03,526
来修改预测数值

718
00:23:04,206 --> 0:23:06,146
因为现存的 metal 缓冲

719
00:23:06,146 --> 0:23:08,286
我们需要一个内核在 metal 缓冲中产生结果

720
00:23:08,546 --> 0:23:10,516
你可以使用你自己的内核

721
00:23:10,516 --> 0:23:11,516
或者也可以使用

722
00:23:11,516 --> 0:23:13,016
MPSMatrix 内核之一

723
00:23:13,016 --> 0:23:13,786
这就是接下来我们要做的

724
00:23:14,496 --> 0:23:16,686
我们首先要将预测包含在一个

725
00:23:16,686 --> 0:23:17,616
MPSMatrix 对象中

726
00:23:18,026 --> 0:23:19,156
然后我们将编码一个内核

727
00:23:19,156 --> 0:23:20,616
以修改预测数值

728
00:23:22,106 --> 0:23:23,106
所以 这里 我们将使用一个

729
00:23:23,106 --> 0:23:24,506
线性神经元内核

730
00:23:24,506 --> 0:23:25,926
我们将用它来做一些简单的事

731
00:23:25,926 --> 0:23:27,526
我们将要缩减预测的数值

732
00:23:28,046 --> 0:23:29,846
最后 我们将会

733
00:23:29,846 --> 0:23:31,796
编码一个 cnnKernel

734
00:23:31,796 --> 0:23:33,656
在实施之前读取预测的数值

735
00:23:37,256 --> 0:23:38,866
所以 在 MPSCommandBuffers 中

736
00:23:38,866 --> 0:23:40,716
使用预测是一个

737
00:23:40,946 --> 0:23:42,996
消除你网络中不必要工作的简单方法

738
00:23:43,666 --> 0:23:45,026
如果你有可以被避开的

739
00:23:45,026 --> 0:23:46,086
内核 你可以使用预测

740
00:23:46,086 --> 0:23:48,066
来利用减少的工作量

741
00:23:48,416 --> 0:23:49,926
如果有应用的

742
00:23:49,926 --> 0:23:51,336
多个内核

743
00:23:51,816 --> 0:23:53,136
你可以使用多个预测

744
00:23:53,376 --> 0:23:54,416
并只通过设定独特的偏移数

745
00:23:54,416 --> 0:23:56,166
值使用一个单一的 metal 缓冲

746
00:23:56,166 --> 0:23:58,916
所以 现在让我们来谈谈

747
00:23:58,916 --> 0:24:00,826
MPSCommandBuffers 的其他特征

748
00:23:58,916 --> 0:24:00,826
MPSCommandBuffers 的其他特征

749
00:24:01,126 --> 0:24:01,806
commitAndContinue

750
00:24:02,406 --> 0:24:05,206
这是一个可以让你

751
00:24:05,206 --> 0:24:07,126
在实施工作的时候

752
00:24:07,126 --> 0:24:09,956
更简单地获得更好的

753
00:24:09,956 --> 0:24:10,846
GPU 利用的方法

754
00:24:11,776 --> 0:24:12,936
所以 为了看看这个是如何有益的

755
00:24:12,936 --> 0:24:14,406
我们首先来复习一下

756
00:24:14,406 --> 0:24:15,356
一个典型的工作量是如何实施的

757
00:24:16,326 --> 0:24:18,046
一般实施 MPS 内核的方法是

758
00:24:18,046 --> 0:24:19,336
将你的工作编码至一个

759
00:24:19,336 --> 0:24:20,386
命令缓冲之后

760
00:24:20,386 --> 0:24:21,476
交付实施

761
00:24:21,966 --> 0:24:22,956
所以 这里我们有一个

762
00:24:22,956 --> 0:24:24,246
关于单一命令缓冲的例子

763
00:24:24,246 --> 0:24:25,246
你编码一些工作

764
00:24:25,246 --> 0:24:26,286
之后我们来实施

765
00:24:27,216 --> 0:24:28,606
现在 在实际中

766
00:24:28,606 --> 0:24:29,506
CPU 的编码时间

767
00:24:29,506 --> 0:24:31,066
将比 GPU 的实施时间

768
00:24:31,066 --> 0:24:33,316
更少 但是我们想要避免

769
00:24:33,396 --> 0:24:35,696
因为节流和类似这样的事情的

770
00:24:35,696 --> 0:24:36,846
空闲时间

771
00:24:37,966 --> 0:24:39,346
所以你可以看到

772
00:24:39,346 --> 0:24:42,956
我们将在 CPU 和 GPU 之间得到一些失速

773
00:24:43,546 --> 0:24:45,776
现在 解决这个问题的一个办法

774
00:24:45,776 --> 0:24:46,816
是使用双重缓冲

775
00:24:47,286 --> 0:24:48,976
使用双重缓冲

776
00:24:48,976 --> 0:24:49,936
我们可以保持两个

777
00:24:49,936 --> 0:24:51,156
命令缓冲 

778
00:24:51,156 --> 0:24:53,036
我们将在对一个工作进行编码的同时实施另一个

779
00:24:53,866 --> 0:24:54,746
现在 这个可以

780
00:24:55,406 --> 0:24:56,896
消除我们之前看到的空闲

781
00:24:56,896 --> 0:24:59,256
不过这个也有一些限制

782
00:24:59,686 --> 0:25:00,546
首先 正如我提到的

783
00:24:59,686 --> 0:25:00,546
首先 正如我提到的

784
00:25:00,546 --> 0:25:01,416
你需要保留两套工作

785
00:25:01,416 --> 0:25:03,216
这意味着 你需要找到一个方法

786
00:25:03,216 --> 0:25:04,696
将你的工作划分为两个

787
00:25:04,696 --> 0:25:05,836
独立的工作量

788
00:25:06,286 --> 0:25:07,586
结果 你可以有

789
00:25:07,586 --> 0:25:09,486
大量增加的内存需求

790
00:25:11,336 --> 0:25:12,646
然而 commitAndContinue 方法

791
00:25:12,646 --> 0:25:13,986
我们可以通过将工作量

792
00:25:13,986 --> 0:25:15,046
分成更小的部分

793
00:25:15,046 --> 0:25:16,726
而获得这个性能的

794
00:25:16,726 --> 0:25:18,276
很多好处

795
00:25:19,456 --> 0:25:20,366
所以 我们将通过

796
00:25:20,366 --> 0:25:21,556
在每个命令缓冲内

797
00:25:21,556 --> 0:25:23,816
利用每层的独立来分解工作

798
00:25:24,906 --> 0:25:25,876
然后我们会使用双重缓冲

799
00:25:25,876 --> 0:25:28,046
来交付更小的组的工作

800
00:25:28,626 --> 0:25:30,596
现在 commitAndContinue

801
00:25:30,596 --> 0:25:31,676
将自动处理这个

802
00:25:31,676 --> 0:25:32,836
内部工作分配

803
00:25:32,836 --> 0:25:34,646
同时也保证

804
00:25:34,646 --> 0:25:35,826
你分配在命令缓冲上的

805
00:25:35,826 --> 0:25:37,056
临时对象都会

806
00:25:37,056 --> 0:25:39,026
对之后编码的工作保持有效

807
00:25:39,536 --> 0:25:42,226
而与双重缓冲一起

808
00:25:42,226 --> 0:25:43,576
它会保证你在 GPU

809
00:25:43,576 --> 0:25:44,856
实施工作同时

810
00:25:44,856 --> 0:25:45,706
继续在 CPU 上编码

811
00:25:46,506 --> 0:25:47,646
通过简单地允许你

812
00:25:47,646 --> 0:25:49,116
分配工作量

813
00:25:49,116 --> 0:25:50,306
你可以避免增加的对于

814
00:25:50,306 --> 0:25:51,656
双重缓冲的内存需求

815
00:25:51,766 --> 0:25:52,716
同时还可以获得

816
00:25:52,766 --> 0:25:54,016
很多提升的 GPU 使用

817
00:25:54,946 --> 0:25:55,856
所以让我们看看

818
00:25:55,856 --> 0:25:56,896
你如何在你自己的代码中将其利用

819
00:25:58,356 --> 0:26:00,316
现在我们有四个

820
00:25:58,356 --> 0:26:00,316
现在我们有四个

821
00:26:00,316 --> 0:26:00,926
编码于 MTLCommandBuffer 的

822
00:26:00,926 --> 0:26:01,676
MPS 内核

823
00:26:02,246 --> 0:26:05,266
最后 我们指派实施的工作

824
00:26:06,556 --> 0:26:08,046
正如我们之前展示的

825
00:26:08,046 --> 0:26:09,636
这将会给你我们

826
00:26:09,636 --> 0:26:11,206
之前看到的停顿

827
00:26:11,446 --> 0:26:12,236
然而 通过使用

828
00:26:12,236 --> 0:26:13,886
MPSCommandBuffers 和新的

829
00:26:13,886 --> 0:26:15,166
CommitAndContinue 方法

830
00:26:15,166 --> 0:26:16,106
我们可以轻易地将其提升

831
00:26:17,226 --> 0:26:18,226
所以 我们将创建一个

832
00:26:18,226 --> 0:26:19,156
MPSCommandBuffer

833
00:26:20,476 --> 0:26:21,406
我们将编码我们的

834
00:26:21,406 --> 0:26:21,836
前两个内核

835
00:26:23,306 --> 0:26:23,936
然后我们会调用

836
00:26:23,936 --> 0:26:24,606
commitAndContinue

837
00:26:25,146 --> 0:26:27,176
它会指派我们已经编码的工作

838
00:26:27,176 --> 0:26:29,966
将任何分配

839
00:26:29,966 --> 0:26:31,136
向前发展

840
00:26:31,136 --> 0:26:32,236
并允许我们立刻继续

841
00:26:32,236 --> 0:26:33,936
对另外两个内核进行编码

842
00:26:34,696 --> 0:26:35,826
最后 我们可以使用一个

843
00:26:35,826 --> 0:26:37,196
定期的指派来指派剩下的工作

844
00:26:37,196 --> 0:26:39,896
所以你可以看到

845
00:26:39,896 --> 0:26:41,426
使用 commitAndContinue 需要

846
00:26:41,426 --> 0:26:43,676
你代码的变化是很少的

847
00:26:43,676 --> 0:26:44,596
但是如果你要利用图表

848
00:26:44,596 --> 0:26:46,426
那就更简单了

849
00:26:47,846 --> 0:26:49,206
当你使用 MPSCommandBuffe

850
00:26:49,206 --> 0:26:51,326
在一个图表中编码 MPS

851
00:26:51,326 --> 0:26:52,106
它会自动使用

852
00:26:52,106 --> 0:26:52,866
commitAndContinue

853
00:26:52,866 --> 0:26:53,956
来定期在编码过程中

854
00:26:54,346 --> 0:26:55,596
提交工作

855
00:26:56,346 --> 0:26:57,516
不需要更深一步的变化

856
00:26:57,886 --> 0:26:59,416
只是简单的使用 MPSCommandBuffer

857
00:26:59,546 --> 0:27:00,806
而不是 MTLCommandBuffer 即可

858
00:26:59,546 --> 0:27:00,806
而不是 MTLCommandBuffer 即可

859
00:27:01,356 --> 0:27:04,076
最后 我想要指出

860
00:27:04,076 --> 0:27:05,516
你还是可以将 commitAndContinue

861
00:27:05,556 --> 0:27:06,786
与双重缓冲相结合

862
00:27:06,786 --> 0:27:09,656
同时也可以得到更好的性能

863
00:27:09,656 --> 0:27:10,816
所以正如你所见

864
00:27:10,816 --> 0:27:12,216
它允许你缩减

865
00:27:12,216 --> 0:27:14,026
我们看到的与 commitAndContinue 一起的小停顿

866
00:27:14,606 --> 0:27:16,606
所以我们有很多

867
00:27:16,606 --> 0:27:18,226
指派工作实施的选择

868
00:27:18,226 --> 0:27:20,326
你可以使用一个

869
00:27:20,326 --> 0:27:22,426
单一的命令缓冲 一次执行一个工作

870
00:27:23,186 --> 0:27:24,326
为了更好的性能

871
00:27:24,386 --> 0:27:25,786
潜在地与增加的

872
00:27:25,786 --> 0:27:26,866
内存消耗一起

873
00:27:26,866 --> 0:27:27,516
你可以使用双重缓冲

874
00:27:28,966 --> 0:27:30,906
现在 通过 MPSCommandBuffer

875
00:27:31,386 --> 0:27:32,746
你可以实现和使用 commitAndContinue

876
00:27:34,696 --> 0:27:36,766
如果你还是想要更好的性能

877
00:27:36,766 --> 0:27:39,586
你可以使用 commitAndContinue 和双重缓冲

878
00:27:39,846 --> 0:27:42,256
所以让我们看看

879
00:27:42,256 --> 0:27:44,326
这些途径如何在现实世界的网络上运行

880
00:27:44,326 --> 0:27:47,006
针对这个例子

881
00:27:47,006 --> 0:27:48,326
我们将会看看在 CIFAR-10 数据集上的

882
00:27:48,326 --> 0:27:50,076
ResNet 50 网络

883
00:27:50,746 --> 0:27:52,226
现在这个数据

884
00:27:52,226 --> 0:27:54,446
通过使用外部 AMD Radeon Pro Vega

885
00:27:54,446 --> 0:27:55,336
64 GPU 来被测算

886
00:27:56,336 --> 0:27:56,926
这是一个拥有多层的

887
00:27:56,926 --> 0:27:58,416
普通图像分类网络

888
00:27:58,416 --> 0:27:59,696
所以这是一个

889
00:27:59,696 --> 0:28:00,956
我们可以看到与 commitAndContinue 一起的好例子

890
00:27:59,696 --> 0:28:00,956
我们可以看到与 commitAndContinue 一起的好例子

891
00:28:01,146 --> 0:28:03,426
我将会把单一缓冲的例子

892
00:28:03,426 --> 0:28:05,106
作为我们的基线

893
00:28:05,436 --> 0:28:06,476
我们在垂直轴上

894
00:28:06,476 --> 0:28:08,036
有性能和内存消耗

895
00:28:08,426 --> 0:28:09,096
让我们看看

896
00:28:09,096 --> 0:28:10,016
双重缓冲是什么样的

897
00:28:10,016 --> 0:28:11,356
现在我们提升了一点性能

898
00:28:11,356 --> 0:28:12,586
但是我们同样

899
00:28:12,926 --> 0:28:14,116
提升了一点

900
00:28:14,116 --> 0:28:15,306
内存消耗

901
00:28:16,156 --> 0:28:17,146
这是因为我们可以

902
00:28:17,146 --> 0:28:18,356
通过在特定时间的飞行状态维持两倍的工作

903
00:28:18,356 --> 0:28:19,886
来实现双重缓冲

904
00:28:20,556 --> 0:28:21,486
所以 让我们来看看使用

905
00:28:21,486 --> 0:28:22,176
CommitAndContinue

906
00:28:23,296 --> 0:28:24,306
因为我们在性能上

907
00:28:24,306 --> 0:28:25,926
非常接近

908
00:28:25,926 --> 0:28:26,996
而却少了很多的内存负担

909
00:28:26,996 --> 0:28:31,186
在这里我们可以看到

910
00:28:31,186 --> 0:28:32,236
与双重缓冲一起的

911
00:28:32,236 --> 0:28:32,816
CommitAndContinue

912
00:28:33,716 --> 0:28:34,646
我们还有一些更好的性能

913
00:28:34,646 --> 0:28:37,006
但我们也同时使用

914
00:28:37,006 --> 0:28:37,856
更多的内存

915
00:28:37,856 --> 0:28:40,526
所以你可以看到

916
00:28:40,526 --> 0:28:42,316
使用 CommitAndContinue

917
00:28:42,316 --> 0:28:43,316
是一个增加最少的内存压力

918
00:28:43,316 --> 0:28:45,266
同时实现更好性能的

919
00:28:45,266 --> 0:28:46,166
非常简单的方法

920
00:28:46,786 --> 0:28:49,266
现在 让我们通过另一个机器学习的 App

921
00:28:49,266 --> 0:28:50,896
也就是去噪

922
00:28:50,896 --> 0:28:51,806
来把所有这些途径

923
00:28:51,806 --> 0:28:53,096
放在一起

924
00:28:53,096 --> 0:28:56,136
正如这个名字所示

925
00:28:56,136 --> 0:28:58,806
去噪将去除充满噪点的图像上的噪点

926
00:28:58,806 --> 0:28:59,976
并生成一个干净的图像

927
00:29:02,116 --> 0:29:03,056
我们将在光线追踪的环境中

928
00:29:03,056 --> 0:29:04,426
来看看这个例子

929
00:29:05,036 --> 0:29:07,446
如果你看了之前的

930
00:29:07,446 --> 0:29:08,796
光线追踪 metal 的视频

931
00:29:08,796 --> 0:29:09,956
你会看到降噪的另一个例子

932
00:29:09,996 --> 0:29:12,016
一个使用图像处理技术的例子

933
00:29:12,096 --> 0:29:13,176
在这里 我们将会在机器学习基础上

934
00:29:13,176 --> 0:29:15,016
看一下解决方案

935
00:29:15,586 --> 0:29:18,606
针对这个例子

936
00:29:18,606 --> 0:29:19,356
我们会看到三个阶段

937
00:29:19,356 --> 0:29:20,396
我们将创建一个

938
00:29:20,396 --> 0:29:21,236
离线训练过程

939
00:29:21,236 --> 0:29:22,526
我们将运行训练网络

940
00:29:22,526 --> 0:29:24,166
最后我们将

941
00:29:24,166 --> 0:29:25,226
把推理图表部署至

942
00:29:25,226 --> 0:29:26,346
滤波新图像

943
00:29:28,286 --> 0:29:29,916
首先 我们需要创建图表

944
00:29:30,496 --> 0:29:32,266
我们来仔细看看这个结构

945
00:29:32,866 --> 0:29:35,316
这里我们将

946
00:29:35,606 --> 0:29:38,066
开始于我们的输入图像

947
00:29:38,066 --> 0:29:39,746
也就是噪点图像

948
00:29:39,746 --> 0:29:40,946
是由我们的光线追踪产生的

949
00:29:41,556 --> 0:29:44,006
我们将会把这个图像

950
00:29:44,006 --> 0:29:45,196
注入编码的阶段

951
00:29:45,346 --> 0:29:46,436
编码器是在空间上压缩图像时

952
00:29:46,436 --> 0:29:48,276
提取更高等级的

953
00:29:48,276 --> 0:29:51,446
特征代表的小的子网络

954
00:29:51,996 --> 0:29:53,716
我们将会把这些结果

955
00:29:53,716 --> 0:29:55,286
逐渐加入我们的解码器阶段

956
00:29:55,856 --> 0:29:57,406
现在这些展示了反转过程

957
00:29:57,606 --> 0:29:58,506
它们将重新构建

958
00:29:58,506 --> 0:29:59,636
特征图中的图像

959
00:30:00,206 --> 0:30:03,646
我们还将使用跳跃连接

960
00:30:03,726 --> 0:30:05,246
它们将特征从

961
00:30:05,246 --> 0:30:07,126
编码的图像支援到

962
00:30:07,126 --> 0:30:07,576
每个解码阶段

963
00:30:08,456 --> 0:30:09,536
将每个编码器的结果转发至

964
00:30:09,536 --> 0:30:11,176
解码器就可以完成这个

965
00:30:11,986 --> 0:30:14,146
最后 降噪的图像

966
00:30:14,146 --> 0:30:14,966
是完全被重建的

967
00:30:16,086 --> 0:30:17,426
所以 让我们仔细看看

968
00:30:17,696 --> 0:30:18,796
编码器阶段

969
00:30:19,476 --> 0:30:21,386
编码器阶段在学习

970
00:30:21,386 --> 0:30:23,336
如何保留特征的同时

971
00:30:23,336 --> 0:30:24,506
压缩图像

972
00:30:24,566 --> 0:30:25,786
特征由三对卷积层

973
00:30:25,786 --> 0:30:27,586
ReLu 层

974
00:30:27,586 --> 0:30:28,756
和一个大的池化层组成

975
00:30:29,696 --> 0:30:30,676
让我们来看一下这个代码

976
00:30:31,556 --> 0:30:32,686
正如我们之前所见

977
00:30:32,686 --> 0:30:33,596
我们可以把每个节点

978
00:30:33,596 --> 0:30:35,886
按照它们在网络中的顺序进行构建

979
00:30:36,366 --> 0:30:39,316
我们也会用相同的方法构建解码器

980
00:30:39,316 --> 0:30:41,596
你可以先从一个不抽样层开始

981
00:30:42,696 --> 0:30:43,846
之后 我们通过跳跃连接

982
00:30:43,846 --> 0:30:45,056
增加对应的编码器结果

983
00:30:45,056 --> 0:30:48,046
最后

984
00:30:48,046 --> 0:30:49,286
我们有两对

985
00:30:49,286 --> 0:30:50,976
卷积层和 ReLu 层

986
00:30:53,996 --> 0:30:55,106
再次和之前一样

987
00:30:55,106 --> 0:30:56,266
我们将嵌入和网络中的每层

988
00:30:56,266 --> 0:30:57,136
对应的节点

989
00:30:58,306 --> 0:31:00,146
现在我们可以把编码器和解码器阶段

990
00:30:58,306 --> 0:31:00,146
现在我们可以把编码器和解码器阶段

991
00:31:00,146 --> 0:31:01,566
放在一起了

992
00:31:04,916 --> 0:31:06,096
所以 首先我们将

993
00:31:06,096 --> 0:31:06,916
连接我们的编码器节点

994
00:31:09,536 --> 0:31:10,746
在我们进一步行动

995
00:31:10,746 --> 0:31:11,776
连接我们的解码节点时

996
00:31:11,776 --> 0:31:12,876
我们需要加放一个编码节点

997
00:31:12,876 --> 0:31:14,566
我们将这个节点称之为瓶颈节点

998
00:31:15,026 --> 0:31:16,266
除了它没有

999
00:31:16,266 --> 0:31:17,696
最终的大型池化层外

1000
00:31:17,696 --> 0:31:18,406
它与编码器是一致的

1001
00:31:18,956 --> 0:31:21,056
在瓶颈节点之后

1002
00:31:21,296 --> 0:31:22,806
我们将会连接解码器节点

1003
00:31:23,486 --> 0:31:25,236
通过从对应的编码器节点

1004
00:31:25,266 --> 0:31:26,306
传递结果图像

1005
00:31:26,306 --> 0:31:28,656
我们将满足跳跃连接

1006
00:31:30,636 --> 0:31:31,876
所以现在我们有推理图表

1007
00:31:32,226 --> 0:31:32,976
我们来看看训练阶段

1008
00:31:35,496 --> 0:31:37,006
为了开始训练阶段

1009
00:31:37,006 --> 0:31:38,086
我们需要计算损耗数值

1010
00:31:38,146 --> 0:31:39,196
我们需要与推理一起启动

1011
00:31:39,196 --> 0:31:40,546
我们需要与推理图表的结果

1012
00:31:40,546 --> 0:31:41,416
一起启动

1013
00:31:41,416 --> 0:31:43,586
对于训练迭代来说

1014
00:31:43,586 --> 0:31:44,796
现在是我们的网络

1015
00:31:44,866 --> 0:31:46,876
对于现有的降噪图像的最好猜测

1016
00:31:47,446 --> 0:31:49,246
我们还将把干净的 RGB 图像

1017
00:31:49,246 --> 0:31:51,156
作为真值

1018
00:31:51,156 --> 0:31:53,076
我们将会用它来计算一个损耗数值

1019
00:31:53,076 --> 0:31:55,066
我们还想要

1020
00:31:55,066 --> 0:31:56,076
计算第二个损耗

1021
00:31:56,566 --> 0:31:58,206
我们将运行一些边缘检测

1022
00:31:58,286 --> 0:31:59,356
我们将使用

1023
00:31:59,356 --> 0:32:00,706
高斯滤波器的拉普拉斯

1024
00:31:59,356 --> 0:32:00,706
高斯滤波器的拉普拉斯

1025
00:32:01,616 --> 0:32:03,026
现在 我们想这样做是因为

1026
00:32:03,546 --> 0:32:04,576
我们想要自己的网络

1027
00:32:04,576 --> 0:32:06,096
学习如何降噪图像

1028
00:32:06,096 --> 0:32:07,086
但与此同时我们还想要

1029
00:32:07,086 --> 0:32:08,516
保证它保留了

1030
00:32:08,516 --> 0:32:09,396
原始图像的边缘

1031
00:32:10,536 --> 0:32:12,436
我们将实施

1032
00:32:12,436 --> 0:32:14,026
高斯滤波器的拉普拉斯

1033
00:32:14,026 --> 0:32:15,976
或者 LoG 滤波器使用卷积

1034
00:32:17,396 --> 0:32:19,326
最后 我们将结合这两个损耗

1035
00:32:19,486 --> 0:32:20,426
第一个损耗是 RGB 损耗

1036
00:32:20,426 --> 0:32:22,956
第二个则是 LoG 损耗

1037
00:32:22,956 --> 0:32:24,336
我们将把两者

1038
00:32:24,336 --> 0:32:25,916
结合为一个最终的损耗

1039
00:32:28,476 --> 0:32:29,956
让我们来仔细看看

1040
00:32:29,956 --> 0:32:30,666
如何做到这一点

1041
00:32:30,796 --> 0:32:32,456
我们将使用

1042
00:32:32,456 --> 0:32:34,546
推理图表的结果

1043
00:32:34,546 --> 0:32:35,796
和真值 RGB 图像

1044
00:32:35,796 --> 0:32:37,086
来创建我们的 RGB 损耗节点

1045
00:32:37,196 --> 0:32:39,476
正如你之前提到的

1046
00:32:39,476 --> 0:32:40,876
我们将使用可分离的损耗内核

1047
00:32:41,246 --> 0:32:44,316
我们将传递图像至我们的

1048
00:32:44,316 --> 0:32:45,656
源和我们的聚类

1049
00:32:46,166 --> 0:32:49,256
对于我们的 LoG 损耗

1050
00:32:49,256 --> 0:32:50,656
我们需要将 LoG 滤波器

1051
00:32:50,656 --> 0:32:52,346
应用至目标 RGB 图像

1052
00:32:52,346 --> 0:32:52,976
和推理图表的结果

1053
00:32:56,476 --> 0:32:57,676
所以我们将使用卷积节点

1054
00:32:57,676 --> 0:32:58,976
实施 LoG 滤波器

1055
00:33:02,136 --> 0:33:03,576
我们将使用卷积的结果

1056
00:33:03,576 --> 0:33:04,916
运算 LoG 损耗

1057
00:33:04,916 --> 0:33:08,116
最后 随着两个损耗都被计算

1058
00:33:08,116 --> 0:33:09,386
我们可以加它们加在一起

1059
00:33:09,386 --> 0:33:11,606
并产生最后的损耗

1060
00:33:12,186 --> 0:33:15,216
有了最后的损耗数值

1061
00:33:15,346 --> 0:33:15,876
我们可以开始

1062
00:33:15,876 --> 0:33:17,206
反向传播阶段

1063
00:33:17,206 --> 0:33:17,946
同时看一看训练图表

1064
00:33:18,976 --> 0:33:20,466
所以 我们要通过计算初始梯度

1065
00:33:20,756 --> 0:33:22,896
来实现这一点

1066
00:33:22,896 --> 0:33:25,166
初始的梯度数值

1067
00:33:25,166 --> 0:33:26,246
可以让我们开启训练图表

1068
00:33:27,316 --> 0:33:28,576
所以这包含的几个梯度节点

1069
00:33:28,576 --> 0:33:29,546
首先是为了伴随着

1070
00:33:29,546 --> 0:33:31,266
对每个正向损耗的梯度节点的增加

1071
00:33:31,266 --> 0:33:33,386
然后就是编码器和

1072
00:33:33,456 --> 0:33:35,136
解码器阶段

1073
00:33:35,926 --> 0:33:36,966
现在 为了每层实施

1074
00:33:36,966 --> 0:33:38,346
图表节点

1075
00:33:38,346 --> 0:33:39,526
将需要很多代码

1076
00:33:39,526 --> 0:33:41,526
同时为错误

1077
00:33:41,526 --> 0:33:42,626
引入很多机会

1078
00:33:43,176 --> 0:33:44,706
然而 通过隐式图表创建

1079
00:33:44,706 --> 0:33:46,396
我们可以让图表

1080
00:33:46,566 --> 0:33:47,886
为我们做所有的工作

1081
00:33:48,426 --> 0:33:51,096
所以这就是所有

1082
00:33:51,096 --> 0:33:51,976
我们需要写来生成训练图表的东西

1083
00:33:55,156 --> 0:33:56,206
首先 我们使用最后损耗的结果

1084
00:33:56,206 --> 0:33:59,046
增加初始梯度节点

1085
00:34:00,496 --> 0:34:01,686
然后使用隐式图表创建

1086
00:34:01,686 --> 0:34:03,656
我们生成所有

1087
00:34:03,656 --> 0:34:05,266
剩余的梯度节点

1088
00:34:07,436 --> 0:34:08,616
现在我们创建了我们的图表

1089
00:34:08,616 --> 0:34:10,746
我们可以开始训练它了

1090
00:34:11,295 --> 0:34:12,826
首先 让我们讨论一下

1091
00:34:12,826 --> 0:34:13,536
我们的输入训练数据

1092
00:34:14,045 --> 0:34:15,246
输入是我们知道

1093
00:34:15,246 --> 0:34:16,376
期望的结果的图像

1094
00:34:16,926 --> 0:34:17,795
在这个情况下我们有充满噪点的图像

1095
00:34:17,795 --> 0:34:19,886
同时也有相对应的干净的图像

1096
00:34:20,856 --> 0:34:22,056
现在两个图像都是熟练掌握 MPS

1097
00:34:22,056 --> 0:34:23,876
使用光线追踪器生成的

1098
00:34:23,876 --> 0:34:26,315
我们通过让

1099
00:34:26,315 --> 0:34:27,545
光线追踪器只运行短时间

1100
00:34:27,545 --> 0:34:28,716
来生成有噪点的图像

1101
00:34:29,275 --> 0:34:31,226
然后通过让光线追踪器

1102
00:34:31,226 --> 0:34:32,376
运行更长的时间

1103
00:34:32,376 --> 0:34:35,045
来获得干净的图像

1104
00:34:35,266 --> 0:34:36,045
现在 通过训练这些图像

1105
00:34:36,045 --> 0:34:37,786
我们希望我们的网络

1106
00:34:37,786 --> 0:34:38,876
会学习如何从有噪点的图像

1107
00:34:38,876 --> 0:34:40,056
接近干净的图像

1108
00:34:40,396 --> 0:34:42,025
我们还将通过一些其他图像

1109
00:34:42,025 --> 0:34:43,346
增大我们的输入数据

1110
00:34:43,346 --> 0:34:45,775
同时通过光线追踪器

1111
00:34:45,775 --> 0:34:48,826
生成曲面法线和反射率

1112
00:34:50,085 --> 0:34:51,556
反射率图像是一个

1113
00:34:51,556 --> 0:34:52,786
三通道图像 它包含着

1114
00:34:52,786 --> 0:34:55,596
反射光数量的数值

1115
00:34:55,596 --> 0:34:58,366
曲面法线

1116
00:34:58,366 --> 0:34:59,316
是一个三通道图像

1117
00:34:59,316 --> 0:35:00,556
每个通道都包含了

1118
00:34:59,316 --> 0:35:00,556
每个通道都包含了

1119
00:35:00,556 --> 0:35:03,686
曲面法线向量的一个成分

1120
00:35:04,286 --> 0:35:06,446
现在 在我们开始训练

1121
00:35:06,446 --> 0:35:07,976
之前 我们需要做一些

1122
00:35:08,196 --> 0:35:09,926
预处理的工作

1123
00:35:09,926 --> 0:35:12,706
正如我所提到的

1124
00:35:12,706 --> 0:35:14,166
这些数据都包含在三个通道中

1125
00:35:15,336 --> 0:35:17,436
然而 MPS 网络和 MPS 

1126
00:35:17,436 --> 0:35:20,586
cnnKernels 使用它们的图像

1127
00:35:20,726 --> 0:35:21,986
作为四通道纹理

1128
00:35:22,546 --> 0:35:23,266
所以我们要

1129
00:35:23,266 --> 0:35:24,836
把这些值关联起来

1130
00:35:25,506 --> 0:35:28,186
现在 因为每个图像是

1131
00:35:28,186 --> 0:35:30,246
三个通道 我们需要将它们

1132
00:35:30,246 --> 0:35:31,136
关联到一个 metal

1133
00:35:31,136 --> 0:35:33,626
纹理数组中 我们不能

1134
00:35:33,826 --> 0:35:35,436
使用 MPS cnn 关联法 

1135
00:35:35,516 --> 0:35:38,816
因为它需要四个通道的特征通道

1136
00:35:39,636 --> 0:35:40,756
但是 我们可以编写一个

1137
00:35:40,756 --> 0:35:42,656
简单的内核来实现这一点

1138
00:35:43,646 --> 0:35:45,006
这里有一个简单的 metal 计算着色器

1139
00:35:45,006 --> 0:35:46,866
将这些图像关联在一起

1140
00:35:46,866 --> 0:35:49,306
我们将开始使用一个

1141
00:35:49,306 --> 0:35:51,276
线程栅格映射到结果的

1142
00:35:51,276 --> 0:35:52,686
每个四通道像素

1143
00:35:52,686 --> 0:35:55,026
我们的参数将作为

1144
00:35:55,026 --> 0:35:56,276
保持图像 RGB 输入

1145
00:35:56,276 --> 0:36:00,036
反照率输入和正常图像关联的结果

1146
00:35:56,276 --> 0:36:00,036
反照率输入和正常图像关联的结果

1147
00:36:00,586 --> 0:36:02,586
我们要让每个线程

1148
00:36:02,586 --> 0:36:04,956
从网格中每个输入的位置

1149
00:36:04,956 --> 0:36:07,166
读取一个像素

1150
00:36:08,056 --> 0:36:09,286
我们将把这些值关联

1151
00:36:09,286 --> 0:36:11,476
在一起 然后用 0 填充

1152
00:36:11,476 --> 0:36:12,926
剩余的未使用的通道

1153
00:36:17,216 --> 0:36:19,896
最后 我们要把结果写在网格中

1154
00:36:19,896 --> 0:36:21,856
相同的位置

1155
00:36:21,906 --> 0:36:23,676
现在我们有了一个着色器

1156
00:36:23,676 --> 0:36:26,076
它可以将这些值关联到

1157
00:36:26,076 --> 0:36:27,436
一个单一的 MPS 图像中 我们来看看

1158
00:36:27,436 --> 0:36:28,176
如何把它传递到图表上

1159
00:36:29,246 --> 0:36:31,086
或者 让我们先看看如何编码

1160
00:36:31,086 --> 0:36:33,536
下面是一个例子 它告诉我们如何

1161
00:36:33,536 --> 0:36:34,616
编码内核并将结果封装

1162
00:36:34,616 --> 0:36:35,696
到 MPS 图像中

1163
00:36:36,896 --> 0:36:37,856
我们的输入

1164
00:36:37,856 --> 0:36:40,326
是包含数据的图像 我们要

1165
00:36:40,496 --> 0:36:42,496
用结果作为图表的输入

1166
00:36:42,496 --> 0:36:44,006
因此我们需要构造一个 MPS 图像

1167
00:36:44,346 --> 0:36:45,506
我们将使用它的纹理

1168
00:36:45,646 --> 0:36:47,446
保存关联内核的结果

1169
00:36:47,926 --> 0:36:50,336
接下来 我们将把每个参数

1170
00:36:50,336 --> 0:36:51,856
绑定到适当的位置

1171
00:36:53,026 --> 0:36:54,976
我们将分派线程

1172
00:36:54,976 --> 0:36:56,416
然后最终传回

1173
00:36:56,626 --> 0:36:58,086
准备传递到网络中的图像

1174
00:36:58,706 --> 0:36:59,726
所以 现在输入已经

1175
00:36:59,726 --> 0:37:01,326
准备好了 我们来看看

1176
00:36:59,726 --> 0:37:01,326
准备好了 我们来看看

1177
00:37:01,326 --> 0:37:02,476
执行训练图

1178
00:37:02,526 --> 0:37:04,436
在训练期间

1179
00:37:04,436 --> 0:37:06,416
我们将执行多次迭代的图表

1180
00:37:06,416 --> 0:37:07,936
我们将在每个训练集中

1181
00:37:08,006 --> 0:37:09,526
执行多个批次

1182
00:37:09,526 --> 0:37:11,016
然后每个期

1183
00:37:11,016 --> 0:37:13,976
执行多个批次

1184
00:37:16,596 --> 0:37:18,886
这里我们要对

1185
00:37:18,886 --> 0:37:19,986
训练图表进行一次迭代

1186
00:37:20,496 --> 0:37:22,956
我们将使用刚才显示的内核将

1187
00:37:22,956 --> 0:37:24,266
除了批处理中的每个图像外的

1188
00:37:24,266 --> 0:37:24,976
所有图像关联在一起 

1189
00:37:27,076 --> 0:37:28,046
我们将把这些关联放入

1190
00:37:28,046 --> 0:37:29,746
阵列中 因为

1191
00:37:29,956 --> 0:37:31,726
这个图表需要一个图像阵列

1192
00:37:31,726 --> 0:37:33,076
一个用于源图像

1193
00:37:33,076 --> 0:37:34,376
一个用于聚类

1194
00:37:34,926 --> 0:37:37,306
现在我们将在这里使用

1195
00:37:37,306 --> 0:37:38,646
MPSCommandBuffers 因为

1196
00:37:38,646 --> 0:37:39,766
正如我们前面看到的 

1197
00:37:39,766 --> 0:37:41,066
这是提高 GPU 利用率的一种

1198
00:37:41,066 --> 0:37:41,706
简单方法

1199
00:37:43,006 --> 0:37:43,946
最后 我们将

1200
00:37:43,946 --> 0:37:45,766
对图像进行编码

1201
00:37:45,766 --> 0:37:46,396
然后提交执行

1202
00:37:47,006 --> 0:37:49,136
现在 让我们仔细看看

1203
00:37:49,136 --> 0:37:49,896
每个训练期

1204
00:37:50,216 --> 0:37:51,526
在这个方案中 我们要

1205
00:37:51,526 --> 0:37:52,626
处理完整的训练

1206
00:37:52,626 --> 0:37:54,156
数据集 每个期 以便

1207
00:37:54,156 --> 0:37:55,106
更好地收敛

1208
00:37:55,796 --> 0:37:57,106
我们还会每隔几个期

1209
00:37:57,106 --> 0:37:59,476
更新一次训练集

1210
00:37:59,476 --> 0:38:00,636
这里是每 100 个期

1211
00:37:59,476 --> 0:38:00,636
这里是每 100 个期

1212
00:38:00,636 --> 0:38:04,156
此时 我们还会执行网络校验

1213
00:38:04,976 --> 0:38:06,356
最后 在每千分之一期

1214
00:38:06,356 --> 0:38:07,126
我们都要降低

1215
00:38:07,126 --> 0:38:08,386
优化器的学习率

1216
00:38:08,526 --> 0:38:10,606
这也将有助于提高收敛性

1217
00:38:10,656 --> 0:38:12,346
我们来看看它的代码

1218
00:38:12,386 --> 0:38:13,116
首先 我们要先每个期一次

1219
00:38:13,116 --> 0:38:14,496
处理一次

1220
00:38:14,496 --> 0:38:15,856
整个训练集

1221
00:38:15,856 --> 0:38:18,546
我们在这里看到的是每一个

1222
00:38:18,546 --> 0:38:18,736
第一百的期

1223
00:38:18,736 --> 0:38:19,876
我们要更新

1224
00:38:19,876 --> 0:38:21,026
我们的训练数据集

1225
00:38:21,026 --> 0:38:22,136
我们要运行校验

1226
00:38:23,416 --> 0:38:24,676
最后 每第一千的期

1227
00:38:24,676 --> 0:38:25,786
我们的学习率

1228
00:38:25,786 --> 0:38:28,936
会下降 2 倍

1229
00:38:29,166 --> 0:38:30,146
所以 现在我们已经训练了

1230
00:38:30,146 --> 0:38:32,466
这个图表 我们可以降噪新的图像

1231
00:38:33,016 --> 0:38:34,596
现在 由于 MPS 可以

1232
00:38:34,596 --> 0:38:36,006
跨多个平台使用和优化

1233
00:38:36,006 --> 0:38:38,276
我们可以轻松地

1234
00:38:38,276 --> 0:38:39,906
在不同的设备上部署训练网络

1235
00:38:40,106 --> 0:38:41,916
例如 你可能希望

1236
00:38:41,916 --> 0:38:43,366
在 Mac 上执行

1237
00:38:43,366 --> 0:38:44,816
计算开销较大的训练

1238
00:38:44,816 --> 0:38:46,636
然后使用训练网络

1239
00:38:46,636 --> 0:38:49,236
在 iPad 过滤图像

1240
00:38:49,776 --> 0:38:51,086
首先 让我们看看

1241
00:38:51,086 --> 0:38:52,546
MPS 中的串行化支持

1242
00:38:52,546 --> 0:38:55,356
现在所有 MPS 内核

1243
00:38:55,356 --> 0:38:56,616
以及图表都支持安全编码

1244
00:38:57,116 --> 0:38:58,386
这允许你轻松地

1245
00:38:58,386 --> 0:38:59,996
保存网络到磁盘上和从磁盘上恢复网络

1246
00:39:01,166 --> 0:39:02,306
对于从数据源

1247
00:39:02,306 --> 0:39:03,036
加载权重的网络

1248
00:39:03,036 --> 0:39:04,286
你必须自己在数据源上

1249
00:39:04,286 --> 0:39:06,976
实现安全编码支持

1250
00:39:07,806 --> 0:39:09,946
现在 这需要支持

1251
00:39:09,946 --> 0:39:11,016
SecureCoding 属性

1252
00:39:11,136 --> 0:39:13,016
和 init 和 encode(coder) 方法

1253
00:39:13,166 --> 0:39:14,506
现在 一旦你的数据源

1254
00:39:14,506 --> 0:39:16,246
符合安全编码

1255
00:39:16,246 --> 0:39:18,716
就很容易序列化和保存图表

1256
00:39:19,276 --> 0:39:20,576
首先 我们要创建

1257
00:39:20,576 --> 0:39:22,086
一个编码器编码图表

1258
00:39:22,816 --> 0:39:23,776
然后我们会调用

1259
00:39:23,776 --> 0:39:24,606
图表上的 encode(with:coder)

1260
00:39:24,606 --> 0:39:25,886
当这种情况发生时

1261
00:39:25,886 --> 0:39:27,116
它会序列化每个

1262
00:39:27,116 --> 0:39:28,376
单独的内核 如果这些

1263
00:39:28,376 --> 0:39:30,196
内核有数据源

1264
00:39:30,196 --> 0:39:31,406
它也会序列化它们

1265
00:39:31,716 --> 0:39:33,676
这样 生成的存档文件

1266
00:39:33,676 --> 0:39:36,996
包含恢复和初始化图表所需的所有信息

1267
00:39:38,156 --> 0:39:40,666
最后 我们可以将数据保存到文件夹中

1268
00:39:41,266 --> 0:39:43,966
现在我们来看看加载它

1269
00:39:44,746 --> 0:39:45,896
因此 为了确保

1270
00:39:45,896 --> 0:39:47,436
在未存档的内核上

1271
00:39:47,436 --> 0:39:49,266
初始化正确的 metal 设备

1272
00:39:49,266 --> 0:39:50,146
我们提供给你们

1273
00:39:50,146 --> 0:39:51,076
MPSKeyedUnarchiver

1274
00:39:51,726 --> 0:39:52,926
它就像一个常规的解压缩工具

1275
00:39:52,926 --> 0:39:54,206
只是你用一个 metal 设备

1276
00:39:54,206 --> 0:39:55,606
初始化它 然后它会在

1277
00:39:55,606 --> 0:39:56,936
所有内核初始化时

1278
00:39:56,936 --> 0:39:58,086
提供这个设备

1279
00:39:58,536 --> 0:39:59,796
因此 在加载数据之后

1280
00:39:59,796 --> 0:40:01,286
我们将使用设备创建一个

1281
00:39:59,796 --> 0:40:01,286
我们将使用设备创建一个

1282
00:40:01,286 --> 0:40:01,896
解压缩工具

1283
00:40:02,386 --> 0:40:03,336
我们将在新设备上

1284
00:40:03,336 --> 0:40:06,736
恢复该图 用现在初始化了的训练网络

1285
00:40:06,736 --> 0:40:09,296
可以使用该图对新图像进行降噪

1286
00:40:09,626 --> 0:40:10,536
那么 让我们来看看

1287
00:40:10,536 --> 0:40:11,386
这个网络是如何运作的

1288
00:40:11,986 --> 0:40:15,086
这里我们把我们的降噪器

1289
00:40:15,166 --> 0:40:15,676
应用了场景中

1290
00:40:16,506 --> 0:40:17,626
顶部区域显示了

1291
00:40:17,626 --> 0:40:19,236
输入噪点图像的场景

1292
00:40:19,236 --> 0:40:19,566
是什么样的

1293
00:40:20,066 --> 0:40:21,006
中心区域显示了

1294
00:40:21,006 --> 0:40:23,486
我们降噪的结果

1295
00:40:23,486 --> 0:40:24,536
你可以看到底部区域显示了

1296
00:40:24,536 --> 0:40:25,546
真值的图像

1297
00:40:26,236 --> 0:40:27,686
正如你所看到的 降噪区域

1298
00:40:27,686 --> 0:40:29,056
看起来几乎和干净的目标

1299
00:40:29,056 --> 0:40:30,956
一样好 除了我们

1300
00:40:30,956 --> 0:40:31,846
用更少的工作

1301
00:40:31,976 --> 0:40:33,086
来实现这一点 因为

1302
00:40:33,086 --> 0:40:34,356
我们没有运行完整的光线跟踪器

1303
00:40:34,946 --> 0:40:37,846
正如你所看到的 使用 MPS

1304
00:40:37,916 --> 0:40:39,156
我们可以很容易地实现复杂的网络

1305
00:40:39,156 --> 0:40:41,066
比如降噪和风格转换

1306
00:40:42,506 --> 0:40:44,206
今年我们将对

1307
00:40:44,716 --> 0:40:46,086
推理和训练的支持

1308
00:40:46,086 --> 0:40:47,086
扩展到一类新的网络

1309
00:40:47,086 --> 0:40:49,146
特征 比如可分耗损和

1310
00:40:49,146 --> 0:40:50,136
随机数字生成

1311
00:40:50,706 --> 0:40:52,856
通过 MPSCommandBuffering

1312
00:40:52,856 --> 0:40:54,136
我们现在支持通过预测和

1313
00:40:54,136 --> 0:40:55,696
commitAndContinue 改进性能和

1314
00:40:55,696 --> 0:40:57,036
获得更好的利用率

1315
00:40:57,036 --> 0:41:00,426
并且我们通过隐式图表创建

1316
00:40:57,036 --> 0:41:00,426
并且我们通过隐式图表创建

1317
00:41:00,426 --> 0:41:01,576
使所有这些特征

1318
00:41:01,576 --> 0:41:01,996
更容易使用

1319
00:41:02,566 --> 0:41:04,946
因此 有关 MPS 和 metal 的

1320
00:41:04,946 --> 0:41:06,556
更多信息 请参见

1321
00:41:06,556 --> 0:41:09,326
在线文档和我们的示例代码

1322
00:41:09,526 --> 0:41:10,706
有关 MPS 和光线跟踪的

1323
00:41:10,706 --> 0:41:12,496
更多信息 请参见前面的

1324
00:41:12,496 --> 0:41:14,976
metal 光线跟踪视频 谢谢

1325
00:41:15,516 --> 0:41:20,500
[掌声]
