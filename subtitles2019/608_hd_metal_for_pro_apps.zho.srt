1
00:00:00,506 --> 0:00:05,500
[音乐]

2
00:00:11,516 --> 0:00:14,566
[掌声]

3
00:00:15,066 --> 0:00:17,186
&gt;&gt; 欢迎来到 Pro App Metal 会议

4
00:00:17,506 --> 0:00:19,286
我叫 Eugene 

5
00:00:19,286 --> 0:00:20,856
与 Dileep 和 Brian 一起 

6
00:00:20,856 --> 0:00:22,586
我们将来讨论一下如何利用 Metal 

7
00:00:22,586 --> 0:00:24,236
启动新的工作流

8
00:00:24,346 --> 0:00:26,416
并充分发挥 Mac 和 iPad 上

9
00:00:26,496 --> 0:00:28,076
Pro App 的所有功能

10
00:00:28,996 --> 0:00:30,636
但是什么是 Pro App 呢

11
00:00:31,156 --> 0:00:32,976
在 Apple 我们将它定义为

12
00:00:32,976 --> 0:00:35,316
从事创造性工作的专业人士

13
00:00:35,396 --> 0:00:37,666
用来进行内容创作的 App 

14
00:00:37,866 --> 0:00:39,796
包括动画设计师 电视直播

15
00:00:39,796 --> 0:00:42,616
摄影 3D 动画

16
00:00:43,286 --> 0:00:45,166
平面媒体和音频制作

17
00:00:46,146 --> 0:00:48,106
另外 它还包括

18
00:00:48,106 --> 0:00:49,496
由你们开发人员创建的

19
00:00:49,496 --> 0:00:51,106
第一方 App 和

20
00:00:51,386 --> 0:00:52,216
第三方 App

21
00:00:53,026 --> 0:00:56,926
例如 Autodesk Maya

22
00:00:57,736 --> 0:00:59,686
它是用于 3D 动画绑定

23
00:00:59,686 --> 0:01:02,456
和视觉效果

24
00:00:59,686 --> 0:01:02,456
和视觉效果

25
00:01:02,456 --> 0:01:06,076
或用于音频和音乐制作的 Logic Pro

26
00:01:06,076 --> 0:01:10,156
还有 Serif Labs Affinity Photo 

27
00:01:10,156 --> 0:01:12,056
用作专业图像编辑

28
00:01:13,106 --> 0:01:14,686
和 Blackmagic 的 DaVinci Resolve

29
00:01:15,166 --> 0:01:17,636
用作专业视频剪辑

30
00:01:18,636 --> 0:01:20,226
Pro App 一直是

31
00:01:20,226 --> 0:01:22,266
我们生态系统中重要的部分

32
00:01:22,266 --> 0:01:23,806
最近我们发布了

33
00:01:23,806 --> 0:01:26,476
全新的 Mac Pro 全新的 Pro Display

34
00:01:26,726 --> 0:01:29,356
XDR 显示器可以强力支持

35
00:01:29,356 --> 0:01:30,956
外部GPU和

36
00:01:30,956 --> 0:01:32,856
全新的搭载 A12X 仿生处理器的 iPad pro

37
00:01:33,166 --> 0:01:34,626
我们的确加倍了我们

38
00:01:34,686 --> 0:01:36,556
在这个领域的关注和承诺

39
00:01:37,526 --> 0:01:39,066
为什么 Pro App 

40
00:01:39,066 --> 0:01:40,166
如此与众不同呢

41
00:01:41,316 --> 0:01:43,156
原因之一是

42
00:01:43,156 --> 0:01:44,806
它处理的是大型数据

43
00:01:45,486 --> 0:01:47,066
最高可以处理到 8K 视频

44
00:01:47,686 --> 0:01:49,296
几十亿个多边形模块 

45
00:01:49,296 --> 0:01:51,486
数千张照片和几百个音轨

46
00:01:52,406 --> 0:01:56,466
它们也需要许多 CPU

47
00:01:56,466 --> 0:01:57,966
和高性能的 GPU

48
00:01:58,536 --> 0:02:01,246
最后 在实现实时交互

49
00:01:58,536 --> 0:02:01,246
最后 在实现实时交互

50
00:02:01,246 --> 0:02:04,726
并同时还要保持

51
00:02:04,806 --> 0:02:06,096
原始内容的完全准确的时候

52
00:02:06,096 --> 0:02:08,175
总是会出现挑战

53
00:02:08,826 --> 0:02:10,216
那么我们来看一下

54
00:02:10,485 --> 0:02:11,045
今天的日程

55
00:02:12,376 --> 0:02:14,146
首先 我们将要介绍

56
00:02:14,146 --> 0:02:15,306
我们平台上的视频编辑的流程

57
00:02:15,306 --> 0:02:17,306
讨论一下怎样

58
00:02:17,306 --> 0:02:19,476
优化它 使它能够处理 8K 内容

59
00:02:20,236 --> 0:02:21,956
接下来 我们将要讨论你们如何

60
00:02:21,956 --> 0:02:24,296
在你的 App 中添加 HDR 支持

61
00:02:25,126 --> 0:02:28,126
接下来 我们要向你们展示

62
00:02:28,126 --> 0:02:30,846
跨所有 CPU 端口和 GPU 通道的扩展

63
00:02:31,456 --> 0:02:33,406
最后 我们要讨论如何

64
00:02:33,406 --> 0:02:35,726
实现最有效的数据传输

65
00:02:36,866 --> 0:02:38,866
首先 我们聊一下

66
00:02:38,866 --> 0:02:40,646
视频编辑流程

67
00:02:40,646 --> 0:02:41,926
和 8K 内容

68
00:02:43,156 --> 0:02:44,816
在 Apple 我们将视频编辑

69
00:02:44,816 --> 0:02:46,396
视作要求最高的

70
00:02:46,606 --> 0:02:47,686
和最具创造性的工作之一

71
00:02:48,086 --> 0:02:50,186
所以我们将视频 App 作为一个用例

72
00:02:50,186 --> 0:02:52,726
来展示 Metal 是如何帮助你们的

73
00:02:53,446 --> 0:02:55,356
在此之前 我想要

74
00:02:55,356 --> 0:02:56,336
向来自 Blackmagic Design 的朋友们

75
00:02:56,336 --> 0:02:57,616
表达无比的感激之情

76
00:02:58,136 --> 0:02:58,956
我们与他们一起

77
00:02:58,956 --> 0:03:00,976
紧密地合作来优化

78
00:02:58,956 --> 0:03:00,976
紧密地合作来优化

79
00:03:01,026 --> 0:03:02,546
DaVinci Resolve 和我们的平台

80
00:03:02,546 --> 0:03:05,006
释放新的 8K 工作流

81
00:03:05,006 --> 0:03:06,436
我们真的非常自豪

82
00:03:06,436 --> 0:03:07,646
可以一起完成这件事

83
00:03:08,526 --> 0:03:10,736
但是我们来看一下当我们第一次尝试

84
00:03:10,736 --> 0:03:14,106
8K 原始内容的时候是什么样的情况

85
00:03:14,866 --> 0:03:17,016
你们看到内容不是实时的

86
00:03:17,666 --> 0:03:19,666
卡顿的情况非常严重

87
00:03:19,666 --> 0:03:20,726
这个体验不太好

88
00:03:22,026 --> 0:03:23,296
所以这样不行

89
00:03:24,176 --> 0:03:25,576
我们看看专业人士

90
00:03:25,756 --> 0:03:27,496
怎么解决这个问题

91
00:03:28,036 --> 0:03:30,706
他们有大量的 8K 原始素材

92
00:03:31,216 --> 0:03:34,386
首先 他们转码得到

93
00:03:34,386 --> 0:03:36,296
所有的基底

94
00:03:36,526 --> 0:03:38,336
然后他们二次取样

95
00:03:38,336 --> 0:03:39,696
并将他们缩放到 4K 的代理

96
00:03:40,046 --> 0:03:41,996
所以他们可以

97
00:03:41,996 --> 0:03:43,686
实时编辑和修改效果 

98
00:03:43,686 --> 0:03:45,376
但是有一个很重要的点

99
00:03:46,256 --> 0:03:48,226
你们不能给等级代理数据调色

100
00:03:48,226 --> 0:03:50,046
原因很简单 因为它不准确

101
00:03:50,626 --> 0:03:52,426
所以你现在必须返回到

102
00:03:52,426 --> 0:03:54,406
你的原始内容 在它上面应用所有的编辑

103
00:03:54,406 --> 0:03:56,386
进行离线渲染工作

104
00:03:56,386 --> 0:03:58,106
这要花费数小时

105
00:03:58,736 --> 0:04:00,636
你需要和导演反复检查

106
00:03:58,736 --> 0:04:00,636
你需要和导演反复检查

107
00:04:00,636 --> 0:04:01,656
并不断还原和重复

108
00:04:02,616 --> 0:04:04,076
在 Apple 我们想要

109
00:04:04,076 --> 0:04:05,666
为用户节省时间

110
00:04:06,586 --> 0:04:08,076
我们非常希望

111
00:04:08,076 --> 0:04:09,486
专业人士可以直接

112
00:04:09,486 --> 0:04:11,356
处理现成的 8K 内容

113
00:04:11,866 --> 0:04:12,966
那么让我来告诉你

114
00:04:13,006 --> 0:04:14,796
我们是如何实现

115
00:04:14,796 --> 0:04:16,226
实时 8K 视频剪辑的

116
00:04:17,476 --> 0:04:19,206
我们首先要构建一个

117
00:04:19,206 --> 0:04:20,875
高效的视频编辑管道流

118
00:04:21,526 --> 0:04:23,166
我们将会包含所有一般设计的

119
00:04:23,166 --> 0:04:24,916
高效的管道流

120
00:04:24,916 --> 0:04:26,516
应该使用什么样的框架 

121
00:04:26,516 --> 0:04:28,646
怎样最大化所有硬件的功能

122
00:04:29,726 --> 0:04:31,626
接下来 我们将讨论如何

123
00:04:31,626 --> 0:04:33,476
管理大型素材

124
00:04:33,996 --> 0:04:35,746
最后 我们会告诉你们一些

125
00:04:36,446 --> 0:04:37,796
当你们尝试保持

126
00:04:37,796 --> 0:04:39,166
可预测的帧频时

127
00:04:39,456 --> 0:04:41,056
可能会遇到的困难

128
00:04:41,056 --> 0:04:41,836
并且告诉你们解决的办法

129
00:04:42,986 --> 0:04:45,756
我们来探讨一下视频编辑的管道流

130
00:04:47,476 --> 0:04:49,366
这些是一般的组成部分

131
00:04:49,366 --> 0:04:52,666
是大部分视频编辑 App 需要具备的

132
00:04:53,366 --> 0:04:54,546
首先我们读取内容

133
00:04:54,546 --> 0:04:56,376
然后我们需要对其解码

134
00:04:56,376 --> 0:04:57,746
然后才能处理它们

135
00:04:57,886 --> 0:04:59,936
最后 呈现或者编码

136
00:05:00,696 --> 0:05:02,846
今天的会议上

137
00:05:02,846 --> 0:05:05,906
我的重点在于解码处理

138
00:05:05,906 --> 0:05:07,226
编码和呈现

139
00:05:07,696 --> 0:05:08,926
我们将讨论

140
00:05:08,926 --> 0:05:10,356
输入和输出块

141
00:05:10,356 --> 0:05:12,106
它们一般使用 AVFoundation 框架

142
00:05:12,696 --> 0:05:14,506
我希望你们看一下

143
00:05:14,506 --> 0:05:16,446
我们在 AVAssetReader 和

144
00:05:17,806 --> 0:05:21,226
我们来讨论一下

145
00:05:21,226 --> 0:05:23,256
如何使解码过程与 Metal 联系更紧密

146
00:05:24,696 --> 0:05:26,316
Apple 提供了一个灵活的

147
00:05:26,316 --> 0:05:27,906
低级框架叫做 Video Toolbox

148
00:05:27,906 --> 0:05:29,446
用来实现高效

149
00:05:29,806 --> 0:05:31,776
和高性能的视频处理

150
00:05:32,346 --> 0:05:34,266
它可以在 iOS macOS 和 tvOS 上使用

151
00:05:34,266 --> 0:05:36,626
支持多种格式

152
00:05:36,626 --> 0:05:38,476
并且可以利用我们设备

153
00:05:38,476 --> 0:05:40,506
上的所有硬件

154
00:05:41,526 --> 0:05:42,766
用来解码的构建块

155
00:05:42,766 --> 0:05:44,016
是一个解压缩会话

156
00:05:44,016 --> 0:05:45,696
我可以快速地

157
00:05:45,696 --> 0:05:47,006
给你展示一下怎样创建

158
00:05:47,826 --> 0:05:50,506
首先 我们来指定

159
00:05:50,506 --> 0:05:52,006
我们想使用硬件视频解码

160
00:05:53,146 --> 0:05:55,296
然后为每一个视频流

161
00:05:55,296 --> 0:05:56,596
创建一个会话

162
00:05:57,296 --> 0:05:59,366
我们在这里通过完成处理程序来创建

163
00:06:01,216 --> 0:06:04,466
我们接着往下走

164
00:06:04,466 --> 0:06:07,176
我们调用带有一个解码标志的

165
00:06:07,176 --> 0:06:08,196
的解码帧

166
00:06:08,196 --> 0:06:09,746
这对于代码非租塞

167
00:06:09,746 --> 0:06:10,976
是非常重要的

168
00:06:11,776 --> 0:06:13,156
Apple 帧解码完成

169
00:06:13,526 --> 0:06:15,246
我们的回调将会被调用

170
00:06:15,246 --> 0:06:18,016
最后请不要忘记

171
00:06:18,066 --> 0:06:20,126
在完成后将它清除

172
00:06:20,606 --> 0:06:23,666
所以现在你们知道了如何解压我们的帧

173
00:06:24,196 --> 0:06:25,776
现在我们来聊一下如何确保

174
00:06:25,776 --> 0:06:27,106
我们能够使用最优化的方法

175
00:06:27,106 --> 0:06:28,216
来完成它

176
00:06:30,066 --> 0:06:32,416
你的 Mac 可能已经安装了一些

177
00:06:32,416 --> 0:06:34,776
用来解码的硬件

178
00:06:35,186 --> 0:06:36,766
为了确保我们使用的是

179
00:06:36,766 --> 0:06:38,816
同样的零拷贝的物理内存 

180
00:06:38,816 --> 0:06:39,846
我们将会利用一个

181
00:06:39,846 --> 0:06:41,826
叫做 IOSurface 的内部对象

182
00:06:42,846 --> 0:06:45,276
IOSurface 是一个

183
00:06:45,276 --> 0:06:47,516
硬件加速图像缓存

184
00:06:47,516 --> 0:06:48,916
带有 GPU 常驻跟踪

185
00:06:49,616 --> 0:06:51,416
它还会给你提供

186
00:06:51,496 --> 0:06:53,376
进程间和框架间端口 

187
00:06:53,376 --> 0:06:55,206
给同样的 GPU 内存 

188
00:06:55,206 --> 0:06:56,666
所以这种情况下它表现极佳

189
00:06:57,696 --> 0:06:59,546
Core Video 和 Metal 提供了

190
00:07:00,046 --> 0:07:02,426
一个便捷的方法

191
00:07:02,426 --> 0:07:04,136
可以发挥 IOSurface 的优势 

192
00:07:04,186 --> 0:07:05,006
通过使用一个

193
00:07:07,196 --> 0:07:08,706
让我们来看一下怎样创建它

194
00:07:09,936 --> 0:07:12,976
在这里来创建一个

195
00:07:12,976 --> 0:07:15,286
我们的 CVMetalTextureCache

196
00:07:15,286 --> 0:07:16,686
我们想要确保我们使用 Metal 设备

197
00:07:16,686 --> 0:07:19,346
我们准备用它来进行像素处理

198
00:07:19,786 --> 0:07:22,446
接下来当我们得到一个新的 CVPixelBuffer

199
00:07:22,446 --> 0:07:24,886
我们需要将它变成 Metal 纹理的

200
00:07:25,306 --> 0:07:26,996
如果我们的像素缓存

201
00:07:26,996 --> 0:07:28,716
是由一个 IOSurface 支持的

202
00:07:28,836 --> 0:07:30,186
则无需任何成本就会自动生成

203
00:07:30,986 --> 0:07:33,206
最后不要忘记清除

204
00:07:33,206 --> 0:07:34,446
你的纹理和像素缓存

205
00:07:34,446 --> 0:07:36,336
确保可以再次使用

206
00:07:36,436 --> 0:07:39,506
在纹理缓存上

207
00:07:39,836 --> 0:07:41,556
现在我们有 MTL 纹理的帧

208
00:07:41,556 --> 0:07:43,986
而且我们准备

209
00:07:43,986 --> 0:07:45,066
做一些像素处理

210
00:07:45,366 --> 0:07:47,196
这里我们有几个选项

211
00:07:48,706 --> 0:07:50,406
当然 我们可以编写自己的

212
00:07:50,406 --> 0:07:51,896
处理和分级操作系统内核

213
00:07:52,206 --> 0:07:53,346
这很容易

214
00:07:53,346 --> 0:07:55,676
因为 Metal 的着色语言是用 C++ 写的

215
00:07:55,676 --> 0:07:58,196
同时 我们十分鼓励

216
00:07:58,196 --> 0:07:59,646
你们使用 Metal 高性能着色器

217
00:07:59,816 --> 0:08:01,946
来做像素处理

218
00:07:59,816 --> 0:08:01,946
来做像素处理

219
00:08:02,416 --> 0:08:03,446
你甚至还可以创建自己的神经网络

220
00:08:03,446 --> 0:08:05,446
作为你们管道流的一部分

221
00:08:06,826 --> 0:08:08,666
现在我们来看一下如何使用 MPS 

222
00:08:08,666 --> 0:08:10,726
运行一个典型的模糊滤镜

223
00:08:12,076 --> 0:08:13,766
首先我们来看一下 Metal 队列

224
00:08:14,276 --> 0:08:15,716
和一般缓冲

225
00:08:17,516 --> 0:08:20,356
我们创建一个高斯模糊操作系统内核

226
00:08:20,536 --> 0:08:24,346
它是 MPS 大量内核中的一个

227
00:08:24,346 --> 0:08:26,066
现在我们可以尝试

228
00:08:26,066 --> 0:08:27,926
进行编码

229
00:08:28,106 --> 0:08:29,666
我们还提供一个回调分配器

230
00:08:29,666 --> 0:08:31,996
以防失败

231
00:08:31,996 --> 0:08:34,246
最后我们提交我们的一般缓存

232
00:08:34,666 --> 0:08:36,616
MPS 是一个非常强大的框架

233
00:08:36,616 --> 0:08:40,256
适用于我们平台上的所有设备

234
00:08:40,326 --> 0:08:41,666
我们鼓励你们多阅读

235
00:08:41,666 --> 0:08:43,206
然后开始使用它

236
00:08:44,166 --> 0:08:45,576
现在我们完成了像素处理

237
00:08:45,576 --> 0:08:47,016
那么我们准备

238
00:08:47,116 --> 0:08:49,766
编码 MTL 纹理来输出格式

239
00:08:50,566 --> 0:08:52,986
当然我们会在这里再次使用

240
00:08:52,986 --> 0:08:54,936
Video Toolbox 让我给你们

241
00:08:54,936 --> 0:08:58,326
展示如何进行最高效的操作

242
00:08:58,956 --> 0:09:00,316
你的新 Mac Pro 可能会有

243
00:08:58,956 --> 0:09:00,316
你的新 Mac Pro 可能会有

244
00:09:00,316 --> 0:09:02,336
几个 GPU 每一个可能拥有

245
00:09:02,456 --> 0:09:04,196
不止一个编码引擎

246
00:09:08,936 --> 0:09:10,446
当然 我们可以让 Video Toolbox

247
00:09:10,446 --> 0:09:12,166
成为最可靠的设备

248
00:09:12,166 --> 0:09:13,996
但是在很多情况下

249
00:09:13,996 --> 0:09:15,206
你想要明确指定一个设备

250
00:09:15,276 --> 0:09:18,076
来最小化拷贝成本

251
00:09:18,326 --> 0:09:20,546
我们来看一下

252
00:09:20,546 --> 0:09:22,246
我们是如何使用 CVPixelBufferPool

253
00:09:22,246 --> 0:09:23,506
实现内存再利用的

254
00:09:28,106 --> 0:09:29,826
这是我们如何得到

255
00:09:30,056 --> 0:09:31,456
所有可利用的编码器

256
00:09:32,566 --> 0:09:34,506
首先我们使用 

257
00:09:34,876 --> 0:09:35,896
EnableHardware 标志来确保

258
00:09:35,896 --> 0:09:37,766
我们利用硬件编码

259
00:09:38,276 --> 0:09:39,996
下面 我们告诉 Video Toolbox

260
00:09:40,136 --> 0:09:41,366
我们想使用哪个设备

261
00:09:41,456 --> 0:09:43,386
这是关键的一步

262
00:09:43,386 --> 0:09:44,566
可以确保我们编码的设备和

263
00:09:44,566 --> 0:09:46,946
我们进行像素处理的设备是同一个

264
00:09:48,386 --> 0:09:49,896
还有一个非常棒的是

265
00:09:49,896 --> 0:09:51,646
我们可以使用 CVPixelBufferPool

266
00:09:51,646 --> 0:09:55,546
得到与硬件编码器格式一致的操作台

267
00:09:57,366 --> 0:09:58,836
这就是我们如何从缓存池中得到缓存

268
00:09:59,146 --> 0:10:02,666
接下来我们再次使用 MetalTextureCache

269
00:09:59,146 --> 0:10:02,666
接下来我们再次使用 MetalTextureCache

270
00:10:03,306 --> 0:10:05,506
现在我们可以转换我们的

271
00:10:05,836 --> 0:10:07,546
Interleaf 过程数据成为

272
00:10:07,546 --> 0:10:09,976
字节格式 这就是 Video Toolbox 所需要的

273
00:10:10,846 --> 0:10:12,696
和之前一样 我们清除所有东西

274
00:10:12,696 --> 0:10:17,016
使缓存可以再次使用

275
00:10:17,016 --> 0:10:18,976
现在我们可以构建

276
00:10:18,976 --> 0:10:21,256
最有效的管道流 

277
00:10:21,256 --> 0:10:22,076
它真的很棒

278
00:10:22,846 --> 0:10:24,106
我们将单独讨论呈现部分

279
00:10:24,106 --> 0:10:26,826
现在我们来简单聊一下 8K

280
00:10:28,256 --> 0:10:30,716
8K 意味着非常庞大的素材

281
00:10:31,076 --> 0:10:32,776
我们来看一下如何处理它们

282
00:10:33,786 --> 0:10:35,116
首先 我们来计算一下

283
00:10:35,636 --> 0:10:37,466
一个 8K 帧就很庞大

284
00:10:38,286 --> 0:10:40,456
它是高清帧的 16 倍

285
00:10:40,456 --> 0:10:44,256
未压缩时总共是 270 兆字节

286
00:10:44,786 --> 0:10:50,336
我们每一帧要传输近 300 兆字节

287
00:10:50,666 --> 0:10:52,296
所以每秒 30 帧

288
00:10:52,296 --> 0:10:55,016
我们就需要每秒 9 千兆字节的带宽

289
00:10:55,386 --> 0:10:57,456
这已经十分接近 PCI 总线的极限了

290
00:10:58,236 --> 0:10:59,826
另外 甚至经过

291
00:10:59,826 --> 0:11:01,916
4 乘 4 的加速 一个 10 分钟的

292
00:10:59,826 --> 0:11:01,916
4 乘 4 的加速 一个 10 分钟的

293
00:11:02,246 --> 0:11:05,256
片段就可以达到 1 太字节

294
00:11:05,796 --> 0:11:07,636
这是一个巨大的挑战

295
00:11:08,006 --> 0:11:09,216
对于实时播放来说

296
00:11:09,556 --> 0:11:11,596
我们来看一下它是什么样的

297
00:11:11,596 --> 0:11:14,996
当我们使用 Xcode 中的工具跟踪

298
00:11:15,206 --> 0:11:17,456
这是一个视频回放会话的系统跟踪

299
00:11:17,456 --> 0:11:19,546
我们之前展示过

300
00:11:20,666 --> 0:11:22,116
如果我们放大虚拟内存跟踪

301
00:11:22,116 --> 0:11:23,666
我们可以看到

302
00:11:23,666 --> 0:11:24,756
非常多折叠的页面

303
00:11:26,056 --> 0:11:27,346
并且对应的补零

304
00:11:27,426 --> 0:11:28,676
成本非常高

305
00:11:29,066 --> 0:11:30,226
我们可以在下面看到

306
00:11:31,226 --> 0:11:32,746
它就解释了

307
00:11:32,746 --> 0:11:33,986
为什么所有的解码线程 

308
00:11:33,986 --> 0:11:35,746
都会被卡住并且无法处理

309
00:11:37,066 --> 0:11:39,536
我们需要更加细心的管理缓存

310
00:11:40,086 --> 0:11:43,816
现代操作系统

311
00:11:43,816 --> 0:11:44,916
不会配置物理内存页

312
00:11:44,916 --> 0:11:46,706
直到它们被使用

313
00:11:47,096 --> 0:11:48,756
所以一旦我们开始

314
00:11:48,756 --> 0:11:50,056
从许多的解码 FATS

315
00:11:50,056 --> 0:11:51,306
访问所有这些新的内存页 我们必须要

316
00:11:51,306 --> 0:11:53,136
等待系统为我们提供

317
00:11:53,136 --> 0:11:54,116
所有这些内存页的信息

318
00:11:55,166 --> 0:11:56,516
解决的办法非常简单

319
00:11:56,816 --> 0:11:59,506
在使用前预热你的 CPU 缓存 

320
00:11:59,506 --> 0:12:01,596
确保所有的内存页

321
00:11:59,506 --> 0:12:01,596
确保所有的内存页

322
00:12:01,596 --> 0:12:05,386
在播放之前是常驻的

323
00:12:06,086 --> 0:12:07,746
现在我给你们一些

324
00:12:07,806 --> 0:12:10,946
管理内存的技巧

325
00:12:11,076 --> 0:12:12,956
每一个配置都有一个系统调用

326
00:12:13,306 --> 0:12:15,246
一个简单的方法就是

327
00:12:15,246 --> 0:12:16,586
尽早配置

328
00:12:16,816 --> 0:12:18,246
避免工作流中间来配置

329
00:12:18,966 --> 0:12:21,036
另一个好的建议就是

330
00:12:21,036 --> 0:12:22,146
一直重复利用你的缓存

331
00:12:22,556 --> 0:12:24,326
这就是为什么

332
00:12:24,326 --> 0:12:27,116
使用像 CVPixelBufferPool 和

333
00:12:27,346 --> 0:12:28,716
CVMetalTextureCache 的对象很重要

334
00:12:30,016 --> 0:12:31,746
现在我们已经提升了

335
00:12:31,746 --> 0:12:34,076
管理帧的方法 

336
00:12:34,076 --> 0:12:35,796
但是伴随着 App 的生命周期

337
00:12:35,796 --> 0:12:37,636
总是会有非常非常多

338
00:12:37,636 --> 0:12:38,926
更小的配置需要做

339
00:12:39,226 --> 0:12:41,056
让我来教你们一些管理它们的小技巧

340
00:12:41,706 --> 0:12:44,236
有了 MTLheap 我们可以

341
00:12:44,236 --> 0:12:47,216
高效管理我们所有的过渡配置

342
00:12:47,906 --> 0:12:49,106
来自 MTLheap 的配置

343
00:12:49,286 --> 0:12:51,266
不需要一个内核调用

344
00:12:51,386 --> 0:12:52,336
因为整个堆

345
00:12:52,336 --> 0:12:54,286
都在创建时间被配置了

346
00:12:54,756 --> 0:12:56,436
从系统的角度上看

347
00:12:56,436 --> 0:12:58,526
堆是一个庞大的资源

348
00:12:58,946 --> 0:13:00,826
所以它是整体常驻的

349
00:12:58,946 --> 0:13:00,826
所以它是整体常驻的

350
00:13:01,936 --> 0:13:03,366
此外 堆的配置

351
00:13:03,806 --> 0:13:06,096
可以允许更紧密的内存打包

352
00:13:06,716 --> 0:13:08,266
使用堆 你可以

353
00:13:08,266 --> 0:13:10,756
在一般缓存中给资源内存命名

354
00:13:11,036 --> 0:13:13,486
这是常规缓存无法是实现的

355
00:13:13,976 --> 0:13:15,626
我来展示一下怎么做

356
00:13:16,976 --> 0:13:18,446
在这个例子中 我们将

357
00:13:18,446 --> 0:13:20,326
重新命名过渡配置

358
00:13:20,746 --> 0:13:23,816
首先 我们使用我们的设备创建一个堆

359
00:13:24,296 --> 0:13:26,926
根据过滤的步骤 

360
00:13:27,136 --> 0:13:31,006
我们为堆的模糊内核创建一致性

361
00:13:32,046 --> 0:13:34,006
接下来 我们配置另外一个缓存

362
00:13:34,006 --> 0:13:37,146
给我们同一个堆的颜色等级一致 

363
00:13:39,216 --> 0:13:40,326
我们不再需要它们

364
00:13:40,326 --> 0:13:41,916
我们将它们标志为可命名的

365
00:13:41,916 --> 0:13:43,966
并且堆可以

366
00:13:43,966 --> 0:13:46,846
在以后的配置中重复利用这些内存

367
00:13:47,736 --> 0:13:49,596
所以当我们配置一个新的

368
00:13:49,626 --> 0:13:51,436
中间缓冲区时 堆可以

369
00:13:51,556 --> 0:13:53,566
自由的重复使用所有被标记

370
00:13:53,566 --> 0:13:55,946
为可命名的内存

371
00:13:55,946 --> 0:13:56,346
非常高效

372
00:13:57,746 --> 0:13:59,236
这是一个快速的介绍

373
00:13:59,236 --> 0:14:01,696
关于怎样管理我们的资源配置

374
00:13:59,236 --> 0:14:01,696
关于怎样管理我们的资源配置

375
00:14:02,306 --> 0:14:04,276
现在我们来讨论一下

376
00:14:04,486 --> 0:14:06,246
如何给我们的朋友呈现

377
00:14:06,646 --> 0:14:08,306
可预测的帧频

378
00:14:09,146 --> 0:14:11,216
这是一个定时的例子

379
00:14:11,416 --> 0:14:13,026
用来三倍缓冲 Metal 的 App

380
00:14:14,016 --> 0:14:15,476
在这个例子中 我们在

381
00:14:15,476 --> 0:14:18,396
60 赫兹的显示器上播放了一个 30 赫兹的视频

382
00:14:19,106 --> 0:14:20,546
注意帧在

383
00:14:20,546 --> 0:14:23,856
节奏不一致的显示器上是怎样显示的

384
00:14:24,566 --> 0:14:26,036
用户会发现卡顿的情况

385
00:14:27,386 --> 0:14:29,276
为什么会这样

386
00:14:29,806 --> 0:14:32,436
注意 CPU 是如何

387
00:14:32,436 --> 0:14:34,516
在 GPU 上工作的 

388
00:14:34,566 --> 0:14:34,896
在没有考虑节奏的情况下

389
00:14:36,516 --> 0:14:38,056
一旦第三个帧

390
00:14:38,426 --> 0:14:39,376
进入 CPU 就卡住了

391
00:14:39,736 --> 0:14:41,086
等到一个可拉的 以便可访问

392
00:14:41,176 --> 0:14:42,606
这不会发生

393
00:14:42,726 --> 0:14:45,236
直到第一帧离开屏幕

394
00:14:46,756 --> 0:14:48,716
所以这个方法最大化了 CPU 的效用

395
00:14:48,956 --> 0:14:52,366
但是却产生了可见的卡顿情况

396
00:14:53,626 --> 0:14:55,696
通常我们希望每一帧

397
00:14:55,696 --> 0:14:57,276
能够在屏幕上停留

398
00:14:57,306 --> 0:14:59,266
同样的时间

399
00:14:59,456 --> 0:15:01,296
为了解决它 Core Video 

400
00:14:59,456 --> 0:15:01,296
为了解决它 Core Video 

401
00:15:01,296 --> 0:15:03,336
提供了一个叫做 CVDisplayLink 的界面

402
00:15:03,646 --> 0:15:05,326
这是一个高精度

403
00:15:05,446 --> 0:15:07,406
的低级定时器 它能够给你发送通知

404
00:15:07,406 --> 0:15:09,616
在移位刷新率的 VBLANK 出现之前

405
00:15:11,646 --> 0:15:13,736
不是让 CPU

406
00:15:13,736 --> 0:15:14,976
排入越多的帧越好

407
00:15:14,976 --> 0:15:17,266
我们使用显示器连接

408
00:15:17,496 --> 0:15:18,986
来决定正确的时间

409
00:15:18,986 --> 0:15:20,906
向GPU提交每一帧

410
00:15:21,696 --> 0:15:24,506
这在很大程度上减少了播放的不稳定性

411
00:15:25,326 --> 0:15:26,386
让我来展示一下

412
00:15:26,386 --> 0:15:28,766
代码片段是如何做到的

413
00:15:28,966 --> 0:15:30,556
首先我们创建一个链接

414
00:15:30,556 --> 0:15:31,646
与我们将要使用的显示器连接

415
00:15:32,206 --> 0:15:35,866
接下来 我们创建一个回调处理程序

416
00:15:35,866 --> 0:15:37,896
并且对于每一个调用

417
00:15:37,966 --> 0:15:40,086
我们可以得到当前时间

418
00:15:40,086 --> 0:15:41,396
和下一次 VBLANK 的时间

419
00:15:41,996 --> 0:15:43,436
我们可以使用这些值

420
00:15:43,686 --> 0:15:44,996
确定何时发出一个当前调用

421
00:15:45,276 --> 0:15:47,876
假设我们已经处理了这些帧

422
00:15:48,486 --> 0:15:50,616
我们可以

423
00:15:50,866 --> 0:15:52,246
按照需要调整我们的期望频率

424
00:15:53,206 --> 0:15:54,566
所以这将会在很大程度上

425
00:15:54,606 --> 0:15:56,286
减少卡顿现象 但是我们还可以

426
00:15:56,286 --> 0:15:57,266
再进一步

427
00:15:58,086 --> 0:16:00,336
例如 在 60 赫兹的显示器上

428
00:15:58,086 --> 0:16:00,336
例如 在 60 赫兹的显示器上

429
00:16:00,396 --> 0:16:02,296
播放 24 赫兹的内容

430
00:16:02,666 --> 0:16:04,206
我们需要三二拆分

431
00:16:04,596 --> 0:16:06,946
这就是说我们要

432
00:16:06,946 --> 0:16:08,916
每三个 VBLANKS 播放偶数个帧

433
00:16:08,916 --> 0:16:11,066
超过两个 VBLANKS 播放奇数个帧

434
00:16:11,786 --> 0:16:13,486
这是我们想到的最佳办法

435
00:16:13,486 --> 0:16:15,076
可以解决错配问题

436
00:16:15,076 --> 0:16:16,206
我刚刚给你们展示的代码片段

437
00:16:16,206 --> 0:16:18,286
可以很好的解决它 

438
00:16:18,286 --> 0:16:20,086
但是好消息是我们还可以做得更好

439
00:16:20,836 --> 0:16:23,386
我们全新的 Pro Display XDR 支持

440
00:16:23,386 --> 0:16:26,446
多种刷新频率 包括 48 赫兹

441
00:16:26,966 --> 0:16:29,286
所以你们 24 赫兹的内容

442
00:16:29,286 --> 0:16:31,546
可以播放得相当流畅 没有卡顿

443
00:16:32,906 --> 0:16:34,696
所以我们做了相当多

444
00:16:34,696 --> 0:16:36,036
重要的优化

445
00:16:37,036 --> 0:16:38,726
现在我要给你们看一下最后结果

446
00:16:39,246 --> 0:16:40,586
这是 DaVinci Resolve 

447
00:16:41,126 --> 0:16:42,916
现在正在播放同样的 8K 流媒体

448
00:16:43,636 --> 0:16:44,866
你可以看到 播放很流畅

449
00:16:44,866 --> 0:16:46,826
没有任何卡顿

450
00:16:47,366 --> 0:16:49,876
这是一个我们

451
00:16:50,046 --> 0:16:51,596
和 Blackmagic 的完美合作

452
00:16:52,156 --> 0:16:53,576
我们一起取得了出色的成绩

453
00:16:53,816 --> 0:16:55,296
我们鼓励你

454
00:16:55,546 --> 0:16:56,716
开始使用我们的

455
00:16:56,956 --> 0:16:58,786
高性能框架

456
00:16:58,786 --> 0:17:00,286
开始为我们的平台创建

457
00:16:58,786 --> 0:17:00,286
开始为我们的平台创建

458
00:17:00,496 --> 0:17:02,366
新的和激动人心的 Pro App

459
00:17:02,856 --> 0:17:05,856
我们已经处理了 8K 中的挑战

460
00:17:06,606 --> 0:17:08,786
现在我们邀请 Dileep 

461
00:17:08,786 --> 0:17:10,896
来谈一谈我们对于 HDR 的支持

462
00:17:11,616 --> 0:17:14,195
和你们如何在你们的 App 上播放它 Dileep

463
00:17:15,516 --> 0:17:20,046
[掌声]

464
00:17:20,546 --> 0:17:21,705
&gt;&gt; 谢谢 Eugene

465
00:17:22,396 --> 0:17:24,566
近年来 高动态

466
00:17:24,566 --> 0:17:26,346
范围图像和显示器

467
00:17:26,346 --> 0:17:27,756
极大地提高了

468
00:17:27,826 --> 0:17:29,966
我们在屏幕上看到的图像的质量 

469
00:17:30,936 --> 0:17:32,876
在 Apple 我们一直在

470
00:17:33,156 --> 0:17:34,246
添加支持来提高

471
00:17:34,246 --> 0:17:36,116
图片技术

472
00:17:36,626 --> 0:17:38,466
如你们所知 我们添加了许多技术

473
00:17:38,466 --> 0:17:40,416
例如 视网膜显示器

474
00:17:40,416 --> 0:17:43,176
4K 和 5K 分辨率

475
00:17:43,466 --> 0:17:45,866
和宽色域颜色空间等

476
00:17:46,256 --> 0:17:47,796
并且已经可以使你们这些开发者

477
00:17:47,796 --> 0:17:50,166
创建出令人惊艳的

478
00:17:50,166 --> 0:17:51,826
高质量的图像

479
00:17:52,556 --> 0:17:54,326
继续刚才的部分 

480
00:17:54,326 --> 0:17:56,576
今年我们为 macOS 上的 HDR

481
00:17:56,576 --> 0:17:58,656
添加了巨大的支持

482
00:17:59,336 --> 0:18:00,726
我非常高兴

483
00:17:59,336 --> 0:18:00,726
我非常高兴

484
00:18:00,726 --> 0:18:02,806
给你们简单讲一下我们对于 

485
00:18:02,856 --> 0:18:04,406
HDR 图像和显示器的支持

486
00:18:05,376 --> 0:18:08,676
为此 我们将来讨论四个话题

487
00:18:09,376 --> 0:18:11,996
第一 我将简单地介绍一下

488
00:18:11,996 --> 0:18:14,186
HDR 图像的一些共同特性

489
00:18:15,106 --> 0:18:17,386
接下来我将介绍我们处理 HDR 的方法

490
00:18:17,386 --> 0:18:20,816
和处理 HDR 的渲染模型

491
00:18:21,066 --> 0:18:23,456
接下来我将详细地谈一谈

492
00:18:23,456 --> 0:18:26,116
如何用 Metal 处理 HDR 图像

493
00:18:26,656 --> 0:18:31,036
最后 会推荐一些最佳操作

494
00:18:32,346 --> 0:18:34,696
首先 来介绍一下

495
00:18:34,696 --> 0:18:37,216
HDR 图像的共同特性

496
00:18:37,636 --> 0:18:38,866
是什么让它们变得与众不同

497
00:18:39,956 --> 0:18:41,506
与标准动态范围图像

498
00:18:41,506 --> 0:18:44,456
或者 SDR 图像相比

499
00:18:44,856 --> 0:18:46,656
HDR 图像有更高的对比度

500
00:18:47,336 --> 0:18:48,826
它们将细节呈现得很好

501
00:18:48,826 --> 0:18:50,826
不论是黑暗区域还是明亮区域的细节

502
00:18:52,126 --> 0:18:54,476
在 SDR 图片上

503
00:18:54,476 --> 0:18:56,126
这些细节是没法辨认的

504
00:18:56,386 --> 0:18:58,426
它们要不就是变形的 要不就是被洗掉了

505
00:19:00,036 --> 0:19:03,206
HDR 图像有更多的色彩

506
00:19:03,206 --> 0:19:04,976
有更广阔的色域

507
00:19:05,486 --> 0:19:07,146
它们看起来非常真实

508
00:19:08,376 --> 0:19:10,336
同时 它们也非常明亮

509
00:19:10,826 --> 0:19:12,266
亮度信息

510
00:19:12,356 --> 0:19:15,566
被编码进了图像本身 

511
00:19:15,566 --> 0:19:17,696
拥有如此强的明亮度和对比度

512
00:19:17,696 --> 0:19:19,816
它们添加了

513
00:19:19,916 --> 0:19:21,976
场景中光照效果滤镜

514
00:19:21,976 --> 0:19:24,856
看起来更贴近真实生活

515
00:19:25,596 --> 0:19:28,176
最后 它们需要在

516
00:19:28,176 --> 0:19:29,886
可使用的显示器上观看

517
00:19:30,816 --> 0:19:32,636
可以保留图像

518
00:19:32,786 --> 0:19:34,496
所有细节的显示器上观看

519
00:19:35,026 --> 0:19:36,356
显示器本身

520
00:19:36,356 --> 0:19:38,316
具有底层技术

521
00:19:38,316 --> 0:19:41,926
能够产生高亮度 高颜色逼真度

522
00:19:41,926 --> 0:19:43,436
和出色的对比度

523
00:19:44,656 --> 0:19:47,026
我们全新的 Pro Display XDR 是一个

524
00:19:47,176 --> 0:19:49,826
很好的例子

525
00:19:50,046 --> 0:19:53,136
现在 我们如何渲染

526
00:19:53,136 --> 0:19:54,866
和展现这些 HDR 内容

527
00:19:54,866 --> 0:19:56,856
在我们的设备上呢

528
00:19:58,036 --> 0:19:59,676
在 Apple 我们有一个

529
00:19:59,676 --> 0:20:00,456
独特的方法来解决

530
00:19:59,676 --> 0:20:00,456
独特的方法来解决

531
00:20:01,076 --> 0:20:04,146
我们叫做 EDR 也就是扩展动态范围

532
00:20:05,636 --> 0:20:07,606
这种方法依靠

533
00:20:07,606 --> 0:20:09,226
我们使用的显示器上

534
00:20:09,226 --> 0:20:10,376
亮度的上方空间来展示

535
00:20:10,376 --> 0:20:12,976
HDR 图片的强光部分和阴影部分

536
00:20:13,656 --> 0:20:16,856
我来详细解释一下这个概念

537
00:20:17,276 --> 0:20:19,096
正如你们所知 设置在显示器上的

538
00:20:19,096 --> 0:20:20,716
亮度是独立的 

539
00:20:20,716 --> 0:20:22,956
它基于周围条件或环境条件

540
00:20:23,986 --> 0:20:25,606
例如 如果你在一个

541
00:20:25,606 --> 0:20:27,446
灯光昏暗的房间

542
00:20:27,446 --> 0:20:29,186
你的显示器上的亮度设置就是 200

543
00:20:29,186 --> 0:20:31,626
尼特 或者更低 

544
00:20:31,626 --> 0:20:34,366
亮度设置对于观看 SDR 内容

545
00:20:34,406 --> 0:20:37,716
是理想的选择 例如 UI 或者

546
00:20:37,716 --> 0:20:39,456
Safari 浏览器或者是 YouTube 视频

547
00:20:40,656 --> 0:20:42,736
但是如果你的显示器可以

548
00:20:42,736 --> 0:20:45,736
产生高达上千尼特的亮度

549
00:20:45,736 --> 0:20:47,396
那么你的显示器就有一个

550
00:20:47,396 --> 0:20:48,926
巨大的亮度的上方空间

551
00:20:49,566 --> 0:20:52,126
同样的 如果你在灯光明亮的条件下

552
00:20:52,126 --> 0:20:54,066
例如办公空间

553
00:20:54,626 --> 0:20:55,696
显示器的亮度设置

554
00:20:55,696 --> 0:20:58,316
会更高 例如 500 尼特

555
00:20:58,966 --> 0:21:00,586
再一次 亮度设置

556
00:20:58,966 --> 0:21:00,586
再一次 亮度设置

557
00:21:00,636 --> 0:21:03,306
对于观看 SDR 内容是理想的 

558
00:21:03,306 --> 0:21:04,806
但是你的显示器上也会有

559
00:21:04,856 --> 0:21:06,756
亮度上层空间剩下

560
00:21:06,756 --> 0:21:07,696
在这种情况下

561
00:21:08,216 --> 0:21:11,016
在处理 HDR 时 

562
00:21:11,016 --> 0:21:11,956
我们利用它

563
00:21:12,476 --> 0:21:14,596
当我们渲染像素时 

564
00:21:14,596 --> 0:21:16,726
我们将 SDR 像素映射到

565
00:21:16,726 --> 0:21:18,336
显示器上的亮度设置

566
00:21:18,766 --> 0:21:21,826
并且利用上层空间来映射 HDR 像素

567
00:21:22,396 --> 0:21:25,146
我们在多大程度上

568
00:21:25,146 --> 0:21:27,266
为这两类建立映射取决于

569
00:21:27,266 --> 0:21:28,646
查看条件 就像你

570
00:21:28,646 --> 0:21:31,586
在这两个例子里可以清楚看到的那样

571
00:21:33,216 --> 0:21:35,236
然而 渲染这个模型时

572
00:21:35,286 --> 0:21:37,356
像素需要被

573
00:21:37,476 --> 0:21:40,076
有序地组织起来

574
00:21:40,256 --> 0:21:43,236
并且我们通过缩放

575
00:21:43,236 --> 0:21:45,176
与显示器 SDR 亮度相关的

576
00:21:45,366 --> 0:21:46,466
HDR 像素来实现它

577
00:21:47,966 --> 0:21:49,786
我们使用之前的

578
00:21:49,786 --> 0:21:51,316
灯光昏暗的房间的例子 来看一看

579
00:21:51,316 --> 0:21:53,026
像素值是如何按照

580
00:21:53,026 --> 0:21:54,756
显示器的亮度排列的

581
00:21:56,266 --> 0:22:01,026
在这里 我们用 X 轴代表亮度

582
00:21:56,266 --> 0:22:01,026
在这里 我们用 X 轴代表亮度

583
00:22:01,026 --> 0:22:03,466
用 Y 轴代表标准化像素值

584
00:22:04,126 --> 0:22:06,216
在这个例子里

585
00:22:06,216 --> 0:22:09,746
显示器的亮度被设置为 200 尼特

586
00:22:10,566 --> 0:22:12,956
在我们的渲染模型中 

587
00:22:12,956 --> 0:22:14,646
我们经常将像素值

588
00:22:14,646 --> 0:22:16,396
标准化像素值设定在

589
00:22:16,396 --> 0:22:19,606
0 到 14 SDR 内容的范围内

590
00:22:19,606 --> 0:22:22,176
并且我们将它映射在显示器的亮度设置上

591
00:22:23,196 --> 0:22:25,406
所以这里的一个像素值

592
00:22:25,776 --> 0:22:28,256
代表 200 尼特

593
00:22:29,116 --> 0:22:30,736
但是你可以看到 

594
00:22:30,736 --> 0:22:32,746
显示器上有一个巨大的上层空间

595
00:22:33,186 --> 0:22:35,316
所以你拥有

596
00:22:35,316 --> 0:22:37,366
一到五的像素值 

597
00:22:37,366 --> 0:22:39,166
来呈现 HDR 内容

598
00:22:40,126 --> 0:22:42,886
一个和 SDR 范围有关的 

599
00:22:42,886 --> 0:22:44,906
5x 的标度

600
00:22:44,906 --> 0:22:46,596
可以充分利用显示器的亮度

601
00:22:47,886 --> 0:22:49,686
我们把这个标度叫做

602
00:22:50,136 --> 0:22:52,366
EDR 最大值

603
00:22:53,036 --> 0:22:54,806
如果环境条件改变

604
00:22:54,906 --> 0:22:57,146
或者是你在一个灯光明亮的房间里

605
00:22:57,146 --> 0:22:58,926
亮度上升到

606
00:22:58,926 --> 0:23:01,806
500 尼特 这时 EDR 最大值

607
00:22:58,926 --> 0:23:01,806
500 尼特 这时 EDR 最大值

608
00:23:01,806 --> 0:23:05,346
会下降 但是注意

609
00:23:05,346 --> 0:23:07,036
像素值在 0 到 1 之间

610
00:23:07,396 --> 0:23:10,196
仍然代表 SDR 内容

611
00:23:10,876 --> 0:23:12,396
但是这时它们的映射不同了

612
00:23:12,396 --> 0:23:15,246
这时一个像素值

613
00:23:15,386 --> 0:23:17,846
代表 500 尼特而不是

614
00:23:17,846 --> 0:23:19,646
刚才例子中的 200 尼特

615
00:23:20,906 --> 0:23:22,506
并且由于你现在有用的

616
00:23:22,506 --> 0:23:24,156
上层空间变小了 在这个情况下

617
00:23:24,156 --> 0:23:26,046
所以你可以呈现 HDR 内容

618
00:23:26,046 --> 0:23:29,396
的像素调用范围变小了

619
00:23:30,236 --> 0:23:32,316
所以只有 2x 在这个例子中

620
00:23:32,316 --> 0:23:34,266
与 SDR 范围相关

621
00:23:34,386 --> 0:23:36,406
用来呈现 HDR 像素

622
00:23:37,626 --> 0:23:39,666
就像你看到的 

623
00:23:39,666 --> 0:23:41,766
我们用这样一种方法安排像素

624
00:23:41,876 --> 0:23:43,816
HDR 像素与 SDR 范围有关

625
00:23:43,816 --> 0:23:46,076
并且它们根据

626
00:23:46,166 --> 0:23:47,686
SDR 范围缩放

627
00:23:48,576 --> 0:23:50,646
我们还用负像素

628
00:23:50,646 --> 0:23:53,656
来呈现 HDR 图像较暗的面

629
00:23:54,646 --> 0:23:58,116
总之 EDR 或

630
00:23:58,116 --> 0:23:59,816
外部动态范围是一个 

631
00:23:59,816 --> 0:24:01,766
与渲染模型有关的显示器 

632
00:23:59,816 --> 0:24:01,766
与渲染模型有关的显示器 

633
00:24:01,766 --> 0:24:03,296
在它里面 我们使用显示器

634
00:24:03,296 --> 0:24:04,686
可利用的上层空间

635
00:24:04,686 --> 0:24:07,386
呈现 HDR 像素

636
00:24:07,626 --> 0:24:10,186
并且我们缩放显示器上与 SDR 亮度

637
00:24:10,186 --> 0:24:12,066
有关的 HDR 像素

638
00:24:13,426 --> 0:24:16,066
使用这个模型

639
00:24:16,066 --> 0:24:18,196
你可以在

640
00:24:18,386 --> 0:24:20,196
非常多的可以设置亮度的显示器上

641
00:24:20,196 --> 0:24:23,116
做 HDR 渲染

642
00:24:23,116 --> 0:24:24,946
但是如果你们有更多可使用的显示器

643
00:24:25,126 --> 0:24:27,196
例如全新的 Pro Display XDR

644
00:24:27,646 --> 0:24:28,926
它有巨大的上层空间

645
00:24:28,926 --> 0:24:31,196
这样内容

646
00:24:31,196 --> 0:24:35,246
看起来会更好

647
00:24:35,436 --> 0:24:37,036
既然我们已经看了

648
00:24:37,036 --> 0:24:38,676
我们处理 HDR 的渲染模型

649
00:24:38,676 --> 0:24:41,416
我们再来看一看

650
00:24:41,416 --> 0:24:43,726
有哪些 API 和你们如何

651
00:24:43,726 --> 0:24:45,866
在你们的 App 上使用它们

652
00:24:48,566 --> 0:24:51,166
在 macOS 和 iOS 上 

653
00:24:51,166 --> 0:24:52,016
你有一些选择

654
00:24:52,886 --> 0:24:56,786
一 你可以使用 AVFoundation API

655
00:24:56,786 --> 0:24:58,816
这些 API 对于媒体播放 App

656
00:24:58,816 --> 0:24:59,886
来说是理想的选择

657
00:25:00,586 --> 0:25:02,646
它们可以为你们处理

658
00:25:02,646 --> 0:25:04,336
所有的色调映射和色彩管理

659
00:25:05,216 --> 0:25:07,376
二 你可以直接使用 Metal

660
00:25:08,026 --> 0:25:09,426
Metal 提供了多种选择

661
00:25:09,426 --> 0:25:11,356
具有很强的灵活性

662
00:25:12,386 --> 0:25:15,196
使用 CAMetalLayer 和 EDR API

663
00:25:15,196 --> 0:25:17,806
你可以完全控制

664
00:25:17,806 --> 0:25:19,226
你的 App 上的 HDR 渲染 

665
00:25:19,226 --> 0:25:21,146
包括色调映射

666
00:25:21,146 --> 0:25:23,066
和色彩管理

667
00:25:24,316 --> 0:25:27,316
这些 API 对于内容创作来说是理想的工具

668
00:25:28,626 --> 0:25:30,696
现在我们使用代码片段

669
00:25:30,696 --> 0:25:32,286
看一看 MetalLayer 和

670
00:25:32,286 --> 0:25:34,336
EDR API 是怎样在你的 App 中

671
00:25:34,336 --> 0:25:35,876
融为一体的 好吗

672
00:25:36,686 --> 0:25:39,086
所以你需要在你的编码基数中做的

673
00:25:39,086 --> 0:25:40,906
最重要的事是 

674
00:25:40,906 --> 0:25:43,026
检查显示器上的 EDR 支持

675
00:25:43,026 --> 0:25:45,076
并且这个屏幕是否

676
00:25:45,076 --> 0:25:47,276
可以提供你想要的性能

677
00:25:47,856 --> 0:25:50,106
接下来通常是 

678
00:25:50,146 --> 0:25:51,306
创建并设置你自己的 MetalLayer

679
00:25:52,426 --> 0:25:53,856
当你设置 MetalLayer 时

680
00:25:54,016 --> 0:25:55,906
你需要选择一个宽色域颜色空间

681
00:25:55,986 --> 0:25:58,436
来配合你的 App

682
00:25:59,466 --> 0:26:01,236
Metal 支持渲染

683
00:25:59,466 --> 0:26:01,236
Metal 支持渲染

684
00:26:01,236 --> 0:26:02,996
宽色域颜色空间 例如

685
00:26:03,106 --> 0:26:05,656
BT2020 或 B3

686
00:26:06,756 --> 0:26:08,436
接下来 你需要选择

687
00:26:08,436 --> 0:26:10,116
与你的内容匹配的转换函数

688
00:26:11,516 --> 0:26:13,386
再次说明 API 支持

689
00:26:13,386 --> 0:26:15,206
所有行业标准的

690
00:26:15,246 --> 0:26:18,116
转换函数 例如 PQ

691
00:26:18,116 --> 0:26:19,416
HLG 或 Gamma

692
00:26:20,876 --> 0:26:23,406
接下来你需要为你的 HDR 渲染

693
00:26:23,406 --> 0:26:25,166
选择像素格式

694
00:26:25,926 --> 0:26:28,606
我们推荐你们使用 float 16

695
00:26:28,606 --> 0:26:30,766
作为首选的像素格式

696
00:26:30,816 --> 0:26:32,636
它可以满足大多数的 HDR 渲染需求

697
00:26:32,636 --> 0:26:35,486
因为 float 16 

698
00:26:35,596 --> 0:26:37,116
足够精确可以

699
00:26:37,216 --> 0:26:38,376
展现 HDR 内容的

700
00:26:38,376 --> 0:26:40,096
色彩和亮度信息

701
00:26:40,646 --> 0:26:43,076
最后 在层设置

702
00:26:43,076 --> 0:26:44,646
你需要提示 Metal

703
00:26:44,966 --> 0:26:47,626
你选择加入 EDR 渲染模型

704
00:26:48,576 --> 0:26:50,066
这就是层设置的一般步骤

705
00:26:50,066 --> 0:26:52,046
你们需要这样做

706
00:26:52,446 --> 0:26:54,446
现在 进入到主渲染循环

707
00:26:54,946 --> 0:26:56,566
在主渲染循环中

708
00:26:56,566 --> 0:26:58,016
你需要得到我们刚刚谈到的

709
00:26:58,016 --> 0:26:59,166
亮度上层空间

710
00:26:59,166 --> 0:27:01,466
或是最大 EDR 信息 是吗

711
00:26:59,166 --> 0:27:01,466
或是最大 EDR 信息 是吗

712
00:27:01,796 --> 0:27:03,806
所以 NSScreen 为你们提供了

713
00:27:03,806 --> 0:27:05,346
这些性能

714
00:27:05,856 --> 0:27:07,996
但是要注意 这个性能是动态的

715
00:27:08,506 --> 0:27:09,676
它在不停地改变

716
00:27:09,676 --> 0:27:11,486
随着你的环境条件

717
00:27:11,486 --> 0:27:13,106
或是显示器的亮度改变

718
00:27:13,616 --> 0:27:15,756
所以你需要注册一个通知

719
00:27:15,756 --> 0:27:17,686
针对这个性能的每一点改变

720
00:27:17,686 --> 0:27:20,506
随着 EDR 最大值改变

721
00:27:20,686 --> 0:27:23,726
你需要修改你的内容

722
00:27:25,516 --> 0:27:27,936
现在如果你正在

723
00:27:27,936 --> 0:27:29,486
在你的 App 中处理

724
00:27:29,486 --> 0:27:30,996
色调映射和色彩管理

725
00:27:31,446 --> 0:27:32,946
你需要在你的着色器上做另外的一些

726
00:27:32,946 --> 0:27:34,686
像素处理

727
00:27:35,206 --> 0:27:36,856
我们来了解一下

728
00:27:36,916 --> 0:27:39,686
你要做的基本步骤

729
00:27:39,936 --> 0:27:43,236
一般视频进入

730
00:27:43,236 --> 0:27:44,636
YUV 色彩格式

731
00:27:45,056 --> 0:27:46,306
所以在你的 App 或着色器上

732
00:27:46,306 --> 0:27:48,046
第一步你需要做的是

733
00:27:48,116 --> 0:27:49,786
将它转换成 RGB 格式

734
00:27:50,876 --> 0:27:53,206
另外 视频内容

735
00:27:53,316 --> 0:27:54,796
编码了某种

736
00:27:54,796 --> 0:27:56,566
非线性传递函数

737
00:27:56,796 --> 0:27:57,766
例如 PQ

738
00:27:58,646 --> 0:28:00,296
所以在 shader 中下一步

739
00:27:58,646 --> 0:28:00,296
所以在 shader 中下一步

740
00:28:00,296 --> 0:28:02,576
是应用逆传递函数

741
00:28:02,576 --> 0:28:04,376
并且线性化你的像素

742
00:28:04,376 --> 0:28:06,726
接下来将它标准化到

743
00:28:06,726 --> 0:28:08,626
0 到 1 的范围内

744
00:28:10,066 --> 0:28:12,806
现在使用

745
00:28:12,886 --> 0:28:14,746
你从 NSScreen 得到的 EDR 最大值

746
00:28:14,916 --> 0:28:16,806
并缩放像素 

747
00:28:16,806 --> 0:28:17,946
按照我们在 EDR 部分讨论的那样

748
00:28:18,426 --> 0:28:21,136
现在进行编辑

749
00:28:21,136 --> 0:28:23,116
分级 或者任何

750
00:28:23,256 --> 0:28:25,286
你的 App 需要的操作

751
00:28:25,286 --> 0:28:27,646
最后来做色调映射

752
00:28:28,986 --> 0:28:30,406
如果亮度改变

753
00:28:30,406 --> 0:28:32,066
你需要用不同的参数集

754
00:28:32,066 --> 0:28:33,686
来做色调映射

755
00:28:34,556 --> 0:28:37,996
如果你的内容在一个色彩空间里

756
00:28:37,996 --> 0:28:39,526
这与播放着的不同

757
00:28:39,526 --> 0:28:41,866
那么你也

758
00:28:41,866 --> 0:28:44,006
使用适当的色彩转换

759
00:28:45,406 --> 0:28:47,116
然而 如果你不想

760
00:28:47,236 --> 0:28:48,616
色调映射或者远程处理

761
00:28:48,616 --> 0:28:49,876
而且你还需要 Metal

762
00:28:49,876 --> 0:28:51,686
来为你处理 

763
00:28:51,686 --> 0:28:52,836
你可以很容易地完成它

764
00:28:53,926 --> 0:28:55,616
当你想要创建一个 Metal Layer 时

765
00:28:56,296 --> 0:28:58,936
在它上面添加一个 EDR 元数据对象

766
00:28:59,986 --> 0:29:01,606
通常 EDR 元数据对象

767
00:28:59,986 --> 0:29:01,606
通常 EDR 元数据对象

768
00:29:01,606 --> 0:29:03,276
可以提供模板显示信息

769
00:29:03,566 --> 0:29:05,286
上的信息并且

770
00:29:05,286 --> 0:29:06,916
它还能告诉 Metal 你想要

771
00:29:06,916 --> 0:29:07,916
在像素间建立怎样的映射

772
00:29:08,836 --> 0:29:10,296
你也需要使用一个 

773
00:29:10,296 --> 0:29:12,636
Metal 中的线性颜色空间

774
00:29:13,176 --> 0:29:16,356
所以一旦你的

775
00:29:16,356 --> 0:29:19,086
像素处理全部完成 你的框架就做好了

776
00:29:19,306 --> 0:29:21,476
使用已经存在的 Metal API

777
00:29:21,606 --> 0:29:23,626
在屏幕上呈现你的框架

778
00:29:24,206 --> 0:29:27,316
正如我刚刚提到的 你需要一个

779
00:29:27,316 --> 0:29:29,496
合适的显示器 例如 Pro Display XDR

780
00:29:29,496 --> 0:29:31,676
来观看这些内容

781
00:29:32,736 --> 0:29:35,416
我们也支持 HDR 10 和 

782
00:29:35,416 --> 0:29:37,526
市场上的杜比视界 TV

783
00:29:38,636 --> 0:29:40,856
这是一个简单的介绍

784
00:29:40,856 --> 0:29:43,626
关于你如何使用 Metal layer

785
00:29:43,836 --> 0:29:46,746
和 EDR API

786
00:29:46,876 --> 0:29:47,746
在你的 App 里来做 HDR 渲染

787
00:29:48,656 --> 0:29:50,716
所以在这部分结束之前

788
00:29:51,336 --> 0:29:53,406
我们来回顾一下主要的收获

789
00:29:53,586 --> 0:29:55,826
和一些建议的最佳操作

790
00:29:58,656 --> 0:30:00,936
记住要修改和更新你的内容

791
00:29:58,656 --> 0:30:00,936
记住要修改和更新你的内容

792
00:30:00,936 --> 0:30:02,946
当亮度发生改变的时候

793
00:30:04,506 --> 0:30:06,366
使用 Float 16 作为首选的像素格式

794
00:30:06,366 --> 0:30:09,066
来满足你大多数的

795
00:30:09,066 --> 0:30:09,896
HDR 渲染需求

796
00:30:11,346 --> 0:30:13,196
当你创建 Metal Layer 时

797
00:30:13,196 --> 0:30:14,566
选择的颜色空间和转换函数

798
00:30:14,796 --> 0:30:18,396
要适应你的内容 然后任何

799
00:30:18,396 --> 0:30:19,936
额外的处理都可以

800
00:30:19,936 --> 0:30:21,446
根据需要在着色器上完成

801
00:30:22,226 --> 0:30:24,596
最后做 HDR 处理

802
00:30:24,886 --> 0:30:27,686
增加计算的上层空间

803
00:30:27,686 --> 0:30:29,226
并增加内存压力

804
00:30:30,006 --> 0:30:32,766
所以不需要色调映射如果

805
00:30:32,836 --> 0:30:34,656
你的内容色调已经有映射了 

806
00:30:35,066 --> 0:30:37,006
或者如果对你来说效果比

807
00:30:37,006 --> 0:30:39,736
颜色准确性更重要

808
00:30:40,936 --> 0:30:43,686
所以 总之 我们已经提供

809
00:30:43,686 --> 0:30:45,876
给你们高性能的 API

810
00:30:45,876 --> 0:30:47,896
一个用作 EDR 渲染模型的显示器

811
00:30:47,896 --> 0:30:50,356
iOS 和 macOS 都支持它

812
00:30:50,356 --> 0:30:53,796
并且支持我们的 Pro Display XDR 显示器

813
00:30:54,796 --> 0:30:56,816
你们可以使用这些工具

814
00:30:56,816 --> 0:30:59,330
创造令人惊艳的 HDR 内容

815
00:31:02,546 --> 0:31:03,936
在下面这个部分 我们将要

816
00:31:03,936 --> 0:31:05,856
讨论你们要如何

817
00:31:05,856 --> 0:31:07,616
使用现有的

818
00:31:07,616 --> 0:31:09,026
我们平台上的计算资源

819
00:31:09,066 --> 0:31:10,786
来达到最完美的表现

820
00:31:10,786 --> 0:31:12,756
并且告诉你们

821
00:31:12,756 --> 0:31:16,146
所有的相关信息 我邀请 Brian Ross 上台

822
00:31:17,516 --> 0:31:20,500
[掌声]

823
00:31:25,366 --> 0:31:26,016
&gt;&gt; 谢谢 Dileep

824
00:31:27,316 --> 0:31:28,926
扩展你的性能 

825
00:31:28,926 --> 0:31:30,896
使用 CPU 和 GPU

826
00:31:30,896 --> 0:31:32,386
相似性是最重要的

827
00:31:32,386 --> 0:31:34,286
并且它有时也是

828
00:31:34,286 --> 0:31:35,936
你可以最容易做到的优化

829
00:31:36,886 --> 0:31:38,206
在这个部分 我们将要讲

830
00:31:38,206 --> 0:31:40,176
几个方法来扩展你的性能 

831
00:31:40,176 --> 0:31:42,566
在你的硬件的基础上

832
00:31:43,366 --> 0:31:44,636
首先 我们来讨论一下

833
00:31:44,636 --> 0:31:46,316
Metal 是怎样帮助你跨越

834
00:31:46,316 --> 0:31:48,346
任意数量的 CPU 内核

835
00:31:49,556 --> 0:31:50,936
接下来 我将谈一下

836
00:31:50,936 --> 0:31:55,326
利用和使用异步 GPU 通道

837
00:31:56,156 --> 0:31:57,476
最后 我将要谈一下

838
00:31:57,476 --> 0:32:01,776
使用多个 GPU 的一些方法

839
00:31:57,476 --> 0:32:01,776
使用多个 GPU 的一些方法

840
00:32:02,366 --> 0:32:05,276
所以今天的主要内容是添加 

841
00:32:05,276 --> 0:32:06,146
越来越多的复杂性

842
00:32:07,276 --> 0:32:09,266
它们需要更多的 CPU 周期来

843
00:32:09,616 --> 0:32:11,486
解码框架 来构建渲染图形

844
00:32:11,486 --> 0:32:14,136
并且编码 Metal 渲染路径

845
00:32:15,446 --> 0:32:17,406
使用今天的设备上的一个 CPU 线程

846
00:32:17,406 --> 0:32:19,466
完成这些是不足够的

847
00:32:20,736 --> 0:32:22,616
最新的 iPhone 是六核的

848
00:32:23,166 --> 0:32:25,196
并且一个 Mac Pro 最高可以有 28 核

849
00:32:26,556 --> 0:32:28,756
因此可扩展的多线程体系结构

850
00:32:28,756 --> 0:32:30,516
对于我们所有设备上的

851
00:32:30,516 --> 0:32:32,006
出色表现是至关重要的

852
00:32:32,896 --> 0:32:34,696
Metal 是为多线程设计的

853
00:32:35,576 --> 0:32:37,256
在这个部分 我们来看两种方法

854
00:32:37,256 --> 0:32:40,306
使你在 CPU 上并行编码

855
00:32:40,536 --> 0:32:42,896
所以我将会

856
00:32:42,896 --> 0:32:45,466
举一个典型的视频框架的例子

857
00:32:46,216 --> 0:32:48,056
使用经典的单线程渲染

858
00:32:48,056 --> 0:32:49,736
你可以串行解码框架

859
00:32:49,736 --> 0:32:51,956
并且在一个命令缓存里

860
00:32:51,956 --> 0:32:53,576
建立命令

861
00:32:53,576 --> 0:32:55,006
来执行 GPU 的命令

862
00:32:55,786 --> 0:32:56,846
你通常还需要

863
00:32:56,936 --> 0:32:58,746
使它适应你们帧像周期

864
00:32:58,746 --> 0:32:59,426
的一小部分

865
00:33:00,386 --> 0:33:02,276
当然 你需要

866
00:33:02,276 --> 0:33:03,536
有最大延迟 因为你 

867
00:33:03,536 --> 0:33:04,856
必须要解码整个命令缓存

868
00:33:04,856 --> 0:33:07,636
在 GPU 使用它之前就完成它

869
00:33:08,176 --> 0:33:09,916
显然 还有更好的办法做到这件事

870
00:33:10,106 --> 0:33:11,506
所以我们首先将要做的是

871
00:33:11,506 --> 0:33:16,656
为 CPU 创建相似性

872
00:33:16,846 --> 0:33:18,546
渲染传输和计算路径

873
00:33:18,546 --> 0:33:20,016
是 Metal 上

874
00:33:20,016 --> 0:33:21,056
多线程的基本粒度

875
00:33:21,866 --> 0:33:23,266
你需要做的只是创建

876
00:33:23,266 --> 0:33:25,286
多个命令缓存并且

877
00:33:25,286 --> 0:33:27,096
在它们上开始处理编码路径

878
00:33:27,156 --> 0:33:27,976
在一条单独的线程上

879
00:33:28,816 --> 0:33:30,566
你可以编码任何你想要的命令

880
00:33:30,986 --> 0:33:32,956
执行的最后一个命令是

881
00:33:32,956 --> 0:33:34,356
由你添加在命令列队中的

882
00:33:34,356 --> 0:33:35,486
最后一个命令决定的

883
00:33:36,106 --> 0:33:37,906
所以现在我们来看一下

884
00:33:37,906 --> 0:33:39,000
怎样在你的代码中完成它

885
00:33:42,336 --> 0:33:43,726
编码多个命令缓存

886
00:33:43,726 --> 0:33:45,096
实际上非常简单

887
00:33:45,556 --> 0:33:47,256
第一件我们需要做的事是

888
00:33:47,256 --> 0:33:48,956
从列队中创建任意个 Metal

889
00:33:48,956 --> 0:33:51,000
命令缓存对象

890
00:33:52,436 --> 0:33:54,686
接下来我们使用

891
00:33:54,686 --> 0:33:56,166
队列等待接口

892
00:33:56,166 --> 0:33:57,426
预先执行命令

893
00:33:57,496 --> 0:33:58,416
这样很好 因为你可以

894
00:33:58,416 --> 0:33:59,686
很早完成它 并不需要

895
00:33:59,726 --> 0:34:01,666
等待编码后再完成它

896
00:33:59,726 --> 0:34:01,666
等待编码后再完成它

897
00:34:02,116 --> 0:34:05,576
最后 对于每一个命令缓存来说

898
00:34:05,576 --> 0:34:06,826
我们创建一个单独的线程

899
00:34:06,826 --> 0:34:08,426
使用异步调度队列

900
00:34:08,426 --> 0:34:10,806
和编码传递

901
00:34:10,806 --> 0:34:12,216
在框架中 就是这样

902
00:34:12,326 --> 0:34:14,235
它非常迅速也非常简单

903
00:34:15,716 --> 0:34:17,065
正如你们在例子中看到的

904
00:34:17,065 --> 0:34:18,286
我们的并行化做的很好

905
00:34:18,286 --> 0:34:19,866
通过使用多个

906
00:34:19,866 --> 0:34:21,076
Metal 命令缓存对象

907
00:34:21,076 --> 0:34:23,226
但是如果你们只有一个

908
00:34:23,226 --> 0:34:25,255
大型效果和混合过程时应该怎么办

909
00:34:26,036 --> 0:34:28,396
在这种情况下 Metal 提供了一个

910
00:34:28,396 --> 0:34:30,286
专用并行编码器

911
00:34:30,286 --> 0:34:32,606
可以让你在多个线程上编码

912
00:34:32,606 --> 0:34:34,146
不需要明确的

913
00:34:34,146 --> 0:34:36,585
划分渲染路径

914
00:34:36,585 --> 0:34:37,346
或命令缓存

915
00:34:38,096 --> 0:34:39,216
我们来看一下

916
00:34:39,216 --> 0:34:41,000
在你的 App 上做这件事是多么的容易

917
00:34:43,346 --> 0:34:44,646
在这里 第一件事我们需要做的

918
00:34:44,646 --> 0:34:46,126
是创建一个并行编码器

919
00:34:46,126 --> 0:34:47,076
在命令缓存上

920
00:34:48,196 --> 0:34:49,416
接下来我们创建任意数量的

921
00:34:49,416 --> 0:34:51,376
下级编码器 就是在这里

922
00:34:51,376 --> 0:34:53,065
我们定义 GPU 执行命令

923
00:34:53,065 --> 0:34:56,255
通过我们创建的下级命令

924
00:34:57,716 --> 0:34:58,846
接下来 我们创建一个单独的线程

925
00:34:58,846 --> 0:35:00,406
并且为每一个线程

926
00:34:58,846 --> 0:35:00,406
并且为每一个线程

927
00:35:00,406 --> 0:35:01,406
调用我们的编码功能

928
00:35:01,636 --> 0:35:02,666
在这里效果和

929
00:35:02,666 --> 0:35:03,866
混合将会被处理

930
00:35:05,326 --> 0:35:06,236
最后我们创建一个通知

931
00:35:06,236 --> 0:35:07,456
在线程已经完成

932
00:35:07,456 --> 0:35:09,616
并且我们完成

933
00:35:09,616 --> 0:35:10,716
并行编码的时候

934
00:35:10,716 --> 0:35:12,406
就像这样 这就是我们要做的所有事情

935
00:35:12,406 --> 0:35:14,266
它很简单也很高效

936
00:35:14,936 --> 0:35:16,206
所以我已经给你们展示了两个方法

937
00:35:16,206 --> 0:35:17,836
解决 CPU 的并行问题

938
00:35:18,246 --> 0:35:19,776
现在我们看 Metal 怎样帮助

939
00:35:19,776 --> 0:35:22,916
你们利用异步GPU通道

940
00:35:25,056 --> 0:35:27,626
现代的 GPU 有一个常见的性能

941
00:35:28,366 --> 0:35:29,836
它们都有许多的通道

942
00:35:29,836 --> 0:35:30,906
可以帮助你们

943
00:35:31,276 --> 0:35:33,416
异步执行 所以这意味着

944
00:35:33,416 --> 0:35:35,316
你也许可以

945
00:35:35,316 --> 0:35:36,476
在一个通道解码视频

946
00:35:36,476 --> 0:35:39,866
同时在另一个通道执行 3D 效果

947
00:35:41,226 --> 0:35:42,706
Metal 可以通过两种方法

948
00:35:42,706 --> 0:35:44,196
选取这种形式的并行化

949
00:35:44,786 --> 0:35:46,176
第一种方法就是正常的

950
00:35:46,176 --> 0:35:47,856
使用渲染传送和

951
00:35:47,856 --> 0:35:49,316
计算编码器 

952
00:35:49,316 --> 0:35:50,386
完成合适的工作

953
00:35:51,216 --> 0:35:52,346
另一种提取 Metal 并行性的方法是

954
00:35:52,346 --> 0:35:55,106
通过分析你的数据依赖

955
00:35:55,836 --> 0:35:57,176
但是这里面最重要的细节

956
00:35:57,176 --> 0:35:58,946
是这全部都是免费的

957
00:35:59,476 --> 0:36:01,366
Metal 在幕后可以为你做很多事情

958
00:35:59,476 --> 0:36:01,366
Metal 在幕后可以为你做很多事情

959
00:36:02,736 --> 0:36:03,336
我们看看是怎样做的

960
00:36:04,006 --> 0:36:06,806
我们来看看 GPU 是怎样

961
00:36:06,806 --> 0:36:08,596
提取一系列的框架

962
00:36:09,066 --> 0:36:11,186
这里我们有另外一个视频框架

963
00:36:11,186 --> 0:36:12,866
在你的 App 里 我们将要

964
00:36:12,866 --> 0:36:13,926
用 Video Toolbox 解码

965
00:36:13,926 --> 0:36:16,146
接下来是用

966
00:36:16,146 --> 0:36:17,776
传送解码器来上传帧

967
00:36:17,856 --> 0:36:19,666
从系统到 VRAM

968
00:36:20,016 --> 0:36:21,886
接下来我们将要应用筛选

969
00:36:21,886 --> 0:36:24,526
通过渲染计算和效果和混合

970
00:36:26,656 --> 0:36:27,666
这个工作可以在

971
00:36:27,666 --> 0:36:28,906
每一个帧上重复

972
00:36:29,596 --> 0:36:30,866
现在我们来看这是如何在

973
00:36:30,866 --> 0:36:33,326
CPU 和 GPU CPU上同时

974
00:36:33,326 --> 0:36:34,926
在一个时间线图中执行的

975
00:36:35,276 --> 0:36:36,506
我们还要看一下我们是否

976
00:36:36,506 --> 0:36:38,016
能做一些优化提升并发性

977
00:36:38,016 --> 0:36:38,766
在一个时间线图中

978
00:36:39,296 --> 0:36:41,556
首先我们要做的是

979
00:36:41,556 --> 0:36:43,746
编码第一帧命令

980
00:36:43,746 --> 0:36:45,796
使用独立线程上的不同编码器

981
00:36:45,796 --> 0:36:48,166
这个工作将会被安排

982
00:36:48,196 --> 0:36:49,636
并最终通过

983
00:36:49,636 --> 0:36:51,446
所有的通道执行

984
00:36:52,266 --> 0:36:53,826
然后我们继续在

985
00:36:53,826 --> 0:36:56,526
第二 三 四帧上完成它

986
00:36:57,056 --> 0:37:00,186
多亏有了 Metal 你可以看到

987
00:36:57,056 --> 0:37:00,186
多亏有了 Metal 你可以看到

988
00:37:00,186 --> 0:37:01,196
我们已经有了

989
00:37:01,196 --> 0:37:02,616
一些免费的并行化

990
00:37:03,816 --> 0:37:05,896
但是我们也可以看到存在许多的缺口

991
00:37:06,586 --> 0:37:07,596
这就意味着一些线程

992
00:37:07,596 --> 0:37:08,856
和通道是没用的

993
00:37:08,856 --> 0:37:10,506
而我们的帧像周期是宝贵的

994
00:37:11,006 --> 0:37:12,996
为了保持效率 我们

995
00:37:12,996 --> 0:37:15,006
想要尽可能地使通道饱和 

996
00:37:16,316 --> 0:37:17,976
Metal 不可能一直为我们满足所有的要求

997
00:37:17,976 --> 0:37:19,546
所以在这种情况下 

998
00:37:19,546 --> 0:37:20,926
我们要做一些优化

999
00:37:21,846 --> 0:37:23,116
你将注意到 CPU 上

1000
00:37:23,116 --> 0:37:24,916
存在巨大的缺口

1001
00:37:25,206 --> 0:37:27,516
这有许多的原因

1002
00:37:27,516 --> 0:37:29,166
但是对于简洁性来说 我要注意

1003
00:37:29,166 --> 0:37:30,076
一个共同的错误

1004
00:37:30,786 --> 0:37:31,856
有时 App 会

1005
00:37:31,856 --> 0:37:33,436
无原因地一直调用或者等待

1006
00:37:33,436 --> 0:37:35,426
直至完成 

1007
00:37:35,426 --> 0:37:36,486
在编码和提交命令缓冲区之后

1008
00:37:37,496 --> 0:37:38,986
在这种情况下 它产生了

1009
00:37:38,986 --> 0:37:41,106
巨大的缺口和泡沫

1010
00:37:41,106 --> 0:37:42,806
对于我们解码工作的时长来说

1011
00:37:43,496 --> 0:37:45,076
它也产生了一些小的缺口

1012
00:37:45,076 --> 0:37:46,486
在 GPU 的解码通道中

1013
00:37:47,306 --> 0:37:49,266
为了修复它 我们可以尝试

1014
00:37:49,266 --> 0:37:51,236
用一个 completionHandler 代替它

1015
00:37:52,086 --> 0:37:53,456
这将会避免 CPU 的堵塞

1016
00:37:53,456 --> 0:37:55,656
并且将所有的后处理放在

1017
00:37:55,656 --> 0:37:57,456
GPU 完成工作之后

1018
00:37:58,076 --> 0:38:00,426
我们试一下看看它怎么样

1019
00:37:58,076 --> 0:38:00,426
我们试一下看看它怎么样

1020
00:38:03,116 --> 0:38:04,976
你可以看到它好多了

1021
00:38:05,296 --> 0:38:07,006
现在我们使 CPU 线程保持工作状态

1022
00:38:07,006 --> 0:38:08,596
你还会注意到

1023
00:38:08,596 --> 0:38:11,006
解码通道被很好地充分使用

1024
00:38:11,296 --> 0:38:13,776
我们也仍然会看到许多缺口

1025
00:38:13,896 --> 0:38:16,146
在传送 计算 和

1026
00:38:16,146 --> 0:38:17,156
选择通道过程中

1027
00:38:18,236 --> 0:38:19,406
仔细来看你可以看到

1028
00:38:19,406 --> 0:38:20,596
一个重写依赖项

1029
00:38:20,596 --> 0:38:22,506
在这里上载

1030
00:38:22,506 --> 0:38:25,186
要等到解码完成才能开始

1031
00:38:26,266 --> 0:38:28,006
修复这个问题的一个方法是

1032
00:38:28,006 --> 0:38:30,406
提前解码 10 个帧

1033
00:38:30,916 --> 0:38:32,396
这将消除依赖性

1034
00:38:32,586 --> 0:38:34,000
我们来试一下看会发生什么

1035
00:38:37,356 --> 0:38:38,726
所以现在我们更新的资源看起来很不错

1036
00:38:39,386 --> 0:38:41,016
我们已经使视频和

1037
00:38:41,016 --> 0:38:43,056
传送通道饱和 但是

1038
00:38:43,056 --> 0:38:43,836
你会注意到

1039
00:38:43,836 --> 0:38:45,676
仍然存在一些缺口

1040
00:38:45,676 --> 0:38:46,596
在计算和渲染通道

1041
00:38:47,566 --> 0:38:49,206
和上次一样

1042
00:38:49,206 --> 0:38:50,676
你可以看到

1043
00:38:50,676 --> 0:38:51,756
还存在另外一个依赖

1044
00:38:51,756 --> 0:38:53,696
筛选无法开始直到

1045
00:38:53,696 --> 0:38:55,916
传送通道上载

1046
00:38:56,126 --> 0:38:56,666
所有数据之后

1047
00:38:58,076 --> 0:38:59,686
和刚才一样 我们可以修复它

1048
00:38:59,766 --> 0:39:02,466
通过预载入位图

1049
00:38:59,766 --> 0:39:02,466
通过预载入位图

1050
00:39:03,146 --> 0:39:05,000
它可以消除依赖

1051
00:39:08,206 --> 0:39:10,826
有了它 我们现在已经消除了

1052
00:39:10,826 --> 0:39:11,846
大部分的缺口并且

1053
00:39:11,846 --> 0:39:13,176
我们拥有非常高效的流程

1054
00:39:13,656 --> 0:39:14,966
所以现在我们已经了解了

1055
00:39:14,966 --> 0:39:16,656
GPU 通道和一些优化的例子

1056
00:39:16,656 --> 0:39:19,456
我们来看一下如何

1057
00:39:19,456 --> 0:39:22,286
继续扩展性能在

1058
00:39:22,286 --> 0:39:23,256
更多的 GPU 上

1059
00:39:25,216 --> 0:39:27,016
GPU 很快变成了一个

1060
00:39:27,066 --> 0:39:28,156
性能倍增器

1061
00:39:29,106 --> 0:39:30,436
支持更多的 GPU 可以

1062
00:39:30,436 --> 0:39:32,116
加速图形处理

1063
00:39:32,596 --> 0:39:35,486
视频编辑和提高你的整体帧频

1064
00:39:36,016 --> 0:39:38,316
在这个部分 首先我会

1065
00:39:38,316 --> 0:39:41,236
认真探讨一下 Metal 是如何

1066
00:39:41,316 --> 0:39:43,616
使用多个 GPU 配置的

1067
00:39:44,576 --> 0:39:45,766
然后我会给你们展示一些

1068
00:39:45,766 --> 0:39:47,056
高效的负载平衡策略

1069
00:39:47,056 --> 0:39:49,336
它的高效现在已被 Pro App 的开发者证明

1070
00:39:49,996 --> 0:39:51,286
最后 我将会谈一下

1071
00:39:51,286 --> 0:39:53,656
在你的 GPU 间实现同步操作

1072
00:39:55,036 --> 0:39:57,866
所以 Metal 可以为你的 Pro App 做些什么呢

1073
00:39:58,146 --> 0:39:59,626
首先 Metal 给你提供所有

1074
00:39:59,626 --> 0:40:01,516
你需要的工具来发现

1075
00:39:59,626 --> 0:40:01,516
你需要的工具来发现

1076
00:40:01,516 --> 0:40:03,776
相互关联的 GPU 和它们的作用

1077
00:40:04,666 --> 0:40:06,076
使用 Metal 可以很容易地管理

1078
00:40:06,076 --> 0:40:07,286
多个 GPU 因为

1079
00:40:07,286 --> 0:40:09,776
它们本质上只是独立的 Metal 设备对象

1080
00:40:10,166 --> 0:40:11,866
所以使用和今天同样的编程

1081
00:40:11,866 --> 0:40:13,226
在单独的 GPU 上

1082
00:40:14,306 --> 0:40:15,906
Metal 也支持崭新的

1083
00:40:16,246 --> 0:40:17,516
对等组传输 API

1084
00:40:18,286 --> 0:40:21,796
这包含远程纹理视图的概念 

1085
00:40:21,796 --> 0:40:23,926
它可以在 GPU 间拷贝数据

1086
00:40:24,866 --> 0:40:26,086
最后 Metal 提供

1087
00:40:26,136 --> 0:40:27,816
强大的共享事件

1088
00:40:27,816 --> 0:40:29,026
让你能够在 GPU 间

1089
00:40:29,026 --> 0:40:30,426
同步你的工作

1090
00:40:30,666 --> 0:40:32,106
现在我们迅速看一下

1091
00:40:32,106 --> 0:40:34,786
如何发现多个 GPU 配置

1092
00:40:36,676 --> 0:40:38,406
Metal 具备的设备性能

1093
00:40:38,406 --> 0:40:39,706
可以为每个设备找到位置

1094
00:40:40,096 --> 0:40:41,866
位置编号和最大

1095
00:40:41,866 --> 0:40:43,336
的传输速率

1096
00:40:44,116 --> 0:40:45,306
这些信息可以用作

1097
00:40:45,736 --> 0:40:47,466
确定最快的

1098
00:40:47,466 --> 0:40:49,966
托管设备和传输设备 

1099
00:40:50,696 --> 0:40:52,246
它还可以用作决定

1100
00:40:52,286 --> 0:40:53,706
一个设备是否是集成的

1101
00:40:54,056 --> 0:40:56,296
严谨的或是外部的或者甚至是

1102
00:40:56,296 --> 0:40:57,326
低性能的或是无头的

1103
00:40:58,316 --> 0:40:59,716
所以一旦我们可以使用它

1104
00:40:59,716 --> 0:41:01,756
检测多个 GPU 

1105
00:40:59,716 --> 0:41:01,756
检测多个 GPU 

1106
00:41:01,756 --> 0:41:03,796
我们就能够考虑如何

1107
00:41:03,796 --> 0:41:05,066
平衡你的负载

1108
00:41:06,636 --> 0:41:08,426
有许多许多方法可以

1109
00:41:08,426 --> 0:41:10,416
平衡 GPU 的负载

1110
00:41:10,416 --> 0:41:11,226
并且有许多不同的设计

1111
00:41:11,226 --> 0:41:12,136
当你们在选择策略的时候

1112
00:41:12,136 --> 0:41:13,756
你们需要考虑一下

1113
00:41:14,526 --> 0:41:15,626
今天的最后我们

1114
00:41:15,726 --> 0:41:17,806
我们要寻找的是一个非常简捷的

1115
00:41:17,806 --> 0:41:19,626
负载平衡策略

1116
00:41:19,676 --> 0:41:20,596
它还具有更高的等级和效率

1117
00:41:21,306 --> 0:41:22,726
我们来仔细看一下几个

1118
00:41:22,726 --> 0:41:24,036
已被证明有效的策略 一些 Pro App

1119
00:41:24,036 --> 0:41:25,956
开发者现在正在使用它们

1120
00:41:26,736 --> 0:41:27,856
第一个也是

1121
00:41:27,856 --> 0:41:31,036
最直接的方式是支持交替帧

1122
00:41:31,226 --> 0:41:32,916
它的意思是在两个 GPU 之间 

1123
00:41:32,916 --> 0:41:35,346
平衡奇偶帧

1124
00:41:35,976 --> 0:41:37,496
它能够很容易地适应

1125
00:41:37,496 --> 0:41:39,236
现有框架 还有可能

1126
00:41:39,236 --> 0:41:40,506
使你处理帧

1127
00:41:40,506 --> 0:41:41,666
的速度加倍

1128
00:41:42,316 --> 0:41:43,886
然而有时 App

1129
00:41:44,566 --> 0:41:46,376
有不同的负载 例如 UI

1130
00:41:46,376 --> 0:41:48,106
更新或图形构建 

1131
00:41:48,106 --> 0:41:51,586
这可能会使负载不平衡

1132
00:41:52,136 --> 0:41:54,156
所以我们看另外一个策略

1133
00:41:54,766 --> 0:41:58,286
这个使用小的 32 乘

1134
00:41:58,336 --> 0:42:00,746
32 的像素图块

1135
00:41:58,336 --> 0:42:00,746
32 的像素图块

1136
00:42:00,826 --> 0:42:02,546
在 GPU 间平均分配

1137
00:42:03,266 --> 0:42:05,196
所以如果你有四个 GPU

1138
00:42:05,196 --> 0:42:06,596
你可以为每个 GPU

1139
00:42:06,596 --> 0:42:07,436
预先选择图块组

1140
00:42:08,076 --> 0:42:09,626
在这里我们进行随机分配

1141
00:42:09,626 --> 0:42:11,516
为了避免与场景产生过多关联

1142
00:42:11,976 --> 0:42:13,986
这意味着图块与 GPU 的映射

1143
00:42:13,986 --> 0:42:15,916
是在帧与帧之间固定的

1144
00:42:16,406 --> 0:42:18,376
这是一个非常好的解决方法

1145
00:42:18,486 --> 0:42:20,386
可以计算大型的负载 

1146
00:42:20,386 --> 0:42:21,806
但是可能不是最好的选择

1147
00:42:21,806 --> 0:42:22,926
对于带宽密集型的 GPU 来说

1148
00:42:23,676 --> 0:42:24,916
我们仔细地来看一下

1149
00:42:24,916 --> 0:42:26,446
了解一下速率跟踪部分

1150
00:42:26,586 --> 0:42:29,886
所以这有一个相似的方法

1151
00:42:29,936 --> 0:42:31,146
它也要使用图块队列

1152
00:42:31,836 --> 0:42:32,796
在这种情况下 

1153
00:42:32,796 --> 0:42:34,136
宿主 App 可以添加

1154
00:42:34,136 --> 0:42:35,676
所有的图块到队列中

1155
00:42:36,426 --> 0:42:37,866
然后它们可以根据需要使用每一个 GPU 

1156
00:42:37,866 --> 0:42:40,026
从队列中除移

1157
00:42:40,026 --> 0:42:41,996
基于一个可以使 GPU 持续工作的算法程序 

1158
00:42:42,866 --> 0:42:44,446
这个方法可以提供非常好的 

1159
00:42:44,446 --> 0:42:45,996
负载平衡 但是它

1160
00:42:45,996 --> 0:42:46,996
增添了更多的复杂性

1161
00:42:48,306 --> 0:42:50,166
所以一旦我们决定了我们的

1162
00:42:50,166 --> 0:42:51,916
负载平衡机制 我们需要

1163
00:42:51,916 --> 0:42:54,146
考虑怎样在不同的 GPU 之间

1164
00:42:54,146 --> 0:42:55,526
同步我们的工作负载

1165
00:42:56,106 --> 0:42:58,626
为了完成它 Metal

1166
00:42:58,626 --> 0:43:00,116
提供了一些强有力的设备

1167
00:42:58,626 --> 0:43:00,116
提供了一些强有力的设备

1168
00:43:00,116 --> 0:43:01,176
叫做共享事件

1169
00:43:01,846 --> 0:43:03,506
它们可以指定

1170
00:43:03,736 --> 0:43:04,966
你们 App 中的同步点

1171
00:43:04,966 --> 0:43:07,306
在同步点中你可以等待和

1172
00:43:07,366 --> 0:43:09,286
特定的命令补全

1173
00:43:10,436 --> 0:43:12,116
这可以跨 GPU 完成

1174
00:43:12,556 --> 0:43:14,606
也可以在 CPU 和 GPU 间完成 

1175
00:43:14,606 --> 0:43:15,526
或者还可以跨进程完成

1176
00:43:16,136 --> 0:43:17,536
我们来实际应用一下

1177
00:43:18,566 --> 0:43:21,016
这里是一个例子 一个单独的

1178
00:43:21,016 --> 0:43:22,416
GPU 负载

1179
00:43:22,416 --> 0:43:24,526
对成对的帧进行动作分析

1180
00:43:25,136 --> 0:43:26,496
注意这是所有的渲染负载

1181
00:43:26,496 --> 0:43:27,746
所以我们不能

1182
00:43:27,746 --> 0:43:29,006
使用我们刚刚提到的

1183
00:43:29,386 --> 0:43:30,566
并行异步通道

1184
00:43:30,566 --> 0:43:33,556
但是如果我们有

1185
00:43:33,556 --> 0:43:35,916
两个 GPU 我们就可以将

1186
00:43:35,916 --> 0:43:36,966
这个工作分配给它们

1187
00:43:36,966 --> 0:43:38,076
来提高性能

1188
00:43:38,436 --> 0:43:40,326
所以这个策略是为了将

1189
00:43:40,326 --> 0:43:42,336
动作分析转移到第二个GPU

1190
00:43:42,906 --> 0:43:45,166
记住每一个动作传送

1191
00:43:45,166 --> 0:43:48,676
必须要分析前面一对帧

1192
00:43:49,316 --> 0:43:50,866
这就是说我们必须要等到

1193
00:43:50,866 --> 0:43:51,956
之前的帧被编写后

1194
00:43:51,956 --> 0:43:54,086
才能从动作传中送读取它们

1195
00:43:54,086 --> 0:43:56,076
并且这个动作

1196
00:43:56,146 --> 0:43:57,096
重复出现在每一对帧上

1197
00:43:57,746 --> 0:44:00,676
所以我们可以完成它通过

1198
00:43:57,746 --> 0:44:00,676
所以我们可以完成它通过

1199
00:44:00,676 --> 0:44:02,156
使用 Metal 的共享事件

1200
00:44:02,666 --> 0:44:03,886
首先 我们要提示完成

1201
00:44:03,886 --> 0:44:05,246
当帧已经完成渲染时

1202
00:44:05,246 --> 0:44:07,276
然后我们要等待提示

1203
00:44:07,276 --> 0:44:10,826
才能通过动作传送读取它们

1204
00:44:11,566 --> 0:44:13,346
有了它 我们可以安全地

1205
00:44:13,346 --> 0:44:14,886
将动作分析转给

1206
00:44:14,886 --> 0:44:17,336
第二个 GPU 和所有并行运行的项目

1207
00:44:18,056 --> 0:44:19,676
由于 Signal 和

1208
00:44:19,766 --> 0:44:21,026
Wait 在 GPU 上编码

1209
00:44:21,346 --> 0:44:23,326
你不会妨碍任何的 CPU 执行命令

1210
00:44:24,426 --> 0:44:25,896
所有现在我们看一看

1211
00:44:25,896 --> 0:44:26,876
我们怎样在代码中实现它

1212
00:44:27,526 --> 0:44:29,806
首先我们需要做的是

1213
00:44:29,806 --> 0:44:31,266
在渲染帧的设备上

1214
00:44:31,736 --> 0:44:33,786
创建一个共享事件

1215
00:44:34,576 --> 0:44:36,416
我们还要创建两个命令队列

1216
00:44:36,446 --> 0:44:37,916
每个设备一个

1217
00:44:39,116 --> 0:44:40,796
现在去渲染帧

1218
00:44:40,796 --> 0:44:42,006
我们创建一个命令缓存并且编码

1219
00:44:42,236 --> 0:44:44,676
然后立刻编码

1220
00:44:44,676 --> 0:44:46,286
一个提示事件来提醒

1221
00:44:46,286 --> 0:44:47,566
其他的 GPU 我们已经完成

1222
00:44:48,606 --> 0:44:50,356
最后 编码动作

1223
00:44:50,356 --> 0:44:54,426
首先我们要

1224
00:44:54,426 --> 0:44:55,576
从队列里创建一个命令缓存

1225
00:44:56,096 --> 0:44:57,496
然后立刻编码一个等待事件

1226
00:44:57,496 --> 0:45:00,416
避免在我们完成前读取帧

1227
00:44:57,496 --> 0:45:00,416
避免在我们完成前读取帧

1228
00:45:01,466 --> 0:45:02,666
然后我们编码动作分析

1229
00:45:02,666 --> 0:45:04,786
并提交 就像你们看到的

1230
00:45:04,786 --> 0:45:05,876
它是一个相当

1231
00:45:05,986 --> 0:45:08,186
直接的过程 并且它也非常强大

1232
00:45:08,576 --> 0:45:10,576
在我继续之前 我们看一下

1233
00:45:10,576 --> 0:45:12,196
我们工具里的

1234
00:45:12,516 --> 0:45:14,916
多个 GPU 和通道是怎样的

1235
00:45:15,486 --> 0:45:18,726
所以 Metal System Trace 展示了

1236
00:45:18,726 --> 0:45:21,146
每一个你的测试 GPU 上的工作

1237
00:45:21,616 --> 0:45:23,446
在这个例子中我们有四个 GPU

1238
00:45:23,446 --> 0:45:26,536
一个内部的 三个外部的 GPU

1239
00:45:26,876 --> 0:45:30,156
每一个 GPU 都具有

1240
00:45:30,436 --> 0:45:32,166
细节可见性 通过展示

1241
00:45:32,166 --> 0:45:34,116
跨所有通道的异步工作负载

1242
00:45:34,116 --> 0:45:35,936
并且它用相关的符号名

1243
00:45:35,996 --> 0:45:39,116
映射了这些工作负载

1244
00:45:39,706 --> 0:45:42,416
在活动总结中

1245
00:45:42,416 --> 0:45:43,616
你可以看到所有的

1246
00:45:43,616 --> 0:45:45,246
执行数据 它们是关于所有的

1247
00:45:45,246 --> 0:45:46,286
相关联的 GPU

1248
00:45:47,566 --> 0:45:48,956
你甚至可以更进一步

1249
00:45:49,016 --> 0:45:50,246
看到更多细节通道信息

1250
00:45:50,246 --> 0:45:53,536
关于任意 GPU 的每一帧的信息

1251
00:45:54,296 --> 0:45:55,676
这包括上一页和

1252
00:45:55,676 --> 0:45:56,926
下一页的信息 在传送

1253
00:45:56,926 --> 0:45:59,716
通道或计算和渲染工作负载中

1254
00:46:00,686 --> 0:46:02,266
你甚至可以看到

1255
00:46:02,266 --> 0:46:03,666
IOSurface 访问

1256
00:46:04,336 --> 0:46:05,476
正如 Eugene 提到的 这是

1257
00:46:05,476 --> 0:46:06,536
非常有用的

1258
00:46:06,536 --> 0:46:07,896
因为许多 Pro App 需要

1259
00:46:07,896 --> 0:46:10,976
使用 IOSurfaces 

1260
00:46:11,406 --> 0:46:13,886
IOSurfaces 对于框架互操作性非常重要

1261
00:46:14,446 --> 0:46:17,546
最后 我们的工具

1262
00:46:17,546 --> 0:46:19,896
提供 Metal 事件和共享事件的可见性

1263
00:46:19,896 --> 0:46:22,096
所以你可以看到

1264
00:46:22,096 --> 0:46:23,646
提示事件和等待事件在哪里发生

1265
00:46:24,466 --> 0:46:26,896
它还展示了使用了多少毫秒

1266
00:46:27,386 --> 0:46:29,366
等待和绘制

1267
00:46:28,756 --> 0:46:29,366
你需要遵循的依赖线

1268
00:46:30,596 --> 0:46:31,606
最后在最底部

1269
00:46:31,746 --> 0:46:32,736
甚至还有一个详细的列表

1270
00:46:32,736 --> 0:46:34,786
记录你们在活动总结中的事件

1271
00:46:35,446 --> 0:46:37,096
所以 Metal system trace 是一个非常棒的

1272
00:46:37,146 --> 0:46:38,796
工具 可以满足你的 Pro App 的所有需要

1273
00:46:39,626 --> 0:46:40,626
所以现在我们明白了怎样

1274
00:46:40,626 --> 0:46:42,846
使用多个 GPU

1275
00:46:42,846 --> 0:46:45,476
我们来看一下怎样在它们之间传输数据

1276
00:46:46,976 --> 0:46:48,646
在 CPU 和 GPU 间

1277
00:46:48,646 --> 0:46:49,936
扩展性能是极其重要的

1278
00:46:49,936 --> 0:46:51,676
但是在今天的最后

1279
00:46:51,676 --> 0:46:53,666
你的 Pro App 只是

1280
00:46:53,666 --> 0:46:55,016
和它最慢的地方一样快

1281
00:46:55,856 --> 0:46:57,236
当你传输大量的

1282
00:46:57,236 --> 0:46:59,776
8K 帧时 你的数据传输

1283
00:46:59,776 --> 0:47:01,286
可以很快地变成瓶颈

1284
00:46:59,776 --> 0:47:01,286
可以很快地变成瓶颈

1285
00:47:01,896 --> 0:47:04,396
在这部分 我们将要

1286
00:47:04,396 --> 0:47:05,276
讨论一下带宽的注意事项

1287
00:47:05,276 --> 0:47:08,436
和它们与全新的 Mac Pro 的关系

1288
00:47:09,476 --> 0:47:11,806
然后我会概述一些 Metal

1289
00:47:11,806 --> 0:47:13,746
对等组转移策略

1290
00:47:14,126 --> 0:47:15,156
其中一些策略

1291
00:47:15,156 --> 0:47:16,796
现在已经被 Pro App 开发者所使用

1292
00:47:17,276 --> 0:47:18,316
最后我会给你们讲一个

1293
00:47:18,356 --> 0:47:20,186
使用的例子来展示

1294
00:47:20,186 --> 0:47:21,676
Infinity Fabric Link 是怎样

1295
00:47:21,676 --> 0:47:23,656
帮助解决具有挑战性的工作流的

1296
00:47:24,286 --> 0:47:27,496
首先我们看一下

1297
00:47:27,496 --> 0:47:29,636
我们关键的连接点的传输速率 

1298
00:47:29,986 --> 0:47:31,866
在这我们的基点是 PCI Express

1299
00:47:31,906 --> 0:47:33,696
gen 3 有 16 个链接

1300
00:47:34,846 --> 0:47:36,206
所以首先我们有 Thunderbolt 3

1301
00:47:36,206 --> 0:47:38,586
实际使用中它的最大输出

1302
00:47:38,586 --> 0:47:41,076
大约是 PCI Express 速率的四分之一

1303
00:47:41,486 --> 0:47:42,846
它是一个非常棒的可扩展的方法

1304
00:47:42,846 --> 0:47:44,456
来计算大规模的工作流

1305
00:47:44,456 --> 0:47:45,996
但是它可能不是最佳的选择

1306
00:47:46,076 --> 0:47:47,386
对于带宽密集型的来说

1307
00:47:48,146 --> 0:47:51,096
接下来我们有两个 GPU 

1308
00:47:51,096 --> 0:47:52,256
每个都有它们自己的 PCI 通道

1309
00:47:52,576 --> 0:47:53,936
这可以使你的带宽增加一倍

1310
00:47:55,026 --> 0:47:57,096
这周我们有了

1311
00:47:57,096 --> 0:47:58,706
全新的 Infinity Fabric Link 和

1312
00:47:58,826 --> 0:48:00,006
对等组传输 API

1313
00:47:58,826 --> 0:48:00,006
对等组传输 API

1314
00:48:00,596 --> 0:48:02,036
它可以在 GPU 间传输数据

1315
00:48:02,036 --> 0:48:04,046
以五倍于

1316
00:48:04,046 --> 0:48:07,166
PCI Express 的速度传输

1317
00:48:07,606 --> 0:48:09,526
所以现在我们来看一下常见的

1318
00:48:09,616 --> 0:48:10,786
Mac Pro 配置

1319
00:48:11,596 --> 0:48:13,156
这个图表展示了许多

1320
00:48:13,156 --> 0:48:15,196
带宽密集型的配置

1321
00:48:16,146 --> 0:48:17,556
在这我们有一个新的 Apple Afterburner

1322
00:48:17,556 --> 0:48:19,056
它有自己的

1323
00:48:19,056 --> 0:48:20,346
专门 PCI 通道

1324
00:48:21,226 --> 0:48:22,876
我们还有两个内部 GPU

1325
00:48:22,876 --> 0:48:24,616
有它们专属的 PCI 通道

1326
00:48:25,496 --> 0:48:26,716
最后你可以链接

1327
00:48:26,816 --> 0:48:28,456
通过 Infinity Fabric Link 这些 GPU

1328
00:48:28,526 --> 0:48:31,566
实现它们之间快速复制数据

1329
00:48:32,976 --> 0:48:34,476
Mac Pro 也可以使你

1330
00:48:34,476 --> 0:48:36,356
拥有最多四个内部 GPU

1331
00:48:36,356 --> 0:48:38,336
它们分享两套 CPI 通道

1332
00:48:39,226 --> 0:48:40,456
因为通道是分享的 

1333
00:48:40,456 --> 0:48:41,726
它将自己借给一个

1334
00:48:41,726 --> 0:48:43,156
可能有更多计算的 Pro App

1335
00:48:43,766 --> 0:48:45,516
在这种情况下 你也可以

1336
00:48:45,516 --> 0:48:47,126
与 Infinity Fabric Link 链接

1337
00:48:47,706 --> 0:48:51,506
所以有许多许多的方法

1338
00:48:51,506 --> 0:48:53,466
管理这些传输策略

1339
00:48:53,886 --> 0:48:55,026
我要来谈一些

1340
00:48:55,026 --> 0:48:56,676
已验证的策略 一些

1341
00:48:56,676 --> 0:48:57,926
Pro App 开发者现在正在使用它们

1342
00:48:59,186 --> 0:49:00,866
最直接的方法是

1343
00:48:59,186 --> 0:49:00,866
最直接的方法是

1344
00:49:00,866 --> 0:49:03,496
传输整个帧来播放

1345
00:49:04,196 --> 0:49:06,646
前提是处理替换帧

1346
00:49:06,986 --> 0:49:08,206
任何在辅助设备上

1347
00:49:08,206 --> 0:49:09,846
处理后的帧都可以

1348
00:49:09,846 --> 0:49:10,876
快速传输到

1349
00:49:10,876 --> 0:49:12,926
显示器附带的 GPU 上 

1350
00:49:13,236 --> 0:49:16,516
然后发送到显示器上

1351
00:49:16,516 --> 0:49:17,926
另一个传输策略是

1352
00:49:17,926 --> 0:49:20,566
将图块发送给每一个 GPU 

1353
00:49:20,566 --> 0:49:22,546
它们是整个帧重要的部分

1354
00:49:23,376 --> 0:49:24,736
所有在辅助设备上处理的

1355
00:49:24,736 --> 0:49:26,146
图块可以被发送到

1356
00:49:26,146 --> 0:49:27,956
显示器 GPU

1357
00:49:27,956 --> 0:49:29,276
然后重建为

1358
00:49:29,276 --> 0:49:30,526
最终输出图像的一部分

1359
00:49:31,566 --> 0:49:33,246
这个结果可以实现很好的负载平衡

1360
00:49:34,186 --> 0:49:36,956
所以我们已经快速浏览了两个策略

1361
00:49:37,336 --> 0:49:39,066
现在我们看一个很好的例子

1362
00:49:39,066 --> 0:49:42,646
关于 Pro App 实际利用 

1363
00:49:43,556 --> 0:49:45,316
所以在过去的六个月

1364
00:49:45,316 --> 0:49:46,976
我有机会与

1365
00:49:46,976 --> 0:49:48,716
Final Cut Pro 团队合作

1366
00:49:49,426 --> 0:49:51,056
他们做出了一些出色的成绩

1367
00:49:51,056 --> 0:49:52,746
来优化全新的 Mac Pro

1368
00:49:53,536 --> 0:49:55,496
他们可以扩展到 28 个 CPU 内核

1369
00:49:55,496 --> 0:49:58,066
和所有的内部 GPU

1370
00:49:58,916 --> 0:50:00,376
他们也充分利用了

1371
00:49:58,916 --> 0:50:00,376
他们也充分利用了

1372
00:50:00,376 --> 0:50:01,436
Infinity Fabric Link

1373
00:50:02,026 --> 0:50:03,416
这使他们能够

1374
00:50:03,526 --> 0:50:06,286
实时编辑多个 8K

1375
00:50:06,286 --> 0:50:06,976
ProRes 视频流

1376
00:50:08,406 --> 0:50:09,836
现在我们来详细了解一下

1377
00:50:09,836 --> 0:50:10,886
它是如何工作的

1378
00:50:12,306 --> 0:50:13,516
这有一个简单的

1379
00:50:13,516 --> 0:50:14,956
时间线图向你们展示了

1380
00:50:14,956 --> 0:50:16,886
视频流从 CPU

1381
00:50:14,956 --> 0:50:16,886
移动到显示器的过程

1382
00:50:17,716 --> 0:50:19,816
在这里我们重点看

1383
00:50:19,876 --> 0:50:22,136
三个带有一些效果的 8k ProRes 

1384
00:50:22,136 --> 0:50:23,796
原始视频流的回放

1385
00:50:24,816 --> 0:50:26,536
这就是它们在一个单独的 GPU 上的样子

1386
00:50:28,116 --> 0:50:29,536
首先 我们在 CPU 上

1387
00:50:29,536 --> 0:50:30,636
编码第一帧命令

1388
00:50:31,706 --> 0:50:33,536
然后上传所有三个视频流

1389
00:50:33,536 --> 0:50:34,946
通过 PCI 传到 VRAM

1390
00:50:36,166 --> 0:50:38,206
最后我们处理这些视频流

1391
00:50:38,206 --> 0:50:40,486
使用 GPU 和显示器上的效果处理

1392
00:50:41,016 --> 0:50:43,276
我们继续处理

1393
00:50:43,276 --> 0:50:44,736
每一个附加帧

1394
00:50:45,876 --> 0:50:47,186
我们可以按照自己的想法使它

1395
00:50:47,186 --> 0:50:48,696
适合我们 30 帧每秒的速度

1396
00:50:48,696 --> 0:50:50,466
它不能完成

1397
00:50:50,846 --> 0:50:52,316
有太多的工作

1398
00:50:52,316 --> 0:50:53,286
被塞进这个空间

1399
00:50:53,626 --> 0:50:55,926
一个 Pro App 将会丢掉至少 30% 

1400
00:50:55,926 --> 0:50:57,296
的帧 在这种情况下

1401
00:50:57,936 --> 0:50:58,916
现在我们来看一下

1402
00:50:58,916 --> 0:51:00,826
在双 GPU 的系统上完成的怎么样

1403
00:50:58,916 --> 0:51:00,826
在双 GPU 的系统上完成的怎么样

1404
00:51:02,046 --> 0:51:04,456
首次 我们编码第一帧

1405
00:51:04,456 --> 0:51:05,466
和上面的例子一样

1406
00:51:06,546 --> 0:51:08,846
对第二帧也同样这么做

1407
00:51:09,386 --> 0:51:10,606
现在这看起来很棒

1408
00:51:10,606 --> 0:51:12,976
我们在这使它并行了

1409
00:51:13,306 --> 0:51:14,696
但是我们也使帧频也变为两倍了吗

1410
00:51:15,406 --> 0:51:16,796
不幸的是 我们没有做到

1411
00:51:17,456 --> 0:51:20,356
问题出在任何

1412
00:51:20,356 --> 0:51:21,516
我们已经在辅助设备上

1413
00:51:21,516 --> 0:51:23,136
处理过的帧必须要

1414
00:51:23,136 --> 0:51:24,996
被写回显示器附带的设备上时

1415
00:51:24,996 --> 0:51:27,096
这就是事情的难点

1416
00:51:27,766 --> 0:51:30,256
为了得到显示器 GPU

1417
00:51:30,256 --> 0:51:33,106
我们必须要复制一个 265 兆字节的

1418
00:51:33,106 --> 0:51:35,936
输出缓冲区通过 PCI 在宿主 App 上 

1419
00:51:35,936 --> 0:51:37,566
然后我们从这再一次复制

1420
00:51:37,566 --> 0:51:39,246
到显示器附带的 GPU 上

1421
00:51:40,606 --> 0:51:43,206
这最多需要 48 毫秒

1422
00:51:43,626 --> 0:51:45,136
现在 我们接着说

1423
00:51:45,136 --> 0:51:46,516
第三帧和第四帧 给你们一个

1424
00:51:46,516 --> 0:51:48,000
更好的画面

1425
00:51:50,436 --> 0:51:51,746
并且你们可以很快发现

1426
00:51:51,746 --> 0:51:52,866
我们使用相当多的

1427
00:51:52,866 --> 0:51:54,936
PCI 带宽 但是我们还是

1428
00:51:54,936 --> 0:51:56,856
看到许多缺口和依赖

1429
00:51:57,296 --> 0:51:58,406
我们仍然比

1430
00:51:58,406 --> 0:52:00,076
单个 GPU 做得好

1431
00:51:58,406 --> 0:52:00,076
单个 GPU 做得好

1432
00:52:00,076 --> 0:52:01,496
但是它并不能使帧速率加倍

1433
00:52:02,386 --> 0:52:04,306
所有的这个 PCI 流量会导致 

1434
00:52:04,306 --> 0:52:05,586
丢失一些帧

1435
00:52:06,146 --> 0:52:09,076
但是为了改进这个地方

1436
00:52:09,376 --> 0:52:11,186
Mac Pro 有了新的

1437
00:52:11,186 --> 0:52:12,456
Infinity Fabric Link 特性

1438
00:52:12,456 --> 0:52:13,586
它拥有了对等组 API

1439
00:52:14,056 --> 0:52:16,776
它完全取代了 GPU 拷贝

1440
00:52:18,436 --> 0:52:20,046
你可以在这里看到是 Infinity

1441
00:52:20,046 --> 0:52:22,316
Fabric Link 传输变得快了很多

1442
00:52:23,046 --> 0:52:24,666
它也释放了相当数量的

1443
00:52:24,666 --> 0:52:27,576
PCI 带宽

1444
00:52:27,576 --> 0:52:30,226
并且使用这些带宽我们可以更早的上传帧

1445
00:52:32,256 --> 0:52:33,786
Infinity Fabric Link 

1446
00:52:33,786 --> 0:52:35,956
也在自己的并行 GPU 通道上运行

1447
00:52:36,526 --> 0:52:37,576
这就是说我们可以传输数据

1448
00:52:37,576 --> 0:52:39,216
并且同时使用渲染

1449
00:52:39,216 --> 0:52:40,596
和计算通道

1450
00:52:41,916 --> 0:52:42,846
这帮助我们提高准确性

1451
00:52:42,846 --> 0:52:44,486
并隐藏潜在因素

1452
00:52:44,856 --> 0:52:48,006
最后 它可以帮助你的 Pro App 处理

1453
00:52:48,316 --> 0:52:49,776
具有挑战性的工作负荷 

1454
00:52:49,776 --> 0:52:50,646
并且支持新的情况

1455
00:52:51,346 --> 0:52:52,406
所以这就是它在一个无聊

1456
00:52:52,406 --> 0:52:53,786
的时间线图上的样子

1457
00:52:54,376 --> 0:52:56,076
但是现在我们来看一下动态的样子

1458
00:52:56,666 --> 0:52:59,336
这是 Final Cut Pro 的样片

1459
00:52:59,336 --> 0:53:00,296
在刚刚的演示中

1460
00:52:59,336 --> 0:53:00,296
在刚刚的演示中

1461
00:53:00,886 --> 0:53:01,856
你可以看到

1462
00:53:01,856 --> 0:53:03,776
它播放了很多 8K 视频流

1463
00:53:03,776 --> 0:53:05,336
同时带有效果和转换

1464
00:53:05,336 --> 0:53:08,316
这也是实时完成的

1465
00:53:08,316 --> 0:53:09,806
利用多个 GPU

1466
00:53:09,806 --> 0:53:10,776
和 Infinity Fabric Link

1467
00:53:11,776 --> 0:53:13,556
Final Cut Pro 是

1468
00:53:13,556 --> 0:53:15,356
利用高效数据传输的

1469
00:53:15,586 --> 0:53:17,066
Pro App 的典范

1470
00:53:17,376 --> 0:53:19,136
在结束这一小节之前

1471
00:53:19,136 --> 0:53:21,156
让我们来看看

1472
00:53:21,156 --> 0:53:22,846
如何在代码中使用

1473
00:53:22,966 --> 0:53:25,336
Infinity Fabric Link 和对等授权

1474
00:53:25,336 --> 0:53:25,796
传输组 API

1475
00:53:26,466 --> 0:53:29,456
你需要做的第一件事

1476
00:53:29,976 --> 0:53:31,756
是检测这些连接

1477
00:53:32,176 --> 0:53:33,666
为方便该操作 Metal

1478
00:53:33,666 --> 0:53:35,376
定义了一个全新的对等组 API

1479
00:53:35,376 --> 0:53:37,626
在 Metal 设备上定义了

1480
00:53:37,626 --> 0:53:40,546
对等组 ID 索引和计数的属性

1481
00:53:41,866 --> 0:53:43,146
通过这种方式 你就可以检测到

1482
00:53:43,146 --> 0:53:44,836
是否已经连接GPU

1483
00:53:44,836 --> 0:53:46,726
是否有共享 PCI 通道

1484
00:53:46,726 --> 0:53:47,546
或双 PCI 通道

1485
00:53:47,916 --> 0:53:49,206
更重要的是 

1486
00:53:49,206 --> 0:53:52,046
你可以用它来确定

1487
00:53:52,046 --> 0:53:53,756
最佳配置

1488
00:53:53,756 --> 0:53:54,886
并根据带宽限制

1489
00:53:54,886 --> 0:53:56,016
扩展性能

1490
00:53:58,226 --> 0:53:59,296
接下来就是如何在

1491
00:53:59,296 --> 0:54:00,746
GPU 之间传输数据

1492
00:53:59,296 --> 0:54:00,746
GPU 之间传输数据

1493
00:54:01,226 --> 0:54:02,766
首先 你需要

1494
00:54:02,766 --> 0:54:04,366
利用辅助设备

1495
00:54:04,366 --> 0:54:05,476
创建共享事件

1496
00:54:06,396 --> 0:54:08,466
我们还创建了渲染纹理

1497
00:54:08,466 --> 0:54:10,006
和远程纹理视图

1498
00:54:10,436 --> 0:54:11,616
远程视图会给你的

1499
00:54:11,616 --> 0:54:13,926
显示器附加一个 GPU 通道

1500
00:54:14,036 --> 0:54:15,396
访问辅助纹理

1501
00:54:17,016 --> 0:54:18,846
接下来 我们要创建一个编码器和渲染

1502
00:54:20,136 --> 0:54:20,976
紧接着要马上

1503
00:54:24,416 --> 0:54:26,066
现在 显示器上

1504
00:54:26,066 --> 0:54:27,446
创建了一个 blit 命令缓冲区

1505
00:54:29,826 --> 0:54:31,046
所以 我们先等渲染完成

1506
00:54:31,046 --> 0:54:32,826
再进行数据传输

1507
00:54:33,446 --> 0:54:36,406
最后 我们用纹理视图

1508
00:54:36,406 --> 0:54:39,026
进行复制 就是这样 非常简单

1509
00:54:41,596 --> 0:54:43,446
使用 Metal 的对等组 API

1510
00:54:43,596 --> 0:54:45,436
来优化 Infinity Fabric Link

1511
00:54:45,676 --> 0:54:47,336
可以通过降低 PCI 带宽

1512
00:54:47,336 --> 0:54:49,196
极大的扩大工作量

1513
00:54:49,726 --> 0:54:51,516
还可以通过并行通道

1514
00:54:51,846 --> 0:54:53,086
来提高并行性

1515
00:54:53,846 --> 0:54:55,026
在结束之前

1516
00:54:55,026 --> 0:54:57,306
让我们再看一个

1517
00:54:57,376 --> 0:54:58,846
非常棒的 Pro App

1518
00:55:00,366 --> 0:55:01,616
我要非常开心地分享一个

1519
00:55:01,616 --> 0:55:03,266
使用 Serif Labs 制作的

1520
00:55:03,266 --> 0:55:04,176
Affinity Photo 的样片

1521
00:55:04,746 --> 0:55:05,916
Serif 的工程师利用 Metal

1522
00:55:05,916 --> 0:55:08,266
完成了一件非常伟大的工作

1523
00:55:08,626 --> 0:55:10,836
他们特别 特别出众地

1524
00:55:10,836 --> 0:55:12,676
向我们展示了

1525
00:55:12,676 --> 0:55:14,686
如何正规利用平台资源

1526
00:55:15,266 --> 0:55:16,836
处理一个传统的文档

1527
00:55:16,836 --> 0:55:18,256
使用单核 CPU 的处理速度

1528
00:55:18,256 --> 0:55:20,126
比使用八核 CPU 

1529
00:55:20,396 --> 0:55:22,296
要快 10 倍

1530
00:55:23,186 --> 0:55:23,936
我们来看一下

1531
00:55:25,566 --> 0:55:26,876
在这个例子里 

1532
00:55:26,876 --> 0:55:29,126
Affinity 将会合成一个

1533
00:55:29,126 --> 0:55:30,296
大型的文档 名字叫

1534
00:55:30,336 --> 0:55:30,936
rabbit trick

1535
00:55:31,726 --> 0:55:32,996
如视频中演示的一样

1536
00:55:32,996 --> 0:55:34,796
它有几百个巨大的图层

1537
00:55:35,026 --> 0:55:37,196
将以 4K 分辨率合成

1538
00:55:38,156 --> 0:55:39,456
有些图层具有像素数据

1539
00:55:39,456 --> 0:55:41,466
而有些图层有程序调整

1540
00:55:42,446 --> 0:55:46,056
这就需要实时的分层合成

1541
00:55:46,056 --> 0:55:47,406
同时也会给 CPU 和 GPU

1542
00:55:47,406 --> 0:55:50,000
造成巨大的负担

1543
00:55:52,006 --> 0:55:53,556
现在就让我们在 CPU 上

1544
00:55:53,596 --> 0:55:54,606
运行这个庞大的文档

1545
00:55:55,396 --> 0:55:57,256
这使用的是 18 核系统

1546
00:55:57,736 --> 0:55:58,636
你可以看到 我们能做到

1547
00:55:58,636 --> 0:56:00,516
实时合成 但是

1548
00:55:58,636 --> 0:56:00,516
实时合成 但是

1549
00:56:00,516 --> 0:56:02,736
这个文档非常复杂

1550
00:56:02,736 --> 0:56:03,896
所以在用户界面上

1551
00:56:03,896 --> 0:56:04,966
有点不稳定

1552
00:56:08,946 --> 0:56:10,286
现在我们切换一下

1553
00:56:10,286 --> 0:56:11,276
在单个 GPU 上运行

1554
00:56:12,266 --> 0:56:13,346
这里 你可以看到

1555
00:56:13,346 --> 0:56:15,076
UI 的响应非常好

1556
00:56:15,076 --> 0:56:16,256
所有运行都很流畅

1557
00:56:16,476 --> 0:56:18,366
帧速率大约为

1558
00:56:18,366 --> 0:56:19,500
每秒 18 帧到 20 帧

1559
00:56:22,616 --> 0:56:23,776
这是最好的部分

1560
00:56:23,776 --> 0:56:25,456
我们可以运行

1561
00:56:25,646 --> 0:56:27,856
4 个外部 GPU 你可以看到

1562
00:56:27,856 --> 0:56:29,076
它的运行依然很流畅

1563
00:56:29,166 --> 0:56:30,746
它还可以一直保持

1564
00:56:30,746 --> 0:56:31,996
每秒超过 60 帧的

1565
00:56:31,996 --> 0:56:32,786
运行速度

1566
00:56:33,436 --> 0:56:34,566
这都归功于

1567
00:56:34,566 --> 0:56:36,906
Affinity 先进的基于磁帖的

1568
00:56:36,906 --> 0:56:37,896
负载均衡方案

1569
00:56:38,586 --> 0:56:39,716
它们可以给任意数量的 GPU

1570
00:56:39,716 --> 0:56:41,466
有效地分配工作

1571
00:56:41,466 --> 0:56:43,326
并通过这种方式

1572
00:56:43,326 --> 0:56:45,046
实现线性性能扩展

1573
00:56:45,656 --> 0:56:48,236
这个是我想分享的

1574
00:56:48,236 --> 0:56:48,686
最后一个例子

1575
00:56:49,696 --> 0:56:50,826
这是 Affinity Photo 的

1576
00:56:50,826 --> 0:56:52,546
最大内存带宽密集型处理器之一

1577
00:56:52,546 --> 0:56:54,236
被称为景深

1578
00:56:55,426 --> 0:56:57,896
我们在 CPU 上实时预览

1579
00:56:58,556 --> 0:57:00,096
你可以直观地看到

1580
00:56:58,556 --> 0:57:00,096
你可以直观地看到

1581
00:57:00,096 --> 0:57:01,226
应用效果和实际渲染之间

1582
00:57:01,226 --> 0:57:02,706
所需的时间

1583
00:57:03,626 --> 0:57:04,956
这同样让人印象深刻

1584
00:57:04,956 --> 0:57:06,996
它速度很快 但 GPU 可以

1585
00:57:06,996 --> 0:57:08,000
让它速度更快

1586
00:57:09,336 --> 0:57:10,066
现在 我们将用 4 个外部 GPU

1587
00:57:10,066 --> 0:57:12,146
运行相同的效果

1588
00:57:12,146 --> 0:57:14,466
你可以看到 

1589
00:57:14,466 --> 0:57:16,536
运行超级流畅

1590
00:57:16,536 --> 0:57:18,086
很轻松地就可以保持

1591
00:57:18,086 --> 0:57:19,346
每秒 60 帧以上的帧速率

1592
00:57:20,196 --> 0:57:21,836
这个特殊的过滤器就是

1593
00:57:21,836 --> 0:57:22,896
内存带宽密集型

1594
00:57:23,276 --> 0:57:25,076
我们获得了很大的改进

1595
00:57:25,396 --> 0:57:27,736
因为现在的 GPU 上

1596
00:57:27,736 --> 0:57:29,696
可以使用大容量

1597
00:57:29,696 --> 0:57:30,536
内存带宽

1598
00:57:31,356 --> 0:57:32,766
这也是非常突出的

1599
00:57:32,766 --> 0:57:34,476
一个示例 告诉我们

1600
00:57:34,476 --> 0:57:36,186
如何在多个 GPU 上正规的

1601
00:57:36,186 --> 0:57:37,376
扩展性能

1602
00:57:37,946 --> 0:57:40,686
所以 在结束此次会议之前

1603
00:57:41,026 --> 0:57:43,116
让我们一起回顾一下关键点

1604
00:57:44,506 --> 0:57:45,856
Apple 提供了丰富的框架

1605
00:57:45,856 --> 0:57:48,006
来解决你所有的 Pro App 的需求

1606
00:57:48,856 --> 0:57:50,526
你可以利用这个生态系统

1607
00:57:50,526 --> 0:57:52,126
以可预测的帧速率

1608
00:57:52,126 --> 0:57:55,586
实现 8K 内容的实时编辑

1609
00:57:57,086 --> 0:57:59,456
Apple 的 AV Foundation 和  

1610
00:57:59,456 --> 0:58:01,516
Core Animation Metal Layer 提供的 API

1611
00:57:59,456 --> 0:58:01,516
Core Animation Metal Layer 提供的 API

1612
00:58:01,516 --> 0:58:03,406
可以无缝支持

1613
00:58:03,406 --> 0:58:04,426
高动态范围

1614
00:58:04,826 --> 0:58:06,196
你可以将其与 HDR TV

1615
00:58:06,256 --> 0:58:08,686
和 Apple 的新 Pro Display XDR

1616
00:58:08,686 --> 0:58:11,256
结合使用 以生成精彩的

1617
00:58:11,256 --> 0:58:11,916
视频和图像

1618
00:58:12,516 --> 0:58:15,436
Mac Pro 最多可以有 28 个 CPU 内核

1619
00:58:15,526 --> 0:58:18,116
和 4 个内部 GPU

1620
00:58:18,666 --> 0:58:20,096
Metal 为你提供所有的 API

1621
00:58:20,206 --> 0:58:21,426
以便扩展这些设备上

1622
00:58:21,426 --> 0:58:22,796
你的使用性能

1623
00:58:24,366 --> 0:58:26,186
最后 我们介绍了一个

1624
00:58:26,186 --> 0:58:27,746
使用 Metal 对等组 API 的

1625
00:58:27,746 --> 0:58:29,656
新硬件功能 Affinity Fabric Link 

1626
00:58:30,516 --> 0:58:32,186
这可以让你优化连接

1627
00:58:32,186 --> 0:58:34,926
解锁更多令人激动

1628
00:58:34,926 --> 0:58:36,146
的使用案例

1629
00:58:37,626 --> 0:58:39,386
想获得更多资讯

1630
00:58:39,386 --> 0:58:41,146
请访问我们的网站

1631
00:58:41,146 --> 0:58:42,626
参观明天的实验室

1632
00:58:42,956 --> 0:58:45,366
同时关注周五的其他 Metal 实验室

1633
00:58:45,596 --> 0:58:46,456
谢谢大家

1634
00:58:47,516 --> 0:58:51,500
[掌声]
