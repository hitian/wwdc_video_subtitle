1
00:00:01,516 --> 0:00:04,500
[ Music ]

2
00:00:08,516 --> 0:00:13,146
[ Applause ]

3
00:00:13,646 --> 0:00:15,286
&gt;&gt; This year, our Create ML

4
00:00:15,286 --> 0:00:17,276
release has new models and a

5
00:00:17,276 --> 0:00:18,416
whole new workflow.

6
00:00:19,646 --> 0:00:21,156
Every workflow starts with

7
00:00:21,156 --> 0:00:21,526
input.

8
00:00:22,166 --> 0:00:23,946
The devices that we develop for,

9
00:00:24,136 --> 0:00:26,106
use, and love, are rich with

10
00:00:26,106 --> 0:00:27,196
information from different

11
00:00:27,196 --> 0:00:29,326
sensors such as a camera, the

12
00:00:29,326 --> 0:00:30,946
microphone, the keyboard,

13
00:00:31,296 --> 0:00:33,236
Accelerometer, even Gyroscope.

14
00:00:34,036 --> 0:00:35,436
And all of these types of input

15
00:00:35,716 --> 0:00:37,406
can be used so you can train

16
00:00:37,406 --> 0:00:38,906
machine learning models and make

17
00:00:38,906 --> 0:00:40,656
your apps more personalized and

18
00:00:40,656 --> 0:00:41,346
more intelligent.

19
00:00:42,756 --> 0:00:44,876
Last year, we supported three of

20
00:00:44,876 --> 0:00:47,136
these types of input; images,

21
00:00:47,436 --> 0:00:48,946
text, and tabular data.

22
00:00:50,086 --> 0:00:51,836
This year, we're increasing the

23
00:00:51,906 --> 0:00:53,446
set of available domains from

24
00:00:53,506 --> 0:00:54,736
three to five.

25
00:00:54,736 --> 0:00:57,146
And now, introducing Activity

26
00:00:57,326 --> 0:00:57,876
and Sound.

27
00:00:58,676 --> 0:01:00,096
We're also expanding the breadth

28
00:00:58,676 --> 0:01:00,096
We're also expanding the breadth

29
00:01:00,156 --> 0:01:01,886
of available models within all

30
00:01:02,736 --> 0:01:03,776
of them.

31
00:01:03,986 --> 0:01:05,626
And all of this is being brought

32
00:01:05,866 --> 0:01:07,036
into a new medium.

33
00:01:07,656 --> 0:01:09,386
We call it Create ML app.

34
00:01:10,426 --> 0:01:12,416
It all starts with identifying

35
00:01:12,416 --> 0:01:13,006
your domain.

36
00:01:14,266 --> 0:01:15,436
And once you filter by your

37
00:01:15,436 --> 0:01:16,936
input, you can see all of the

38
00:01:16,936 --> 0:01:18,366
available model types you can

39
00:01:18,366 --> 0:01:18,836
create.

40
00:01:20,946 --> 0:01:22,286
Create ML then breaks down the

41
00:01:22,286 --> 0:01:23,966
task of creating machine

42
00:01:23,966 --> 0:01:25,556
learning model into three simple

43
00:01:25,556 --> 0:01:28,486
phases; input, training, and

44
00:01:29,336 --> 0:01:29,486
output.

45
00:01:30,156 --> 0:01:32,056
This new environment changes the

46
00:01:32,056 --> 0:01:33,726
way you interact with machine

47
00:01:33,726 --> 0:01:34,746
learning on the system.

48
00:01:35,316 --> 0:01:37,696
The app then displays an

49
00:01:37,696 --> 0:01:39,476
overview of your data and a rich

50
00:01:39,476 --> 0:01:41,306
set of analytics as it trains.

51
00:01:42,006 --> 0:01:43,156
You can visualize your model's

52
00:01:43,246 --> 0:01:44,466
progress in an easy to

53
00:01:44,466 --> 0:01:46,386
understand graphical view that

54
00:01:46,386 --> 0:01:47,586
displays the accuracy of your

55
00:01:47,586 --> 0:01:49,156
model across iterations.

56
00:01:49,666 --> 0:01:52,296
You can also see a breakdown of

57
00:01:52,296 --> 0:01:53,836
the precision and recall values

58
00:01:53,886 --> 0:01:55,396
for each class your model was

59
00:01:55,396 --> 0:01:55,906
trained on.

60
00:01:56,646 --> 0:01:58,276
And the table is interactive so

61
00:01:58,736 --> 0:02:00,316
you can filter by class or by

62
00:01:58,736 --> 0:02:00,316
you can filter by class or by

63
00:02:00,316 --> 0:02:02,336
percentage to better understand

64
00:02:02,336 --> 0:02:03,436
your model's performance.

65
00:02:04,096 --> 0:02:07,136
The process of testing is as

66
00:02:07,196 --> 0:02:08,586
simple as dragging and dropping

67
00:02:08,586 --> 0:02:09,045
in new data.

68
00:02:10,175 --> 0:02:11,366
You can have the ability to

69
00:02:11,366 --> 0:02:13,306
train and retest just by

70
00:02:13,306 --> 0:02:14,316
clicking the Test button.

71
00:02:16,006 --> 0:02:17,436
And what's really unique about

72
00:02:17,436 --> 0:02:18,866
Create ML is you can easily

73
00:02:18,866 --> 0:02:20,516
preview trained models in the

74
00:02:20,516 --> 0:02:21,166
Output tab.

75
00:02:21,936 --> 0:02:23,156
This new feature allows you to

76
00:02:23,256 --> 0:02:24,776
see exactly how your model will

77
00:02:24,826 --> 0:02:26,606
predict without having to

78
00:02:26,606 --> 0:02:27,976
incorporate your models into

79
00:02:27,976 --> 0:02:28,206
your apps.

80
00:02:29,256 --> 0:02:30,676
This means no more waiting to

81
00:02:30,676 --> 0:02:31,286
deploy them.

82
00:02:31,896 --> 0:02:33,056
You can do this directly in

83
00:02:33,056 --> 0:02:34,846
Create ML, saving you time to

84
00:02:34,846 --> 0:02:36,186
perfect your models instead.

85
00:02:36,796 --> 0:02:39,516
The Preview section is also

86
00:02:39,516 --> 0:02:41,296
custom built for every template,

87
00:02:41,686 --> 0:02:43,266
ensuring a complete end-to-end

88
00:02:43,266 --> 0:02:44,776
experience for every task.

89
00:02:46,246 --> 0:02:47,606
But what better way to see this

90
00:02:47,996 --> 0:02:49,206
than to show it to you live?

91
00:02:51,126 --> 0:02:51,726
Let's take a look.

92
00:02:52,516 --> 0:02:57,606
[ Applause ]

93
00:02:58,106 --> 0:02:59,746
Now, over in Xcode, I've been

94
00:02:59,746 --> 0:03:01,336
working on a flower classifier

95
00:02:59,746 --> 0:03:01,336
working on a flower classifier

96
00:03:01,796 --> 0:03:02,896
app to help me identify

97
00:03:02,896 --> 0:03:04,296
different types of flowers.

98
00:03:05,046 --> 0:03:06,406
And I've been using a model that

99
00:03:06,406 --> 0:03:07,496
I downloaded from the Model

100
00:03:07,496 --> 0:03:09,696
Gallery called Resnet50.

101
00:03:10,096 --> 0:03:11,576
And this is a well-known image

102
00:03:11,576 --> 0:03:13,146
classifier model that's been

103
00:03:13,146 --> 0:03:14,896
trained to recognize 1,000

104
00:03:14,896 --> 0:03:15,726
different classes.

105
00:03:16,956 --> 0:03:18,186
But this model is taking up

106
00:03:18,226 --> 0:03:19,736
about 100 megabytes of my app.

107
00:03:20,746 --> 0:03:22,076
And we can see when I actually

108
00:03:22,076 --> 0:03:24,386
try it on different images it

109
00:03:25,456 --> 0:03:27,496
knows that this Hibiscus is a

110
00:03:27,496 --> 0:03:29,196
flower, but it doesn't know the

111
00:03:29,196 --> 0:03:29,826
exact type.

112
00:03:30,306 --> 0:03:32,856
So, it doesn't quite suit my

113
00:03:33,386 --> 0:03:33,516
needs.

114
00:03:33,756 --> 0:03:35,866
Now, what I can do is from Xcode

115
00:03:37,386 --> 0:03:39,386
I can open Developer Tools and

116
00:03:39,386 --> 0:03:41,216
launch Create ML.

117
00:03:42,696 --> 0:03:44,876
This then prompts me to create a

118
00:03:44,876 --> 0:03:45,506
new document.

119
00:03:45,506 --> 0:03:48,506
And we can see I'm launched into

120
00:03:48,506 --> 0:03:50,296
the Template View where I can

121
00:03:50,356 --> 0:03:52,386
see all the available models we

122
00:03:53,006 --> 0:03:53,926
can create.

123
00:03:54,116 --> 0:03:55,276
Since I'm working with images,

124
00:03:55,646 --> 0:03:57,416
I'll filter by image and select

125
00:03:57,746 --> 0:03:58,746
the Image Classifier.

126
00:04:00,026 --> 0:04:00,896
We can then name this.

127
00:04:05,366 --> 0:04:07,276
And then, pick the place to save

128
00:04:07,276 --> 0:04:08,516
it so we can come back to it

129
00:04:08,516 --> 0:04:08,816
later.

130
00:04:09,426 --> 0:04:12,226
And then, launch into the New

131
00:04:12,626 --> 0:04:13,286
App view.

132
00:04:14,036 --> 0:04:16,346
And you can see that I'm, I'm

133
00:04:16,346 --> 0:04:18,435
first prompted to drag in input

134
00:04:18,435 --> 0:04:19,166
as training data.

135
00:04:19,166 --> 0:04:21,356
And if I progress through some

136
00:04:21,356 --> 0:04:22,786
of the other tabs, they're not

137
00:04:22,786 --> 0:04:24,416
unlocked yet because I haven't

138
00:04:24,416 --> 0:04:25,256
gone through the flow.

139
00:04:26,516 --> 0:04:27,756
So, let's try this sequentially.

140
00:04:28,416 --> 0:04:31,906
On my desktop, I set aside some

141
00:04:31,906 --> 0:04:33,116
images of different types of

142
00:04:33,116 --> 0:04:33,566
flowers.

143
00:04:34,396 --> 0:04:36,306
And you can see, I have some

144
00:04:36,306 --> 0:04:40,266
hibiscus, some passionflower,

145
00:04:40,266 --> 0:04:43,836
and then even some roses,

146
00:04:45,316 --> 0:04:46,306
dahlias, and daisies.

147
00:04:47,756 --> 0:04:48,876
I could take this folder and

148
00:04:48,876 --> 0:04:51,136
drag it in and immediately see

149
00:04:51,136 --> 0:04:53,136
that I have 65 different images

150
00:04:53,256 --> 0:04:54,686
contained within it and they're

151
00:04:54,686 --> 0:04:59,706
across five different classes.

152
00:04:59,816 --> 0:05:01,376
Now, since we have our input

153
00:04:59,816 --> 0:05:01,376
Now, since we have our input

154
00:05:01,446 --> 0:05:03,076
data, I can hit the Run button

155
00:05:03,356 --> 0:05:04,836
and automatically this model

156
00:05:04,836 --> 0:05:05,666
begins training.

157
00:05:06,456 --> 0:05:07,816
It first starts by extracting

158
00:05:07,816 --> 0:05:09,046
features from the images.

159
00:05:09,556 --> 0:05:10,616
And then, we can see the

160
00:05:10,616 --> 0:05:12,416
progress as training begins.

161
00:05:13,796 --> 0:05:15,216
I can see a breakdown of how the

162
00:05:15,216 --> 0:05:16,446
model's performing on this data.

163
00:05:17,116 --> 0:05:18,546
But what I'd really like to do

164
00:05:18,546 --> 0:05:20,206
is see how the model performs on

165
00:05:20,206 --> 0:05:21,776
new data that it hasn't seen.

166
00:05:22,256 --> 0:05:23,496
So, I'll navigate to the Testing

167
00:05:23,496 --> 0:05:25,836
tab and I'll drag in these new

168
00:05:25,836 --> 0:05:27,886
flowers that I've set aside and

169
00:05:28,476 --> 0:05:29,266
hit Test.

170
00:05:34,296 --> 0:05:35,686
Now, what I'd really like to do

171
00:05:35,686 --> 0:05:36,886
is take a look at the trained

172
00:05:36,886 --> 0:05:38,136
model in the Output tab.

173
00:05:38,136 --> 0:05:40,816
And we can see here I have a

174
00:05:40,816 --> 0:05:42,996
flower classifier that's 66

175
00:05:43,066 --> 0:05:43,586
kilobytes.

176
00:05:44,326 --> 0:05:46,886
Now, to actually preview this,

177
00:05:47,106 --> 0:05:49,006
I've taken some other photos and

178
00:05:49,006 --> 0:05:50,416
perhaps this hibiscus that

179
00:05:50,806 --> 0:05:52,046
wasn't working before with

180
00:05:52,106 --> 0:05:52,516
Resnet.

181
00:05:53,766 --> 0:05:55,466
And I can see now, this model

182
00:05:55,466 --> 0:05:57,006
can correctly predict exactly

183
00:05:57,006 --> 0:05:57,506
what it is.

184
00:05:58,106 --> 0:05:59,366
And I can see other predictions

185
00:05:59,366 --> 0:06:00,476
the model has made and

186
00:05:59,366 --> 0:06:00,476
the model has made and

187
00:06:00,476 --> 0:06:02,106
confidence values for each one.

188
00:06:02,356 --> 0:06:05,376
I can even take a full folder

189
00:06:05,376 --> 0:06:09,006
and drag them in and debug any

190
00:06:09,006 --> 0:06:10,276
image that this model has

191
00:06:10,276 --> 0:06:10,876
predicted on.

192
00:06:12,356 --> 0:06:13,896
Now, once I'm satisfied, I can

193
00:06:13,896 --> 0:06:15,656
take this model and drag it out.

194
00:06:20,196 --> 0:06:21,546
And then, reintegrate that into

195
00:06:21,616 --> 0:06:21,836
my app.

196
00:06:23,246 --> 0:06:24,856
But what's more, is you can also

197
00:06:24,856 --> 0:06:26,736
leverage the power of Continuity

198
00:06:26,736 --> 0:06:28,186
Camera in Create ML.

199
00:06:29,106 --> 0:06:31,196
And from this, what I can do is

200
00:06:31,196 --> 0:06:33,936
I can import from my phone which

201
00:06:33,936 --> 0:06:34,226
is attached.

202
00:06:34,826 --> 0:06:37,106
And I can try to take a photo of

203
00:06:37,656 --> 0:06:39,596
this flower that I have here on

204
00:06:39,596 --> 0:06:41,376
stage, and we can see how it

205
00:06:41,376 --> 0:06:41,626
does.

206
00:06:42,146 --> 0:06:44,526
And it actually turns out okay.

207
00:06:46,516 --> 0:06:52,586
[ Applause ]

208
00:06:53,086 --> 0:06:54,106
Now, if you're not happy with

209
00:06:54,106 --> 0:06:55,866
your performance or if you'd

210
00:06:55,866 --> 0:06:56,886
just like to run some more

211
00:06:56,886 --> 0:06:58,226
experiments, there's a Plus

212
00:06:58,326 --> 0:06:59,206
button here, as well.

213
00:06:59,706 --> 0:07:00,906
And what you can do is you can

214
00:06:59,706 --> 0:07:00,906
And what you can do is you can

215
00:07:00,976 --> 0:07:03,076
select more training data.

216
00:07:03,256 --> 0:07:04,516
You can toggle how our

217
00:07:04,516 --> 0:07:06,226
validation data is specified and

218
00:07:06,846 --> 0:07:08,616
even your testing data, as well.

219
00:07:10,116 --> 0:07:11,476
This time, I might want to tweak

220
00:07:11,526 --> 0:07:12,496
some augmentations.

221
00:07:13,236 --> 0:07:14,286
And then, I can hit Run to

222
00:07:14,286 --> 0:07:14,706
train.

223
00:07:16,096 --> 0:07:17,896
And that's a look at the new

224
00:07:17,896 --> 0:07:19,466
workflow in Create ML.

225
00:07:20,016 --> 0:07:21,066
Let's go back to the slides.

226
00:07:22,516 --> 0:07:24,736
[ Applause ]

227
00:07:25,236 --> 0:07:27,656
So, you've seen Create ML gives

228
00:07:27,656 --> 0:07:29,376
you a whole new way to train

229
00:07:29,376 --> 0:07:30,476
your custom machine learning

230
00:07:30,476 --> 0:07:32,276
models on the Mac, with a

231
00:07:32,276 --> 0:07:33,506
beautiful look and feel.

232
00:07:34,296 --> 0:07:35,826
And with additions like metrics

233
00:07:35,876 --> 0:07:37,756
visualization, live progress,

234
00:07:37,966 --> 0:07:40,016
and interactive preview, Create

235
00:07:40,016 --> 0:07:42,306
ML app sets the bar for a great

236
00:07:42,306 --> 0:07:43,666
model training experience.

237
00:07:45,006 --> 0:07:46,746
In the demo, we walked through

238
00:07:46,986 --> 0:07:48,476
just one model that you can

239
00:07:48,476 --> 0:07:49,556
create with Create ML.

240
00:07:50,146 --> 0:07:51,396
But this release, we're

241
00:07:51,396 --> 0:07:52,436
introducing nine.

242
00:07:53,306 --> 0:07:54,816
So, let's take a high-level tour

243
00:07:54,876 --> 0:07:56,196
of all of the models you can

244
00:07:56,196 --> 0:07:58,176
create and some examples of

245
00:07:58,236 --> 0:07:59,646
sample apps.

246
00:08:00,766 --> 0:08:02,066
Starting with the image domain,

247
00:08:02,396 --> 0:08:04,186
we have the Image Classifier and

248
00:08:04,186 --> 0:08:04,996
Object Detector.

249
00:08:06,436 --> 0:08:08,176
An Image Classifier can be used

250
00:08:08,176 --> 0:08:10,076
for categorizing images based on

251
00:08:10,076 --> 0:08:10,646
their contents.

252
00:08:11,166 --> 0:08:12,706
For example, the Art Style

253
00:08:12,706 --> 0:08:14,736
identifier uses a custom Image

254
00:08:14,736 --> 0:08:16,496
Classifier to determine the most

255
00:08:16,556 --> 0:08:18,086
likely movement of a piece.

256
00:08:18,966 --> 0:08:20,226
It then separately provides an

257
00:08:20,226 --> 0:08:22,436
overview of notable artists to

258
00:08:22,436 --> 0:08:23,916
complete the app experience.

259
00:08:26,636 --> 0:08:27,856
In Create ML, the Image

260
00:08:27,936 --> 0:08:29,826
Classifier leverages core Apple

261
00:08:29,906 --> 0:08:31,286
technology by performing

262
00:08:31,286 --> 0:08:32,986
transfer learning on top of the

263
00:08:32,986 --> 0:08:34,216
vision feature print model

264
00:08:34,506 --> 0:08:35,525
already in the OS.

265
00:08:36,145 --> 0:08:37,696
This allows you to benefit from

266
00:08:37,746 --> 0:08:39,385
faster training times and a

267
00:08:39,385 --> 0:08:43,006
reduced model size in your app.

268
00:08:43,436 --> 0:08:44,766
Also, you have the option to

269
00:08:44,766 --> 0:08:46,746
train with augmentation to make

270
00:08:46,746 --> 0:08:48,326
your models more robust to

271
00:08:48,366 --> 0:08:49,206
unseen input.

272
00:08:50,336 --> 0:08:51,996
If you instead want to identify

273
00:08:52,106 --> 0:08:53,796
multiple objects within an image

274
00:08:53,796 --> 0:08:55,716
instead of one single one, you

275
00:08:55,716 --> 0:08:57,126
might want to create an Object

276
00:08:57,126 --> 0:08:57,626
Detector.

277
00:08:58,976 --> 0:09:00,696
Object Detectors can be used for

278
00:08:58,976 --> 0:09:00,696
Object Detectors can be used for

279
00:09:00,726 --> 0:09:02,376
localizing and recognizing

280
00:09:02,376 --> 0:09:03,876
contents within an image.

281
00:09:04,866 --> 0:09:06,336
For example, these can be

282
00:09:06,396 --> 0:09:07,886
trained to detect one or more

283
00:09:07,886 --> 0:09:10,246
classes such as specific playing

284
00:09:10,246 --> 0:09:12,196
cards or the exact suits

285
00:09:12,316 --> 0:09:13,096
contained on them.

286
00:09:14,626 --> 0:09:16,096
The Object Detector is a deep

287
00:09:16,096 --> 0:09:17,476
learning-based model and

288
00:09:17,476 --> 0:09:19,636
performs data augmentation to

289
00:09:19,696 --> 0:09:20,786
make it more robust.

290
00:09:21,286 --> 0:09:23,036
And it does this entirely on

291
00:09:23,466 --> 0:09:25,806
your Mac's GPU.

292
00:09:26,126 --> 0:09:27,976
Our next domain is Sound.

293
00:09:29,186 --> 0:09:30,696
Within Sound, we have a new

294
00:09:30,696 --> 0:09:31,746
model called the Sound

295
00:09:31,746 --> 0:09:32,356
Classifier.

296
00:09:33,816 --> 0:09:35,156
This model allows you to

297
00:09:35,156 --> 0:09:36,886
determine the most dominant

298
00:09:36,956 --> 0:09:38,506
sound within an audio stream.

299
00:09:40,206 --> 0:09:41,796
Since audio data is time series

300
00:09:41,866 --> 0:09:43,486
based, you could differentiate

301
00:09:43,556 --> 0:09:45,246
between the start and end points

302
00:09:45,246 --> 0:09:46,926
of different sounds such as when

303
00:09:46,926 --> 0:09:48,496
the guitar solo ends and the

304
00:09:48,496 --> 0:09:49,486
crowd goes wild.

305
00:09:51,656 --> 0:09:53,016
This model leverages transfer

306
00:09:53,016 --> 0:09:54,326
learning so you can also

307
00:09:54,326 --> 0:09:55,646
experience faster training

308
00:09:55,696 --> 0:09:55,946
times.

309
00:09:56,916 --> 0:09:58,376
And we also understand that

310
00:09:58,376 --> 0:10:00,066
optimizing performance across

311
00:09:58,376 --> 0:10:00,066
optimizing performance across

312
00:10:00,186 --> 0:10:01,546
complex applications is

313
00:10:01,576 --> 0:10:02,146
challenging.

314
00:10:02,676 --> 0:10:03,586
Which is why we want to

315
00:10:03,586 --> 0:10:05,486
emphasize that these models are

316
00:10:05,566 --> 0:10:06,986
lightweight and run on the

317
00:10:06,986 --> 0:10:09,736
Neural Engine, making them ideal

318
00:10:09,736 --> 0:10:11,566
for real-time applications on

319
00:10:11,636 --> 0:10:12,276
any device.

320
00:10:12,996 --> 0:10:16,986
Our third domain is Activity.

321
00:10:17,586 --> 0:10:19,466
And within Activity, we have the

322
00:10:19,576 --> 0:10:20,916
Activity Classifier for the

323
00:10:20,916 --> 0:10:21,436
first time.

324
00:10:22,826 --> 0:10:24,966
This model also operates on time

325
00:10:25,046 --> 0:10:25,736
series-based data.

326
00:10:25,846 --> 0:10:28,596
And Activity Classifiers can be

327
00:10:28,596 --> 0:10:30,236
trained to categorize contents

328
00:10:30,236 --> 0:10:32,396
of motion data from a variety of

329
00:10:32,396 --> 0:10:33,396
sensors such as the

330
00:10:33,396 --> 0:10:35,326
Accelerometer and Gyroscope.

331
00:10:37,036 --> 0:10:37,936
These models are deep

332
00:10:37,996 --> 0:10:39,536
learning-based and train on the

333
00:10:39,536 --> 0:10:40,006
GPU.

334
00:10:40,496 --> 0:10:41,976
And they result in small model

335
00:10:42,036 --> 0:10:43,866
sizes that are also ideal for

336
00:10:43,866 --> 0:10:45,436
deployment on any device.

337
00:10:47,166 --> 0:10:49,046
Our second to last input is

338
00:10:49,046 --> 0:10:49,216
Text.

339
00:10:50,166 --> 0:10:52,356
Within Text, there are two model

340
00:10:52,356 --> 0:10:54,426
types available; the Text

341
00:10:54,486 --> 0:10:56,376
Classifier and the Word Tagger.

342
00:10:58,456 --> 0:11:00,256
Text classification can be used

343
00:10:58,456 --> 0:11:00,256
Text classification can be used

344
00:11:00,256 --> 0:11:02,516
to label sentences, paragraphs,

345
00:11:02,516 --> 0:11:04,516
or even entire articles based on

346
00:11:04,516 --> 0:11:05,106
their contents.

347
00:11:05,906 --> 0:11:07,246
You can train these for custom

348
00:11:07,246 --> 0:11:08,746
topic identification or

349
00:11:08,746 --> 0:11:09,926
categorization tasks.

350
00:11:11,476 --> 0:11:12,566
In Create ML, there are a

351
00:11:12,566 --> 0:11:14,026
variety of different algorithms

352
00:11:14,026 --> 0:11:15,696
for you to try and even a new

353
00:11:15,696 --> 0:11:17,456
transfer learning option this

354
00:11:17,986 --> 0:11:18,096
year.

355
00:11:18,896 --> 0:11:21,166
The Word Tagger is slightly more

356
00:11:21,166 --> 0:11:21,616
nuanced.

357
00:11:22,586 --> 0:11:24,266
It's ideal for labeling tokens

358
00:11:24,466 --> 0:11:26,176
or words of interest in text.

359
00:11:27,186 --> 0:11:28,706
General purpose examples of this

360
00:11:28,976 --> 0:11:30,876
are things like tagging

361
00:11:30,876 --> 0:11:32,426
different parts of speech or

362
00:11:32,426 --> 0:11:33,846
recognizing named entities,

363
00:11:34,246 --> 0:11:35,346
though you could customize your

364
00:11:35,346 --> 0:11:36,976
own to do things like tag

365
00:11:37,056 --> 0:11:37,486
cheeses.

366
00:11:38,356 --> 0:11:39,876
With a Cheese Tagger, you could

367
00:11:39,876 --> 0:11:41,306
be sure to identify different

368
00:11:41,306 --> 0:11:43,046
flavor notes from any cheese

369
00:11:43,086 --> 0:11:43,646
description.

370
00:11:44,196 --> 0:11:47,816
Our last domain is the most

371
00:11:47,816 --> 0:11:49,846
general of all five; Tabular

372
00:11:49,846 --> 0:11:50,016
Data.

373
00:11:51,076 --> 0:11:52,516
And within this, we have three

374
00:11:52,516 --> 0:11:54,286
model types; the Tabular

375
00:11:54,676 --> 0:11:57,386
Classifier, Tabular Regressor,

376
00:11:58,046 --> 0:11:59,046
and Recommender.

377
00:11:59,716 --> 0:12:01,696
Classifiers are for categorizing

378
00:11:59,716 --> 0:12:01,696
Classifiers are for categorizing

379
00:12:01,776 --> 0:12:03,446
samples based on their features

380
00:12:03,446 --> 0:12:03,966
of interest.

381
00:12:04,676 --> 0:12:06,216
And features can be a variety of

382
00:12:06,216 --> 0:12:07,516
different types such as

383
00:12:07,516 --> 0:12:10,286
integers, doubles, strings, so

384
00:12:10,286 --> 0:12:11,466
long as your target is a

385
00:12:11,466 --> 0:12:12,436
discrete value.

386
00:12:14,216 --> 0:12:15,376
These allow you to do things

387
00:12:15,426 --> 0:12:16,996
like determine if a seat is

388
00:12:17,036 --> 0:12:18,836
comfortable or not based on a

389
00:12:18,836 --> 0:12:20,236
particular person's height and

390
00:12:20,236 --> 0:12:21,966
weight and specific properties

391
00:12:22,006 --> 0:12:23,466
of the seat such as the amount

392
00:12:23,466 --> 0:12:24,036
of leg room.

393
00:12:25,476 --> 0:12:26,716
What's unique about the Tabular

394
00:12:26,766 --> 0:12:28,736
Classifier is it extracts away

395
00:12:28,956 --> 0:12:30,306
the underlying algorithm for

396
00:12:30,306 --> 0:12:30,536
you.

397
00:12:30,916 --> 0:12:32,796
And identifies the best multiple

398
00:12:32,796 --> 0:12:34,136
classifiers for your data.

399
00:12:35,766 --> 0:12:37,156
If you instead want a model that

400
00:12:37,156 --> 0:12:38,656
will predict a numeric value,

401
00:12:38,776 --> 0:12:40,936
such as a rating or a score, you

402
00:12:40,936 --> 0:12:42,306
may instead want to use the

403
00:12:42,306 --> 0:12:43,256
Tabular Regressor.

404
00:12:44,516 --> 0:12:46,166
This model quantifies samples

405
00:12:46,296 --> 0:12:47,216
based on their defining

406
00:12:47,216 --> 0:12:47,696
features.

407
00:12:47,786 --> 0:12:49,176
So, you could train one to

408
00:12:49,206 --> 0:12:50,566
estimate the price of a house

409
00:12:51,036 --> 0:12:52,956
based on its location and number

410
00:12:52,956 --> 0:12:54,316
of bedrooms, bathrooms, and

411
00:12:54,316 --> 0:12:55,126
parking spaces.

412
00:12:56,556 --> 0:12:57,956
Like the Classifier, the

413
00:12:57,956 --> 0:12:59,546
Regressor also automatically

414
00:12:59,546 --> 0:13:01,386
detects the best of multiple

415
00:12:59,546 --> 0:13:01,386
detects the best of multiple

416
00:13:01,386 --> 0:13:02,336
regressors for your data.

417
00:13:03,176 --> 0:13:03,866
Though, you still have the

418
00:13:03,866 --> 0:13:06,146
flexibility to choose a specific

419
00:13:06,256 --> 0:13:08,436
boosted or decision tree, random

420
00:13:08,506 --> 0:13:10,356
forest, or linear regressor, if

421
00:13:10,356 --> 0:13:11,426
you like.

422
00:13:12,026 --> 0:13:14,056
And our last model is the

423
00:13:14,056 --> 0:13:16,036
Recommender which allows you to

424
00:13:16,036 --> 0:13:17,996
recommend content based on user

425
00:13:17,996 --> 0:13:18,536
behavior.

426
00:13:19,626 --> 0:13:20,866
The Recommender can be trained

427
00:13:20,866 --> 0:13:23,306
on user-item interactions with

428
00:13:23,306 --> 0:13:24,276
or without ratings.

429
00:13:24,576 --> 0:13:26,206
And it's able to be deployed on

430
00:13:26,206 --> 0:13:28,586
device, saving you the hassle of

431
00:13:28,736 --> 0:13:30,896
setting up the server.

432
00:13:31,506 --> 0:13:33,376
As we saw, Create ML comes with

433
00:13:33,446 --> 0:13:35,456
great features to help you set

434
00:13:35,456 --> 0:13:36,356
up your machine learning

435
00:13:36,356 --> 0:13:38,616
experiments, use native support

436
00:13:38,666 --> 0:13:40,726
for data visualization, metrics,

437
00:13:40,856 --> 0:13:41,596
and performance.

438
00:13:42,336 --> 0:13:43,796
And the machine learning models

439
00:13:43,796 --> 0:13:45,606
you train can easily be saved

440
00:13:45,606 --> 0:13:46,906
and shared with members of your

441
00:13:47,016 --> 0:13:47,286
team.

442
00:13:48,536 --> 0:13:50,366
Of course, all of this leverages

443
00:13:50,406 --> 0:13:52,076
the power and efficiency of

444
00:13:52,106 --> 0:13:53,216
training on your Mac.

445
00:13:55,206 --> 0:13:56,866
This new medium augments other

446
00:13:56,866 --> 0:13:58,266
ways you have available to you

447
00:13:58,546 --> 0:13:59,566
to create machine learning

448
00:13:59,566 --> 0:14:01,166
models such as in Swift

449
00:13:59,566 --> 0:14:01,166
models such as in Swift

450
00:14:01,236 --> 0:14:02,976
Playgrounds, Swift Scripts, or

451
00:14:03,056 --> 0:14:04,556
Swift Frepple [phonetic], Xcode

452
00:14:04,556 --> 0:14:04,856
Playground.

453
00:14:05,716 --> 0:14:07,276
But allows you to do so without

454
00:14:07,276 --> 0:14:09,486
writing a single line of code.

455
00:14:10,456 --> 0:14:12,166
We believe this brings machine

456
00:14:12,166 --> 0:14:13,706
learning to everyone.

457
00:14:15,376 --> 0:14:17,446
To summarize, in Create ML this

458
00:14:17,516 --> 0:14:19,876
year, you have new models, nine

459
00:14:19,936 --> 0:14:21,536
templates, and a whole new

460
00:14:21,536 --> 0:14:21,946
workflow.

461
00:14:22,516 --> 0:14:28,500
[ Applause ]
