1
00:00:06,473 --> 0:00:11,245
（CORE ML 3框架）

2
00:00:15,482 --> 0:00:17,518
大家好 我是

3
00:00:17,584 --> 0:00:20,387
我是Apple的一名工程师

4
00:00:21,321 --> 0:00:23,690
今天能与大家一起分享

5
00:00:23,757 --> 0:00:27,895
我们今年在Core ML 3中

6
00:00:30,430 --> 0:00:32,366
Core ML尽可能地简化了

7
00:00:32,966 --> 0:00:35,536
把机器学习无缝集成到app的过程

8
00:00:36,737 --> 0:00:40,307
可以让你创建多种多样的新奇

9
00:00:41,375 --> 0:00:44,244
而这一切的中心就是模型自身

10
00:00:47,047 --> 0:00:47,881
你可以从许多所支持的训练库中

11
00:00:48,549 --> 0:00:50,284
获得模型

12
00:00:50,851 --> 0:00:53,053
通过使用我们作为

13
00:00:53,620 --> 0:00:55,522
所提供的转换器转换训练库来实现

14
00:00:57,291 --> 0:01:00,727
通过添加新的

15
00:00:57,291 --> 0:01:00,727
通过添加新的

16
00:01:01,094 --> 0:01:04,331
我们把获得模型的过程变得更简单了

17
00:01:05,331 --> 0:01:06,466
（在设备上实现模型个性化）

18
00:01:06,967 --> 0:01:08,902
在这场演讲中 我们要讲许多话题

19
00:01:09,536 --> 0:01:11,805
从在设备上个性化模型

20
00:01:12,372 --> 0:01:14,474
到我们对神经网络所添加的额外支持

21
00:01:15,042 --> 0:01:16,009
等等

22
00:01:17,578 --> 0:01:19,112
让我们先讲

23
00:01:19,546 --> 0:01:21,448
在设备上个性化你的模型

24
00:01:24,785 --> 0:01:25,853
从传统上说

25
00:01:26,353 --> 0:01:29,489
这些模型要么与app绑定

26
00:01:30,123 --> 0:01:32,092
一旦你的设备上有了模型

27
00:01:32,926 --> 0:01:35,696
并在你的app内针对性能进行了

28
00:01:38,932 --> 0:01:40,934
关于把你的app与模型相关联

29
00:01:41,235 --> 0:01:44,705
这意味着你可以为所有用户提供

30
00:01:46,473 --> 0:01:47,641
但每个用户都是独一无二的

31
00:01:49,276 --> 0:01:50,911
他们每个人都有自己的特别需求

32
00:01:51,445 --> 0:01:54,248
他们自己的与app相交互的方式

33
00:01:55,482 --> 0:01:56,950
我认为这为我们创造了一个机遇

34
00:01:59,219 --> 0:02:01,154
如果每个用户都能得到一个

35
00:01:59,219 --> 0:02:01,154
如果每个用户都能得到一个

36
00:02:01,522 --> 0:02:03,357
特别为他们个性化的模型怎么样？

37
00:02:05,526 --> 0:02:07,861
嗯 让我们以一个用户为例

38
00:02:08,996 --> 0:02:10,297
我们可以获取那个用户的数据

39
00:02:11,298 --> 0:02:12,733
设置一种云服务

40
00:02:13,734 --> 0:02:15,469
向那个云服务发送用户数据

41
00:02:16,303 --> 0:02:18,172
并在云内创建那个

42
00:02:18,505 --> 0:02:21,375
然后再把模型部署给用户

43
00:02:23,277 --> 0:02:24,478
这给你们开发人员以及我们的用户们

44
00:02:24,545 --> 0:02:26,980
带来了许多挑战

45
00:02:28,815 --> 0:02:32,586
对你们而言 挑战是

46
00:02:32,653 --> 0:02:35,189
使用这些云服务管理那种个性化服务

47
00:02:35,756 --> 0:02:38,225
以及创建一个可以扩展到百万用户的

48
00:02:39,526 --> 0:02:40,494
对用户来说

49
00:02:40,561 --> 0:02:42,296
很显然他们需要暴露他们的全部数据

50
00:02:43,130 --> 0:02:45,165
他们并不想这样做

51
00:02:45,232 --> 0:02:47,100
他们不得不暴露自己的数据

52
00:02:47,167 --> 0:02:49,036
而这些数据将由另一方进行管理

53
00:02:51,505 --> 0:02:52,539
在Core ML 3上

54
00:02:53,273 --> 0:02:56,276
你可以完全在设备上执行这种

55
00:03:03,684 --> 0:03:04,985
获取具有用户所创建

56
00:03:05,652 --> 0:03:07,921
或重新生成的数据的那个通用模型

57
00:03:09,056 --> 0:03:10,924
你可以用那些数据

58
00:03:11,358 --> 0:03:12,392
对用户个性化那个模型

59
00:03:14,962 --> 0:03:16,830
这意味着数据将保持私密性

60
00:03:17,531 --> 0:03:18,599
它永远不会离开设备

61
00:03:19,733 --> 0:03:22,636
这意味着不需要服务器来执行

62
00:03:23,937 --> 0:03:25,305
并且这还意味着你可以在任何地方

63
00:03:25,372 --> 0:03:28,675
好吧 你不会仅仅为了要更新

64
00:03:29,276 --> 0:03:30,310
而把用户束缚在Wi-Fi

65
00:03:30,944 --> 0:03:32,246
（模型剖析）

66
00:03:33,413 --> 0:03:35,249
在我们继续讲之前

67
00:03:35,315 --> 0:03:36,884
看看有什么变化

68
00:03:38,886 --> 0:03:41,522
目前 你的模型主要由参数组成

69
00:03:41,889 --> 0:03:43,423
一些诸如各层权重这样的东西

70
00:03:43,490 --> 0:03:44,791
如果有神经网络的话 比如说

71
00:03:45,425 --> 0:03:47,561
还有一些元数据

72
00:03:48,161 --> 0:03:50,664
还有作者以及一个界面

73
00:03:50,731 --> 0:03:52,132
这就是app自身所关注的地方

74
00:03:52,866 --> 0:03:54,635
它描述了你如何与这个模型相交互

75
00:03:56,503 --> 0:03:57,538
在Core ML 3上

76
00:03:57,804 --> 0:04:00,541
我们添加了一组新参数 用于更新

77
00:03:57,804 --> 0:04:00,541
我们添加了一组新参数 用于更新

78
00:04:00,607 --> 0:04:03,410
这组新参数描述了模型的哪些部分

79
00:04:04,011 --> 0:04:06,180
我们添加了一个新的更新界面

80
00:04:06,246 --> 0:04:07,381
你的app可以用于执行这些更新

81
00:04:10,584 --> 0:04:12,219
这意味着可以通过那个界面

82
00:04:12,686 --> 0:04:14,321
直接获取全部功能

83
00:04:14,688 --> 0:04:17,024
我们压缩了大量细节

84
00:04:17,524 --> 0:04:20,027
这些都包含在那一个模型文件中

85
00:04:22,329 --> 0:04:23,764
因此就像是做预测一样

86
00:04:23,830 --> 0:04:26,667
我们提供一组输入

87
00:04:27,801 --> 0:04:29,102
更新非常简单

88
00:04:29,169 --> 0:04:30,737
你只需要提供一组训练样本

89
00:04:31,171 --> 0:04:32,806
你就能得到那个模型的新版本

90
00:04:33,140 --> 0:04:34,842
这个新版本是针对那些数据进行适应

91
00:04:36,176 --> 0:04:37,477
（所支持的模型类型）

92
00:04:38,145 --> 0:04:39,179
对Core ML 3而言

93
00:04:39,479 --> 0:04:42,783
我们支持给最近邻分类器

94
00:04:43,217 --> 0:04:44,351
以及神经网络创建可更新的模型

95
00:04:44,885 --> 0:04:46,653
并且我们还将支持在你的管道内

96
00:04:46,720 --> 0:04:47,654
嵌入一个可支持的模型

97
00:04:48,121 --> 0:04:49,823
意思是你的管道也变得可更新了

98
00:04:52,092 --> 0:04:53,126
（演示

99
00:04:53,193 --> 0:04:55,362
有了这些信息 我认为我们应该

100
00:04:56,263 --> 0:04:58,298
因此我要把舞台交给

101
00:04:59,032 --> 0:04:59,900
Anil

102
00:05:06,673 --> 0:05:07,608
谢谢Michael

103
00:05:08,075 --> 0:05:09,009
大家好

104
00:05:10,010 --> 0:05:14,681
今天我要演示如何使用模型个性化

105
00:05:14,948 --> 0:05:17,117
为用户们创建自定义体验

106
00:05:17,818 --> 0:05:21,622
为此我有一款app 它帮助老师们

107
00:05:22,523 --> 0:05:24,391
我使用模型个性化

108
00:05:24,691 --> 0:05:25,993
给这个app添加了

109
00:05:26,059 --> 0:05:28,896
但在我们讲这个功能之前

110
00:05:29,496 --> 0:05:30,964
切换到演示屏

111
00:05:37,771 --> 0:05:39,606
太棒了 这就是那款app

112
00:05:40,174 --> 0:05:41,875
它叫做

113
00:05:42,442 --> 0:05:46,146
它可以让你获取家庭作业的一张照片

114
00:05:47,047 --> 0:05:51,318
然后开始像老师在纸上评级一样

115
00:05:52,319 --> 0:05:54,354
你可以像这样标记为正确

116
00:05:54,788 --> 0:05:56,290
或像这样标记为错误

117
00:05:57,090 --> 0:05:58,125
非常直截了当

118
00:05:58,892 --> 0:05:59,893
非常简单

119
00:06:00,194 --> 0:06:03,497
这款app使用PencilKit

120
00:06:03,864 --> 0:06:07,067
并预训练Core ML模型来识别

121
00:06:09,203 --> 0:06:11,205
最近我添加了一个新功能

122
00:06:11,605 --> 0:06:15,976
可以让老师们为学生们提供一些

123
00:06:17,211 --> 0:06:18,078
也就是贴纸

124
00:06:19,146 --> 0:06:22,015
孩子们绝对喜欢收集

125
00:06:22,449 --> 0:06:24,852
因此我认为这对于app来说

126
00:06:25,118 --> 0:06:28,088
如果他们可以允许…

127
00:06:29,423 --> 0:06:30,490
要给学生发贴纸

128
00:06:30,757 --> 0:06:32,626
我可以轻触上边的这个加号按钮

129
00:06:34,561 --> 0:06:37,030
滚动浏览贴纸列表 选择其中一个

130
00:06:37,798 --> 0:06:41,602
把它拖动到正确的位置 并调整尺寸

131
00:06:42,903 --> 0:06:43,837
就是这样

132
00:06:44,905 --> 0:06:47,107
但我认为我们可以把这个流程

133
00:06:47,574 --> 0:06:49,476
让用户们也觉得非常神奇

134
00:06:51,178 --> 0:06:52,446
让我们稍微思考一下

135
00:06:54,114 --> 0:06:56,950
用户仅使用

136
00:06:57,651 --> 0:07:00,654
如果他们可以

137
00:06:57,651 --> 0:07:00,654
如果他们可以

138
00:07:01,054 --> 0:07:03,190
快速地手绘一些东西是不是很酷

139
00:07:03,490 --> 0:07:06,660
然后app会自动选择正确尺寸的

140
00:07:06,727 --> 0:07:08,562
并把它放在正确的位置上

141
00:07:10,097 --> 0:07:13,433
嗯 我们绝对可以通过机器学习

142
00:07:13,834 --> 0:07:15,035
因此让我们思考一些可选方案

143
00:07:15,302 --> 0:07:16,837
让我切换到幻灯片中

144
00:07:17,671 --> 0:07:21,208
有些人已经用过Core ML了

145
00:07:21,275 --> 0:07:23,477
嗯 我们实际上可以预训练…

146
00:07:24,278 --> 0:07:26,547
一个可以识别贴纸的模型

147
00:07:26,847 --> 0:07:28,248
并把它发布为app的一部分

148
00:07:28,315 --> 0:07:29,349
（使用预训练的贴纸模型？）

149
00:07:29,416 --> 0:07:31,885
嗯 我们可以这样做

150
00:07:32,586 --> 0:07:35,722
其一 app中有许多贴纸

151
00:07:36,023 --> 0:07:38,392
我们可能需要收集大量训练数据

152
00:07:38,692 --> 0:07:40,260
才能预训练这些模型

153
00:07:41,261 --> 0:07:43,730
即使某个用户可能仅对

154
00:07:43,797 --> 0:07:45,432
其中一小部分贴纸感兴趣

155
00:07:47,134 --> 0:07:48,168
其二

156
00:07:49,603 --> 0:07:51,271
如果我计划在将来引入一批新贴纸

157
00:07:51,572 --> 0:07:54,441
这个预训练的模型该如何处理

158
00:07:56,009 --> 0:07:57,945
嗯 我可能得预训练模型

159
00:07:58,312 --> 0:08:02,382
并通过app更新来发布它

160
00:07:58,312 --> 0:08:02,382
并通过app更新来发布它

161
00:08:04,484 --> 0:08:06,854
最后 我认为这是最关键的点

162
00:08:07,187 --> 0:08:09,723
这个预训练模型对于不同的用户来说

163
00:08:12,659 --> 0:08:15,329
不同的用户有不同的手绘方式

164
00:08:16,396 --> 0:08:19,099
如果我去外面要求一百个不同的人

165
00:08:19,399 --> 0:08:21,301
快速手绘出这个漂亮的贴纸

166
00:08:21,702 --> 0:08:23,270
我至少会得到50个不同的答案

167
00:08:24,071 --> 0:08:26,373
真正让人震惊的是人们的个性

168
00:08:27,007 --> 0:08:28,976
那么在这种情况下

169
00:08:30,677 --> 0:08:34,780
我们是否应该…

170
00:08:35,381 --> 0:08:36,383
如何进行手绘…

171
00:08:38,018 --> 0:08:41,522
或用户是否应该训练app

172
00:08:41,889 --> 0:08:43,823
识别你的手绘的方式？

173
00:08:44,925 --> 0:08:47,761
嗯 这正是模型个性化所提供的功能

174
00:08:49,763 --> 0:08:53,734
我要做的是使用模型个性化

175
00:08:53,800 --> 0:08:57,337
和我从用户那里收集的用户数据

176
00:08:57,404 --> 0:08:59,907
来定义一个模型来满足他们的需要

177
00:08:59,973 --> 0:09:02,176
让我演示一下那如何转化为用户体验

178
00:08:59,973 --> 0:09:02,176
让我演示一下那如何转化为用户体验

179
00:09:02,242 --> 0:09:03,777
（用户可以训练模型）

180
00:09:08,582 --> 0:09:11,084
我要切换到演示屏继续评级

181
00:09:12,119 --> 0:09:14,588
第三个答案…第三个问题

182
00:09:14,655 --> 0:09:15,689
对于幼儿园的孩子们来说非常棘手

183
00:09:15,756 --> 0:09:17,324
但我认为Jane已经解决了

184
00:09:17,391 --> 0:09:19,560
那个图解中有四个三角形

185
00:09:20,060 --> 0:09:20,994
做得很好 Jane

186
00:09:21,929 --> 0:09:24,598
嗯 现在我想给她发一个贴纸

187
00:09:24,665 --> 0:09:26,366
鼓励她对细节的关注

188
00:09:26,433 --> 0:09:28,235
但我想通过快速手绘来发贴纸

189
00:09:28,969 --> 0:09:29,970
让我们试着做一下

190
00:09:33,841 --> 0:09:37,277
app看起来告诉我说它不能识别

191
00:09:37,611 --> 0:09:40,113
这很公平

192
00:09:40,614 --> 0:09:42,416
让我试着添加一个贴纸

193
00:09:42,749 --> 0:09:45,886
但这一次我想创建一个快捷方式

194
00:09:45,953 --> 0:09:48,188
我要选择我上次所使用的那个贴纸

195
00:09:50,290 --> 0:09:53,260
现在app要求我提供一个样本

196
00:09:53,727 --> 0:09:56,029
就是我会如何手绘这个特定的贴纸

197
00:09:56,697 --> 0:09:57,898
它不一定非常完美

198
00:09:57,965 --> 0:10:00,000
它甚至看起来也可以跟贴纸不一样

199
00:10:00,300 --> 0:10:02,569
这只是我自己的表示

200
00:10:02,903 --> 0:10:06,507
表示我想如何手绘那个贴纸 对吗？

201
00:10:06,573 --> 0:10:10,644
因此我使用了一颗星来…

202
00:10:12,412 --> 0:10:13,881
代表那个特定的贴纸

203
00:10:15,649 --> 0:10:17,751
app要求我再提供几个样本

204
00:10:17,818 --> 0:10:20,120
这也很公平 因为这只需要几秒钟

205
00:10:20,821 --> 0:10:23,657
但现在看起来app…

206
00:10:24,591 --> 0:10:28,595
现在我在屏幕上看到了贴纸

207
00:10:29,930 --> 0:10:33,300
在我返回之前 让我再向贴纸库中

208
00:10:34,701 --> 0:10:38,005
那儿有一个非常漂亮的“击掌”手势

209
00:10:38,305 --> 0:10:39,373
就在这儿

210
00:10:40,941 --> 0:10:42,910
我在考虑我应该用什么来作为

211
00:10:43,777 --> 0:10:46,246
我希望是一种容易记住的东西

212
00:10:46,313 --> 0:10:47,247
很容易画出来的东西

213
00:10:47,581 --> 0:10:48,916
数字五怎么样

214
00:10:48,982 --> 0:10:50,484
从某种程度上来说可以代表“击掌”

215
00:10:53,287 --> 0:10:56,590
太棒了 又提供了两个样本

216
00:10:58,058 --> 0:10:59,493
让我们返回到屏幕上

217
00:10:59,560 --> 0:11:03,096
试着为绝望等待的Jane

218
00:10:59,560 --> 0:11:03,096
试着为绝望等待的Jane

219
00:11:04,631 --> 0:11:05,632
那不是很酷吗？

220
00:11:11,471 --> 0:11:14,074
我非常高兴我不必浏览贴纸选择器

221
00:11:14,141 --> 0:11:16,877
并从那些乱糟糟的贴纸堆中

222
00:11:17,811 --> 0:11:20,414
太棒了 下一个问题

223
00:11:20,480 --> 0:11:22,182
让我再给她发一个小星星

224
00:11:23,383 --> 0:11:25,152
我对这款app超级满意

225
00:11:25,219 --> 0:11:27,020
在顶部贴一个大的“击掌”贴纸

226
00:11:27,521 --> 0:11:28,455
那怎么样？

227
00:11:36,363 --> 0:11:37,764
这只是一个例子

228
00:11:38,165 --> 0:11:41,034
你们可以思考使用这个新功能

229
00:11:41,101 --> 0:11:43,203
打造一些非常优秀的体验

230
00:11:43,971 --> 0:11:45,272
在我结束之前

231
00:11:45,339 --> 0:11:47,374
让我快速总结一下要实施这个功能

232
00:11:47,441 --> 0:11:48,842
所需要采取的操作

233
00:11:48,909 --> 0:11:49,877
（用户可以训练模型）

234
00:11:49,943 --> 0:11:51,245
我要做的第一件事

235
00:11:51,912 --> 0:11:56,483
是向项目中导入一个可更新的

236
00:11:57,150 --> 0:11:58,685
它在Xcode中看起来是这样的

237
00:12:01,054 --> 0:12:02,856
因为我要通过添加新贴纸或类

238
00:12:02,923 --> 0:12:05,192
来试着个性化这个模型

239
00:12:05,492 --> 0:12:07,995
使用最邻近分类器很有道理

240
00:12:09,930 --> 0:12:13,600
虽然那是个填充到最邻近分类器中的

241
00:12:13,934 --> 0:12:16,069
预训练的神经网络功能提取器

242
00:12:16,436 --> 0:12:19,106
用于帮助改善预测效率和稳健性

243
00:12:20,440 --> 0:12:23,310
但这就是它

244
00:12:23,677 --> 0:12:25,512
因为Core ML

245
00:12:25,879 --> 0:12:27,848
从API界面提取全部模型细节

246
00:12:31,985 --> 0:12:33,320
你可以使用这个模型进行预测

247
00:12:33,387 --> 0:12:34,521
并不需要任何修改

248
00:12:35,522 --> 0:12:38,725
Xcode中你会看到跟以前一样的

249
00:12:40,460 --> 0:12:42,996
但今年的新功能是一个更新部分

250
00:12:44,431 --> 0:12:48,669
描述一组输入 是这个模型用于

251
00:12:49,336 --> 0:12:51,138
正如你所预期的那样

252
00:12:51,205 --> 0:12:52,372
它需要一个灰度图像的贴纸

253
00:12:52,873 --> 0:12:55,475
以及同样是灰度图像的相应的手绘

254
00:12:55,776 --> 0:12:59,346
而相应的贴纸作为真正的标签

255
00:13:00,347 --> 0:13:03,217
关于代码

256
00:13:03,617 --> 0:13:06,720
自动生成一组类

257
00:13:07,487 --> 0:13:09,223
现在它生成新类

258
00:13:09,656 --> 0:13:12,259
用于帮助你以自我方式提供训练数据

259
00:13:13,327 --> 0:13:14,595
如果你看一下这个类

260
00:13:14,995 --> 0:13:16,430
你会看到一组属性

261
00:13:16,697 --> 0:13:19,199
与你在Xcode中

262
00:13:19,266 --> 0:13:22,035
那么我们在这里看到了手绘和贴纸

263
00:13:24,938 --> 0:13:29,042
一旦你从用户那儿收集到

264
00:13:29,610 --> 0:13:34,114
或用于为用户进行个性化的全部

265
00:13:34,848 --> 0:13:38,252
真正的个性化需要三个简单的步骤

266
00:13:39,786 --> 0:13:42,456
第一 你需要获取

267
00:13:43,023 --> 0:13:44,791
你可以从捆绑包获取

268
00:13:45,158 --> 0:13:47,461
或从已更新模型之前的快照中获取

269
00:13:49,096 --> 0:13:52,566
接下来你要准备所支持格式的

270
00:13:53,300 --> 0:13:57,638
为此 你可以使用我所展示的原生类

271
00:13:57,704 --> 0:14:00,340
或创建你自己的功能提供器

272
00:13:57,704 --> 0:14:00,340
或创建你自己的功能提供器

273
00:14:01,675 --> 0:14:04,511
最后你要启动一个更新任务

274
00:14:06,446 --> 0:14:09,716
一旦更新完成 就调用完成处理器

275
00:14:10,217 --> 0:14:14,688
那会为你提供已更新的模型

276
00:14:15,322 --> 0:14:16,256
就是如此简单

277
00:14:16,723 --> 0:14:20,260
我已经迫不及待地想看到

278
00:14:20,327 --> 0:14:21,562
在你们的app和框架中会创建出

279
00:14:21,962 --> 0:14:23,597
就这样

280
00:14:23,964 --> 0:14:25,966
讲一些更复杂的情境

281
00:14:26,033 --> 0:14:27,234
和模型个性化

282
00:14:27,301 --> 0:14:28,335
谢谢

283
00:14:37,144 --> 0:14:38,145
好的 谢谢Anil

284
00:14:41,448 --> 0:14:42,482
简单回顾一下

285
00:14:43,150 --> 0:14:44,785
Anil刚给我们演示了

286
00:14:46,253 --> 0:14:48,055
并尝试实现个性化体验

287
00:14:48,689 --> 0:14:52,626
通过提供一些模型很容易接受的

288
00:14:52,693 --> 0:14:53,927
然后我们看到我们得到了怎样的输出

289
00:14:54,962 --> 0:14:56,930
最初我们并没有得到很多

290
00:14:58,031 --> 0:14:59,166
那是因为在内部

291
00:14:59,466 --> 0:15:01,201
虽然我们已经预训练了神经网络

292
00:14:59,466 --> 0:15:01,201
虽然我们已经预训练了神经网络

293
00:15:01,535 --> 0:15:03,804
但它注入的是一个

294
00:15:04,238 --> 0:15:05,239
实际上是空的K最近邻基类分类器

295
00:15:05,305 --> 0:15:06,607
它没有可以进行分类的近邻

296
00:15:10,110 --> 0:15:11,912
因此我们要更新它并给它提供

297
00:15:11,979 --> 0:15:14,748
正如Anil给我们所展示的那样

298
00:15:15,115 --> 0:15:17,818
我们所选择的贴纸以及我们所绘制的

299
00:15:18,552 --> 0:15:20,621
然后我们把这些与我们的基础模型

300
00:15:21,221 --> 0:15:24,691
注入那个可更新的K最近邻基础模型

301
00:15:26,026 --> 0:15:27,995
这就为我们提供了新版的模型

302
00:15:29,329 --> 0:15:30,631
（用已更新模型进行预测）

303
00:15:31,098 --> 0:15:34,701
这个新版本可以更可靠地识别

304
00:15:35,669 --> 0:15:38,038
从内部来说 唯一发生改变的

305
00:15:38,105 --> 0:15:40,240
就是那个可更新K最近邻基础模型

306
00:15:41,575 --> 0:15:42,943
（更新任务）

307
00:15:44,144 --> 0:15:45,779
让我们看一下ML更新任务类

308
00:15:45,846 --> 0:15:46,980
我们今年引入了这个类

309
00:15:47,314 --> 0:15:49,249
用于帮助管理这些更新过程

310
00:15:50,684 --> 0:15:53,687
因此它有一个与它相关联的状态

311
00:15:53,754 --> 0:15:56,156
并且它可以恢复或取消那个任务

312
00:15:57,658 --> 0:16:00,127
要构建一个状态 你只需要传入

313
00:15:57,658 --> 0:16:00,127
要构建一个状态 你只需要传入

314
00:16:00,594 --> 0:16:04,431
模型的那个基础URL和配置

315
00:16:06,066 --> 0:16:08,502
正如Anil所演示的那样

316
00:16:09,603 --> 0:16:10,704
对于完成处理器

317
00:16:11,004 --> 0:16:12,506
我们将在你完成更新任务后进行调用

318
00:16:12,573 --> 0:16:14,007
并且它会给你提供一个更新情境

319
00:16:14,808 --> 0:16:17,110
当你完成更新后

320
00:16:17,177 --> 0:16:18,345
你可以用它来编写那个模型

321
00:16:18,879 --> 0:16:20,013
对它进行预测

322
00:16:20,380 --> 0:16:21,849
并查询任务的其它部分

323
00:16:21,915 --> 0:16:23,817
那可以让我们得到一部分更新情境

324
00:16:26,453 --> 0:16:29,022
在代码中 正如Anil所演示的

325
00:16:29,790 --> 0:16:33,460
你只需要构建一个MLupdateTask

326
00:16:33,961 --> 0:16:36,163
你的配置和你的完成处理器

327
00:16:36,230 --> 0:16:38,098
在这里我们用于检查准确度

328
00:16:39,032 --> 0:16:40,934
把模型保留在这个代码块的范围之外

329
00:16:41,568 --> 0:16:42,736
并保存那个模型

330
00:16:43,337 --> 0:16:46,206
这非常棒 用起来很不错

331
00:16:46,907 --> 0:16:49,843
但如果是更复杂的用例怎么样呢

332
00:16:49,910 --> 0:16:51,044
如果是神经网络会怎么样？

333
00:16:51,111 --> 0:16:52,479
（可更新的神经网络）

334
00:16:52,779 --> 0:16:56,016
嗯 最简单的神经网络只有几个层

335
00:16:56,750 --> 0:16:58,485
每个层都有一些输入和一些权重

336
00:16:58,852 --> 0:17:00,888
输入和权重结合使用创建一个输出

337
00:16:58,852 --> 0:17:00,888
输入和权重结合使用创建一个输出

338
00:17:02,589 --> 0:17:03,657
要调整那个输出

339
00:17:03,724 --> 0:17:05,492
我们需要在这些层中调整权重

340
00:17:05,858 --> 0:17:08,362
为此 我们需要把

341
00:17:10,664 --> 0:17:13,133
我们需要一些方式来告诉它

342
00:17:13,867 --> 0:17:16,703
如果我们想要一个微笑脸

343
00:17:17,171 --> 0:17:18,105
我们需要对此进行修正

344
00:17:18,172 --> 0:17:19,940
这要在我们的损失函数上实现

345
00:17:20,307 --> 0:17:21,575
损失函数描述那个delta

346
00:17:22,876 --> 0:17:24,944
最后我们需要把这个提供给我们的

347
00:17:25,212 --> 0:17:26,946
优化器会获取那个损失 我们的输出

348
00:17:27,214 --> 0:17:29,983
并算出实际上要在这些层中

349
00:17:33,520 --> 0:17:34,788
在Core ML 3上

350
00:17:34,855 --> 0:17:38,125
我们支持卷积更新和完全…

351
00:17:38,492 --> 0:17:41,962
完全连接的层以及通过更多层

352
00:17:42,029 --> 0:17:42,930
进行反向传播

353
00:17:43,297 --> 0:17:45,199
我们无条件支持交叉熵

354
00:17:45,532 --> 0:17:47,201
和均方误差损失类型

355
00:17:48,101 --> 0:17:50,737
此外我们还支持随机梯度下降

356
00:17:50,804 --> 0:17:52,639
和Adam优化策略

357
00:17:55,209 --> 0:17:56,243
这非常棒 对吗？

358
00:17:56,577 --> 0:17:59,546
但还有其它与神经网络相关联的参数

359
00:18:00,047 --> 0:18:01,915
比如学习速率

360
00:18:02,850 --> 0:18:05,018
这些都要被封装在那个模型内

361
00:18:06,820 --> 0:18:09,423
然而我们理解你们中有些人

362
00:18:10,958 --> 0:18:11,925
你可以通过

363
00:18:11,992 --> 0:18:14,461
覆盖更新参数字典

364
00:18:14,728 --> 0:18:15,929
和模型配置在运行时进行修改

365
00:18:16,330 --> 0:18:17,664
你可以通过使用MLParameterKey

366
00:18:18,632 --> 0:18:21,201
覆盖内部的值

367
00:18:21,768 --> 0:18:23,537
我们给你们提供了很大的灵活度

368
00:18:24,671 --> 0:18:25,939
（Xcode中的参数）

369
00:18:26,573 --> 0:18:29,243
此外 如果你在考虑

370
00:18:29,309 --> 0:18:30,544
我的模型内到底嵌入了多少参数

371
00:18:31,111 --> 0:18:34,214
你可以在Xcode中查看

372
00:18:34,548 --> 0:18:37,150
将为你提供那些参数的值

373
00:18:37,417 --> 0:18:39,586
以及该模型内到底定义了哪些参数

374
00:18:44,057 --> 0:18:45,692
你可能想要更多的灵活度

375
00:18:45,759 --> 0:18:48,495
而不仅仅是我们之前所演示的API

376
00:18:49,763 --> 0:18:50,731
在你的MLUpdateTask中

377
00:18:50,797 --> 0:18:52,933
你可以提供一个

378
00:18:53,634 --> 0:18:54,835
而不是提供完成处理器

379
00:18:55,469 --> 0:18:57,704
并提供进度处理器

380
00:18:58,405 --> 0:19:00,207
将允许你输入特定事件

381
00:18:58,405 --> 0:19:00,207
将允许你输入特定事件

382
00:19:00,274 --> 0:19:02,843
因此当训练开始

383
00:19:03,277 --> 0:19:04,811
我们将调用你的进度处理器

384
00:19:05,946 --> 0:19:08,682
并为你提供更新情境

385
00:19:11,051 --> 0:19:12,019
此外

386
00:19:12,085 --> 0:19:14,454
我们还会告诉你是哪个事件导致

387
00:19:15,422 --> 0:19:16,757
并为你提供关键指标

388
00:19:16,823 --> 0:19:18,525
从而你可以在处理

389
00:19:18,892 --> 0:19:20,894
每一小批或每个epoch时

390
00:19:23,163 --> 0:19:25,098
在代码中 仍然是非常得直截了当

391
00:19:25,566 --> 0:19:27,434
你构建这个

392
00:19:27,901 --> 0:19:29,336
并告诉它你对哪些事件感兴趣

393
00:19:29,703 --> 0:19:30,938
并提供一个它可以调用的代码块

394
00:19:32,673 --> 0:19:34,975
此外 你还要提供完成处理器

395
00:19:35,676 --> 0:19:36,910
和你刚刚用于

396
00:19:37,177 --> 0:19:39,046
提供进度处理器的

397
00:19:41,982 --> 0:19:43,116
（后台中的CORE ML）

398
00:19:43,684 --> 0:19:45,385
我们已经讲了如何更新模型

399
00:19:45,452 --> 0:19:46,653
以及更新模型意味着什么

400
00:19:47,254 --> 0:19:50,357
嗯 我们目前还没有真正讲到的是

401
00:19:51,525 --> 0:19:53,126
在我们之前演示过的评级app中

402
00:19:53,193 --> 0:19:56,763
我们在他与app第二次交互

403
00:19:57,130 --> 0:19:59,199
我们获取那个数据并把它发送给模型

404
00:20:00,567 --> 0:20:01,702
但那可能会不合适

405
00:20:01,768 --> 0:20:04,071
如果你有数百万数据点会怎样？

406
00:20:05,005 --> 0:20:06,840
如果你的模型极其复杂会怎样？

407
00:20:07,975 --> 0:20:08,976
嗯 我对此感到很激动

408
00:20:09,309 --> 0:20:11,044
我想说使用

409
00:20:11,879 --> 0:20:14,481
将会给你的app

410
00:20:15,148 --> 0:20:16,650
即使用户没有在使用你的app

411
00:20:17,084 --> 0:20:18,719
或即使他们并没有与设备进行交互

412
00:20:19,620 --> 0:20:23,557
你都可以使用BGTaskScheduler

413
00:20:24,124 --> 0:20:26,226
我们将为你提供数分钟来执行

414
00:20:26,660 --> 0:20:27,694
和进一步的计算

415
00:20:29,029 --> 0:20:30,364
要了解更多信息…是的

416
00:20:33,834 --> 0:20:34,735
太棒了

417
00:20:34,801 --> 0:20:37,037
要了解更多信息 我强烈推荐你们

418
00:20:37,104 --> 0:20:39,606
查看“关于App后台执行的改进”

419
00:20:43,343 --> 0:20:45,045
此外 你要如何获得可更新的模型？

420
00:20:45,312 --> 0:20:46,880
嗯 我们之前讲过了

421
00:20:47,414 --> 0:20:48,982
你可以通过

422
00:20:49,049 --> 0:20:50,851
从许多所支持的训练库中转换模型

423
00:20:51,285 --> 0:20:52,653
这并没有变

424
00:20:53,987 --> 0:20:55,989
当你转化模型时

425
00:20:56,356 --> 0:20:57,758
你只需要传入

426
00:20:58,392 --> 0:20:59,960
它会获取那些可训练参数

427
00:21:00,027 --> 0:21:01,929
比如你想采取哪种优化策略

428
00:21:02,429 --> 0:21:03,730
哪个层可更新

429
00:21:04,131 --> 0:21:06,033
我们会获取那些信息

430
00:21:06,600 --> 0:21:08,168
然后模型的其余部分与之前一模一样

431
00:21:10,204 --> 0:21:12,840
如果你们想直接修改模型自身

432
00:21:13,140 --> 0:21:14,741
我们也完全支持

433
00:21:15,609 --> 0:21:17,144
（模型个性化概述）

434
00:21:17,911 --> 0:21:20,414
我们讲了如何在app中

435
00:21:20,480 --> 0:21:22,382
使用设备上的模型个性化

436
00:21:22,850 --> 0:21:24,785
为用户创建更个性化的体验

437
00:21:25,953 --> 0:21:28,288
你可以通过新的灵活但简单的

438
00:21:29,289 --> 0:21:31,491
非常棒 你完全可以在设备上实现

439
00:21:32,192 --> 0:21:33,026
有了这些信息

440
00:21:33,894 --> 0:21:36,230
我要把舞台交给我的同事

441
00:21:36,296 --> 0:21:37,831
她会讲我们今年针对神经网络

442
00:21:37,898 --> 0:21:39,600
所添加的一些很棒的新功能

443
00:21:40,234 --> 0:21:41,502
（神经网络）

444
00:21:45,572 --> 0:21:46,673
好的

445
00:21:48,275 --> 0:21:49,376
我感到非常激动…

446
00:21:50,277 --> 0:21:53,914
我要讲的是今年Core ML中

447
00:21:55,015 --> 0:21:56,183
但在此之前

448
00:21:57,084 --> 0:22:01,154
我想花几分钟笼统地讲一下神经网络

449
00:21:57,084 --> 0:22:01,154
我想花几分钟笼统地讲一下神经网络

450
00:22:02,856 --> 0:22:05,959
嗯 我们都知道神经网络致力于

451
00:22:06,026 --> 0:22:08,095
解决具有挑战性的任务

452
00:22:08,595 --> 0:22:11,932
比如了解图片内容或文档内容

453
00:22:12,266 --> 0:22:13,267
或音频剪辑的内容

454
00:22:14,501 --> 0:22:18,972
我们可以使用这个功能来创建一些

455
00:22:20,774 --> 0:22:25,979
如果你深入了解一下神经网络

456
00:22:26,847 --> 0:22:28,849
我们可能会更好地理解它

457
00:22:30,250 --> 0:22:31,251
让我们来试一下

458
00:22:31,818 --> 0:22:35,055
但我们不是从研究者的角度来看

459
00:22:35,422 --> 0:22:36,857
让我们尝试从一个不同的视角来看

460
00:22:37,291 --> 0:22:40,727
让我们从程序员的视角来看

461
00:22:41,895 --> 0:22:44,398
如果你查看Core ML模型内部

462
00:22:44,865 --> 0:22:47,334
我们所看到的类似一个图形

463
00:22:48,335 --> 0:22:49,503
如果你再仔细查看

464
00:22:49,903 --> 0:22:54,608
我们会意识到那个图形

465
00:22:55,375 --> 0:22:56,410
让我们再看一眼

466
00:22:58,512 --> 0:23:02,049
这是我们都能理解的一个

467
00:22:58,512 --> 0:23:02,049
这是我们都能理解的一个

468
00:23:02,816 --> 0:23:05,452
这是与它相对应的图形表示

469
00:23:06,386 --> 0:23:09,356
你可能已经注意到了 代码中的操作

470
00:23:09,723 --> 0:23:11,892
就是图形中的这些注释

471
00:23:12,726 --> 0:23:17,097
而可读取的比如X、Y、Z

472
00:23:18,031 --> 0:23:20,133
如果你返回去看神经网络图形

473
00:23:21,201 --> 0:23:23,437
它现在显示的是相应的代码片段

474
00:23:24,037 --> 0:23:26,139
看起来与之前的非常类似

475
00:23:26,974 --> 0:23:29,176
但我要指出几个不同点

476
00:23:32,312 --> 0:23:36,483
第一 我们现在所拥有的

477
00:23:36,550 --> 0:23:40,988
而是这些多维变量 变量有多个参数

478
00:23:41,488 --> 0:23:46,193
它可以有形状参数和排名参数

479
00:23:46,493 --> 0:23:48,195
就是它所拥有的一些维度

480
00:23:49,062 --> 0:23:50,130
第二件事是

481
00:23:50,197 --> 0:23:53,500
操纵这些多维度变量的函数

482
00:23:53,800 --> 0:23:56,203
现在变成了这些专业的数学函数

483
00:23:56,570 --> 0:23:59,139
有时候也叫做层或操作

484
00:24:01,275 --> 0:24:03,644
如果你真的看一下神经网络

485
00:24:08,115 --> 0:24:12,753
我们会看到它实质上是一个图形

486
00:24:13,220 --> 0:24:17,391
包含这些非常大的多维度变量

487
00:24:17,758 --> 0:24:20,227
以及这些非常复杂的数学函数

488
00:24:20,661 --> 0:24:24,932
从实质上说 它是要进行大量计算

489
00:24:25,866 --> 0:24:29,336
关于Core ML

490
00:24:30,103 --> 0:24:32,973
它把全部这些复杂的东西都封装到

491
00:24:33,574 --> 0:24:35,042
也就是Core ML框架

492
00:24:35,108 --> 0:24:38,245
然后进行一些优化并非常高效地执行

493
00:24:40,547 --> 0:24:43,517
因此如果我们返回去看

494
00:24:43,851 --> 0:24:48,255
嗯 我们会很轻松地使用非循环图形

495
00:24:48,889 --> 0:24:51,491
我们大约有40种不同的层类型

496
00:24:51,758 --> 0:24:55,696
通过这些层 我们可以表示绝大部分

497
00:24:55,762 --> 0:24:57,731
和循环架构

498
00:24:58,866 --> 0:24:59,867
今年有什么新功能呢？

499
00:25:00,434 --> 0:25:05,372
嗯 你可能已经注意到了

500
00:25:05,706 --> 0:25:08,075
我们都知道代码

501
00:25:08,141 --> 0:25:09,576
会比简单的直线式代码复杂的多

502
00:25:10,310 --> 0:25:11,278
比如说

503
00:25:11,345 --> 0:25:15,415
使用像分支这样的控制流很常见

504
00:25:16,049 --> 0:25:17,551
如这段代码所示

505
00:25:18,118 --> 0:25:19,653
在Core ML 3中

506
00:25:19,720 --> 0:25:22,890
新功能是我们可以在神经网络规范内

507
00:25:22,956 --> 0:25:24,691
表达同样的分支概念

508
00:25:30,831 --> 0:25:34,401
另一种常见的控制流的形式

509
00:25:34,902 --> 0:25:39,206
我们也可以在Core ML网络内

510
00:25:40,174 --> 0:25:42,976
继续研究代码的另一个复杂特性

511
00:25:44,044 --> 0:25:46,780
当我们编写动态代码时

512
00:25:47,214 --> 0:25:49,650
就是在运行时分配内存

513
00:25:50,083 --> 0:25:51,318
如这段代码所示

514
00:25:51,385 --> 0:25:54,855
我们正在按照程序的输入分配内存

515
00:25:54,922 --> 0:25:56,490
从而可以在运行时改变内存的分配

516
00:25:56,857 --> 0:25:59,560
今年我们可以在Core ML

517
00:25:59,960 --> 0:26:03,197
通过动态层来实现

518
00:25:59,960 --> 0:26:03,197
通过动态层来实现

519
00:26:03,664 --> 0:26:06,400
它可以让我们根据图形的输入

520
00:26:06,667 --> 0:26:07,935
修改多数组的形状

521
00:26:08,302 --> 0:26:11,405
你可能在想我们为什么

522
00:26:11,471 --> 0:26:15,409
添加这些新的复杂的代码结构呢

523
00:26:15,742 --> 0:26:16,844
答案很简单

524
00:26:16,910 --> 0:26:20,981
因为神经网络研究正在积极地探索

525
00:26:21,281 --> 0:26:23,951
从而使神经网络变得更强大

526
00:26:24,017 --> 0:26:27,654
事实上 许多最先进的神经网络

527
00:26:28,155 --> 0:26:30,524
都内嵌了某种控制流

528
00:26:31,658 --> 0:26:36,063
研究者们不断探索的另一个方面是

529
00:26:36,129 --> 0:26:38,065
某种新操作

530
00:26:38,565 --> 0:26:43,370
为此我们今年向Core ML中

531
00:26:44,371 --> 0:26:47,441
我们不仅把当前层变得更通用了

532
00:26:47,508 --> 0:26:50,878
我们还添加了大量新的基础数学运算

533
00:26:51,411 --> 0:26:53,614
因此如果你遇到了一个新层

534
00:26:54,081 --> 0:26:57,217
它很可能会

535
00:26:57,284 --> 0:26:58,986
以Core ML 3中的层来表示

536
00:27:06,927 --> 0:27:11,331
有了这些控制流功能、动态行为

537
00:27:11,398 --> 0:27:12,299
和新层

538
00:27:12,833 --> 0:27:15,969
Core ML模型

539
00:27:16,637 --> 0:27:18,105
最重要的是

540
00:27:18,172 --> 0:27:22,943
绝大多数流行的架构都可以轻松地

541
00:27:23,277 --> 0:27:24,178
以Core ML格式表达

542
00:27:24,845 --> 0:27:27,748
你可以从这张幻灯片上看到

543
00:27:28,115 --> 0:27:32,386
突出显示的那些将在未来几个月实现

544
00:27:32,452 --> 0:27:34,955
它们极大地推动了

545
00:27:35,355 --> 0:27:38,292
现在你可以在Core ML中

546
00:27:38,592 --> 0:27:40,160
并把它们集成到app中

547
00:27:40,761 --> 0:27:41,662
真是太棒了

548
00:27:45,766 --> 0:27:47,100
（如何创建ML模型）

549
00:27:48,035 --> 0:27:50,737
现在你可能在想

550
00:27:51,071 --> 0:27:53,640
利用这些新功能

551
00:27:53,707 --> 0:27:55,776
嗯 答案是与去年一样

552
00:27:56,376 --> 0:27:58,846
要创建一个Core ML模型

553
00:27:59,813 --> 0:28:04,351
第一 因为Core ML是一个

554
00:27:59,813 --> 0:28:04,351
第一 因为Core ML是一个

555
00:28:04,818 --> 0:28:07,788
我们总是可以使用任意编程语言

556
00:28:08,121 --> 0:28:09,957
通过程序来指定模型

557
00:28:11,358 --> 0:28:12,993
因此我们总是可以使用这个方法

558
00:28:13,560 --> 0:28:15,462
但在绝大多数情况下

559
00:28:15,529 --> 0:28:18,532
我们希望使用转换器来实现

560
00:28:18,799 --> 0:28:22,202
通过把图形从不同的表示转换为

561
00:28:22,769 --> 0:28:24,271
Core ML表示来实现

562
00:28:24,972 --> 0:28:27,608
让我们具体看一下这两种方法

563
00:28:29,409 --> 0:28:31,812
在这里我要展示一个简单的神经网络

564
00:28:32,379 --> 0:28:36,483
并演示如何使用Core ML工具

565
00:28:36,884 --> 0:28:40,754
它是围绕Protobuf规范的

566
00:28:41,889 --> 0:28:43,323
我个人很喜欢这个方法

567
00:28:43,590 --> 0:28:47,494
特别是当我转换一个我非常了解

568
00:28:47,928 --> 0:28:50,764
如果我有一个可用的预训练的权重

569
00:28:51,098 --> 0:28:54,635
这是一个很好的数据

570
00:28:55,669 --> 0:28:56,670
话虽如此

571
00:28:57,371 --> 0:28:59,439
神经网络通常更复杂一些

572
00:28:59,973 --> 0:29:03,911
我们最好是使用转换器

573
00:28:59,973 --> 0:29:03,911
我们最好是使用转换器

574
00:29:04,878 --> 0:29:07,447
我们在GitHub上有一些转换器

575
00:29:07,714 --> 0:29:09,416
通过这些转换器

576
00:29:10,250 --> 0:29:12,252
你可以到达绝大部分机器学习框架

577
00:29:13,187 --> 0:29:16,623
好消息是通过支持

578
00:29:17,090 --> 0:29:19,326
这些转换器也进行了更新

579
00:29:19,393 --> 0:29:20,561
变得更强健了

580
00:29:21,395 --> 0:29:24,665
如果你之前用过我们的转换器

581
00:29:25,299 --> 0:29:28,502
你可能会遇到类似这样的报错信息

582
00:29:28,569 --> 0:29:30,704
比如也许它在抱怨缺失一个层

583
00:29:30,771 --> 0:29:32,306
或层中缺失一个属性

584
00:29:33,207 --> 0:29:35,242
现在所有这些都会消失

585
00:29:35,309 --> 0:29:38,045
因为我们更新了转换器

586
00:29:38,378 --> 0:29:40,080
转换器可以充分利用

587
00:29:41,315 --> 0:29:42,649
（前面是一马平川）

588
00:29:47,254 --> 0:29:50,624
那么我们已经讲了

589
00:29:50,691 --> 0:29:52,826
现在是时候在实际操作中

590
00:29:52,893 --> 0:29:54,661
为此我要邀请我朋友

591
00:29:56,830 --> 0:29:57,965
（问答APP）

592
00:29:58,265 --> 0:30:01,068
谢谢 谢谢Aseem

593
00:29:58,265 --> 0:30:01,068
谢谢 谢谢Aseem

594
00:30:01,869 --> 0:30:03,403
大家好 我是Allen

595
00:30:03,837 --> 0:30:06,740
今天我要给大家演示如何使用

596
00:30:06,807 --> 0:30:10,410
把用于自然语言处理的最先进的

597
00:30:10,477 --> 0:30:12,579
引入到我们的app中

598
00:30:14,848 --> 0:30:17,084
我喜欢阅读与历史相关的内容

599
00:30:17,918 --> 0:30:20,754
无论何时当我遇到一些

600
00:30:21,255 --> 0:30:23,624
我脑子里经常会浮现一些问题

601
00:30:23,690 --> 0:30:25,559
我很想知道问题的答案

602
00:30:26,360 --> 0:30:28,028
但有时我会很不耐烦

603
00:30:28,495 --> 0:30:30,063
我不想阅读整篇文章

604
00:30:30,998 --> 0:30:33,867
因此如果我可以创建一个app

605
00:30:34,301 --> 0:30:37,638
可以扫描文档然后给出回答

606
00:30:38,238 --> 0:30:42,276
我就开始用Core ML 3中的

607
00:30:42,676 --> 0:30:43,577
让我来给你们展示一下

608
00:30:51,418 --> 0:30:52,819
好的 这就是我的app

609
00:30:54,021 --> 0:30:58,292
你可以看到 它显示了一篇文章

610
00:30:59,326 --> 0:31:02,162
你可以看到 这篇文章很长

611
00:30:59,326 --> 0:31:02,162
你可以看到 这篇文章很长

612
00:31:02,462 --> 0:31:04,031
我当然没有时间通读一遍

613
00:31:04,698 --> 0:31:05,766
而且我有一些相关的疑问

614
00:31:06,333 --> 0:31:07,768
让我来问问这个app

615
00:31:10,671 --> 0:31:11,738
试着问第一个问题

616
00:31:13,807 --> 0:31:15,342
NeXT是由谁成立的？

617
00:31:19,479 --> 0:31:20,614
Steve Jobs

618
00:31:26,787 --> 0:31:28,589
好的 我想这是对的

619
00:31:29,289 --> 0:31:30,524
让我再问一个问题

620
00:31:34,261 --> 0:31:36,330
它的总部在哪儿？

621
00:31:39,533 --> 0:31:41,735
加利福尼亚的红杉城

622
00:31:46,206 --> 0:31:49,042
现在我还有一个非常感兴趣的问题

623
00:31:49,610 --> 0:31:50,644
让我试一试

624
00:31:53,280 --> 0:31:55,048
工程师们的工资是多少？

625
00:31:58,352 --> 0:32:01,455
7万5千美元或5万美元

626
00:31:58,352 --> 0:32:01,455
7万5千美元或5万美元

627
00:32:02,556 --> 0:32:03,457
有意思

628
00:32:09,863 --> 0:32:11,265
这不是很酷吗？

629
00:32:11,865 --> 0:32:13,267
那么现在…

630
00:32:15,736 --> 0:32:18,572
让我们更深入地看一下

631
00:32:20,574 --> 0:32:24,144
这款app的中心部分

632
00:32:24,211 --> 0:32:28,348
机器学习模型

633
00:32:28,415 --> 0:32:29,349
是Transformers的

634
00:32:29,816 --> 0:32:30,884
这个名字很长

635
00:32:31,351 --> 0:32:34,421
我们可以和其他研究者一样

636
00:32:35,289 --> 0:32:37,658
那么BERT模型是做什么的？

637
00:32:38,225 --> 0:32:40,227
嗯 通常是…

638
00:32:40,527 --> 0:32:42,896
它实际上是一个神经网络

639
00:32:44,498 --> 0:32:48,869
可以实施多任务用于理解自然语言

640
00:32:51,071 --> 0:32:53,340
但BERT模型内有什么？

641
00:32:54,808 --> 0:32:55,809
有一些模块

642
00:32:56,310 --> 0:32:57,477
这些模块内有什么？

643
00:32:58,645 --> 0:33:00,280
有层 许多许多层

644
00:32:58,645 --> 0:33:00,280
有层 许多许多层

645
00:33:01,381 --> 0:33:03,050
你可以看到 它非常复杂

646
00:33:03,350 --> 0:33:06,053
但通过Core ML 3中的

647
00:33:06,587 --> 0:33:09,022
我可以轻松地把这个模型

648
00:33:12,259 --> 0:33:14,661
但首先问题是

649
00:33:15,395 --> 0:33:17,631
嗯 你可以从我们的模型库网站上

650
00:33:18,999 --> 0:33:21,101
得到模型

651
00:33:22,236 --> 0:33:24,071
或你可以…如果你喜欢的话

652
00:33:24,338 --> 0:33:26,807
如果你可以…你可以训练一个模型

653
00:33:28,075 --> 0:33:29,977
比如前几天的一个晚上

654
00:33:30,043 --> 0:33:32,579
我用TensorFlow训练了

655
00:33:33,247 --> 0:33:35,883
这是我工作区的一张截图

656
00:33:36,517 --> 0:33:39,086
抱歉 我的工作区乱糟糟的

657
00:33:39,686 --> 0:33:43,056
但要使用Core ML的新转换器

658
00:33:43,724 --> 0:33:49,696
我需要把一个模型导入到

659
00:33:51,031 --> 0:33:54,768
然后我需要做的就是键入三行

660
00:33:55,869 --> 0:33:57,437
导入TF Core ML转换器

661
00:33:58,038 --> 0:33:59,206
调用转换函数

662
00:33:59,840 --> 0:34:01,575
然后保存为ML模型

663
00:33:59,840 --> 0:34:01,575
然后保存为ML模型

664
00:34:03,177 --> 0:34:06,613
你可以看到

665
00:34:07,080 --> 0:34:09,283
但要让app执行问答操作

666
00:34:09,616 --> 0:34:12,485
还需要几个步骤 我想具体讲一下

667
00:34:13,387 --> 0:34:15,088
要使用QA模型

668
00:34:15,789 --> 0:34:18,525
我需要准备一个问题和一段内容

669
00:34:19,059 --> 0:34:20,893
然后把它们分开

670
00:34:21,695 --> 0:34:24,364
模型要预测的是

671
00:34:24,898 --> 0:34:28,101
答案在段落中的位置

672
00:34:28,802 --> 0:34:31,338
你可以把它看作是个荧光笔

673
00:34:33,473 --> 0:34:35,909
然后我就可以开始创建我的app了

674
00:34:36,409 --> 0:34:38,478
模型自身并不构成app

675
00:34:39,112 --> 0:34:40,280
除此之外

676
00:34:40,547 --> 0:34:45,351
我还利用其它框架的许多功能

677
00:34:46,186 --> 0:34:49,056
比如我使用语音框架的

678
00:34:49,121 --> 0:34:52,659
把我的声音翻译为文本

679
00:34:53,560 --> 0:34:58,065
我使用自然语言API帮助我创建

680
00:34:58,832 --> 0:35:03,070
最后我使用AVFoundation的

681
00:34:58,832 --> 0:35:03,070
最后我使用AVFoundation的

682
00:35:03,403 --> 0:35:06,406
为我播放答案的音频

683
00:35:07,040 --> 0:35:10,777
这些组成部分都利用了设备上的

684
00:35:11,078 --> 0:35:14,381
因此使用这个app

685
00:35:18,218 --> 0:35:19,319
谢谢

686
00:35:19,386 --> 0:35:23,423
想象一下有多少新想法

687
00:35:23,490 --> 0:35:26,260
和新的用户体验可以引入到app中

688
00:35:27,027 --> 0:35:28,128
到此结束 谢谢

689
00:35:36,270 --> 0:35:38,739
好的 谢谢Allen

690
00:35:40,841 --> 0:35:43,410
好的 在我们总结之前

691
00:35:43,477 --> 0:35:47,881
我想再强调今年引入到

692
00:35:47,948 --> 0:35:51,018
我相信许多Core ML用户

693
00:35:52,186 --> 0:35:53,320
让我们先看第一个

694
00:35:53,654 --> 0:35:54,988
额外更新

695
00:35:56,990 --> 0:35:59,426
请想象一下幻灯片中所显示的

696
00:35:59,493 --> 0:36:03,697
假如我们有两个模型

697
00:35:59,493 --> 0:36:03,697
假如我们有两个模型

698
00:36:04,798 --> 0:36:05,933
如果你看一下内部

699
00:36:06,400 --> 0:36:09,203
这两个模型都是管道模型

700
00:36:09,603 --> 0:36:11,471
共享一个通用的功能提取器

701
00:36:12,206 --> 0:36:13,307
这种情况经常发生

702
00:36:13,373 --> 0:36:15,776
共享…

703
00:36:15,843 --> 0:36:18,879
训练深度神经网络以获得功能很常见

704
00:36:19,213 --> 0:36:22,049
并且那些功能可以注入到不同的

705
00:36:23,684 --> 0:36:24,885
实际上在幻灯片中

706
00:36:25,519 --> 0:36:29,189
我们注意到我们在这两个管道内

707
00:36:29,456 --> 0:36:30,724
使用了同一模型的多个副本

708
00:36:31,225 --> 0:36:32,759
这很明显效率很低

709
00:36:33,527 --> 0:36:34,995
为了提高效率

710
00:36:35,362 --> 0:36:37,865
我们启动了一个新模型类型

711
00:36:38,498 --> 0:36:39,600
如这里所示

712
00:36:40,968 --> 0:36:42,736
请看 想法非常简单

713
00:36:43,036 --> 0:36:45,639
链接模型就是

714
00:36:45,906 --> 0:36:47,808
对已经引入app的模型的一个引用

715
00:36:48,542 --> 0:36:52,779
这就把在不同模型中共享一个模型

716
00:36:54,915 --> 0:36:57,417
我还可以把链接模型看作是

717
00:36:57,484 --> 0:37:01,121
它就像是链接到一个动态库一样

718
00:36:57,484 --> 0:37:01,121
它就像是链接到一个动态库一样

719
00:37:01,922 --> 0:37:04,191
并且它只有几个参数

720
00:37:04,258 --> 0:37:07,828
其中包括它所链接到的模型的名称

721
00:37:09,062 --> 0:37:10,797
这对于可更新的模型或管道来说

722
00:37:11,665 --> 0:37:13,867
非常有用

723
00:37:14,935 --> 0:37:16,069
让我们看下一个功能

724
00:37:16,136 --> 0:37:17,337
（链接模型）

725
00:37:17,738 --> 0:37:19,806
假如你有一个Core ML模型

726
00:37:19,873 --> 0:37:21,708
接受图片作为输入

727
00:37:22,142 --> 0:37:26,980
目前为止Core ML希望图片是

728
00:37:27,714 --> 0:37:31,285
但如果你的图片来自不同的源

729
00:37:31,351 --> 0:37:32,653
是不同的格式会怎么样？

730
00:37:33,554 --> 0:37:34,855
在大部分情况下

731
00:37:35,522 --> 0:37:39,426
你可以使用Vision框架

732
00:37:39,493 --> 0:37:41,562
从而可以通过VNCoreMLRequest类

733
00:37:42,162 --> 0:37:43,597
这有一定的好处

734
00:37:43,664 --> 0:37:47,234
Vision可以替我们处理

735
00:37:47,634 --> 0:37:51,939
Vision也可以执行预处理

736
00:37:53,273 --> 0:37:57,377
然而在某些情况下 我们可能会

737
00:37:57,644 --> 0:38:01,348
比如当我们尝试调用更新API时

738
00:37:57,644 --> 0:38:01,348
比如当我们尝试调用更新API时

739
00:38:02,349 --> 0:38:03,417
对于这些情况

740
00:38:03,483 --> 0:38:06,119
我们发布了一些新初始化程序方法

741
00:38:06,453 --> 0:38:07,521
如幻灯片所示

742
00:38:07,588 --> 0:38:11,825
因此现在我们可以直接从URL

743
00:38:18,265 --> 0:38:22,503
这应该使得在Core ML中

744
00:38:24,371 --> 0:38:26,240
继续讲我想强调的最后一个功能

745
00:38:26,907 --> 0:38:30,310
在Core ML API中有一个类

746
00:38:31,278 --> 0:38:34,848
用于约束Core ML模型

747
00:38:34,915 --> 0:38:36,950
可以在哪些设备上执行

748
00:38:37,618 --> 0:38:42,055
比如[听不清]默认值是“全部”

749
00:38:42,589 --> 0:38:45,826
即全部计算机设备可用

750
00:38:45,893 --> 0:38:47,327
包括神经引擎

751
00:38:48,629 --> 0:38:51,398
现在我们向这个类中又添加了

752
00:38:53,300 --> 0:38:58,272
第一个是可以指定

753
00:38:59,239 --> 0:39:00,707
模型可以在其上执行的

754
00:38:59,239 --> 0:39:00,707
模型可以在其上执行的

755
00:39:01,275 --> 0:39:02,276
你可以想象一下

756
00:39:02,342 --> 0:39:05,279
如你在Mac上运行Core ML

757
00:39:05,345 --> 0:39:08,348
因为有许多不同的GPU

758
00:39:10,150 --> 0:39:13,720
我们所添加的另一个选项叫做

759
00:39:14,721 --> 0:39:18,225
我们的想法是如果你的模型

760
00:39:18,959 --> 0:39:21,562
但不是在float32中进行累积

761
00:39:21,628 --> 0:39:22,930
而恰好是在float60中

762
00:39:23,664 --> 0:39:27,901
现在这可以很大地提高

763
00:39:28,702 --> 0:39:30,537
但无论何时当我们降低精度时

764
00:39:30,871 --> 0:39:33,340
一定要记得检查模型的准确度

765
00:39:33,874 --> 0:39:36,643
准确度可能会下降或也可能不会下降

766
00:39:36,710 --> 0:39:37,945
取决于模型类型

767
00:39:38,712 --> 0:39:43,784
当你修改模型的精确度时

768
00:39:44,218 --> 0:39:46,553
我强烈鼓励你尝试一下这个选项

769
00:39:46,620 --> 0:39:48,322
看看是否对你的模型有帮助

770
00:39:50,357 --> 0:39:53,227
好的 我们在这场演讲中

771
00:39:53,293 --> 0:39:55,462
让我快速地总结一下

772
00:39:56,463 --> 0:39:58,999
我们讲了

773
00:39:59,566 --> 0:40:02,269
通过在设备上

774
00:39:59,566 --> 0:40:02,269
通过在设备上

775
00:40:02,336 --> 0:40:04,471
来为用户们打造个性化体验

776
00:40:05,205 --> 0:40:08,809
我们讲了如何向我们的规范中

777
00:40:08,876 --> 0:40:12,346
并且现在我们可以向app中

778
00:40:12,813 --> 0:40:13,814
引入最先进的神经网络架构了

779
00:40:14,381 --> 0:40:17,985
我们还讲了一些与GPU有关的

780
00:40:20,053 --> 0:40:22,422
这里有一些你可能会感兴趣

781
00:40:22,723 --> 0:40:23,891
并且与本场演讲相关的演讲

782
00:40:25,259 --> 0:40:26,326
谢谢大家
