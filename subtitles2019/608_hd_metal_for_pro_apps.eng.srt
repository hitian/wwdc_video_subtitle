1
00:00:00,506 --> 0:00:05,500
[ Music ]

2
00:00:11,516 --> 0:00:14,566
[ Applause ]

3
00:00:15,066 --> 0:00:16,606
&gt;&gt; Welcome to the Metal for Pro

4
00:00:16,606 --> 0:00:17,186
Apps session.

5
00:00:17,506 --> 0:00:19,286
My name is Eugene, and together

6
00:00:19,286 --> 0:00:20,856
with Dileep and Brian, we'll be

7
00:00:20,856 --> 0:00:22,586
talking about utilizing Metal to

8
00:00:22,586 --> 0:00:24,236
enable new workflows and unleash

9
00:00:24,346 --> 0:00:26,416
all the power of Macs and iPads

10
00:00:26,496 --> 0:00:28,076
for your Pro applications.

11
00:00:28,996 --> 0:00:30,636
But what is a Pro App?

12
00:00:31,156 --> 0:00:32,976
We at Apple define it as an

13
00:00:32,976 --> 0:00:35,316
application used by creative

14
00:00:35,396 --> 0:00:36,896
professionals in the content

15
00:00:36,896 --> 0:00:37,666
making business.

16
00:00:37,866 --> 0:00:39,796
That includes animators and live

17
00:00:39,796 --> 0:00:42,616
TV, photography, 3D animation,

18
00:00:43,286 --> 0:00:44,516
print media, and audio

19
00:00:44,516 --> 0:00:45,166
production.

20
00:00:46,146 --> 0:00:48,106
Additionally, it includes both

21
00:00:48,106 --> 0:00:49,496
first party as well as

22
00:00:49,496 --> 0:00:51,106
third-party apps created by

23
00:00:51,386 --> 0:00:52,216
developers like you.

24
00:00:53,026 --> 0:00:56,926
These are apps such as Autodesk

25
00:00:57,736 --> 0:00:59,686
Maya for 3D animation rigging

26
00:00:59,686 --> 0:01:02,456
and visual effects or maybe

27
00:00:59,686 --> 0:01:02,456
and visual effects or maybe

28
00:01:02,456 --> 0:01:05,586
Logic Pro for audio and music

29
00:01:05,636 --> 0:01:06,076
production.

30
00:01:06,076 --> 0:01:10,156
Serif Labs Affinity Photo for

31
00:01:10,156 --> 0:01:12,056
professional image editing or

32
00:01:13,106 --> 0:01:14,686
Black Magic's DaVinci Resolve,

33
00:01:15,166 --> 0:01:16,336
professional application for

34
00:01:16,336 --> 0:01:17,636
video editing.

35
00:01:18,636 --> 0:01:20,226
Pro apps have always been an

36
00:01:20,226 --> 0:01:22,266
important of our ecosystem, and

37
00:01:22,266 --> 0:01:23,806
with the recent release of the

38
00:01:23,806 --> 0:01:26,476
new Mac Pro our new Pro Display

39
00:01:26,726 --> 0:01:29,356
XDR robust support for external

40
00:01:29,356 --> 0:01:30,956
GPU's and the new A12X

41
00:01:30,956 --> 0:01:32,856
bionic-powered iPad pro.

42
00:01:33,166 --> 0:01:34,626
We really doubled down on our

43
00:01:34,686 --> 0:01:36,206
focus and commitment in this

44
00:01:36,206 --> 0:01:36,556
space.

45
00:01:37,526 --> 0:01:39,066
So why are pro apps different

46
00:01:39,066 --> 0:01:40,166
from other workloads?

47
00:01:41,316 --> 0:01:43,156
One key thing is that they

48
00:01:43,156 --> 0:01:44,806
operate on really large assets.

49
00:01:45,486 --> 0:01:47,066
This includes up to 8K video,

50
00:01:47,686 --> 0:01:49,296
billions of polygons, thousands

51
00:01:49,296 --> 0:01:50,936
of photos, hundreds of audio

52
00:01:50,936 --> 0:01:51,486
tracks.

53
00:01:52,406 --> 0:01:56,466
They also require a lot of CPU

54
00:01:56,466 --> 0:01:57,966
and GPU horsepower.

55
00:01:58,536 --> 0:02:01,246
Finally, there is always the

56
00:01:58,536 --> 0:02:01,246
Finally, there is always the

57
00:02:01,246 --> 0:02:04,726
challenge of achieving real-time

58
00:02:04,806 --> 0:02:06,096
interaction while maintaining

59
00:02:06,096 --> 0:02:07,496
the full fidelity of the

60
00:02:07,496 --> 0:02:08,175
original content.

61
00:02:08,826 --> 0:02:10,216
So let's go to the agenda of

62
00:02:10,485 --> 0:02:11,045
today's talk.

63
00:02:12,376 --> 0:02:14,146
First, we'll introduce the video

64
00:02:14,146 --> 0:02:15,306
editing pipeline on our

65
00:02:15,306 --> 0:02:17,306
platforms and discuss how to

66
00:02:17,306 --> 0:02:19,016
optimize it for groundbreaking

67
00:02:19,016 --> 0:02:19,476
8K.

68
00:02:20,236 --> 0:02:21,956
Next, we'll talk about how you

69
00:02:21,956 --> 0:02:24,296
can add HDR support to your app.

70
00:02:25,126 --> 0:02:28,126
Then, we show you how to scale

71
00:02:28,126 --> 0:02:30,516
across all CPU ports and GPU

72
00:02:30,516 --> 0:02:30,846
channels.

73
00:02:31,456 --> 0:02:33,406
And finally, we'll discuss how

74
00:02:33,406 --> 0:02:35,216
to achieve most efficient data

75
00:02:35,216 --> 0:02:35,726
transfers.

76
00:02:36,866 --> 0:02:38,866
So let's start by talking about

77
00:02:38,866 --> 0:02:40,646
the video editing pipeline with

78
00:02:40,646 --> 0:02:41,926
8K content in mind.

79
00:02:43,156 --> 0:02:44,816
We at Apple find video editing

80
00:02:44,816 --> 0:02:46,396
as one of the most demanding and

81
00:02:46,606 --> 0:02:47,686
creative workloads.

82
00:02:48,086 --> 0:02:50,186
So we will use video apps as a

83
00:02:50,186 --> 0:02:52,656
use case to show how Metal helps

84
00:02:52,656 --> 0:02:52,726
you.

85
00:02:53,446 --> 0:02:55,356
But before we start, I'd like to

86
00:02:55,356 --> 0:02:56,336
give a huge thanks to our

87
00:02:56,336 --> 0:02:57,616
friends at Black Magic Design.

88
00:02:58,136 --> 0:02:58,956
We've been working with them

89
00:02:58,956 --> 0:03:00,976
really closely optimizing both

90
00:02:58,956 --> 0:03:00,976
really closely optimizing both

91
00:03:01,026 --> 0:03:02,546
DaVinci Resolve and our platform

92
00:03:02,546 --> 0:03:05,006
to unleash new 8K workflows, and

93
00:03:05,006 --> 0:03:06,436
we're really proud of what we

94
00:03:06,436 --> 0:03:07,646
have achieved together.

95
00:03:08,526 --> 0:03:10,736
But let's see how it all worked

96
00:03:10,736 --> 0:03:13,416
before when we first tried 8K

97
00:03:13,416 --> 0:03:14,106
raw content.

98
00:03:14,866 --> 0:03:16,756
You see the result is not real

99
00:03:16,786 --> 0:03:17,016
time.

100
00:03:17,666 --> 0:03:19,666
We have heavy stuttering, and

101
00:03:19,666 --> 0:03:20,726
the experience is not great.

102
00:03:22,026 --> 0:03:23,296
So that doesn't work.

103
00:03:24,176 --> 0:03:25,576
Let's see how professionals

104
00:03:25,756 --> 0:03:27,496
worked around this problem.

105
00:03:28,036 --> 0:03:30,296
So they have huge raw footage in

106
00:03:30,296 --> 0:03:30,706
8K.

107
00:03:31,216 --> 0:03:34,386
First, they transcoded to get

108
00:03:34,386 --> 0:03:36,296
all the color base.

109
00:03:36,526 --> 0:03:38,336
Then they sub-sampled and

110
00:03:38,336 --> 0:03:39,696
downscaled it to 4K proxy.

111
00:03:40,046 --> 0:03:41,996
So they can apply edits and

112
00:03:41,996 --> 0:03:43,686
affects in real time, but there

113
00:03:43,686 --> 0:03:45,376
is one really important catch.

114
00:03:46,256 --> 0:03:48,226
You cannot color grade proxy

115
00:03:48,226 --> 0:03:49,596
data simply because it's not

116
00:03:49,596 --> 0:03:50,046
accurate.

117
00:03:50,626 --> 0:03:52,426
So now you have to go back and

118
00:03:52,426 --> 0:03:54,406
apply all of your edits to the

119
00:03:54,406 --> 0:03:56,386
original content, run an offline

120
00:03:56,386 --> 0:03:58,106
render job which may take hours.

121
00:03:58,736 --> 0:04:00,636
Review it with your director and

122
00:03:58,736 --> 0:04:00,636
Review it with your director and

123
00:04:00,636 --> 0:04:01,656
then rinse and repeat.

124
00:04:02,616 --> 0:04:04,076
We at Apple want to make it

125
00:04:04,076 --> 0:04:05,666
faster for our users.

126
00:04:06,586 --> 0:04:08,076
We really want all the

127
00:04:08,076 --> 0:04:09,486
professionals to work straight

128
00:04:09,486 --> 0:04:11,356
in 8K content out of the box.

129
00:04:11,866 --> 0:04:12,966
So let me tell you the story of

130
00:04:13,006 --> 0:04:14,796
how we enabled real time video

131
00:04:14,796 --> 0:04:16,226
editing in 8K.

132
00:04:17,476 --> 0:04:19,206
So it starts with building an

133
00:04:19,206 --> 0:04:20,245
efficient video editing

134
00:04:20,245 --> 0:04:20,875
pipeline.

135
00:04:21,526 --> 0:04:23,166
We'll cover the general design

136
00:04:23,166 --> 0:04:24,916
of an efficient pipeline, what

137
00:04:24,916 --> 0:04:26,516
frameworks to use, and how to

138
00:04:26,516 --> 0:04:28,246
maximize all the available

139
00:04:28,246 --> 0:04:28,646
hardware.

140
00:04:29,726 --> 0:04:31,626
Then, we'll discuss how to

141
00:04:31,626 --> 0:04:33,476
manage real large assets.

142
00:04:33,996 --> 0:04:35,746
And finally, we'll tell you

143
00:04:36,446 --> 0:04:37,796
about some challenges you might

144
00:04:37,796 --> 0:04:39,166
face trying to maintain a

145
00:04:39,456 --> 0:04:41,056
predictable frame rate and how

146
00:04:41,056 --> 0:04:41,836
to overcome them.

147
00:04:42,986 --> 0:04:45,026
So let's dive into the video

148
00:04:45,026 --> 0:04:45,756
editing pipeline.

149
00:04:47,476 --> 0:04:49,366
Here are typical building blocks

150
00:04:49,366 --> 0:04:52,366
most video editing apps need to

151
00:04:52,366 --> 0:04:52,666
have.

152
00:04:53,366 --> 0:04:54,546
So we start by reading the

153
00:04:54,546 --> 0:04:56,376
content, then we need to decode

154
00:04:56,376 --> 0:04:57,746
it so we can process it.

155
00:04:57,886 --> 0:04:59,936
And finally, present or encode.

156
00:05:00,696 --> 0:05:02,846
In today's session, I'll be

157
00:05:02,846 --> 0:05:05,906
focusing on the decode process,

158
00:05:05,906 --> 0:05:07,226
encode and display blocks.

159
00:05:07,696 --> 0:05:08,926
We will be covering the import

160
00:05:08,926 --> 0:05:10,356
and export blocks which

161
00:05:10,356 --> 0:05:11,726
typically use AVFoundation

162
00:05:11,786 --> 0:05:12,106
framework.

163
00:05:12,696 --> 0:05:14,506
I encourage you to check out our

164
00:05:14,506 --> 0:05:16,446
samples on AVAssetReader and

165
00:05:16,446 --> 0:05:17,206
AVAssetWriter.

166
00:05:17,806 --> 0:05:21,226
Let's dive in how to make

167
00:05:21,226 --> 0:05:23,256
decoding part closer to Metal.

168
00:05:24,696 --> 0:05:26,316
Apple provides a flexible

169
00:05:26,316 --> 0:05:27,906
low-level framework called Video

170
00:05:27,906 --> 0:05:29,446
Toolbox to achieve efficient,

171
00:05:29,806 --> 0:05:31,056
high-performance video

172
00:05:31,296 --> 0:05:31,776
processing.

173
00:05:32,346 --> 0:05:34,266
It can be used on iOS, macOS,

174
00:05:34,266 --> 0:05:36,626
and tvOS, supports a huge number

175
00:05:36,626 --> 0:05:38,476
of formats and leverages any

176
00:05:38,476 --> 0:05:40,066
available hardware on our

177
00:05:40,066 --> 0:05:40,506
devices.

178
00:05:41,526 --> 0:05:42,766
The building block for the

179
00:05:42,766 --> 0:05:44,016
decode is a decompression

180
00:05:44,016 --> 0:05:45,696
session, and let me quickly show

181
00:05:45,696 --> 0:05:47,006
you how to set it up.

182
00:05:47,826 --> 0:05:50,506
First, we specify that we want

183
00:05:50,506 --> 0:05:51,526
to use hardware video

184
00:05:51,526 --> 0:05:52,006
decoding.

185
00:05:53,146 --> 0:05:55,296
Then we create a session for

186
00:05:55,296 --> 0:05:56,596
each video stream.

187
00:05:57,296 --> 0:05:58,736
We set it up with a completion

188
00:05:58,736 --> 0:05:59,366
handler here.

189
00:06:01,216 --> 0:06:04,466
While we go through our video

190
00:06:04,466 --> 0:06:07,176
stream we call decode frame with

191
00:06:07,176 --> 0:06:08,196
an async flag.

192
00:06:08,196 --> 0:06:09,746
This is really important to make

193
00:06:09,746 --> 0:06:10,976
the call a non-blocking one.

194
00:06:11,776 --> 0:06:13,156
Apple frame decode completion,

195
00:06:13,526 --> 0:06:15,076
our callback is going to be

196
00:06:15,076 --> 0:06:15,246
called.

197
00:06:15,246 --> 0:06:18,016
And finally please don't forget

198
00:06:18,066 --> 0:06:20,126
to clean up after you are done.

199
00:06:20,606 --> 0:06:23,126
So now we know how to decompress

200
00:06:23,126 --> 0:06:23,666
our frames.

201
00:06:24,196 --> 0:06:25,776
Now let's talk about how to make

202
00:06:25,776 --> 0:06:27,106
sure that we are doing it in a

203
00:06:27,106 --> 0:06:28,216
most optimal way.

204
00:06:30,066 --> 0:06:32,416
Your Mac might have set several

205
00:06:32,416 --> 0:06:34,236
hardware decoding blocks

206
00:06:34,236 --> 0:06:34,776
available.

207
00:06:35,186 --> 0:06:36,766
To make sure we are using the

208
00:06:36,766 --> 0:06:38,816
same physical memory with zero

209
00:06:38,816 --> 0:06:39,846
copies we'll leverage an

210
00:06:39,846 --> 0:06:41,086
internal object called an

211
00:06:41,086 --> 0:06:41,826
IOSurface.

212
00:06:42,846 --> 0:06:45,276
IOSurface is a hardware

213
00:06:45,276 --> 0:06:47,516
accelerated image buffer with

214
00:06:47,516 --> 0:06:48,916
GPU residency tracking.

215
00:06:49,616 --> 0:06:51,416
It also gives you interprocess

216
00:06:51,496 --> 0:06:53,376
and interframework access to the

217
00:06:53,376 --> 0:06:55,206
same GPU memory so it's perfect

218
00:06:55,206 --> 0:06:56,666
for this scenario.

219
00:06:57,696 --> 0:06:59,546
Core Video and Metal provides

220
00:07:00,046 --> 0:07:02,426
you an easy way to leverage the

221
00:07:02,426 --> 0:07:04,136
benefits of IOSurface using an

222
00:07:04,186 --> 0:07:05,006
object called

223
00:07:05,356 --> 0:07:06,716
CVMetalTextureCache.

224
00:07:07,196 --> 0:07:08,706
Let's see how to set it up.

225
00:07:09,936 --> 0:07:12,976
So here we create our

226
00:07:12,976 --> 0:07:15,286
CVMetalTextureCache, and we want

227
00:07:15,286 --> 0:07:16,686
to make sure we use the Metal

228
00:07:16,686 --> 0:07:18,196
device we're going to be using

229
00:07:18,196 --> 0:07:19,346
for pixel processing.

230
00:07:19,786 --> 0:07:22,446
So next whenever we get a new CV

231
00:07:22,446 --> 0:07:23,936
pixel buffer, we need to turn it

232
00:07:23,936 --> 0:07:24,886
into a Metal texture.

233
00:07:25,306 --> 0:07:26,996
It happens automatically at zero

234
00:07:26,996 --> 0:07:28,716
cost if our pixel buffer is

235
00:07:28,836 --> 0:07:30,186
backed by an IOSurface.

236
00:07:30,986 --> 0:07:33,206
Finally, don't forget to clean

237
00:07:33,206 --> 0:07:34,446
up your textures and pixel

238
00:07:34,446 --> 0:07:36,336
buffers to ensure proper reuse

239
00:07:36,436 --> 0:07:39,506
in the texture cache.

240
00:07:39,836 --> 0:07:41,556
So now we have our frame as an

241
00:07:41,556 --> 0:07:43,986
MTL texture, and we are ready to

242
00:07:43,986 --> 0:07:45,066
do some pixel processing.

243
00:07:45,366 --> 0:07:47,196
Here we have several options.

244
00:07:48,706 --> 0:07:50,406
Of course, we can write our own

245
00:07:50,406 --> 0:07:51,896
processing and grading kernels

246
00:07:52,206 --> 0:07:53,346
and it's really easy since

247
00:07:53,346 --> 0:07:54,576
Metal's shader language is

248
00:07:54,796 --> 0:07:55,676
C++ based.

249
00:07:55,676 --> 0:07:58,196
At the same time, we highly

250
00:07:58,196 --> 0:07:59,646
encourage you to use Metal

251
00:07:59,816 --> 0:08:01,186
performance shaders to do your

252
00:07:59,816 --> 0:08:01,186
performance shaders to do your

253
00:08:01,186 --> 0:08:01,946
pixel processing.

254
00:08:02,416 --> 0:08:03,446
You can even build your own

255
00:08:03,446 --> 0:08:04,976
neural network as part of your

256
00:08:04,976 --> 0:08:05,446
pipeline.

257
00:08:06,826 --> 0:08:08,666
Now let's see how to use MPS to

258
00:08:08,666 --> 0:08:10,726
run a typical blur filter.

259
00:08:12,076 --> 0:08:13,766
So we start with the Metal queue

260
00:08:14,276 --> 0:08:15,716
and the common buffer.

261
00:08:17,516 --> 0:08:20,356
We create a Gaussian blur

262
00:08:20,536 --> 0:08:23,246
kernel, one of many built into

263
00:08:23,996 --> 0:08:24,346
MPS.

264
00:08:24,346 --> 0:08:26,066
And now, we can attempt to

265
00:08:26,066 --> 0:08:27,926
encode the work in place and we

266
00:08:28,106 --> 0:08:29,666
provide a fallback allocator in

267
00:08:29,666 --> 0:08:31,996
the case it fails.

268
00:08:31,996 --> 0:08:33,515
And, finally, we commit our

269
00:08:33,716 --> 0:08:34,246
common buffer.

270
00:08:34,666 --> 0:08:36,616
MPS is a really powerful

271
00:08:36,616 --> 0:08:38,916
framework tuned for every device

272
00:08:38,916 --> 0:08:40,256
on our platform.

273
00:08:40,326 --> 0:08:41,666
We encourage you to read more

274
00:08:41,666 --> 0:08:43,206
and start using it.

275
00:08:44,166 --> 0:08:45,576
So we are done with the pixel

276
00:08:45,576 --> 0:08:47,016
processing and we are ready to

277
00:08:47,116 --> 0:08:49,046
encode our MTL texture to the

278
00:08:49,046 --> 0:08:49,766
output format.

279
00:08:50,566 --> 0:08:52,986
Of course, we will again use

280
00:08:52,986 --> 0:08:54,936
Video Toolbox here and let me

281
00:08:54,936 --> 0:08:56,456
show you how to do that in the

282
00:08:56,456 --> 0:08:58,326
most efficient way.

283
00:08:58,956 --> 0:09:00,316
Your new Mac Pro might have

284
00:08:58,956 --> 0:09:00,316
Your new Mac Pro might have

285
00:09:00,316 --> 0:09:02,336
several GPU's and each of them

286
00:09:02,456 --> 0:09:03,426
might have more than one

287
00:09:03,426 --> 0:09:04,196
encoding engine.

288
00:09:08,936 --> 0:09:10,446
Of course, we can let Video

289
00:09:10,446 --> 0:09:12,166
Toolbox be the best available

290
00:09:12,166 --> 0:09:13,996
device, but in many cases you'll

291
00:09:13,996 --> 0:09:15,206
want to specify a device

292
00:09:15,276 --> 0:09:17,596
explicitly to minimize copy

293
00:09:17,596 --> 0:09:18,076
overhead.

294
00:09:18,326 --> 0:09:20,546
So let's see how we do this and

295
00:09:20,546 --> 0:09:22,246
how to use CVPixelBufferPool to

296
00:09:22,246 --> 0:09:23,506
keep memory recycled.

297
00:09:28,106 --> 0:09:29,826
So here is how we get a list of

298
00:09:30,056 --> 0:09:31,456
all available encoders.

299
00:09:32,566 --> 0:09:34,506
First, we use the enable

300
00:09:34,876 --> 0:09:35,896
hardware flag to ensure we are

301
00:09:35,896 --> 0:09:37,766
leveraging hardware encoding.

302
00:09:38,276 --> 0:09:39,996
Then, we tell Video Toolbox

303
00:09:40,136 --> 0:09:41,366
which device we want to use.

304
00:09:41,456 --> 0:09:43,386
This is a critical step to

305
00:09:43,386 --> 0:09:44,566
ensure we're encoding on the

306
00:09:44,566 --> 0:09:46,436
same device we did our pixel

307
00:09:46,436 --> 0:09:46,946
processing.

308
00:09:48,386 --> 0:09:49,896
Another great thing here is we

309
00:09:49,896 --> 0:09:51,646
can use CVPixelBufferPool to get

310
00:09:51,646 --> 0:09:53,426
the surfaces in the exact format

311
00:09:53,726 --> 0:09:55,546
used by the hardware encoder.

312
00:09:57,366 --> 0:09:58,836
So this is how we get a buffer

313
00:09:59,146 --> 0:10:00,836
from the pool and then we use

314
00:09:59,146 --> 0:10:00,836
from the pool and then we use

315
00:10:01,166 --> 0:10:02,666
MetalTextureCache again.

316
00:10:03,306 --> 0:10:05,506
Now we can convert our

317
00:10:05,836 --> 0:10:07,546
interleaved process data to

318
00:10:07,546 --> 0:10:08,896
biplanar format which is what

319
00:10:08,896 --> 0:10:09,976
Video Toolbox needs.

320
00:10:10,846 --> 0:10:12,696
And, as usual, we clean up

321
00:10:12,696 --> 0:10:14,246
everything to keep buffers

322
00:10:15,786 --> 0:10:17,016
recycled.

323
00:10:17,016 --> 0:10:18,976
So we can now build the most

324
00:10:18,976 --> 0:10:21,256
efficient pipeline possible and

325
00:10:21,256 --> 0:10:22,076
that's really great.

326
00:10:22,846 --> 0:10:24,106
We'll cover display section

327
00:10:24,106 --> 0:10:25,546
separately and now let's talk

328
00:10:25,546 --> 0:10:26,826
about 8K for a bit.

329
00:10:28,256 --> 0:10:30,716
8K means really large assets.

330
00:10:31,076 --> 0:10:32,676
So let's see how to deal with

331
00:10:32,676 --> 0:10:32,776
them.

332
00:10:33,786 --> 0:10:35,116
First, let's do the math.

333
00:10:35,636 --> 0:10:37,466
An 8K frame is just huge.

334
00:10:38,286 --> 0:10:40,456
It is 16 times larger than an HD

335
00:10:40,456 --> 0:10:42,566
frame totaling up to 270

336
00:10:42,566 --> 0:10:44,256
megabytes uncompressed.

337
00:10:44,786 --> 0:10:49,256
And we have to send almost 300

338
00:10:49,256 --> 0:10:50,336
megabytes every frame.

339
00:10:50,666 --> 0:10:52,296
So for 30 frames per second we

340
00:10:52,296 --> 0:10:54,316
have nine gigabytes per second

341
00:10:54,316 --> 0:10:55,016
of bandwidth.

342
00:10:55,386 --> 0:10:56,796
It's really close to the PCI

343
00:10:56,796 --> 0:10:57,456
Express limit.

344
00:10:58,236 --> 0:10:59,826
Moreover, even with ProRes

345
00:10:59,826 --> 0:11:01,916
4 by 4 compression, a 10-minute

346
00:10:59,826 --> 0:11:01,916
4 by 4 compression, a 10-minute

347
00:11:02,246 --> 0:11:04,496
clip can easily take massive one

348
00:11:04,726 --> 0:11:05,256
terabyte.

349
00:11:05,796 --> 0:11:07,636
This creates a real challenge

350
00:11:08,006 --> 0:11:09,216
for real-time playback.

351
00:11:09,556 --> 0:11:11,596
So let's see what it looks like

352
00:11:11,596 --> 0:11:12,986
when we trace it using

353
00:11:12,986 --> 0:11:14,996
Instruments in Xcode.

354
00:11:15,206 --> 0:11:17,456
So here is a system trace for

355
00:11:17,456 --> 0:11:18,936
the video playback session we

356
00:11:18,936 --> 0:11:19,546
showed earlier.

357
00:11:20,666 --> 0:11:22,116
If we zoom into the Virtual

358
00:11:22,116 --> 0:11:23,666
Memory Track, we see a huge

359
00:11:23,666 --> 0:11:24,756
amount of page folds.

360
00:11:26,056 --> 0:11:27,346
And the associated zero fill

361
00:11:27,426 --> 0:11:28,676
cost is really high.

362
00:11:29,066 --> 0:11:30,226
We can see it below.

363
00:11:31,226 --> 0:11:32,746
So that naturally explains why

364
00:11:32,746 --> 0:11:33,986
all the decoding threads are

365
00:11:33,986 --> 0:11:35,746
stuck and cannot proceed.

366
00:11:37,066 --> 0:11:38,366
We need to manage our memory

367
00:11:38,576 --> 0:11:39,536
more carefully.

368
00:11:40,086 --> 0:11:43,816
Modern operating system

369
00:11:43,816 --> 0:11:44,916
don't actually physically

370
00:11:44,916 --> 0:11:46,346
allocate memory pages until they

371
00:11:46,346 --> 0:11:46,706
are used.

372
00:11:47,096 --> 0:11:48,756
So once we start accessing all

373
00:11:48,756 --> 0:11:50,056
of these new pages from many

374
00:11:50,056 --> 0:11:51,306
decoding threads we have to

375
00:11:51,306 --> 0:11:53,136
wait for the system to map all

376
00:11:53,136 --> 0:11:54,116
those pages for us.

377
00:11:55,166 --> 0:11:56,006
The way to figure that is

378
00:11:56,006 --> 0:11:56,516
simple.

379
00:11:56,816 --> 0:11:59,506
Pre-warm your CPU buffers before

380
00:11:59,506 --> 0:12:01,596
use to make sure all the pages

381
00:11:59,506 --> 0:12:01,596
use to make sure all the pages

382
00:12:01,596 --> 0:12:03,536
are resident before playback

383
00:12:04,376 --> 0:12:05,386
starts.

384
00:12:06,086 --> 0:12:07,746
Now let me give you a few more

385
00:12:07,806 --> 0:12:10,946
memory management tips.

386
00:12:11,076 --> 0:12:12,606
Every allocation has a system

387
00:12:12,606 --> 0:12:12,956
call.

388
00:12:13,306 --> 0:12:15,246
One simple rule is to allocate

389
00:12:15,246 --> 0:12:16,586
early enough and avoid

390
00:12:16,816 --> 0:12:18,246
mid-workflow allocations.

391
00:12:18,966 --> 0:12:21,036
Another good advice is to always

392
00:12:21,036 --> 0:12:22,146
reuse your buffers.

393
00:12:22,556 --> 0:12:24,326
This is why it's so important to

394
00:12:24,326 --> 0:12:25,666
use objects such as

395
00:12:25,666 --> 0:12:27,116
CVPixelBufferPool and

396
00:12:27,346 --> 0:12:28,716
CVMetalTextureCache.

397
00:12:30,016 --> 0:12:31,746
So now we have improved the way

398
00:12:31,746 --> 0:12:34,076
we manage our frames but there

399
00:12:34,076 --> 0:12:35,796
are always many, many smaller

400
00:12:35,796 --> 0:12:37,636
allocations needed along the

401
00:12:37,636 --> 0:12:38,926
lifetime of your app.

402
00:12:39,226 --> 0:12:40,426
Let me give you some tips on how

403
00:12:40,426 --> 0:12:41,056
to manage those.

404
00:12:41,706 --> 0:12:44,236
With MTLheap's we can

405
00:12:44,236 --> 0:12:45,836
efficiently manage all of our

406
00:12:46,086 --> 0:12:47,216
transit allocations.

407
00:12:47,906 --> 0:12:49,106
Allocating from a MTLheap

408
00:12:49,286 --> 0:12:51,266
doesn't require a kernel call

409
00:12:51,386 --> 0:12:52,336
since the entire heap is

410
00:12:52,336 --> 0:12:54,286
allocated at creation time.

411
00:12:54,756 --> 0:12:56,436
The heap is a monolithic

412
00:12:56,436 --> 0:12:58,266
resource from the system's point

413
00:12:58,266 --> 0:12:58,526
of view.

414
00:12:58,946 --> 0:13:00,306
So it's made resident as a

415
00:12:58,946 --> 0:13:00,306
So it's made resident as a

416
00:13:00,306 --> 0:13:00,826
whole.

417
00:13:01,936 --> 0:13:03,366
Also, allocating from heap

418
00:13:03,806 --> 0:13:05,496
allows for tighter memory

419
00:13:05,946 --> 0:13:06,096
packing,

420
00:13:06,716 --> 0:13:08,266
and with heaps you can alias

421
00:13:08,266 --> 0:13:10,096
resource memory within the

422
00:13:10,096 --> 0:13:10,756
common buffer.

423
00:13:11,036 --> 0:13:12,346
Something we trust impossible

424
00:13:12,346 --> 0:13:13,486
with the regular buffers.

425
00:13:13,976 --> 0:13:15,626
Let me show you how to do this.

426
00:13:16,976 --> 0:13:18,446
In this sample, we will be

427
00:13:18,446 --> 0:13:20,326
aliasing transit allocations.

428
00:13:20,746 --> 0:13:23,066
First, we created the heap using

429
00:13:23,066 --> 0:13:23,816
our device.

430
00:13:24,296 --> 0:13:26,926
Along the filter stages, we

431
00:13:27,136 --> 0:13:28,736
created the uniforms for our

432
00:13:28,736 --> 0:13:31,006
blur kernel from that heap.

433
00:13:32,046 --> 0:13:34,006
Next, we allocate another buffer

434
00:13:34,006 --> 0:13:35,886
for color grade uniforms from

435
00:13:35,886 --> 0:13:37,146
that same heap.

436
00:13:37,736 --> 0:13:39,216
So after the color grading

437
00:13:39,216 --> 0:13:40,326
stage, we don't need those

438
00:13:40,326 --> 0:13:41,916
anymore and we mark them as

439
00:13:41,916 --> 0:13:43,966
aliasable, and the heap can

440
00:13:43,966 --> 0:13:45,486
actually recycle that memory for

441
00:13:45,696 --> 0:13:46,846
future allocations.

442
00:13:47,736 --> 0:13:49,596
So when we allocate a new

443
00:13:49,626 --> 0:13:51,436
intermediate buffer, the heap is

444
00:13:51,556 --> 0:13:53,566
free to reuse any memory marked

445
00:13:53,566 --> 0:13:55,946
as aliasable so this is really

446
00:13:55,946 --> 0:13:56,346
efficient.

447
00:13:57,746 --> 0:13:59,236
So that was a quick overview of

448
00:13:59,236 --> 0:14:01,046
how to manage our resource

449
00:13:59,236 --> 0:14:01,046
how to manage our resource

450
00:14:01,046 --> 0:14:01,696
allocations.

451
00:14:02,306 --> 0:14:04,276
Now let's talk about how to

452
00:14:04,486 --> 0:14:06,246
present our friends with a

453
00:14:06,646 --> 0:14:08,306
predictable frame rate.

454
00:14:09,146 --> 0:14:11,216
So here is a timing sample for

455
00:14:11,416 --> 0:14:13,026
triple buffer Metal application.

456
00:14:14,016 --> 0:14:15,476
In this example, we're playing a

457
00:14:15,476 --> 0:14:17,986
30-hertz video on a 60-hertz

458
00:14:18,056 --> 0:14:18,396
display.

459
00:14:19,106 --> 0:14:20,546
Notice how the frames are

460
00:14:20,546 --> 0:14:21,776
showing up on the display at a

461
00:14:21,776 --> 0:14:23,856
non-uniform cadence.

462
00:14:24,566 --> 0:14:26,036
Users feel it as stutters.

463
00:14:27,386 --> 0:14:29,276
So why is this happening?

464
00:14:29,806 --> 0:14:32,436
Note how the CPU is incurring

465
00:14:32,436 --> 0:14:34,516
GPU work without regard for

466
00:14:34,566 --> 0:14:34,896
timing.

467
00:14:36,516 --> 0:14:38,056
Once the third frame is

468
00:14:38,426 --> 0:14:39,376
enqueued, the CPU is blocked

469
00:14:39,736 --> 0:14:41,086
waiting for a drawable to

470
00:14:41,176 --> 0:14:42,606
become available which is not

471
00:14:42,726 --> 0:14:44,496
going to happen until frame one

472
00:14:44,496 --> 0:14:45,236
leaves the glass.

473
00:14:46,756 --> 0:14:48,716
So this approach maximizes GPU

474
00:14:48,956 --> 0:14:51,836
utilization but produces visible

475
00:14:51,836 --> 0:14:52,366
stutters.

476
00:14:53,626 --> 0:14:55,696
We generally want each frame to

477
00:14:55,696 --> 0:14:57,276
remain on the glass an equal

478
00:14:57,306 --> 0:14:59,266
amount of time.

479
00:14:59,456 --> 0:15:01,296
As a solution, Core Video offers

480
00:14:59,456 --> 0:15:01,296
As a solution, Core Video offers

481
00:15:01,296 --> 0:15:02,166
an interface called

482
00:15:02,316 --> 0:15:03,336
CVDisplayLink.

483
00:15:03,646 --> 0:15:05,326
This is a high-precision

484
00:15:05,446 --> 0:15:07,406
low-level timer which notifies

485
00:15:07,406 --> 0:15:09,616
you before every VBLANK at a

486
00:15:09,616 --> 0:15:10,896
displaced refresh rate.

487
00:15:11,646 --> 0:15:13,736
Rather than let the CPU

488
00:15:13,736 --> 0:15:14,976
enqueue as many frames as

489
00:15:14,976 --> 0:15:17,266
possible, We use display link to

490
00:15:17,496 --> 0:15:18,986
determine the right time to

491
00:15:18,986 --> 0:15:20,906
submit each frame to the GPU.

492
00:15:21,696 --> 0:15:23,886
This significantly reduces video

493
00:15:23,886 --> 0:15:24,506
playback jitter.

494
00:15:25,326 --> 0:15:26,386
So let me show you the code

495
00:15:26,386 --> 0:15:28,766
snippet how to do this.

496
00:15:28,966 --> 0:15:30,556
We started by making a link with

497
00:15:30,556 --> 0:15:31,646
the display we will be using.

498
00:15:32,206 --> 0:15:35,866
Then, we set up our callback

499
00:15:35,866 --> 0:15:37,896
handler and for every call we

500
00:15:37,966 --> 0:15:40,086
will get the current time and

501
00:15:40,086 --> 0:15:41,396
the next VBLANK time.

502
00:15:41,996 --> 0:15:43,436
And we can use these values to

503
00:15:43,686 --> 0:15:44,996
determine when to issue a

504
00:15:45,276 --> 0:15:46,716
present call assuming we have

505
00:15:46,956 --> 0:15:47,876
processed frames ready.

506
00:15:48,486 --> 0:15:50,616
And we can adjust the desired

507
00:15:50,866 --> 0:15:52,246
frequency to our needs.

508
00:15:53,206 --> 0:15:54,566
So this will significantly

509
00:15:54,606 --> 0:15:56,286
reduce stutters but we can take

510
00:15:56,286 --> 0:15:57,266
it a step further.

511
00:15:58,086 --> 0:16:00,336
For example, playing 24-hertz

512
00:15:58,086 --> 0:16:00,336
For example, playing 24-hertz

513
00:16:00,396 --> 0:16:02,296
content on a 60-hertz display,

514
00:16:02,666 --> 0:16:04,206
we need three-two pull down.

515
00:16:04,596 --> 0:16:06,946
It means we will present even

516
00:16:06,946 --> 0:16:08,916
frames for three VBLANKS and odd

517
00:16:08,916 --> 0:16:11,066
frames over two VBLANKS.

518
00:16:11,786 --> 0:16:13,486
This is the best we can do given

519
00:16:13,486 --> 0:16:15,076
the mismatch, and the code

520
00:16:15,076 --> 0:16:16,206
snippet I just showed you will

521
00:16:16,206 --> 0:16:18,286
handle this just fine, but the

522
00:16:18,286 --> 0:16:19,796
good news is we can do even

523
00:16:19,796 --> 0:16:20,086
better.

524
00:16:20,836 --> 0:16:23,386
Our new Pro Display XDR supports

525
00:16:23,386 --> 0:16:25,546
multiple refresh rates including

526
00:16:25,656 --> 0:16:26,446
48-hertz.

527
00:16:26,966 --> 0:16:29,286
So your 24-hertz content will

528
00:16:29,286 --> 0:16:31,286
play extremely smoothly jitter

529
00:16:31,286 --> 0:16:31,546
free.

530
00:16:32,906 --> 0:16:34,696
So we have made quite a few

531
00:16:34,696 --> 0:16:36,036
important optimizations.

532
00:16:37,036 --> 0:16:38,056
Now I'd like to show you the

533
00:16:38,056 --> 0:16:38,726
final result.

534
00:16:39,246 --> 0:16:40,586
This is DaVinci Resolve now

535
00:16:41,126 --> 0:16:42,916
playing that same 8k stream.

536
00:16:43,636 --> 0:16:44,866
As you can see, playback is

537
00:16:44,866 --> 0:16:46,826
smooth with no stutters.

538
00:16:47,366 --> 0:16:49,876
This has been a great

539
00:16:50,046 --> 0:16:51,326
collaboration for us with Black

540
00:16:51,326 --> 0:16:51,596
Magic.

541
00:16:52,156 --> 0:16:53,576
We achieved outstanding results

542
00:16:53,816 --> 0:16:55,296
together, and we encourage you

543
00:16:55,546 --> 0:16:56,716
to start leveraging our

544
00:16:56,956 --> 0:16:58,786
high-performance frameworks and

545
00:16:58,786 --> 0:17:00,286
start building new and exciting

546
00:16:58,786 --> 0:17:00,286
start building new and exciting

547
00:17:00,496 --> 0:17:02,366
pro apps for our platform.

548
00:17:02,856 --> 0:17:05,406
We have tackled that 8k

549
00:17:05,406 --> 0:17:05,856
challenge.

550
00:17:06,606 --> 0:17:08,786
Now I'd like to invite Dileep to

551
00:17:08,786 --> 0:17:10,896
talk about our support for HDR

552
00:17:11,616 --> 0:17:13,056
and how you can enable it in

553
00:17:13,056 --> 0:17:13,406
your app.

554
00:17:13,925 --> 0:17:14,195
Dileep?

555
00:17:15,516 --> 0:17:20,046
[ Applause ]

556
00:17:20,546 --> 0:17:21,705
&gt;&gt; Thanks, Eugene.

557
00:17:22,396 --> 0:17:24,566
In recent years high-dynamic

558
00:17:24,566 --> 0:17:26,346
range rendering and displays

559
00:17:26,346 --> 0:17:27,756
have greatly enhanced the

560
00:17:27,826 --> 0:17:29,576
quality of images that we see on

561
00:17:29,576 --> 0:17:29,966
screen.

562
00:17:30,936 --> 0:17:32,876
At Apple we have been constantly

563
00:17:33,156 --> 0:17:34,246
adding support to improve

564
00:17:34,246 --> 0:17:36,116
the image technology.

565
00:17:36,626 --> 0:17:38,466
As you know, we have added many

566
00:17:38,466 --> 0:17:40,416
technologies such as retina

567
00:17:40,416 --> 0:17:43,176
display, 4K and 5K resolution,

568
00:17:43,466 --> 0:17:45,866
wide gamut color space and many

569
00:17:46,256 --> 0:17:47,796
and have enabled you, the

570
00:17:47,796 --> 0:17:50,166
developers, to create amazing

571
00:17:50,166 --> 0:17:51,826
and high-quality images.

572
00:17:52,556 --> 0:17:54,326
Continuing in that part, this

573
00:17:54,326 --> 0:17:56,576
year we are adding great support

574
00:17:56,576 --> 0:17:58,656
for HDR on macOS.

575
00:17:59,336 --> 0:18:00,726
I'm excited to give you an

576
00:17:59,336 --> 0:18:00,726
I'm excited to give you an

577
00:18:00,726 --> 0:18:02,806
overview of the support for HDR

578
00:18:02,856 --> 0:18:04,406
rendering and display.

579
00:18:05,376 --> 0:18:07,826
To do that, I'll cover four

580
00:18:07,826 --> 0:18:08,676
topics with you.

581
00:18:09,376 --> 0:18:11,996
One, I'll briefly talk about

582
00:18:11,996 --> 0:18:13,696
some common traits of HDR

583
00:18:13,696 --> 0:18:14,186
images.

584
00:18:15,106 --> 0:18:17,386
Then I'll describe our approach

585
00:18:17,386 --> 0:18:19,666
to HDR, our rendering model of

586
00:18:20,726 --> 0:18:20,816
HDR.

587
00:18:21,066 --> 0:18:23,456
Then I'll go into detail on how

588
00:18:23,456 --> 0:18:26,116
to use Metal for HDR rendering.

589
00:18:26,656 --> 0:18:28,496
And finally, wrap it up with

590
00:18:28,496 --> 0:18:30,416
some recommendations on best

591
00:18:30,416 --> 0:18:31,036
practices.

592
00:18:32,346 --> 0:18:34,696
So let's begin with describing

593
00:18:34,696 --> 0:18:36,536
some common traits of HDR

594
00:18:36,536 --> 0:18:37,216
images.

595
00:18:37,636 --> 0:18:38,866
What makes them special?

596
00:18:39,956 --> 0:18:41,506
Compared to standard dynamic

597
00:18:41,506 --> 0:18:44,456
range or SDR images, HDR images

598
00:18:44,856 --> 0:18:46,656
have better contrast levels.

599
00:18:47,336 --> 0:18:48,826
They have great details in the

600
00:18:48,826 --> 0:18:50,436
dark and the bright areas of the

601
00:18:50,436 --> 0:18:50,826
image.

602
00:18:52,126 --> 0:18:54,476
Usually SDR images, these

603
00:18:54,476 --> 0:18:56,126
details are not discernible.

604
00:18:56,386 --> 0:18:58,276
They're either crushed or washed

605
00:18:58,276 --> 0:18:58,426
out.

606
00:19:00,036 --> 0:19:03,206
HDR images have more colors with

607
00:19:03,206 --> 0:19:04,976
wide range of colors in them.

608
00:19:05,486 --> 0:19:07,146
They look very realistic.

609
00:19:08,376 --> 0:19:10,336
Also, they are really bright.

610
00:19:10,826 --> 0:19:12,266
The brightness information is

611
00:19:12,356 --> 0:19:15,566
encoded in the image itself with

612
00:19:15,566 --> 0:19:17,696
such a high brightness and great

613
00:19:17,696 --> 0:19:19,816
contrast ratios, they make it

614
00:19:19,916 --> 0:19:21,976
possible to add lighting effects

615
00:19:21,976 --> 0:19:24,216
in the scene that look closer to

616
00:19:24,216 --> 0:19:24,856
real life.

617
00:19:25,596 --> 0:19:28,176
And finally, they need to be

618
00:19:28,176 --> 0:19:29,886
viewed on a capable display.

619
00:19:30,816 --> 0:19:32,636
The display that can preserve

620
00:19:32,786 --> 0:19:34,496
all the details of the image.

621
00:19:35,026 --> 0:19:36,356
The display in itself should

622
00:19:36,356 --> 0:19:38,316
have underlying technologies to

623
00:19:38,316 --> 0:19:39,666
be able to produce high

624
00:19:39,666 --> 0:19:41,926
brightness, high color fidelity,

625
00:19:41,926 --> 0:19:43,436
and great contrast ratios.

626
00:19:44,656 --> 0:19:47,026
Our new Pro Display XDR is a

627
00:19:47,176 --> 0:19:49,826
great example of that.

628
00:19:50,046 --> 0:19:53,136
Now, how do we render and

629
00:19:53,136 --> 0:19:54,866
display these amazing HDR

630
00:19:54,866 --> 0:19:56,856
contents on our devices?

631
00:19:58,036 --> 0:19:59,676
At Apple, we have a unique

632
00:19:59,676 --> 0:20:00,456
approach for this.

633
00:19:59,676 --> 0:20:00,456
approach for this.

634
00:20:01,076 --> 0:20:03,256
We call this EDR, extended

635
00:20:03,256 --> 0:20:04,146
dynamic range.

636
00:20:05,636 --> 0:20:07,606
In this approach, we use the

637
00:20:07,606 --> 0:20:09,226
brightness headroom available on

638
00:20:09,226 --> 0:20:10,376
the display to show the

639
00:20:10,376 --> 0:20:12,376
highlights and shadows of HDR

640
00:20:12,376 --> 0:20:12,976
images.

641
00:20:13,656 --> 0:20:15,976
Let me explain the concept in

642
00:20:16,686 --> 0:20:16,856
detail.

643
00:20:17,276 --> 0:20:19,096
As you know, the brightness set

644
00:20:19,096 --> 0:20:20,716
on a display is dependent on the

645
00:20:20,716 --> 0:20:22,006
viewing conditions or the

646
00:20:22,006 --> 0:20:22,956
ambient conditions.

647
00:20:23,986 --> 0:20:25,606
For example, if you're in a

648
00:20:25,606 --> 0:20:27,446
dimmed room the brightness set

649
00:20:27,446 --> 0:20:29,186
on your display could be 200

650
00:20:29,186 --> 0:20:31,626
nits, maybe low, and the

651
00:20:31,626 --> 0:20:34,366
brightness set is ideal to view

652
00:20:34,406 --> 0:20:37,716
SDR contents such as UI or

653
00:20:37,716 --> 0:20:39,456
Safari or YouTube video.

654
00:20:40,656 --> 0:20:42,736
But if your display is capable

655
00:20:42,736 --> 0:20:45,736
of producing up to thousand nits

656
00:20:45,736 --> 0:20:47,396
then you have a huge brightness

657
00:20:47,396 --> 0:20:48,516
headroom available on the

658
00:20:48,516 --> 0:20:48,926
display.

659
00:20:49,566 --> 0:20:52,126
Similarly, if you're in well-lit

660
00:20:52,126 --> 0:20:54,066
conditions such as office space,

661
00:20:54,626 --> 0:20:55,696
the brightness set on the

662
00:20:55,696 --> 0:20:58,026
display could be higher, say 500

663
00:20:58,026 --> 0:20:58,316
nits.

664
00:20:58,966 --> 0:21:00,586
And again, the brightness set is

665
00:20:58,966 --> 0:21:00,586
And again, the brightness set is

666
00:21:00,636 --> 0:21:03,306
ideal to view SDR contents but

667
00:21:03,306 --> 0:21:04,806
still you have brightness

668
00:21:04,856 --> 0:21:06,756
headroom left on the display in

669
00:21:06,756 --> 0:21:07,696
this condition too.

670
00:21:08,216 --> 0:21:11,016
In an approach to HDR, we take

671
00:21:11,016 --> 0:21:11,956
advantage of this.

672
00:21:12,476 --> 0:21:14,596
When we render the pixels, we

673
00:21:14,596 --> 0:21:16,726
map the SDR pixels to the

674
00:21:16,726 --> 0:21:18,336
brightness set on the display

675
00:21:18,766 --> 0:21:20,756
and use the headroom to map the

676
00:21:20,796 --> 0:21:21,826
HDR pixels.

677
00:21:22,396 --> 0:21:25,146
The extent to which we map these

678
00:21:25,146 --> 0:21:27,266
two categories really depends on

679
00:21:27,266 --> 0:21:28,646
the viewing conditions as you

680
00:21:28,646 --> 0:21:30,086
can clearly see in the two

681
00:21:30,086 --> 0:21:31,586
examples here.

682
00:21:33,216 --> 0:21:35,236
However, too, rendering this

683
00:21:35,286 --> 0:21:37,356
model, the pixels needs to be

684
00:21:37,476 --> 0:21:40,076
structured in a certain way and

685
00:21:40,256 --> 0:21:43,236
we do that by scaling the HDR

686
00:21:43,236 --> 0:21:45,176
pixels relative to the SDR

687
00:21:45,366 --> 0:21:46,466
brightness of the display.

688
00:21:47,966 --> 0:21:49,786
Let's use our previous example

689
00:21:49,786 --> 0:21:51,316
of a dimmed room and see how the

690
00:21:51,316 --> 0:21:53,026
pixel values are structured

691
00:21:53,026 --> 0:21:54,246
relative to the brightness of

692
00:21:54,246 --> 0:21:54,756
the display.

693
00:21:56,266 --> 0:21:58,106
In here, we represent the

694
00:21:58,156 --> 0:22:01,026
brightness in X axis and the

695
00:21:58,156 --> 0:22:01,026
brightness in X axis and the

696
00:22:01,026 --> 0:22:02,976
normalized pixel values in Y

697
00:22:02,976 --> 0:22:03,466
axis.

698
00:22:04,126 --> 0:22:06,216
In this example, the brightness

699
00:22:06,216 --> 0:22:09,746
of the display set to 200 nits.

700
00:22:10,566 --> 0:22:12,956
In our rendering model we always

701
00:22:12,956 --> 0:22:14,646
reserve the pixel values, the

702
00:22:14,646 --> 0:22:16,396
normalized pixel values in the

703
00:22:16,396 --> 0:22:19,606
range 0 to 14 SDR contents and

704
00:22:19,606 --> 0:22:21,576
we map it to the brightness set

705
00:22:21,576 --> 0:22:22,176
on the display.

706
00:22:23,196 --> 0:22:25,406
So a pixel value of one here

707
00:22:25,776 --> 0:22:28,256
corresponds to 200 nits.

708
00:22:29,116 --> 0:22:30,736
But as you can see, there is a

709
00:22:30,736 --> 0:22:32,276
huge headroom available on the

710
00:22:32,336 --> 0:22:32,746
display.

711
00:22:33,186 --> 0:22:35,316
So you have pixel values from

712
00:22:35,316 --> 0:22:37,366
one through five available to

713
00:22:37,366 --> 0:22:39,166
represent HDR contents.

714
00:22:40,126 --> 0:22:42,886
A scale factor of 5x relative to

715
00:22:42,886 --> 0:22:44,906
the SDR range to take full

716
00:22:44,906 --> 0:22:46,016
advantage of the display

717
00:22:46,016 --> 0:22:46,596
brightness.

718
00:22:47,886 --> 0:22:49,686
We call this scale factor as

719
00:22:50,136 --> 0:22:52,366
maximum EDR.

720
00:22:53,036 --> 0:22:54,806
If the viewing conditions change

721
00:22:54,906 --> 0:22:57,146
or you're in a well-lit room and

722
00:22:57,146 --> 0:22:58,926
the brightness is increased to

723
00:22:58,926 --> 0:23:01,806
500 nits, then the maximum EDR

724
00:22:58,926 --> 0:23:01,806
500 nits, then the maximum EDR

725
00:23:01,806 --> 0:23:05,346
drops down but note the pixel

726
00:23:05,346 --> 0:23:07,036
values in the range zero to one

727
00:23:07,396 --> 0:23:09,416
are still dedicated for SDR

728
00:23:09,566 --> 0:23:10,196
contents.

729
00:23:10,876 --> 0:23:12,396
But they're mapped differently

730
00:23:12,396 --> 0:23:15,246
now, so now a pixel value of one

731
00:23:15,386 --> 0:23:17,846
corresponds to 500 nits instead

732
00:23:17,846 --> 0:23:19,646
of 200 in the previous example.

733
00:23:20,906 --> 0:23:22,506
And since you have a smaller

734
00:23:22,506 --> 0:23:24,156
headroom available here, in this

735
00:23:24,156 --> 0:23:26,046
case, you have a smaller range

736
00:23:26,046 --> 0:23:27,786
of pixel calls available to

737
00:23:27,786 --> 0:23:29,396
represent HDR contents.

738
00:23:30,236 --> 0:23:32,316
So merely 2x here in this

739
00:23:32,316 --> 0:23:34,266
example, relative to the SDR

740
00:23:34,386 --> 0:23:36,406
range to represent HDR pixels.

741
00:23:37,626 --> 0:23:39,666
As you can see, we structured

742
00:23:39,666 --> 0:23:41,766
our pixels in such a way that

743
00:23:41,876 --> 0:23:43,816
the HDR pixels are relative to

744
00:23:43,816 --> 0:23:46,076
the SDR range and they scale

745
00:23:46,166 --> 0:23:47,686
relative to the SDR range.

746
00:23:48,576 --> 0:23:50,646
We also use negative pixels for

747
00:23:50,646 --> 0:23:52,176
representing the darker side of

748
00:23:52,436 --> 0:23:53,656
the HDR image.

749
00:23:54,646 --> 0:23:58,116
So in summary, EDR or external

750
00:23:58,116 --> 0:23:59,816
dynamic range is a display

751
00:23:59,816 --> 0:24:01,766
referred rendering model in

752
00:23:59,816 --> 0:24:01,766
referred rendering model in

753
00:24:01,766 --> 0:24:03,296
which we use the brightness

754
00:24:03,296 --> 0:24:04,686
headroom available on the

755
00:24:04,686 --> 0:24:07,386
display for HDR pixels, and we

756
00:24:07,626 --> 0:24:10,186
scale the HDR pixels relative to

757
00:24:10,186 --> 0:24:11,656
the SDR brightness of the

758
00:24:11,656 --> 0:24:12,066
display.

759
00:24:13,426 --> 0:24:16,066
The advantage of this model is

760
00:24:16,066 --> 0:24:18,196
that you can do HDR rendering on

761
00:24:18,386 --> 0:24:20,196
pretty much any display on which

762
00:24:20,196 --> 0:24:23,116
we can set brightness, but if

763
00:24:23,116 --> 0:24:24,946
you have more capable display

764
00:24:25,126 --> 0:24:27,196
such as of a new Pro Display XDR

765
00:24:27,646 --> 0:24:28,926
with its huge headroom

766
00:24:28,926 --> 0:24:31,196
availability then the contents

767
00:24:31,196 --> 0:24:35,246
are going to look just better.

768
00:24:35,436 --> 0:24:37,036
Now that we have looked into our

769
00:24:37,036 --> 0:24:38,676
rendering model of our approach

770
00:24:38,676 --> 0:24:41,416
to HDR, let's look into what

771
00:24:41,416 --> 0:24:43,726
API's do we have and how you can

772
00:24:43,726 --> 0:24:45,266
use those API's in your

773
00:24:45,266 --> 0:24:45,866
application.

774
00:24:48,566 --> 0:24:51,166
On both macOS and iOS, you have

775
00:24:51,166 --> 0:24:52,016
a couple of options.

776
00:24:52,886 --> 0:24:55,526
One, you can use AVFoundation

777
00:24:56,506 --> 0:24:56,786
API's.

778
00:24:56,786 --> 0:24:58,816
These API's are ideal for media

779
00:24:58,816 --> 0:24:59,886
playback applications.

780
00:25:00,586 --> 0:25:02,646
They handle all aspects of tone

781
00:25:02,646 --> 0:25:04,186
mapping and color management for

782
00:25:04,186 --> 0:25:04,336
you.

783
00:25:05,216 --> 0:25:07,376
Two, you can directly use Metal.

784
00:25:08,026 --> 0:25:09,426
Metal provides with a lot of

785
00:25:09,426 --> 0:25:11,356
options and great flexibility.

786
00:25:12,386 --> 0:25:15,196
Using the CAMetalLayer and EDR

787
00:25:15,196 --> 0:25:17,806
API's, you can take full control

788
00:25:17,806 --> 0:25:19,226
of HDR rendering in your

789
00:25:19,226 --> 0:25:21,146
application including tone

790
00:25:21,146 --> 0:25:23,066
mapping and color management.

791
00:25:24,316 --> 0:25:26,186
These API's are ideal for

792
00:25:26,426 --> 0:25:27,316
content creation.

793
00:25:28,626 --> 0:25:30,696
Now using a code snippet, let's

794
00:25:30,696 --> 0:25:32,286
look at how the metal layer and

795
00:25:32,286 --> 0:25:34,336
the EDR API's all come together

796
00:25:34,336 --> 0:25:35,876
in an application, shall we?

797
00:25:36,686 --> 0:25:39,086
So the first and the foremost

798
00:25:39,086 --> 0:25:40,906
that you do in your code base is

799
00:25:40,906 --> 0:25:43,026
to check for the EDR support on

800
00:25:43,026 --> 0:25:45,076
the display, and this screen

801
00:25:45,076 --> 0:25:46,276
provides you with the property

802
00:25:46,276 --> 0:25:47,276
for that.

803
00:25:47,856 --> 0:25:50,106
Then as usual, you create and

804
00:25:50,146 --> 0:25:51,306
set up your metal layer.

805
00:25:52,426 --> 0:25:53,856
When you set up the metal layer,

806
00:25:54,016 --> 0:25:55,906
you need to choose a wide gamut

807
00:25:55,986 --> 0:25:57,816
color space that suits your

808
00:25:57,816 --> 0:25:58,436
application.

809
00:25:59,466 --> 0:26:01,236
Metal supports rendering into

810
00:25:59,466 --> 0:26:01,236
Metal supports rendering into

811
00:26:01,236 --> 0:26:02,996
wide gamut color spaces such as

812
00:26:03,106 --> 0:26:05,656
BT2020 or B3.

813
00:26:06,756 --> 0:26:08,436
Next, you need to choose the

814
00:26:08,436 --> 0:26:10,116
transfer function that matches

815
00:26:10,116 --> 0:26:10,756
your content.

816
00:26:11,516 --> 0:26:13,386
Again, the API's have support

817
00:26:13,386 --> 0:26:15,206
for all industry standard

818
00:26:15,246 --> 0:26:18,116
transfer functions such as PQ,

819
00:26:18,116 --> 0:26:19,416
HLG, or Gamma.

820
00:26:20,876 --> 0:26:23,406
Then you need to choose pixel

821
00:26:23,406 --> 0:26:25,166
format for your HDR rendering.

822
00:26:25,926 --> 0:26:28,606
We recommend that you use float

823
00:26:28,606 --> 0:26:30,766
16 as a preferred pixel format

824
00:26:30,816 --> 0:26:32,636
for most of your HDR rendering

825
00:26:32,636 --> 0:26:35,486
needs because float 16 has

826
00:26:35,596 --> 0:26:37,116
enough precision to carry the

827
00:26:37,216 --> 0:26:38,376
color and the brightness

828
00:26:38,376 --> 0:26:40,096
information for HDR contents.

829
00:26:40,646 --> 0:26:43,076
And finally, in the layers set

830
00:26:43,076 --> 0:26:44,646
up you need to indicate to Metal

831
00:26:44,966 --> 0:26:46,866
that you have opted in to EDR

832
00:26:46,866 --> 0:26:47,626
rendering model.

833
00:26:48,576 --> 0:26:50,066
So this is a typical layer set

834
00:26:50,066 --> 0:26:52,046
up that you would do.

835
00:26:52,446 --> 0:26:54,156
Next, moving on to main render

836
00:26:54,226 --> 0:26:54,446
loop.

837
00:26:54,946 --> 0:26:56,566
In the main render loop you need

838
00:26:56,566 --> 0:26:58,016
to get the brightness headroom

839
00:26:58,016 --> 0:26:59,166
that we talked about or the

840
00:26:59,166 --> 0:27:01,466
maximum EDR information, right?

841
00:26:59,166 --> 0:27:01,466
maximum EDR information, right?

842
00:27:01,796 --> 0:27:03,806
So NSScreen provides you with

843
00:27:03,806 --> 0:27:05,346
the property for that.

844
00:27:05,856 --> 0:27:07,416
But note, this property is

845
00:27:07,416 --> 0:27:07,996
dynamic.

846
00:27:08,506 --> 0:27:09,676
It keeps changing with the

847
00:27:09,676 --> 0:27:11,486
viewing conditions or when the

848
00:27:11,486 --> 0:27:12,646
brightness of the display

849
00:27:12,646 --> 0:27:13,106
changes.

850
00:27:13,616 --> 0:27:15,756
So you need to register for a

851
00:27:15,756 --> 0:27:17,686
notification for any changes on

852
00:27:17,686 --> 0:27:20,506
this property and as maximum EDR

853
00:27:20,686 --> 0:27:22,976
changes, you need to redraw your

854
00:27:23,066 --> 0:27:23,726
contents.

855
00:27:25,516 --> 0:27:27,936
Now, if you are handling tone

856
00:27:27,936 --> 0:27:29,486
mapping and color management

857
00:27:29,486 --> 0:27:30,996
yourselves in the application,

858
00:27:31,446 --> 0:27:32,946
you need to do some additional

859
00:27:32,946 --> 0:27:34,686
pixel processing in the shaders.

860
00:27:35,206 --> 0:27:36,856
Let's review some common steps

861
00:27:36,916 --> 0:27:39,686
that you would do.

862
00:27:39,936 --> 0:27:43,236
Typically the video come in

863
00:27:43,236 --> 0:27:44,636
YUV or YCBCR color format.

864
00:27:45,056 --> 0:27:46,306
So the first step in your

865
00:27:46,306 --> 0:27:48,046
application or in your shaders

866
00:27:48,116 --> 0:27:49,786
is to convert it to RGB.

867
00:27:50,876 --> 0:27:53,206
Also, the video contents come

868
00:27:53,316 --> 0:27:54,796
encoded with some kind of

869
00:27:54,796 --> 0:27:56,566
non-linear transfer functions

870
00:27:56,796 --> 0:27:57,766
such as PQ.

871
00:27:58,646 --> 0:28:00,296
So the next step in the shader

872
00:27:58,646 --> 0:28:00,296
So the next step in the shader

873
00:28:00,296 --> 0:28:02,576
is to apply inverse transfer

874
00:28:02,576 --> 0:28:04,376
function and linearize your

875
00:28:04,376 --> 0:28:06,726
pixels, and then normalize it in

876
00:28:06,726 --> 0:28:08,626
the range zero to one.

877
00:28:10,066 --> 0:28:12,806
And then use the maximum EDR

878
00:28:12,886 --> 0:28:14,746
that you got from NSScreen and

879
00:28:14,916 --> 0:28:16,806
scale the pixels as we discussed

880
00:28:16,806 --> 0:28:17,946
in the EDR section.

881
00:28:18,426 --> 0:28:21,136
And then perform editing,

882
00:28:21,136 --> 0:28:23,116
grading, or any processing that

883
00:28:23,256 --> 0:28:25,286
suits your application, and

884
00:28:25,286 --> 0:28:27,646
finally, perform tone mapping.

885
00:28:28,986 --> 0:28:30,406
If the brightness changes then

886
00:28:30,406 --> 0:28:32,066
you need to do the tone mapping

887
00:28:32,066 --> 0:28:32,976
with different set of

888
00:28:32,976 --> 0:28:33,686
parameters.

889
00:28:34,556 --> 0:28:37,996
If your contents are in a color

890
00:28:37,996 --> 0:28:39,526
space that is different from the

891
00:28:39,526 --> 0:28:41,866
one on the display then you also

892
00:28:41,866 --> 0:28:43,406
need to apply proper color

893
00:28:43,466 --> 0:28:44,006
conversions.

894
00:28:45,406 --> 0:28:47,116
However, if you don't want to

895
00:28:47,236 --> 0:28:48,616
handle tone mapping or

896
00:28:48,616 --> 0:28:49,876
teleprocessing, and you want

897
00:28:49,876 --> 0:28:51,686
Metal to handle it for you, you

898
00:28:51,686 --> 0:28:52,836
can easily do that.

899
00:28:53,926 --> 0:28:55,616
When you create a Metal layer,

900
00:28:56,296 --> 0:28:58,596
attach an EDR metadata object

901
00:28:58,596 --> 0:28:58,936
with it.

902
00:28:59,986 --> 0:29:01,606
Typically the EDR metadata

903
00:28:59,986 --> 0:29:01,606
Typically the EDR metadata

904
00:29:01,606 --> 0:29:03,276
object provides the information

905
00:29:03,566 --> 0:29:05,286
on the mastering display and it

906
00:29:05,286 --> 0:29:06,916
also tells Metal how you want to

907
00:29:06,916 --> 0:29:07,916
map your pixels.

908
00:29:08,836 --> 0:29:10,296
You also need to use one of the

909
00:29:10,296 --> 0:29:12,176
linear color spaces available

910
00:29:12,176 --> 0:29:12,636
with Metal.

911
00:29:13,176 --> 0:29:16,356
So once all your pixel

912
00:29:16,356 --> 0:29:18,406
processing is done, your frame

913
00:29:18,406 --> 0:29:19,086
is ready.

914
00:29:19,306 --> 0:29:21,476
Use the existing Metal API's to

915
00:29:21,606 --> 0:29:23,226
present your frame on the

916
00:29:23,226 --> 0:29:23,626
screen.

917
00:29:24,206 --> 0:29:27,316
As we noted earlier, you need a

918
00:29:27,316 --> 0:29:29,496
capable display such as of a Pro

919
00:29:29,496 --> 0:29:31,126
Display XDR to view these

920
00:29:31,126 --> 0:29:31,676
contents.

921
00:29:32,736 --> 0:29:35,416
We also support HDR 10 and Dolby

922
00:29:35,416 --> 0:29:37,026
Vision TV's available in the

923
00:29:37,026 --> 0:29:37,526
market.

924
00:29:38,636 --> 0:29:40,856
So this is a simple illustration

925
00:29:40,856 --> 0:29:43,626
of how you can use Metal layer

926
00:29:43,836 --> 0:29:46,746
and EDR API's for HDR rendering

927
00:29:46,876 --> 0:29:47,746
in your application.

928
00:29:48,656 --> 0:29:50,716
So before we end this section,

929
00:29:51,336 --> 0:29:53,406
let's review some key takeaways

930
00:29:53,586 --> 0:29:55,196
and some recommendations on best

931
00:29:55,196 --> 0:29:55,826
practices.

932
00:29:58,656 --> 0:30:00,936
Remember to redraw and update

933
00:29:58,656 --> 0:30:00,936
Remember to redraw and update

934
00:30:00,936 --> 0:30:02,536
your content as the brightness

935
00:30:02,536 --> 0:30:02,946
changes.

936
00:30:04,506 --> 0:30:06,366
Use float 16 as a preferred

937
00:30:06,366 --> 0:30:09,066
pixel format for most of your

938
00:30:09,066 --> 0:30:09,896
HDR rendering needs.

939
00:30:11,346 --> 0:30:13,196
When you set up the Metal layer,

940
00:30:13,196 --> 0:30:14,566
select the color space and

941
00:30:14,796 --> 0:30:16,426
transfer function that matches

942
00:30:16,426 --> 0:30:18,396
your content and then perform

943
00:30:18,396 --> 0:30:19,936
any additional processing in the

944
00:30:19,936 --> 0:30:21,446
shaders as necessary.

945
00:30:22,226 --> 0:30:24,596
Last, but not the least, HDR

946
00:30:24,886 --> 0:30:27,686
processing adds to computational

947
00:30:27,686 --> 0:30:29,226
overhead and adds to memory pressure.

948
00:30:30,006 --> 0:30:32,766
So bypass tone mapping if your

949
00:30:32,836 --> 0:30:34,656
contents are already tone mapped

950
00:30:35,066 --> 0:30:37,006
or if performance is more

951
00:30:37,006 --> 0:30:39,136
important for you than color

952
00:30:39,136 --> 0:30:39,736
accuracy.

953
00:30:40,936 --> 0:30:43,686
So, in summary, we have provided

954
00:30:43,686 --> 0:30:45,876
you with powerful API's, a

955
00:30:45,876 --> 0:30:47,896
display for EDR rendering model

956
00:30:47,896 --> 0:30:50,356
support on both iOS and macOS,

957
00:30:50,356 --> 0:30:52,986
and a great support for our Pro

958
00:30:52,986 --> 0:30:53,796
Display XDR.

959
00:30:54,796 --> 0:30:56,816
I'm sure you can use these tools

960
00:30:56,816 --> 0:30:59,330
to create amazing HDR contents.

961
00:31:02,546 --> 0:31:03,936
In the next section, we are

962
00:31:03,936 --> 0:31:05,856
going to talk about how you can

963
00:31:05,856 --> 0:31:07,616
leverage the computational

964
00:31:07,616 --> 0:31:09,026
resources available on the

965
00:31:09,066 --> 0:31:10,786
platform to get the best

966
00:31:10,786 --> 0:31:12,756
possible performance and to tell

967
00:31:12,756 --> 0:31:15,386
you all about it, I invite Brian

968
00:31:15,386 --> 0:31:16,146
Ross on stage.

969
00:31:17,516 --> 0:31:20,500
[ Applause ]

970
00:31:25,366 --> 0:31:26,016
&gt;&gt; Thanks, Dileep.

971
00:31:27,316 --> 0:31:28,926
Scaling your performance to

972
00:31:28,926 --> 0:31:30,896
harness both CPU and GPU

973
00:31:30,896 --> 0:31:32,386
parallelism is the most

974
00:31:32,386 --> 0:31:34,286
important and sometimes the

975
00:31:34,286 --> 0:31:35,936
easiest optimization you can do.

976
00:31:36,886 --> 0:31:38,206
In this section, I'm going to

977
00:31:38,206 --> 0:31:40,176
talk about several ways to scale

978
00:31:40,176 --> 0:31:41,276
your performance based on the

979
00:31:41,276 --> 0:31:42,566
architecture of your hardware.

980
00:31:43,366 --> 0:31:44,636
So first, I'll talk about how

981
00:31:44,636 --> 0:31:46,316
Metal can help you to scale

982
00:31:46,316 --> 0:31:48,346
across any number of CPU cores.

983
00:31:49,556 --> 0:31:50,936
Next, I'll talk about how to

984
00:31:50,936 --> 0:31:54,226
leverage, utilize asynchronous

985
00:31:54,286 --> 0:31:55,326
GPU channels.

986
00:31:56,156 --> 0:31:57,476
And finally, I'll close this

987
00:31:57,476 --> 0:31:59,826
section by going over a few ways

988
00:32:00,276 --> 0:32:01,776
to use multiple GPU's.

989
00:32:02,366 --> 0:32:05,276
So today's props are adding more

990
00:32:05,276 --> 0:32:06,146
and more complexity.

991
00:32:07,276 --> 0:32:09,266
They demand more CPU cycles to

992
00:32:09,616 --> 0:32:11,486
decode frames, build render

993
00:32:11,486 --> 0:32:13,736
graphs, and encode metal render

994
00:32:13,736 --> 0:32:14,136
passes.

995
00:32:15,446 --> 0:32:17,406
Doing all this on a single CPU

996
00:32:17,406 --> 0:32:18,706
thread is not sufficient for

997
00:32:18,706 --> 0:32:19,466
today's devices.

998
00:32:20,736 --> 0:32:22,616
The latest iPhone has six cores

999
00:32:23,166 --> 0:32:25,196
and a Mac Pro can have up to 28.

1000
00:32:26,556 --> 0:32:28,756
Therefore scalable multithread

1001
00:32:28,756 --> 0:32:30,516
architecture is key to great

1002
00:32:30,516 --> 0:32:31,566
performance on all of our

1003
00:32:31,566 --> 0:32:32,006
devices.

1004
00:32:32,896 --> 0:32:34,106
Metal is designed for

1005
00:32:34,106 --> 0:32:34,696
multithreading.

1006
00:32:35,576 --> 0:32:37,256
In this section, let's look at

1007
00:32:37,256 --> 0:32:38,746
two ways how you can parallelize

1008
00:32:38,746 --> 0:32:40,306
your encoding on the CPU.

1009
00:32:40,536 --> 0:32:42,896
So I'm going to set up an

1010
00:32:42,896 --> 0:32:45,166
example of a typical video

1011
00:32:45,166 --> 0:32:45,466
frame.

1012
00:32:46,216 --> 0:32:48,056
With a classic single threaded

1013
00:32:48,056 --> 0:32:49,736
rendering, you could serially

1014
00:32:49,736 --> 0:32:51,956
decode frames and build commands

1015
00:32:51,956 --> 0:32:53,576
into a single command buffer in

1016
00:32:53,576 --> 0:32:55,006
GPU execution order.

1017
00:32:55,786 --> 0:32:56,846
And you typically have to fit

1018
00:32:56,936 --> 0:32:58,746
this into some tiny fraction of

1019
00:32:58,746 --> 0:32:59,426
your frame time.

1020
00:33:00,386 --> 0:33:02,276
And of course, you're going to

1021
00:33:02,276 --> 0:33:03,536
have maximum latency because you

1022
00:33:03,536 --> 0:33:04,856
have to encode the entire

1023
00:33:04,856 --> 0:33:06,936
command buffer before the GPU

1024
00:33:06,936 --> 0:33:07,636
can consume it.

1025
00:33:08,176 --> 0:33:09,446
Obviously, there's a better way

1026
00:33:09,446 --> 0:33:09,916
to do this.

1027
00:33:10,106 --> 0:33:11,506
So what we're going to do is

1028
00:33:11,506 --> 0:33:13,326
start by building in parallelism

1029
00:33:13,436 --> 0:33:16,656
with the CPU.

1030
00:33:16,846 --> 0:33:18,546
Render blit and compute passes

1031
00:33:18,546 --> 0:33:20,016
are the basic granularity of

1032
00:33:20,016 --> 0:33:21,056
multithreading on Metal.

1033
00:33:21,866 --> 0:33:23,266
All you need to do is create

1034
00:33:23,266 --> 0:33:25,286
multiple command buffers and

1035
00:33:25,286 --> 0:33:27,096
start encoding passes into each

1036
00:33:27,156 --> 0:33:27,976
on a separate thread.

1037
00:33:28,816 --> 0:33:30,126
You can encode in any order you

1038
00:33:30,126 --> 0:33:30,566
wish.

1039
00:33:30,986 --> 0:33:32,956
The final order of execution is

1040
00:33:32,956 --> 0:33:34,356
determined by the order that you

1041
00:33:34,356 --> 0:33:35,486
added to the command queue.

1042
00:33:36,106 --> 0:33:37,906
So now let's look at how you can

1043
00:33:37,906 --> 0:33:39,000
do this in your code.

1044
00:33:42,336 --> 0:33:43,726
Encoding multiple command

1045
00:33:43,726 --> 0:33:44,686
buffers is actually quite

1046
00:33:44,726 --> 0:33:45,096
simple.

1047
00:33:45,556 --> 0:33:47,256
The first thing we do is we

1048
00:33:47,256 --> 0:33:48,956
create any number of Metal

1049
00:33:48,956 --> 0:33:50,366
command buffer objects from the

1050
00:33:50,906 --> 0:33:51,000
queue.

1051
00:33:52,436 --> 0:33:54,686
Next, we define the GPU

1052
00:33:54,686 --> 0:33:56,166
execution order up front by

1053
00:33:56,166 --> 0:33:57,426
using the enqueue interface.

1054
00:33:57,496 --> 0:33:58,416
This is great because you could

1055
00:33:58,416 --> 0:33:59,686
do it early and you don't have

1056
00:33:59,726 --> 0:34:00,956
to wait for encoding to complete

1057
00:33:59,726 --> 0:34:00,956
to wait for encoding to complete

1058
00:34:01,046 --> 0:34:01,666
first.

1059
00:34:02,116 --> 0:34:05,576
And finally, for each command

1060
00:34:05,576 --> 0:34:06,826
buffer we create a separate

1061
00:34:06,826 --> 0:34:08,426
thread using the asynchronous

1062
00:34:08,426 --> 0:34:10,806
dispatch queue and encode passes

1063
00:34:10,806 --> 0:34:12,216
for the frame and that's it.

1064
00:34:12,326 --> 0:34:13,786
It's really fast and it's really

1065
00:34:13,786 --> 0:34:14,235
simple.

1066
00:34:15,716 --> 0:34:17,065
So as you could see in our

1067
00:34:17,065 --> 0:34:18,286
example, we've done a good job

1068
00:34:18,286 --> 0:34:19,866
parallelizing with multiple

1069
00:34:19,866 --> 0:34:21,076
Metal command buffer objects,

1070
00:34:21,076 --> 0:34:23,226
but what if you have one really

1071
00:34:23,226 --> 0:34:25,255
large effects and blending pass?

1072
00:34:26,036 --> 0:34:28,396
In this case, Metal offers a

1073
00:34:28,396 --> 0:34:30,286
dedicated parallel encoder that

1074
00:34:30,286 --> 0:34:32,606
allows you to encode on multiple

1075
00:34:32,606 --> 0:34:34,146
threads without explicitly

1076
00:34:34,146 --> 0:34:36,585
dividing up the render pass or

1077
00:34:36,585 --> 0:34:37,346
the command buffer.

1078
00:34:38,096 --> 0:34:39,216
Let's take a look at how easy

1079
00:34:39,216 --> 0:34:39,996
this is to doing your

1080
00:34:39,996 --> 0:34:41,000
application.

1081
00:34:43,346 --> 0:34:44,646
So here, the first thing we do

1082
00:34:44,646 --> 0:34:46,126
is create a parallel encoder

1083
00:34:46,126 --> 0:34:47,076
from the command buffer.

1084
00:34:48,196 --> 0:34:49,416
Then we create any number of

1085
00:34:49,416 --> 0:34:51,376
subordinate coders and this is

1086
00:34:51,376 --> 0:34:53,065
actually where we define the GPU

1087
00:34:53,065 --> 0:34:54,786
execution order by the order

1088
00:34:54,786 --> 0:34:56,255
that we create the subordinates.

1089
00:34:57,716 --> 0:34:58,846
Next, we create a separate

1090
00:34:58,846 --> 0:35:00,406
thread and call our encoding

1091
00:34:58,846 --> 0:35:00,406
thread and call our encoding

1092
00:35:00,406 --> 0:35:01,406
function for each.

1093
00:35:01,636 --> 0:35:02,666
This is where the effects and

1094
00:35:02,666 --> 0:35:03,866
blending will be processed.

1095
00:35:05,326 --> 0:35:06,236
And finally we set up a

1096
00:35:06,236 --> 0:35:07,456
notification when the threads

1097
00:35:07,456 --> 0:35:09,616
are complete and we end

1098
00:35:09,616 --> 0:35:10,716
parallelizing encoding, and

1099
00:35:10,716 --> 0:35:11,296
that's it.

1100
00:35:11,376 --> 0:35:12,406
That's all you have to do.

1101
00:35:12,406 --> 0:35:13,786
It's very simple and very

1102
00:35:13,786 --> 0:35:14,266
efficient.

1103
00:35:14,936 --> 0:35:16,206
So I've shown you two ways on

1104
00:35:16,206 --> 0:35:17,836
how to parallelize on the CPU.

1105
00:35:18,246 --> 0:35:19,776
Now let's see how Metal can help

1106
00:35:19,776 --> 0:35:22,226
you to leverage asynchronous GPU

1107
00:35:22,226 --> 0:35:22,916
channels.

1108
00:35:25,056 --> 0:35:26,916
Modern GPU's today have a common

1109
00:35:26,916 --> 0:35:27,626
capability.

1110
00:35:28,366 --> 0:35:29,836
They each contain a number of

1111
00:35:29,836 --> 0:35:30,906
channels that allow you to

1112
00:35:31,276 --> 0:35:33,416
execute asynchronously so this

1113
00:35:33,416 --> 0:35:35,316
means that you can potentially

1114
00:35:35,316 --> 0:35:36,476
decode video on one channel

1115
00:35:36,476 --> 0:35:39,296
while also executing 3D effects

1116
00:35:39,296 --> 0:35:39,866
on another.

1117
00:35:41,226 --> 0:35:42,706
Metal could extract this type of

1118
00:35:42,706 --> 0:35:44,196
parallelism in two ways.

1119
00:35:44,786 --> 0:35:46,176
The first comes naturally just

1120
00:35:46,176 --> 0:35:47,856
by using the render, blit, and

1121
00:35:47,856 --> 0:35:49,316
compute encoders for the

1122
00:35:49,316 --> 0:35:50,386
appropriate workloads.

1123
00:35:51,216 --> 0:35:52,346
The other way Metal extracts

1124
00:35:52,346 --> 0:35:54,196
parallelism is by analyzing your

1125
00:35:54,196 --> 0:35:55,106
data dependencies.

1126
00:35:55,836 --> 0:35:57,176
But the most compelling detail

1127
00:35:57,176 --> 0:35:58,356
of all here is you get most of

1128
00:35:58,356 --> 0:35:58,946
this for free.

1129
00:35:59,476 --> 0:36:00,796
Metal does a lot of this for you

1130
00:35:59,476 --> 0:36:00,796
Metal does a lot of this for you

1131
00:36:00,796 --> 0:36:01,366
under the hood.

1132
00:36:02,736 --> 0:36:03,336
Let's see how.

1133
00:36:04,006 --> 0:36:06,806
So let's look at how the GPU

1134
00:36:06,806 --> 0:36:08,026
executes a series of these

1135
00:36:08,026 --> 0:36:08,596
frames.

1136
00:36:09,066 --> 0:36:10,696
Here I have another video frame

1137
00:36:10,696 --> 0:36:11,186
example.

1138
00:36:11,186 --> 0:36:12,866
In your application we're going

1139
00:36:12,866 --> 0:36:13,926
to be decoding with Video

1140
00:36:13,926 --> 0:36:16,146
Toolbox followed by using the

1141
00:36:16,146 --> 0:36:17,776
blit encoder to upload those

1142
00:36:17,856 --> 0:36:19,666
frames from system to VRAM.

1143
00:36:20,016 --> 0:36:21,886
Then we'll apply filtering with

1144
00:36:21,886 --> 0:36:23,896
compute and effects and blending

1145
00:36:23,896 --> 0:36:24,526
with render.

1146
00:36:26,656 --> 0:36:27,666
This work will happen

1147
00:36:27,666 --> 0:36:28,906
repetitively for each frame.

1148
00:36:29,596 --> 0:36:30,866
So now let's see how this gets

1149
00:36:30,866 --> 0:36:33,326
executed on both the CPU and the

1150
00:36:33,326 --> 0:36:34,926
GPU in a timeline diagram.

1151
00:36:35,276 --> 0:36:36,506
Let's also see if we can apply

1152
00:36:36,506 --> 0:36:38,016
some optimizations to improve

1153
00:36:38,016 --> 0:36:38,766
concurrency.

1154
00:36:39,296 --> 0:36:41,556
The first thing we're going to

1155
00:36:41,556 --> 0:36:43,746
do is encode frame one commands

1156
00:36:43,746 --> 0:36:45,106
using the various encoders on

1157
00:36:45,106 --> 0:36:45,796
separate threads.

1158
00:36:45,796 --> 0:36:48,166
This work is going to get

1159
00:36:48,196 --> 0:36:49,636
scheduled and eventually

1160
00:36:49,636 --> 0:36:50,786
executed across all the

1161
00:36:50,786 --> 0:36:51,446
channels.

1162
00:36:52,266 --> 0:36:53,826
And then we continue on with

1163
00:36:53,826 --> 0:36:56,526
frames two, three, and four.

1164
00:36:57,056 --> 0:37:00,186
Thanks to Metal, you can see

1165
00:36:57,056 --> 0:37:00,186
Thanks to Metal, you can see

1166
00:37:00,186 --> 0:37:01,196
that we're already achieving

1167
00:37:01,196 --> 0:37:02,616
some parallelism for free.

1168
00:37:03,816 --> 0:37:04,916
But we can also see there's a

1169
00:37:04,916 --> 0:37:05,896
lot of gaps.

1170
00:37:06,586 --> 0:37:07,596
This means that some of the

1171
00:37:07,596 --> 0:37:08,856
threads and channels are sitting

1172
00:37:08,856 --> 0:37:10,256
idle during our valuable frame

1173
00:37:10,256 --> 0:37:10,506
time.

1174
00:37:11,006 --> 0:37:12,996
To maintain efficiency, we want

1175
00:37:12,996 --> 0:37:14,396
to saturate our channels as much

1176
00:37:14,396 --> 0:37:15,006
as possible.

1177
00:37:16,316 --> 0:37:17,616
Metal can't always do all this

1178
00:37:17,616 --> 0:37:17,976
for us.

1179
00:37:17,976 --> 0:37:19,546
So in this case it's time to

1180
00:37:19,546 --> 0:37:20,926
apply some optimizations.

1181
00:37:21,846 --> 0:37:23,116
You'll notice on the CPU there

1182
00:37:23,116 --> 0:37:24,916
is extremely large gaps.

1183
00:37:25,206 --> 0:37:27,516
This can happen for many reasons

1184
00:37:27,516 --> 0:37:29,166
but for simplicity I'll focus on

1185
00:37:29,166 --> 0:37:30,076
a common mistake.

1186
00:37:30,786 --> 0:37:31,856
Sometimes applications

1187
00:37:31,856 --> 0:37:33,436
gratuitously call or wait until

1188
00:37:33,436 --> 0:37:35,426
completed after encoding and

1189
00:37:35,426 --> 0:37:36,486
committing a command buffer.

1190
00:37:37,496 --> 0:37:38,986
In this scenario it's creating

1191
00:37:38,986 --> 0:37:41,106
large gaps or bubbles for the

1192
00:37:41,106 --> 0:37:42,806
duration of our decode workload.

1193
00:37:43,496 --> 0:37:45,076
It's also causing small gaps in

1194
00:37:45,076 --> 0:37:46,486
the decode channel in the GPU.

1195
00:37:47,306 --> 0:37:49,266
To fix that, we can try to

1196
00:37:49,266 --> 0:37:50,286
replace the weight with a

1197
00:37:50,286 --> 0:37:51,236
completion handler.

1198
00:37:52,086 --> 0:37:53,456
This will avoid blocking on the

1199
00:37:53,456 --> 0:37:55,656
CPU and schedule any post

1200
00:37:55,656 --> 0:37:56,966
processing after the GPU is

1201
00:37:56,966 --> 0:37:57,456
completed.

1202
00:37:58,076 --> 0:37:59,306
Let's try that and see where it

1203
00:37:59,306 --> 0:38:00,426
gets us.

1204
00:37:59,306 --> 0:38:00,426
gets us.

1205
00:38:03,116 --> 0:38:04,426
So you can see that's much

1206
00:38:04,426 --> 0:38:04,976
better.

1207
00:38:05,296 --> 0:38:06,436
We're now keeping our CPU

1208
00:38:06,436 --> 0:38:07,006
threads busy.

1209
00:38:07,006 --> 0:38:08,596
You will also notice that the

1210
00:38:08,596 --> 0:38:10,286
decoding channel is saturated

1211
00:38:10,286 --> 0:38:11,006
really nicely.

1212
00:38:11,296 --> 0:38:13,776
We could still see quite a few

1213
00:38:13,896 --> 0:38:16,146
gaps in the blit, compute, and

1214
00:38:16,146 --> 0:38:17,156
render channels.

1215
00:38:18,236 --> 0:38:19,406
Looking closely, you can see

1216
00:38:19,406 --> 0:38:20,596
that there is a rewrite

1217
00:38:20,596 --> 0:38:22,506
dependency where the upload

1218
00:38:22,506 --> 0:38:24,746
can't begin until the decode is

1219
00:38:24,746 --> 0:38:25,186
finished.

1220
00:38:26,266 --> 0:38:28,006
One solution to fix this problem

1221
00:38:28,006 --> 0:38:30,096
is to decode say 10 frames

1222
00:38:30,096 --> 0:38:30,406
ahead.

1223
00:38:30,916 --> 0:38:31,806
This will remove that

1224
00:38:31,806 --> 0:38:32,396
dependency.

1225
00:38:32,586 --> 0:38:33,576
Let's try it and see what

1226
00:38:33,576 --> 0:38:34,000
happens.

1227
00:38:37,356 --> 0:38:38,726
So now our resource updates look

1228
00:38:38,726 --> 0:38:39,046
great.

1229
00:38:39,386 --> 0:38:41,016
We're saturating both the video

1230
00:38:41,016 --> 0:38:43,056
and the blit channels, but

1231
00:38:43,056 --> 0:38:43,836
you'll notice that there is

1232
00:38:43,836 --> 0:38:45,676
still a few gaps in the compute

1233
00:38:45,676 --> 0:38:46,596
and render channels.

1234
00:38:47,566 --> 0:38:49,206
Similar to last time if you look

1235
00:38:49,206 --> 0:38:50,676
closely, you could see that

1236
00:38:50,676 --> 0:38:51,756
there's another dependency but

1237
00:38:51,756 --> 0:38:53,696
the filtering cannot begin until

1238
00:38:53,696 --> 0:38:55,916
the blit channel has uploaded

1239
00:38:56,126 --> 0:38:56,666
all the data.

1240
00:38:58,076 --> 0:38:59,686
Similar to before, we can fix

1241
00:38:59,766 --> 0:39:01,806
this by preloading our bit maps

1242
00:38:59,766 --> 0:39:01,806
this by preloading our bit maps

1243
00:39:01,806 --> 0:39:02,466
ahead of time.

1244
00:39:03,146 --> 0:39:04,156
This will remove that

1245
00:39:04,156 --> 0:39:05,000
dependency.

1246
00:39:08,206 --> 0:39:10,826
And with this, we've now closed

1247
00:39:10,826 --> 0:39:11,846
most of the gaps and we have a

1248
00:39:11,846 --> 0:39:13,176
really efficient pipeline.

1249
00:39:13,656 --> 0:39:14,966
So now that I've reviewed the

1250
00:39:14,966 --> 0:39:16,656
GPU channels and some example

1251
00:39:16,656 --> 0:39:19,456
optimizations, let's see how to

1252
00:39:19,456 --> 0:39:22,286
continue scaling performance on

1253
00:39:22,286 --> 0:39:23,256
more GPU's.

1254
00:39:25,216 --> 0:39:27,016
GPU's are quickly becoming a

1255
00:39:27,066 --> 0:39:28,156
performance multiplier.

1256
00:39:29,106 --> 0:39:30,436
Supporting more GPU's can

1257
00:39:30,436 --> 0:39:32,116
accelerate image processing,

1258
00:39:32,596 --> 0:39:34,536
video editing, and improve your

1259
00:39:34,536 --> 0:39:35,486
overall frame rate.

1260
00:39:36,016 --> 0:39:38,316
In this section, I'm first going

1261
00:39:38,316 --> 0:39:41,236
to go over how Metal can be used

1262
00:39:41,316 --> 0:39:42,606
to leverage multi GPU

1263
00:39:42,606 --> 0:39:43,616
configurations.

1264
00:39:44,576 --> 0:39:45,766
Then I'll show you a few load

1265
00:39:45,766 --> 0:39:47,056
balancing strategies proven

1266
00:39:47,056 --> 0:39:49,006
effective by Pro App developers

1267
00:39:49,006 --> 0:39:49,336
today.

1268
00:39:49,996 --> 0:39:51,286
And finally, I'll discuss how to

1269
00:39:51,286 --> 0:39:52,976
synchronize operations between

1270
00:39:52,976 --> 0:39:53,656
your GPU's.

1271
00:39:55,036 --> 0:39:57,046
So what can Metal do for your

1272
00:39:57,046 --> 0:39:57,866
Pro App?

1273
00:39:58,146 --> 0:39:59,626
To start, Metal gives you all

1274
00:39:59,626 --> 0:40:01,516
the tools you need to detect all

1275
00:39:59,626 --> 0:40:01,516
the tools you need to detect all

1276
00:40:01,516 --> 0:40:02,796
the connected GPU's and their

1277
00:40:02,796 --> 0:40:03,776
capabilities.

1278
00:40:04,666 --> 0:40:06,076
With Metal it's easy to manage

1279
00:40:06,076 --> 0:40:07,286
multiple GPU's because they're

1280
00:40:07,286 --> 0:40:08,796
essentially just separate Metal

1281
00:40:08,796 --> 0:40:09,776
device objects.

1282
00:40:10,166 --> 0:40:11,866
So program them as the same as

1283
00:40:11,866 --> 0:40:13,226
you do today for a single GPU.

1284
00:40:14,306 --> 0:40:15,906
Metal also supports a brand-new

1285
00:40:16,246 --> 0:40:17,516
peer group transferring PI.

1286
00:40:18,286 --> 0:40:19,746
This incorporates the concept of

1287
00:40:19,866 --> 0:40:21,796
remote texture views which allow

1288
00:40:21,796 --> 0:40:23,926
you to copy data between GPU's.

1289
00:40:24,866 --> 0:40:26,086
And finally, Metal offers

1290
00:40:26,136 --> 0:40:27,816
powerful shared events that

1291
00:40:27,816 --> 0:40:29,026
allow you to synchronize your

1292
00:40:29,026 --> 0:40:30,426
workloads between GPU's.

1293
00:40:30,666 --> 0:40:32,106
Now let's take a quick look at

1294
00:40:32,106 --> 0:40:33,836
how to detect multi GPU

1295
00:40:33,836 --> 0:40:34,786
configurations.

1296
00:40:36,676 --> 0:40:38,406
Metal exposes device properties

1297
00:40:38,406 --> 0:40:39,706
to identify the location,

1298
00:40:40,096 --> 0:40:41,866
location number, and max

1299
00:40:41,866 --> 0:40:43,336
transfer rate for each device.

1300
00:40:44,116 --> 0:40:45,306
This information could be used

1301
00:40:45,736 --> 0:40:47,466
to say determine the fastest

1302
00:40:47,466 --> 0:40:49,496
possible hosted device transfer

1303
00:40:49,496 --> 0:40:49,966
device.

1304
00:40:50,696 --> 0:40:52,246
It can also be used to determine

1305
00:40:52,286 --> 0:40:53,706
if a device is integrated,

1306
00:40:54,056 --> 0:40:56,296
discreet, or external or even

1307
00:40:56,296 --> 0:40:57,326
low power or headless.

1308
00:40:58,316 --> 0:40:59,716
So once we're able to detect

1309
00:40:59,716 --> 0:41:01,756
multiple GPU's with this, it's

1310
00:40:59,716 --> 0:41:01,756
multiple GPU's with this, it's

1311
00:41:01,756 --> 0:41:03,796
time to think about how to

1312
00:41:03,796 --> 0:41:05,066
balance your workloads.

1313
00:41:06,636 --> 0:41:08,426
There is many, many ways to load

1314
00:41:08,426 --> 0:41:10,416
balance between GPU's, and

1315
00:41:10,416 --> 0:41:11,226
there's a lot of design

1316
00:41:11,226 --> 0:41:12,136
decisions that you have to

1317
00:41:12,136 --> 0:41:13,076
consider when you select

1318
00:41:13,076 --> 0:41:13,756
strategy.

1319
00:41:14,526 --> 0:41:15,626
At the end of the day what we

1320
00:41:15,726 --> 0:41:17,806
seek is a really simple load

1321
00:41:17,806 --> 0:41:19,626
balancing strategy with higher

1322
00:41:19,676 --> 0:41:20,596
scale and efficiency.

1323
00:41:21,306 --> 0:41:22,726
Let's go over a few proven

1324
00:41:22,726 --> 0:41:24,036
strategies that some Pro App

1325
00:41:24,036 --> 0:41:25,956
developers are using today.

1326
00:41:26,736 --> 0:41:27,856
The first and most

1327
00:41:27,856 --> 0:41:29,916
straightforward is supporting

1328
00:41:29,916 --> 0:41:31,036
alternating frames.

1329
00:41:31,226 --> 0:41:32,916
So the concept is to ping pong

1330
00:41:32,916 --> 0:41:34,526
odd and even frames between the

1331
00:41:34,526 --> 0:41:35,346
two GPU's.

1332
00:41:35,976 --> 0:41:37,496
This easily fits into existing

1333
00:41:37,496 --> 0:41:39,236
architectures and can

1334
00:41:39,236 --> 0:41:40,506
potentially double the rate that

1335
00:41:40,506 --> 0:41:41,666
you process frames.

1336
00:41:42,316 --> 0:41:43,886
However, sometimes apps have

1337
00:41:44,566 --> 0:41:46,376
variable workloads like UI

1338
00:41:46,376 --> 0:41:48,106
updates or graph building, and

1339
00:41:48,106 --> 0:41:50,516
this might result in unbalanced

1340
00:41:50,866 --> 0:41:51,586
load balancing.

1341
00:41:52,136 --> 0:41:53,636
So let's take a look at another

1342
00:41:53,636 --> 0:41:54,156
strategy.

1343
00:41:54,766 --> 0:41:58,286
This one uses small 32 by

1344
00:41:58,336 --> 0:42:00,746
32-pixel tiles to distribute

1345
00:41:58,336 --> 0:42:00,746
32-pixel tiles to distribute

1346
00:42:00,826 --> 0:42:01,826
rendering more evenly among the

1347
00:42:01,826 --> 0:42:02,546
GPU's.

1348
00:42:03,266 --> 0:42:05,196
So if you have four GPU's, you

1349
00:42:05,196 --> 0:42:06,596
can preselect separate tile

1350
00:42:06,596 --> 0:42:07,436
groups for each.

1351
00:42:08,076 --> 0:42:09,626
Here we use a random assignment

1352
00:42:09,626 --> 0:42:10,946
to avoid too much correlation

1353
00:42:10,946 --> 0:42:11,516
with the scene.

1354
00:42:11,976 --> 0:42:13,986
This means that mapping of tiles

1355
00:42:13,986 --> 0:42:15,546
to GPU's is constant from frame

1356
00:42:15,546 --> 0:42:15,916
to frame.

1357
00:42:16,406 --> 0:42:18,376
This is a really good solution

1358
00:42:18,486 --> 0:42:20,386
for compute heavy workloads but

1359
00:42:20,386 --> 0:42:21,806
might not be the best choice for

1360
00:42:21,806 --> 0:42:22,926
bandwidth intensive ones.

1361
00:42:23,676 --> 0:42:24,916
To see this in more detail,

1362
00:42:24,916 --> 0:42:26,016
check out the rate tracing

1363
00:42:26,016 --> 0:42:26,446
section.

1364
00:42:26,586 --> 0:42:29,886
So here's a similar approach

1365
00:42:29,936 --> 0:42:31,146
that uses a tile queue.

1366
00:42:31,836 --> 0:42:32,796
In this case, the host

1367
00:42:32,796 --> 0:42:34,136
application can populate the

1368
00:42:34,136 --> 0:42:35,676
queue with all the tiles.

1369
00:42:36,426 --> 0:42:37,866
They can then be dequeued on

1370
00:42:37,866 --> 0:42:40,026
demand by each GPU based on an

1371
00:42:40,026 --> 0:42:41,606
algorithm that keeps the GPU's

1372
00:42:41,606 --> 0:42:41,996
busy.

1373
00:42:42,866 --> 0:42:44,446
This approach may provide really

1374
00:42:44,446 --> 0:42:45,996
good load balancing but it is

1375
00:42:45,996 --> 0:42:46,996
adding more complexity.

1376
00:42:48,306 --> 0:42:50,166
So once we've decided on our

1377
00:42:50,166 --> 0:42:51,916
load balancing scheme, we need

1378
00:42:51,916 --> 0:42:52,926
to think about how to

1379
00:42:53,016 --> 0:42:54,146
synchronize our workloads

1380
00:42:54,146 --> 0:42:55,526
between the GPU's.

1381
00:42:56,106 --> 0:42:58,626
To accomplish this, Metal

1382
00:42:58,626 --> 0:43:00,116
provides a powerful construct

1383
00:42:58,626 --> 0:43:00,116
provides a powerful construct

1384
00:43:00,116 --> 0:43:01,176
called shared events.

1385
00:43:01,846 --> 0:43:03,506
They allow you to specify

1386
00:43:03,736 --> 0:43:04,966
synchronization points in your

1387
00:43:04,966 --> 0:43:07,306
app where you can wait and

1388
00:43:07,366 --> 0:43:08,856
signal for specific command

1389
00:43:08,856 --> 0:43:09,286
completion.

1390
00:43:10,436 --> 0:43:12,116
This can be done across GPU's,

1391
00:43:12,556 --> 0:43:14,606
between a CPU and the GPU, and

1392
00:43:14,606 --> 0:43:15,526
across processes.

1393
00:43:16,136 --> 0:43:17,536
Let's put this into practice.

1394
00:43:18,566 --> 0:43:21,016
So here's an example of a single

1395
00:43:21,016 --> 0:43:22,416
GPU workload that performs a

1396
00:43:22,416 --> 0:43:23,926
motion analysis on pairs of

1397
00:43:23,926 --> 0:43:24,526
frames.

1398
00:43:25,136 --> 0:43:26,496
Notice that these are all render

1399
00:43:26,496 --> 0:43:27,746
workloads so we can't take

1400
00:43:27,746 --> 0:43:29,006
advantage of the parallel

1401
00:43:29,386 --> 0:43:30,566
asynchronous channels that we

1402
00:43:30,566 --> 0:43:33,556
talked about earlier, but if we

1403
00:43:33,556 --> 0:43:35,916
have two GPU's, we can divide

1404
00:43:35,916 --> 0:43:36,966
this work between them to

1405
00:43:36,966 --> 0:43:38,076
improve performance.

1406
00:43:38,436 --> 0:43:40,326
So the strategy here is to move

1407
00:43:40,326 --> 0:43:41,486
the motion analysis to the

1408
00:43:41,486 --> 0:43:42,336
second GPU.

1409
00:43:42,906 --> 0:43:45,166
Keep in mind that each motion

1410
00:43:45,166 --> 0:43:47,726
pass has to analyze the previous

1411
00:43:47,776 --> 0:43:48,676
pair of frames.

1412
00:43:49,316 --> 0:43:50,866
This means that we have to wait

1413
00:43:50,866 --> 0:43:51,956
for the previous frames to be

1414
00:43:51,956 --> 0:43:54,086
written before we read them from

1415
00:43:54,086 --> 0:43:56,076
the motion pass and this repeats

1416
00:43:56,146 --> 0:43:57,096
for each frame pair.

1417
00:43:57,746 --> 0:44:00,676
So we can accomplish this by

1418
00:43:57,746 --> 0:44:00,676
So we can accomplish this by

1419
00:44:00,676 --> 0:44:02,156
using Metal shared events.

1420
00:44:02,666 --> 0:44:03,886
First, we need to signal

1421
00:44:03,886 --> 0:44:05,246
completion when the frames are

1422
00:44:05,246 --> 0:44:07,276
done rendering, and then we wait

1423
00:44:07,276 --> 0:44:08,956
for that signal before reading

1424
00:44:08,956 --> 0:44:10,826
them with motion pass.

1425
00:44:11,566 --> 0:44:13,346
And with this, we can safely

1426
00:44:13,346 --> 0:44:14,886
offload the motion analysis to a

1427
00:44:14,886 --> 0:44:16,836
second GPU and everything runs

1428
00:44:16,836 --> 0:44:17,336
in parallel.

1429
00:44:18,056 --> 0:44:19,676
And because the signal

1430
00:44:19,766 --> 0:44:21,026
and wait are encoded on the GPU,

1431
00:44:21,346 --> 0:44:22,776
you don't block any CPU

1432
00:44:22,776 --> 0:44:23,326
execution.

1433
00:44:24,426 --> 0:44:25,896
So now let's take a look at how

1434
00:44:25,896 --> 0:44:26,876
we can do this in our code.

1435
00:44:27,526 --> 0:44:29,806
So the first thing we're going

1436
00:44:29,806 --> 0:44:31,266
to do is create a shared event

1437
00:44:31,736 --> 0:44:33,076
from the device that renders our

1438
00:44:33,076 --> 0:44:33,786
frames.

1439
00:44:34,576 --> 0:44:36,416
We also create two command

1440
00:44:36,446 --> 0:44:37,916
queues, one for each device.

1441
00:44:39,116 --> 0:44:40,796
Now to render the frames, we

1442
00:44:40,796 --> 0:44:42,006
create a command buffer and

1443
00:44:42,236 --> 0:44:44,676
encode, then immediately encode

1444
00:44:44,676 --> 0:44:46,286
a signal event to notify the

1445
00:44:46,286 --> 0:44:47,566
other GPU's that we're complete.

1446
00:44:48,606 --> 0:44:50,356
And finally, to encode the

1447
00:44:50,356 --> 0:44:54,426
motion, we start by creating a

1448
00:44:54,426 --> 0:44:55,576
command buffer from the queue.

1449
00:44:56,096 --> 0:44:57,496
Then immediately encode a wait

1450
00:44:57,496 --> 0:44:59,296
event to avoid reading the

1451
00:44:59,296 --> 0:45:00,416
frames before they're done.

1452
00:44:59,296 --> 0:45:00,416
frames before they're done.

1453
00:45:01,466 --> 0:45:02,666
And then we encode the motion

1454
00:45:02,666 --> 0:45:04,786
analysis and commit, and as you

1455
00:45:04,786 --> 0:45:05,876
can see it's a fairly

1456
00:45:05,986 --> 0:45:07,306
straightforward process and it's

1457
00:45:07,306 --> 0:45:08,186
very powerful.

1458
00:45:08,576 --> 0:45:10,576
And before I move on, let's take

1459
00:45:10,576 --> 0:45:12,196
a look at how we can look at

1460
00:45:12,516 --> 0:45:14,316
multi GPU's and channels in our

1461
00:45:14,316 --> 0:45:14,916
tools.

1462
00:45:15,486 --> 0:45:18,726
So Metal System Trace shows the

1463
00:45:18,726 --> 0:45:20,616
work for each of your test

1464
00:45:20,616 --> 0:45:21,146
GPU's.

1465
00:45:21,616 --> 0:45:22,896
In this example we're using four

1466
00:45:22,966 --> 0:45:23,446
GPU's.

1467
00:45:23,446 --> 0:45:25,896
One internal, and three external

1468
00:45:25,896 --> 0:45:26,536
GPU's.

1469
00:45:26,876 --> 0:45:30,156
It exposes detailed visibility

1470
00:45:30,436 --> 0:45:32,166
into each GPU by showing all the

1471
00:45:32,166 --> 0:45:34,116
asynchronous workloads across

1472
00:45:34,116 --> 0:45:35,936
all the channels, and it maps

1473
00:45:35,996 --> 0:45:38,266
those workloads with relevant

1474
00:45:38,316 --> 0:45:39,116
symbol names.

1475
00:45:39,706 --> 0:45:42,416
In the activity summary, you

1476
00:45:42,416 --> 0:45:43,616
could actually see all the

1477
00:45:43,616 --> 0:45:45,246
execution statistics for all the

1478
00:45:45,246 --> 0:45:46,286
connected GPU's.

1479
00:45:47,566 --> 0:45:48,956
You could even dive deeper to

1480
00:45:49,016 --> 0:45:50,246
see more detailed channel

1481
00:45:50,246 --> 0:45:52,776
information for any GPU on a per

1482
00:45:52,776 --> 0:45:53,536
frame basis.

1483
00:45:54,296 --> 0:45:55,676
This includes details for page

1484
00:45:55,676 --> 0:45:56,926
on and page off in the blit

1485
00:45:56,926 --> 0:45:58,996
channel or compute and render

1486
00:45:58,996 --> 0:45:59,716
workloads.

1487
00:46:00,686 --> 0:46:02,266
You can even drill down to see

1488
00:46:02,266 --> 0:46:03,666
IOSurface access.

1489
00:46:04,336 --> 0:46:05,476
As Eugene mentioned, this is

1490
00:46:05,476 --> 0:46:06,536
something that's very useful

1491
00:46:06,536 --> 0:46:07,896
because a lot of Pro Apps need

1492
00:46:07,896 --> 0:46:10,976
to utilize IOSurfaces, which is

1493
00:46:11,406 --> 0:46:12,946
really necessary for framework

1494
00:46:13,006 --> 0:46:13,886
interoperability.

1495
00:46:14,446 --> 0:46:17,546
And finally, our tools give you

1496
00:46:17,546 --> 0:46:19,146
visibility into Metal events and

1497
00:46:19,146 --> 0:46:19,896
shared events.

1498
00:46:19,896 --> 0:46:22,096
So you can actually see where

1499
00:46:22,096 --> 0:46:23,206
the signal and wait events

1500
00:46:23,206 --> 0:46:23,646
occur.

1501
00:46:24,466 --> 0:46:25,406
It also shows how many

1502
00:46:25,406 --> 0:46:26,896
milliseconds are spent waiting

1503
00:46:27,386 --> 0:46:28,756
and draws dependency lines for

1504
00:46:28,756 --> 0:46:29,366
you to follow.

1505
00:46:30,596 --> 0:46:31,606
And finally at the bottom,

1506
00:46:31,746 --> 0:46:32,736
there's even detailed lists

1507
00:46:32,736 --> 0:46:33,996
about your events in the

1508
00:46:33,996 --> 0:46:34,786
activity summary.

1509
00:46:35,446 --> 0:46:37,096
So Metal system trace is a great

1510
00:46:37,146 --> 0:46:38,796
tool for all your Pro App needs.

1511
00:46:39,626 --> 0:46:40,626
So now that we understand how to

1512
00:46:40,626 --> 0:46:42,846
utilize multiple GPU's, let's

1513
00:46:42,846 --> 0:46:44,306
look at how to transfer data

1514
00:46:44,306 --> 0:46:45,476
between them.

1515
00:46:46,976 --> 0:46:48,646
Scaling performance across CPU's

1516
00:46:48,646 --> 0:46:49,936
and GPU's is extremely

1517
00:46:49,936 --> 0:46:51,676
important, but at the end of the

1518
00:46:51,676 --> 0:46:53,666
day your Pro App is only as fast

1519
00:46:53,666 --> 0:46:55,016
as its slowest bottleneck.

1520
00:46:55,856 --> 0:46:57,236
When you're transferring massive

1521
00:46:57,236 --> 0:46:59,776
8K frames, your data transfers

1522
00:46:59,776 --> 0:47:00,786
can quickly become that

1523
00:46:59,776 --> 0:47:00,786
can quickly become that

1524
00:47:00,786 --> 0:47:01,286
bottleneck.

1525
00:47:01,896 --> 0:47:04,396
In this section, I'm going to

1526
00:47:04,396 --> 0:47:05,276
talk about bandwidth

1527
00:47:05,276 --> 0:47:07,186
considerations and how they

1528
00:47:07,186 --> 0:47:08,436
relate to the new Mac Pro.

1529
00:47:09,476 --> 0:47:11,806
Then I'll review a few Metal

1530
00:47:11,806 --> 0:47:13,746
peer groups transfer strategies,

1531
00:47:14,126 --> 0:47:15,156
and some of these are already in

1532
00:47:15,156 --> 0:47:16,796
use today by Pro App developers.

1533
00:47:17,276 --> 0:47:18,316
And finally I'll walk you

1534
00:47:18,356 --> 0:47:20,186
through an example use case to

1535
00:47:20,186 --> 0:47:21,676
show how Infinity Fabric Link

1536
00:47:21,676 --> 0:47:22,926
can help unlock challenging

1537
00:47:22,926 --> 0:47:23,656
workflows.

1538
00:47:24,286 --> 0:47:27,496
So let's start by looking at the

1539
00:47:27,496 --> 0:47:28,686
transfer rates for our key

1540
00:47:28,726 --> 0:47:29,636
connection points.

1541
00:47:29,986 --> 0:47:31,866
Our baseline here is PCI Express

1542
00:47:31,906 --> 0:47:33,696
gen 3 with 16 links.

1543
00:47:34,846 --> 0:47:36,206
So first we have Thunderbolt 3.

1544
00:47:36,206 --> 0:47:38,586
In the real world this maxes out

1545
00:47:38,586 --> 0:47:39,956
around one-quarter of the rate

1546
00:47:39,956 --> 0:47:41,076
of PCI Express.

1547
00:47:41,486 --> 0:47:42,846
It's a really great scalable

1548
00:47:42,846 --> 0:47:44,456
solution for compute heavy

1549
00:47:44,456 --> 0:47:45,996
workloads but maybe not the best

1550
00:47:46,076 --> 0:47:47,386
for bandwidth intensive ones.

1551
00:47:48,146 --> 0:47:51,096
Next we have two GPU's each with

1552
00:47:51,096 --> 0:47:52,256
their one PCI lanes.

1553
00:47:52,576 --> 0:47:53,936
This can double your bandwidth.

1554
00:47:55,026 --> 0:47:57,096
And this week we introduced the

1555
00:47:57,096 --> 0:47:58,706
new Infinity Fabric Link with

1556
00:47:58,826 --> 0:48:00,006
the peer group transfer API

1557
00:47:58,826 --> 0:48:00,006
the peer group transfer API

1558
00:48:00,596 --> 0:48:02,036
which can transfer data between

1559
00:48:02,036 --> 0:48:04,046
GPU's at speeds up to five times

1560
00:48:04,046 --> 0:48:07,166
that of PCI Express.

1561
00:48:07,606 --> 0:48:09,526
So now let's look at some common

1562
00:48:09,616 --> 0:48:10,786
Mac Pro configurations.

1563
00:48:11,596 --> 0:48:13,156
This diagram illustrates a great

1564
00:48:13,156 --> 0:48:14,426
configuration for bandwidth

1565
00:48:14,426 --> 0:48:15,196
intensive ones.

1566
00:48:16,146 --> 0:48:17,556
Here we have a new Apple

1567
00:48:17,556 --> 0:48:19,056
Afterburner which has its own

1568
00:48:19,056 --> 0:48:20,346
dedicated PCI lanes.

1569
00:48:21,226 --> 0:48:22,876
We also have two internal GPU's

1570
00:48:22,876 --> 0:48:24,386
with their own dedicated PCI

1571
00:48:24,386 --> 0:48:24,616
lanes.

1572
00:48:25,496 --> 0:48:26,716
And finally, you can connect

1573
00:48:26,816 --> 0:48:28,456
those GPU's with Infinity Fabric

1574
00:48:28,526 --> 0:48:30,346
Link to quickly copy data

1575
00:48:30,346 --> 0:48:31,566
between them.

1576
00:48:32,976 --> 0:48:34,476
The Mac Pro also allows you to

1577
00:48:34,476 --> 0:48:36,356
have up to four internal GPU's

1578
00:48:36,356 --> 0:48:38,096
that share two sets of PCI

1579
00:48:38,096 --> 0:48:38,336
lanes.

1580
00:48:39,226 --> 0:48:40,456
Because the lanes are shared, it

1581
00:48:40,456 --> 0:48:41,726
lends itself maybe to a more

1582
00:48:41,726 --> 0:48:43,156
compute heavy pro application.

1583
00:48:43,766 --> 0:48:45,516
And in this case, it can also be

1584
00:48:45,516 --> 0:48:46,556
connected with the Infinity

1585
00:48:46,596 --> 0:48:47,126
Fabric Link.

1586
00:48:47,706 --> 0:48:51,506
So there is many, many ways to

1587
00:48:51,506 --> 0:48:52,646
manage these transfer

1588
00:48:52,646 --> 0:48:53,466
strategies.

1589
00:48:53,886 --> 0:48:55,026
I'm going to go over a few

1590
00:48:55,026 --> 0:48:56,676
proven strategies that some Pro

1591
00:48:56,676 --> 0:48:57,926
App developers are using today.

1592
00:48:59,186 --> 0:49:00,866
The most straightforward

1593
00:48:59,186 --> 0:49:00,866
The most straightforward

1594
00:49:00,866 --> 0:49:02,446
approach is to transfer entire

1595
00:49:02,506 --> 0:49:03,496
frames for display.

1596
00:49:04,196 --> 0:49:05,396
The premise is to process

1597
00:49:05,396 --> 0:49:06,646
alternating frames.

1598
00:49:06,986 --> 0:49:08,206
Any frame processed on the

1599
00:49:08,206 --> 0:49:09,846
auxiliary device can be

1600
00:49:09,846 --> 0:49:10,876
transferred quickly to the

1601
00:49:10,876 --> 0:49:12,926
display attached GPU and then

1602
00:49:13,236 --> 0:49:16,516
sent to the display.

1603
00:49:16,516 --> 0:49:17,926
Another transfer strategy is to

1604
00:49:17,926 --> 0:49:20,566
send tiles to each GPU that are

1605
00:49:20,566 --> 0:49:22,156
essentially pieces of the entire

1606
00:49:22,156 --> 0:49:22,546
frame.

1607
00:49:23,376 --> 0:49:24,736
All the tiles processed on the

1608
00:49:24,736 --> 0:49:26,146
auxiliary device can be sent to

1609
00:49:26,146 --> 0:49:27,956
the display GPU and then

1610
00:49:27,956 --> 0:49:29,276
reconstructed as part of the

1611
00:49:29,276 --> 0:49:30,526
final output image.

1612
00:49:31,566 --> 0:49:32,826
This result has really good load

1613
00:49:32,826 --> 0:49:33,246
balancing.

1614
00:49:34,186 --> 0:49:35,826
So we've looked at two

1615
00:49:35,826 --> 0:49:36,956
strategies quickly.

1616
00:49:37,336 --> 0:49:39,066
Now let's see a great example of

1617
00:49:39,066 --> 0:49:40,806
a Pro App actually leveraging

1618
00:49:40,806 --> 0:49:42,646
the Infinity Fabric Link.

1619
00:49:43,556 --> 0:49:45,316
So over the last six months,

1620
00:49:45,316 --> 0:49:46,976
I've had the opportunity to

1621
00:49:46,976 --> 0:49:48,326
collaborate with the Final Cut

1622
00:49:48,326 --> 0:49:48,716
Pro team.

1623
00:49:49,426 --> 0:49:51,056
They've done an outstanding job

1624
00:49:51,056 --> 0:49:52,746
optimizing for the new Mac Pro.

1625
00:49:53,536 --> 0:49:55,496
They're scaling across 28 CPU

1626
00:49:55,496 --> 0:49:58,066
cores and all internal GPU's.

1627
00:49:58,916 --> 0:50:00,376
They've also fully utilized the

1628
00:49:58,916 --> 0:50:00,376
They've also fully utilized the

1629
00:50:00,376 --> 0:50:01,436
Infinity Fabric Link.

1630
00:50:02,026 --> 0:50:03,416
This is helping them to enable

1631
00:50:03,526 --> 0:50:06,286
real time editing of multiple 8K

1632
00:50:06,286 --> 0:50:06,976
ProRes video streams.

1633
00:50:08,406 --> 0:50:09,836
Now let's take a closer look at

1634
00:50:09,836 --> 0:50:10,886
how this works.

1635
00:50:12,306 --> 0:50:13,516
So here we have a simple

1636
00:50:13,516 --> 0:50:14,956
timeline diagram that shows how

1637
00:50:14,956 --> 0:50:16,886
video streams move from the CPU

1638
00:50:16,996 --> 0:50:17,716
to the display.

1639
00:50:17,716 --> 0:50:19,816
In this case we're focusing on

1640
00:50:19,876 --> 0:50:22,136
playback of three 8k ProRes raw

1641
00:50:22,136 --> 0:50:23,796
video streams with some effects.

1642
00:50:24,816 --> 0:50:25,706
This is how it might look on a

1643
00:50:25,766 --> 0:50:26,536
single GPU.

1644
00:50:28,116 --> 0:50:29,536
So first, we encode frame one

1645
00:50:29,536 --> 0:50:30,636
commands on the CPU.

1646
00:50:31,706 --> 0:50:33,536
Then upload all three streams

1647
00:50:33,536 --> 0:50:34,946
over PCI to VRAM.

1648
00:50:36,166 --> 0:50:38,206
Finally we process those streams

1649
00:50:38,206 --> 0:50:39,976
with effects on the GPU and

1650
00:50:39,976 --> 0:50:40,486
display.

1651
00:50:41,016 --> 0:50:43,276
We continue this process for

1652
00:50:43,276 --> 0:50:44,736
each of the additional frames.

1653
00:50:45,876 --> 0:50:47,186
And as much as we want this to

1654
00:50:47,186 --> 0:50:48,696
fit within our 30 frames per

1655
00:50:48,696 --> 0:50:50,466
second, it won't.

1656
00:50:50,846 --> 0:50:52,316
It's just too much work to pack

1657
00:50:52,316 --> 0:50:53,286
into that space.

1658
00:50:53,626 --> 0:50:55,926
A Pro App will drop at least 30%

1659
00:50:55,926 --> 0:50:56,696
of their frames in this

1660
00:50:56,696 --> 0:50:57,296
scenario.

1661
00:50:57,936 --> 0:50:58,916
Now let's see how this might

1662
00:50:58,916 --> 0:51:00,826
work on a dual GPU system.

1663
00:50:58,916 --> 0:51:00,826
work on a dual GPU system.

1664
00:51:02,046 --> 0:51:04,456
So first, we encode frame one as

1665
00:51:04,456 --> 0:51:05,466
in the previous example.

1666
00:51:06,546 --> 0:51:07,816
For frame two, we follow a

1667
00:51:07,816 --> 0:51:08,846
similar process.

1668
00:51:09,386 --> 0:51:10,606
Now this is looking really good.

1669
00:51:10,606 --> 0:51:12,286
We've got things going in

1670
00:51:12,286 --> 0:51:12,976
parallel here.

1671
00:51:13,306 --> 0:51:14,696
But do we double our frame rate?

1672
00:51:15,406 --> 0:51:16,796
Unfortunately, we don't.

1673
00:51:17,456 --> 0:51:20,356
The problem comes when any frame

1674
00:51:20,356 --> 0:51:21,516
that we've processed on the

1675
00:51:21,516 --> 0:51:23,136
auxiliary device has to somehow

1676
00:51:23,136 --> 0:51:24,996
be copied back to the display

1677
00:51:24,996 --> 0:51:26,206
attach device, and this is where

1678
00:51:26,266 --> 0:51:27,096
things get tricky.

1679
00:51:27,766 --> 0:51:30,256
To get the display GPU, we have

1680
00:51:30,256 --> 0:51:33,106
to copy a 265-megabyte output

1681
00:51:33,106 --> 0:51:35,936
buffer over PCI to the host, and

1682
00:51:35,936 --> 0:51:37,566
then we copy a second time from

1683
00:51:37,566 --> 0:51:38,866
there to the display attached

1684
00:51:38,866 --> 0:51:39,246
GPU.

1685
00:51:40,606 --> 0:51:42,026
This can take up to 48

1686
00:51:42,026 --> 0:51:43,206
milliseconds on a good day.

1687
00:51:43,626 --> 0:51:45,136
So now, let's continue with

1688
00:51:45,136 --> 0:51:46,516
frames three and four to give

1689
00:51:46,516 --> 0:51:48,000
you a better picture.

1690
00:51:50,436 --> 0:51:51,746
And you can quickly see that

1691
00:51:51,746 --> 0:51:52,866
we're using a considerable

1692
00:51:52,866 --> 0:51:54,936
amount of PCI bandwidth but also

1693
00:51:54,936 --> 0:51:56,106
we see a lot of gaps and

1694
00:51:56,106 --> 0:51:56,856
dependencies.

1695
00:51:57,296 --> 0:51:58,406
We're still doing better than

1696
00:51:58,406 --> 0:52:00,076
the single GPU case, but it's

1697
00:51:58,406 --> 0:52:00,076
the single GPU case, but it's

1698
00:52:00,076 --> 0:52:01,326
not going to double our frame

1699
00:52:01,326 --> 0:52:01,496
rate.

1700
00:52:02,386 --> 0:52:04,306
All this PCI traffic will result

1701
00:52:04,306 --> 0:52:05,586
in dropping some frames.

1702
00:52:06,146 --> 0:52:09,076
But to improve on this problem,

1703
00:52:09,376 --> 0:52:11,186
the Mac Pro introduces the new

1704
00:52:11,186 --> 0:52:12,456
Infinity Fabric Link feature

1705
00:52:12,456 --> 0:52:13,586
with the peer group API.

1706
00:52:14,056 --> 0:52:16,006
This completely blows away the

1707
00:52:16,006 --> 0:52:16,776
GPU copy.

1708
00:52:18,436 --> 0:52:20,046
You could see here with Infinity

1709
00:52:20,046 --> 0:52:21,656
Fabric Link the transfer is much

1710
00:52:21,656 --> 0:52:22,316
faster.

1711
00:52:23,046 --> 0:52:24,666
It also frees up a considerable

1712
00:52:24,666 --> 0:52:27,576
amount of PCI bandwidth and with

1713
00:52:27,576 --> 0:52:29,186
that bandwidth we can upload our

1714
00:52:29,246 --> 0:52:30,226
frames earlier.

1715
00:52:32,256 --> 0:52:33,786
Infinity Fabric Link also

1716
00:52:33,786 --> 0:52:35,556
operates on its own parallel GPU

1717
00:52:35,556 --> 0:52:35,956
channel.

1718
00:52:36,526 --> 0:52:37,576
This means you could transfer

1719
00:52:37,576 --> 0:52:39,216
data while using the render and

1720
00:52:39,216 --> 0:52:40,306
compute channels at the same

1721
00:52:40,306 --> 0:52:40,596
time.

1722
00:52:41,916 --> 0:52:42,846
This helps us to improve

1723
00:52:42,846 --> 0:52:44,486
concurrency and hide latency.

1724
00:52:44,856 --> 0:52:46,316
At the end of the day, this can

1725
00:52:46,316 --> 0:52:48,006
enable your Pro App to unlock

1726
00:52:48,316 --> 0:52:49,776
challenging workloads and enable

1727
00:52:49,776 --> 0:52:50,646
new use cases.

1728
00:52:51,346 --> 0:52:52,406
So this is what it looks like on

1729
00:52:52,406 --> 0:52:53,786
a boring timeline diagram.

1730
00:52:54,376 --> 0:52:55,566
But now let's see what it looks

1731
00:52:55,566 --> 0:52:56,076
in action.

1732
00:52:56,666 --> 0:52:59,336
This is the Final Cut Pro demo

1733
00:52:59,336 --> 0:53:00,296
you saw in the keynote.

1734
00:52:59,336 --> 0:53:00,296
you saw in the keynote.

1735
00:53:00,886 --> 0:53:01,856
You can see it plays back

1736
00:53:01,856 --> 0:53:03,776
multiple streams of 8K video

1737
00:53:03,776 --> 0:53:05,336
with effects and transitions.

1738
00:53:05,336 --> 0:53:08,316
This is also done in real time

1739
00:53:08,316 --> 0:53:09,806
using multiple GPU's and the

1740
00:53:09,806 --> 0:53:10,776
Infinity Fabric Link.

1741
00:53:11,776 --> 0:53:13,556
Final Cut Pro is an outstanding

1742
00:53:13,556 --> 0:53:15,356
example of a Pro App utilizing

1743
00:53:15,586 --> 0:53:17,066
efficient data transfers.

1744
00:53:17,376 --> 0:53:19,136
So now before we close this

1745
00:53:19,136 --> 0:53:21,156
section, let's look at how to

1746
00:53:21,156 --> 0:53:22,846
use Infinity Fabric Link and the

1747
00:53:22,966 --> 0:53:25,336
peer grant transfer group API in

1748
00:53:25,336 --> 0:53:25,796
your code.

1749
00:53:26,466 --> 0:53:29,456
So the first thing you need to

1750
00:53:29,976 --> 0:53:31,756
do is detect these connections.

1751
00:53:32,176 --> 0:53:33,666
To facilitate this, Metal

1752
00:53:33,666 --> 0:53:35,376
defines a brand-new peer group

1753
00:53:35,376 --> 0:53:37,626
API, defines properties on the

1754
00:53:37,626 --> 0:53:39,516
Metal device for peer group ID,

1755
00:53:39,596 --> 0:53:40,546
index, and count.

1756
00:53:41,866 --> 0:53:43,146
With this you can detect if you

1757
00:53:43,146 --> 0:53:44,836
have linked GPU's and if they

1758
00:53:44,836 --> 0:53:46,726
have shared PCI lanes or dual

1759
00:53:46,726 --> 0:53:47,546
PCI lanes.

1760
00:53:47,916 --> 0:53:49,206
More importantly, you can use

1761
00:53:49,206 --> 0:53:52,046
this to determine the best

1762
00:53:52,046 --> 0:53:53,756
configuration for you and scale

1763
00:53:53,756 --> 0:53:54,886
your performance based on the

1764
00:53:54,886 --> 0:53:56,016
bandwidth limitations.

1765
00:53:58,226 --> 0:53:59,296
And this is how you transfer

1766
00:53:59,296 --> 0:54:00,746
data between GPU's.

1767
00:53:59,296 --> 0:54:00,746
data between GPU's.

1768
00:54:01,226 --> 0:54:02,766
The first thing you need to do

1769
00:54:02,766 --> 0:54:04,366
is create your shared event from

1770
00:54:04,366 --> 0:54:05,476
the auxiliary device.

1771
00:54:06,396 --> 0:54:08,466
We also create a render texture

1772
00:54:08,466 --> 0:54:10,006
and a remote texture view.

1773
00:54:10,436 --> 0:54:11,616
The remote view will give our

1774
00:54:11,616 --> 0:54:13,926
display attached GPU access to

1775
00:54:14,036 --> 0:54:15,396
the auxiliary texture.

1776
00:54:17,016 --> 0:54:18,436
Next we create an encoder and

1777
00:54:18,436 --> 0:54:18,846
render.

1778
00:54:20,136 --> 0:54:20,976
This should immediately be

1779
00:54:21,056 --> 0:54:22,486
followed by the encoded signal

1780
00:54:23,366 --> 0:54:23,526
event.

1781
00:54:24,416 --> 0:54:26,066
Now on the display device we

1782
00:54:26,066 --> 0:54:27,446
create a blit command buffer.

1783
00:54:28,036 --> 0:54:29,426
We immediately encode a wait

1784
00:54:29,426 --> 0:54:29,756
event.

1785
00:54:29,826 --> 0:54:31,046
So we wait for the rendering to

1786
00:54:31,046 --> 0:54:32,476
complete before transferring the

1787
00:54:32,476 --> 0:54:32,826
data.

1788
00:54:33,446 --> 0:54:36,406
And finally we do a copy using

1789
00:54:36,406 --> 0:54:37,736
the textured view, and that's

1790
00:54:37,736 --> 0:54:38,006
it.

1791
00:54:38,406 --> 0:54:39,026
Very simple.

1792
00:54:41,596 --> 0:54:43,446
Utilizing Metal peer group API

1793
00:54:43,596 --> 0:54:45,436
to leverage Infinity Fabric Link

1794
00:54:45,676 --> 0:54:47,336
can unlock challenging workloads

1795
00:54:47,336 --> 0:54:49,196
by reducing your PCI bandwidth.

1796
00:54:49,726 --> 0:54:51,516
It also can enhance concurrency

1797
00:54:51,846 --> 0:54:53,086
by using a parallel channel.

1798
00:54:53,846 --> 0:54:55,026
So before I conclude this

1799
00:54:55,026 --> 0:54:57,306
session, let's look at one more

1800
00:54:57,376 --> 0:54:58,846
really great Pro App in action.

1801
00:55:00,366 --> 0:55:01,616
So now I'm excited to share a

1802
00:55:01,616 --> 0:55:03,266
demo of Affinity Photo from

1803
00:55:03,266 --> 0:55:04,176
Serif Labs.

1804
00:55:04,746 --> 0:55:05,916
The engineers at Serif have done

1805
00:55:05,916 --> 0:55:07,886
an outstanding job of adopting

1806
00:55:07,886 --> 0:55:08,266
Metal.

1807
00:55:08,626 --> 0:55:10,836
They're also a really, really

1808
00:55:10,836 --> 0:55:12,676
good example of how to

1809
00:55:12,676 --> 0:55:13,996
officially leverage platform

1810
00:55:13,996 --> 0:55:14,686
resources.

1811
00:55:15,266 --> 0:55:16,836
On a typical document, their

1812
00:55:16,836 --> 0:55:18,256
performance can be around 10

1813
00:55:18,256 --> 0:55:20,126
times faster on a single GPU

1814
00:55:20,396 --> 0:55:21,876
when compared to an eight course

1815
00:55:21,876 --> 0:55:22,296
CPU.

1816
00:55:23,186 --> 0:55:23,936
Let's take a look.

1817
00:55:25,566 --> 0:55:26,876
So in this example, Affinity is

1818
00:55:26,876 --> 0:55:29,126
going to be live compositing a

1819
00:55:29,126 --> 0:55:30,296
massive document called the

1820
00:55:30,336 --> 0:55:30,936
rabbit trick.

1821
00:55:31,726 --> 0:55:32,996
As the video demonstrates, it

1822
00:55:32,996 --> 0:55:34,796
has hundreds of massive layers,

1823
00:55:35,026 --> 0:55:36,616
and they'll be compositing at 4K

1824
00:55:36,616 --> 0:55:37,196
resolution.

1825
00:55:38,156 --> 0:55:39,456
Some layers have pixel data

1826
00:55:39,456 --> 0:55:40,656
while others have procedural

1827
00:55:40,656 --> 0:55:41,466
adjustments.

1828
00:55:42,446 --> 0:55:43,476
This will be hierarchically

1829
00:55:43,476 --> 0:55:46,056
composited in real time, and

1830
00:55:46,056 --> 0:55:47,406
this will also put a tremendous

1831
00:55:47,406 --> 0:55:49,456
load on both the CPU and the

1832
00:55:49,886 --> 0:55:50,000
GPU.

1833
00:55:52,006 --> 0:55:53,556
Now let's run this massive

1834
00:55:53,596 --> 0:55:54,606
document on the CPU.

1835
00:55:55,396 --> 0:55:57,256
This is using an 18-core system.

1836
00:55:57,736 --> 0:55:58,636
You could see that we're able to

1837
00:55:58,636 --> 0:56:00,516
composite in real time; however,

1838
00:55:58,636 --> 0:56:00,516
composite in real time; however,

1839
00:56:00,516 --> 0:56:02,736
the document is so complex it

1840
00:56:02,736 --> 0:56:03,896
gets a little bit choppy in the

1841
00:56:03,896 --> 0:56:04,966
user interface.

1842
00:56:08,946 --> 0:56:10,286
Now let's switch and run that on

1843
00:56:10,286 --> 0:56:11,276
a single GPU.

1844
00:56:12,266 --> 0:56:13,346
Here, you can see the UI

1845
00:56:13,346 --> 0:56:15,076
responds really well and

1846
00:56:15,076 --> 0:56:16,256
everything runs smoothly.

1847
00:56:16,476 --> 0:56:18,366
The frame rate runs about 18 to

1848
00:56:18,366 --> 0:56:19,500
20 frames per second.

1849
00:56:22,616 --> 0:56:23,776
And now for the best part.

1850
00:56:23,776 --> 0:56:25,456
We're going to enable a total of

1851
00:56:25,646 --> 0:56:27,856
four external GPU's and as you

1852
00:56:27,856 --> 0:56:29,076
can see it runs incredibly

1853
00:56:29,166 --> 0:56:30,746
smooth and it maintains greater

1854
00:56:30,746 --> 0:56:31,996
than 60 frames per second the

1855
00:56:31,996 --> 0:56:32,786
entire time.

1856
00:56:33,436 --> 0:56:34,566
This is due in part to

1857
00:56:34,566 --> 0:56:36,906
Affinity's advanced tile-based

1858
00:56:36,906 --> 0:56:37,896
load balancing scheme.

1859
00:56:38,586 --> 0:56:39,716
They can distribute their work

1860
00:56:39,716 --> 0:56:41,466
efficiently among any number of

1861
00:56:41,466 --> 0:56:43,326
GPU's, and with this they can

1862
00:56:43,326 --> 0:56:44,556
achieve linear performance

1863
00:56:44,556 --> 0:56:45,046
scaling.

1864
00:56:45,656 --> 0:56:48,236
Here is one last example that I

1865
00:56:48,236 --> 0:56:48,686
want to share.

1866
00:56:49,696 --> 0:56:50,826
This is one of Affinity Photo's

1867
00:56:50,826 --> 0:56:52,546
most memory bandwidth intensive

1868
00:56:52,546 --> 0:56:54,236
filters known as depth of field.

1869
00:56:55,426 --> 0:56:56,566
Here we're previewing in real

1870
00:56:56,566 --> 0:56:57,896
time on the CPU.

1871
00:56:58,556 --> 0:57:00,096
You can visually see the time it

1872
00:56:58,556 --> 0:57:00,096
You can visually see the time it

1873
00:57:00,096 --> 0:57:01,226
takes between applying the

1874
00:57:01,226 --> 0:57:02,286
effect and it actually

1875
00:57:02,286 --> 0:57:02,706
rendering.

1876
00:57:03,626 --> 0:57:04,956
This is still impressive, and

1877
00:57:04,956 --> 0:57:06,996
it's fast, but the GPU can make

1878
00:57:06,996 --> 0:57:08,000
this even better.

1879
00:57:09,336 --> 0:57:10,066
So now we're going to run the

1880
00:57:10,066 --> 0:57:11,866
same effect with four external

1881
00:57:11,866 --> 0:57:12,146
GPU's.

1882
00:57:12,146 --> 0:57:14,466
You could see here it runs

1883
00:57:14,466 --> 0:57:16,536
amazingly smooth and easily

1884
00:57:16,536 --> 0:57:18,086
maintains a frame rate greater

1885
00:57:18,086 --> 0:57:19,346
than 60 frames per second.

1886
00:57:20,196 --> 0:57:21,836
This particular filter is memory

1887
00:57:21,836 --> 0:57:22,896
bandwidth intensive.

1888
00:57:23,276 --> 0:57:25,076
So we get great improvement here

1889
00:57:25,396 --> 0:57:27,736
because of the massive memory

1890
00:57:27,736 --> 0:57:29,696
bandwidth available on modern

1891
00:57:29,696 --> 0:57:30,536
GPU's today.

1892
00:57:31,356 --> 0:57:32,766
And this is an outstanding

1893
00:57:32,766 --> 0:57:34,476
example of how to officially

1894
00:57:34,476 --> 0:57:36,186
scale performance across

1895
00:57:36,186 --> 0:57:37,376
multiple GPU's.

1896
00:57:37,946 --> 0:57:40,686
So before we close this session,

1897
00:57:41,026 --> 0:57:42,346
let's review some of the key

1898
00:57:42,346 --> 0:57:43,116
takeaways.

1899
00:57:44,506 --> 0:57:45,856
Apple provides a wealth of

1900
00:57:45,856 --> 0:57:47,716
frameworks to solve all your Pro

1901
00:57:47,716 --> 0:57:48,006
App needs.

1902
00:57:48,856 --> 0:57:50,526
You can leverage this ecosystem

1903
00:57:50,526 --> 0:57:52,126
to achieve real-time editing

1904
00:57:52,126 --> 0:57:54,576
performance on 8k content with a

1905
00:57:54,576 --> 0:57:55,586
predictable frame rate.

1906
00:57:57,086 --> 0:57:59,456
Apple's AV Foundation and Core

1907
00:57:59,456 --> 0:58:01,516
Animation Metal Layer provide

1908
00:57:59,456 --> 0:58:01,516
Animation Metal Layer provide

1909
00:58:01,516 --> 0:58:03,406
API's to seamlessly support high

1910
00:58:03,406 --> 0:58:04,426
dynamic range.

1911
00:58:04,826 --> 0:58:06,196
You can couple this with HDR

1912
00:58:06,256 --> 0:58:08,686
TV's and Apple's new Pro Display

1913
00:58:08,686 --> 0:58:11,256
XDR to generate amazing videos

1914
00:58:11,256 --> 0:58:11,916
and images.

1915
00:58:12,516 --> 0:58:15,436
The Mac Pro can have up to 28

1916
00:58:15,526 --> 0:58:17,266
CPU cores and four internal

1917
00:58:17,266 --> 0:58:18,116
GPU's.

1918
00:58:18,666 --> 0:58:20,096
Metal provides all the API for

1919
00:58:20,206 --> 0:58:21,426
you to scale your performance

1920
00:58:21,426 --> 0:58:22,796
across all these devices.

1921
00:58:24,366 --> 0:58:26,186
And finally, we introduced a new

1922
00:58:26,186 --> 0:58:27,746
hardware feature Affinity Fabric

1923
00:58:27,746 --> 0:58:29,296
Link with a Metal peer group

1924
00:58:29,296 --> 0:58:29,656
API.

1925
00:58:30,516 --> 0:58:32,186
This empowers you to leverage

1926
00:58:32,186 --> 0:58:34,926
this connection to unlock new

1927
00:58:34,926 --> 0:58:36,146
and exciting use cases.

1928
00:58:37,626 --> 0:58:39,386
For more information, please

1929
00:58:39,386 --> 0:58:41,146
visit our website and please

1930
00:58:41,146 --> 0:58:42,626
visit us in tomorrow's lab.

1931
00:58:42,956 --> 0:58:44,456
Also check out additional Metal

1932
00:58:44,456 --> 0:58:45,366
labs on Friday.

1933
00:58:45,596 --> 0:58:46,456
Thank you very much.

1934
00:58:47,516 --> 0:58:51,500
[ Applause ]
