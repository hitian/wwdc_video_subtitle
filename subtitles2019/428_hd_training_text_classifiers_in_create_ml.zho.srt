1
00:00:00,506 --> 0:00:04,500
[音乐]

2
00:00:07,516 --> 0:00:14,026
[掌声]

3
00:00:14,526 --> 0:00:15,626
&gt;&gt; 嗨 大家

4
00:00:15,836 --> 0:00:16,516
大家下午好

5
00:00:17,316 --> 0:00:18,456
欢迎大家来到这次会议

6
00:00:19,796 --> 0:00:20,836
我是 Tao

7
00:00:21,246 --> 0:00:22,446
我来自 Core ML 团队

8
00:00:23,276 --> 0:00:25,016
今天我们十分激动

9
00:00:25,016 --> 0:00:26,916
能够来讨论我们今年

10
00:00:26,916 --> 0:00:28,676
在 Create ML 中添加的一些新功能

11
00:00:29,016 --> 0:00:30,136
在机器学习讨论会的

12
00:00:30,136 --> 0:00:31,536
新内容中 你们了解了

13
00:00:31,536 --> 0:00:34,986
全新的 Create ML App

14
00:00:34,986 --> 0:00:36,336
这是 Apple 设计的

15
00:00:36,336 --> 0:00:38,226
一款出色的新工具

16
00:00:38,226 --> 0:00:40,146
它可指导你完成

17
00:00:40,146 --> 0:00:41,206
机器学习模型培训的基本步骤

18
00:00:42,226 --> 0:00:43,806
我们相信这会使

19
00:00:43,806 --> 0:00:46,016
你们的机器学习工作流程

20
00:00:46,016 --> 0:00:46,756
变得简单易用

21
00:00:48,206 --> 0:00:49,366
现在 让我们

22
00:00:49,366 --> 0:00:49,976
从文本分类开始

23
00:00:52,546 --> 0:00:53,956
什么是文本分类

24
00:00:54,536 --> 0:00:55,966
这是一个机器学习的任务

25
00:00:56,346 --> 0:00:58,796
它将文本分类为

26
00:00:58,886 --> 0:01:00,446
一组预定义标签

27
00:00:58,886 --> 0:01:00,446
一组预定义标签

28
00:01:03,136 --> 0:01:04,566
你可以将其用于情感分析

29
00:01:04,566 --> 0:01:07,626
例如将文本分类为

30
00:01:07,626 --> 0:01:09,936
正面或负面

31
00:01:11,396 --> 0:01:12,756
或者做垃圾邮件检测

32
00:01:12,756 --> 0:01:16,096
或者更复杂的事情

33
00:01:16,386 --> 0:01:18,596
如主题分析 将文本分类为

34
00:01:18,596 --> 0:01:21,786
食物类 政治类或科学类

35
00:01:23,146 --> 0:01:24,556
好 自去年以来

36
00:01:24,556 --> 0:01:25,976
文本分类一直被推崇

37
00:01:26,516 --> 0:01:28,296
但我们今年正在增加

38
00:01:28,296 --> 0:01:30,776
对艺术迁移学习状态的支持

39
00:01:31,636 --> 0:01:33,156
今天 我将向你们

40
00:01:33,156 --> 0:01:35,206
具体举例说明

41
00:01:35,206 --> 0:01:37,346
如何使用迁移学习

42
00:01:37,346 --> 0:01:38,046
训练文本分类器

43
00:01:39,446 --> 0:01:41,336
要训练这样的一个模型

44
00:01:41,336 --> 0:01:42,566
你要做的第一件事

45
00:01:42,886 --> 0:01:44,616
就是收集一些训练数据

46
00:01:46,336 --> 0:01:48,386
一旦获得数据后

47
00:01:48,386 --> 0:01:50,066
你们便可以轻松地进行整理

48
00:01:51,116 --> 0:01:54,056
我这儿有运动类 娱乐类和自然类

49
00:01:55,166 --> 0:01:56,996
在每个文件夹下

50
00:01:56,996 --> 0:01:57,626
我有一些文本文件

51
00:01:58,236 --> 0:02:00,316
而且他们中的每一个都是

52
00:01:58,236 --> 0:02:00,316
而且他们中的每一个都是

53
00:02:00,316 --> 0:02:02,996
一个训练样例

54
00:02:03,146 --> 0:02:04,996
它们的标签就是

55
00:02:04,996 --> 0:02:05,406
它们所在文件夹的名称

56
00:02:05,946 --> 0:02:07,786
就是这样

57
00:02:07,786 --> 0:02:08,806
这就是你们要对这些数据

58
00:02:08,806 --> 0:02:09,186
做的所有处理

59
00:02:10,156 --> 0:02:11,636
我会给你们一个快速演示

60
00:02:11,636 --> 0:02:12,576
告诉你们如何做到这一点

61
00:02:12,776 --> 0:02:15,606
在我的桌面上

62
00:02:15,606 --> 0:02:15,956
我有一个训练数据的文件夹

63
00:02:20,386 --> 0:02:22,026
那么 我决定找点乐子

64
00:02:22,716 --> 0:02:24,356
我没有使用纯文本作为标签

65
00:02:24,356 --> 0:02:26,546
而是使用了一些表情符号

66
00:02:27,426 --> 0:02:29,116
例如 对于娱乐类我使用

67
00:02:29,116 --> 0:02:30,306
一个摄像机图标

68
00:02:31,106 --> 0:02:33,836
对于运动类 我用了一个橄榄球

69
00:02:35,196 --> 0:02:36,836
对于自然类

70
00:02:36,836 --> 0:02:39,486
我则用了一个可爱的小帐篷

71
00:02:40,856 --> 0:02:40,966
旁边有棵大松树

72
00:02:41,186 --> 0:02:42,536
你注意那儿还有

73
00:02:42,656 --> 0:02:43,306
这个其他文件夹

74
00:02:44,186 --> 0:02:45,686
这其实是我不想要的

75
00:02:45,686 --> 0:02:46,936
训练数据

76
00:02:46,936 --> 0:02:49,466
我希望我的模型能够学习

77
00:02:49,466 --> 0:02:51,326
任何不属于

78
00:02:51,326 --> 0:02:53,416
以上三个目标类的东西

79
00:02:53,416 --> 0:02:55,756
我希望我的模型将它们

80
00:02:56,726 --> 0:02:58,516
分到这个类中

81
00:02:58,686 --> 0:03:00,286
那么 我们来看看

82
00:02:58,686 --> 0:03:00,286
那么 我们来看看

83
00:03:00,286 --> 0:03:00,936
这里的一些例子

84
00:03:01,766 --> 0:03:05,186
例如 如果你们读了

85
00:03:05,186 --> 0:03:06,056
这个句子 有一些关于

86
00:03:06,056 --> 0:03:07,586
作家和 IMDB 的东西

87
00:03:07,586 --> 0:03:09,026
这显然与

88
00:03:09,026 --> 0:03:09,806
娱乐有关

89
00:03:13,006 --> 0:03:15,066
如果我进入其他文件夹

90
00:03:15,926 --> 0:03:20,006
它不是以上三个类中的一个

91
00:03:24,536 --> 0:03:25,546
这是关于数据的问题

92
00:03:25,796 --> 0:03:32,446
现在 我要进入 Create ML App

93
00:03:34,436 --> 0:03:36,806
为此 我转到开发人员工具中

94
00:03:36,806 --> 0:03:39,356
并找到 Create ML

95
00:03:42,116 --> 0:03:43,256
然而我要做一个新文件

96
00:03:43,256 --> 0:03:48,336
然后转去文本

97
00:03:48,496 --> 0:03:49,496
我会这样命名它

98
00:03:50,736 --> 0:03:53,906
创建 好的 我相信你们

99
00:03:53,906 --> 0:03:56,476
已经在早期的会议中

100
00:03:56,476 --> 0:03:58,096
看到了这个用户界面

101
00:03:58,096 --> 0:03:59,916
对象连接和子分类

102
00:04:00,226 --> 0:04:01,466
所以 我在这里就

103
00:04:01,466 --> 0:04:02,826
直接拖动我的训练数据

104
00:04:03,446 --> 0:04:05,956
所以它会为你们提供一些

105
00:04:05,956 --> 0:04:06,926
有关你们训练数据的反馈

106
00:04:07,366 --> 0:04:08,606
但是文本分类器的新功能是

107
00:04:08,606 --> 0:04:11,236
这个特殊的参数部分

108
00:04:11,866 --> 0:04:15,026
所以 对于今天的演示

109
00:04:15,026 --> 0:04:16,296
我将选择迁移学习

110
00:04:17,736 --> 0:04:19,065
如果我们看看它的话就知道

111
00:04:19,065 --> 0:04:20,596
自去年以来

112
00:04:20,596 --> 0:04:21,995
实际上前两种算法

113
00:04:21,995 --> 0:04:22,136
已经被鼓励使用了

114
00:04:22,776 --> 0:04:23,826
那么今年我们正在

115
00:04:23,826 --> 0:04:24,606
添加迁移学习

116
00:04:25,096 --> 0:04:27,086
对于演示 我将

117
00:04:27,086 --> 0:04:28,546
使用名为 Dynamic Embedding 的

118
00:04:28,546 --> 0:04:29,826
此功能提取器

119
00:04:30,156 --> 0:04:32,496
我将在稍后的演示之后

120
00:04:32,496 --> 0:04:33,946
详细介绍

121
00:04:33,946 --> 0:04:35,936
什么是迁移学习

122
00:04:35,936 --> 0:04:37,846
但现在你需要知道的

123
00:04:37,846 --> 0:04:39,256
是用 Dynamic Embedding 进行的迁移学习

124
00:04:39,676 --> 0:04:41,686
它实际上是一种

125
00:04:41,686 --> 0:04:43,096
注重输入文本的

126
00:04:43,096 --> 0:04:45,446
语义含义的算法

127
00:04:47,036 --> 0:04:48,216
我要开始训练数据了

128
00:04:49,346 --> 0:04:50,506
因此 一般来说

129
00:04:50,506 --> 0:04:52,726
迁移学习需要更长的时间来训练

130
00:04:53,516 --> 0:04:54,716
对于这个特定的数据集

131
00:04:55,176 --> 0:04:57,416
在这台特定的机器上

132
00:04:57,416 --> 0:04:58,316
大约需要五分钟

133
00:04:59,376 --> 0:05:01,196
好了 我不会干等着

134
00:04:59,376 --> 0:05:01,196
好了 我不会干等着

135
00:05:02,666 --> 0:05:04,636
相反 我在这里预先选择的

136
00:05:04,966 --> 0:05:07,116
解决方案是在完全相同的数据上

137
00:05:07,116 --> 0:05:08,386
进行训练的

138
00:05:08,956 --> 0:05:12,286
模型一旦经过训练后

139
00:05:12,286 --> 0:05:14,996
精度测试可以很好地

140
00:05:14,996 --> 0:05:16,846
总结你的模型

141
00:05:16,846 --> 0:05:18,786
对不同的数据执行情况如何

142
00:05:18,786 --> 0:05:21,676
分解为不同的类做得如何

143
00:05:22,666 --> 0:05:24,216
看起来我的模型

144
00:05:24,216 --> 0:05:26,246
在训练验证和测试数据方面

145
00:05:26,246 --> 0:05:26,836
做得很好

146
00:05:27,486 --> 0:05:30,446
所以 我将直接跳转到

147
00:05:30,446 --> 0:05:31,196
输出选项卡

148
00:05:31,946 --> 0:05:34,566
此预览窗格给你提供了

149
00:05:34,636 --> 0:05:37,116
有关模型的一些总结

150
00:05:37,116 --> 0:05:38,906
以及一些快速实验的

151
00:05:38,906 --> 0:05:40,506
不同方法

152
00:05:41,286 --> 0:05:44,576
例如 如果你转到右下角

153
00:05:45,246 --> 0:05:47,526
则可以直接添加 File

154
00:05:47,526 --> 0:05:50,166
以进行快速测试

155
00:05:50,336 --> 0:05:56,016
或者 你可以跟踪

156
00:05:56,016 --> 0:05:57,756
模型能够预测该文件夹中

157
00:05:57,756 --> 0:06:00,406
所有文本文件的文件夹

158
00:05:57,756 --> 0:06:00,406
所有文本文件的文件夹

159
00:06:01,256 --> 0:06:02,696
该模型实际上

160
00:06:02,696 --> 0:06:04,856
将使用每个文件中的

161
00:06:04,856 --> 0:06:06,276
整个文本来进行

162
00:06:06,276 --> 0:06:06,776
单个预测

163
00:06:07,306 --> 0:06:10,336
但是还有另一种方法

164
00:06:10,336 --> 0:06:12,416
可以让你进行快速实验

165
00:06:12,826 --> 0:06:13,626
即手动输入

166
00:06:16,446 --> 0:06:19,356
因此 在这个特定的文本输入部分

167
00:06:19,506 --> 0:06:22,066
当你 当我键入每个空格时

168
00:06:22,376 --> 0:06:25,566
或者如果我

169
00:06:25,616 --> 0:06:27,406
停止输入一段时间

170
00:06:27,406 --> 0:06:28,436
模型将进行预测

171
00:06:29,186 --> 0:06:30,966
那么 让我们看看它是如何运作的

172
00:06:33,136 --> 0:06:35,336
真是反败为胜啊

173
00:06:36,076 --> 0:06:40,886
运动类 让我们来试试

174
00:06:40,926 --> 0:06:41,546
不同的东西

175
00:06:42,896 --> 0:06:46,796
本季结局为情节

176
00:06:47,486 --> 0:06:48,966
增添了一丝转折

177
00:06:49,456 --> 0:06:52,076
这似乎刚刚好

178
00:06:52,386 --> 0:06:56,826
娱乐类 [掌声]

179
00:06:57,326 --> 0:06:58,516
我实际上也想尝试

180
00:06:58,516 --> 0:07:00,086
一些更近期和

181
00:06:58,516 --> 0:07:00,086
一些更近期和

182
00:07:00,086 --> 0:07:00,566
更相关的东西

183
00:07:01,006 --> 0:07:03,166
我昨晚才想到这件事

184
00:07:04,266 --> 0:07:15,976
猛龙是联盟总冠军

185
00:07:18,316 --> 0:07:18,796
自然类 [笑声]

186
00:07:20,476 --> 0:07:21,856
好吧 如果我切换语境的话

187
00:07:26,016 --> 0:07:27,096
[掌声]

188
00:07:27,096 --> 0:07:27,946
它也可以预测运动类

189
00:07:28,516 --> 0:07:32,926
[掌声]

190
00:07:33,426 --> 0:07:35,206
好了 我对模型的表现

191
00:07:35,206 --> 0:07:35,966
非常满意

192
00:07:36,766 --> 0:07:38,276
现在我准备好进行布置

193
00:07:38,556 --> 0:07:40,186
所以 我只需将其拖出来

194
00:07:40,536 --> 0:07:42,086
我就可以把它放在

195
00:07:42,146 --> 0:07:42,626
我的 iOS 设备上

196
00:07:51,556 --> 0:07:53,186
这就是你如何使用

197
00:07:53,186 --> 0:07:54,876
迁移学习训练

198
00:07:54,876 --> 0:07:55,146
文本分类器

199
00:07:56,366 --> 0:07:58,286
但你们可能想问

200
00:07:58,286 --> 0:07:59,856
什么是迁移学习

201
00:08:02,196 --> 0:08:03,896
迁移学习是一种功能强大的

202
00:08:03,896 --> 0:08:05,736
机器学习技术

203
00:08:05,736 --> 0:08:07,526
这其中针对一个特定任务的

204
00:08:07,526 --> 0:08:09,516
大量数据训练模型

205
00:08:10,086 --> 0:08:11,936
可以被重新用于另一个任务

206
00:08:11,936 --> 0:08:15,226
因此你们作为开发人员

207
00:08:15,226 --> 0:08:17,226
只需要准备有限数目的数据

208
00:08:17,226 --> 0:08:19,486
并同样可以获得

209
00:08:19,486 --> 0:08:21,256
个性化的机器学习模型

210
00:08:21,706 --> 0:08:25,816
Create ML 如今实际上使用

211
00:08:25,816 --> 0:08:26,646
迁移学习来进行

212
00:08:26,646 --> 0:08:27,866
图像分类

213
00:08:28,326 --> 0:08:31,536
现在我们将它带到文本中

214
00:08:32,426 --> 0:08:34,296
那么 要为文本训练

215
00:08:34,296 --> 0:08:36,866
一个好的迁移学习模型

216
00:08:36,866 --> 0:08:38,256
问题就有点不同了

217
00:08:39,176 --> 0:08:40,796
如果你们读到这句话

218
00:08:41,056 --> 0:08:44,806
“我能把车停在公园入口附近”

219
00:08:46,736 --> 0:08:48,936
对于一个使用传统技术

220
00:08:49,506 --> 0:08:51,776
或研究嵌入

221
00:08:51,776 --> 0:08:54,726
进行训练的模型

222
00:08:54,726 --> 0:08:57,586
这两个部分看起来是完全相同的

223
00:08:57,766 --> 0:08:59,386
但是对于一个使用 Dynamic Embedding 

224
00:08:59,386 --> 0:09:01,036
的迁移学习训练的模型

225
00:08:59,386 --> 0:09:01,036
的迁移学习训练的模型

226
00:09:01,036 --> 0:09:03,706
因为它注重

227
00:09:03,706 --> 0:09:04,916
整个上下文的

228
00:09:04,916 --> 0:09:06,716
语义含义

229
00:09:07,406 --> 0:09:09,826
所以它能够弄清楚

230
00:09:09,826 --> 0:09:11,216
这两个部分实际上意味着

231
00:09:11,216 --> 0:09:12,666
不同的事物

232
00:09:16,136 --> 0:09:18,206
要训练这样好的一个模型

233
00:09:18,206 --> 0:09:19,586
你需要在很多文本上训练

234
00:09:20,056 --> 0:09:21,586
这正是我们所做的

235
00:09:22,566 --> 0:09:26,716
我们对数十亿文本进行了训练

236
00:09:26,876 --> 0:09:28,096
并将这种预先训练的模型

237
00:09:28,096 --> 0:09:29,586
发送到你们的移动设备上去

238
00:09:30,066 --> 0:09:31,956
更重要的是

239
00:09:31,956 --> 0:09:34,446
我们优化了其性能

240
00:09:34,446 --> 0:09:38,316
因此你们只需准备

241
00:09:38,466 --> 0:09:40,126
有限数量的原始文本

242
00:09:40,626 --> 0:09:43,686
将其发送到 Create ML App 上

243
00:09:44,006 --> 0:09:46,286
在它深处 它将与

244
00:09:46,286 --> 0:09:47,736
已经是你们 OS 中

245
00:09:47,736 --> 0:09:50,956
一部分的模型进行交互

246
00:09:50,956 --> 0:09:52,816
并提供自定义文本分类器

247
00:09:55,696 --> 0:09:57,236
而且 你们可以在 iOS 设备上

248
00:09:57,236 --> 0:09:59,116
无缝地部署

249
00:09:59,436 --> 0:10:01,386
相同的模型 因为

250
00:09:59,436 --> 0:10:01,386
相同的模型 因为

251
00:10:01,386 --> 0:10:03,116
预训练模型

252
00:10:03,116 --> 0:10:06,166
已经可供你们使用

253
00:10:06,476 --> 0:10:09,216
好了 这就是使用 Create ML App

254
00:10:09,216 --> 0:10:11,016
训练文本分类器的

255
00:10:11,016 --> 0:10:12,116
工作流程

256
00:10:13,216 --> 0:10:14,816
如果你也想编写代码

257
00:10:15,056 --> 0:10:17,706
那同样会很容易

258
00:10:18,816 --> 0:10:20,106
要使用带 Dynamic Embedding 的

259
00:10:20,106 --> 0:10:22,136
迁移学习

260
00:10:22,136 --> 0:10:23,496
你唯一需要指定的是

261
00:10:23,496 --> 0:10:24,816
此模型参数

262
00:10:25,616 --> 0:10:27,096
其余代码

263
00:10:27,096 --> 0:10:27,976
与去年完全相同

264
00:10:32,986 --> 0:10:35,246
现在 我已经向你们展示了

265
00:10:35,246 --> 0:10:37,756
如何训练文本分类器

266
00:10:37,756 --> 0:10:39,866
但我还想给你们一些简单的提示

267
00:10:39,866 --> 0:10:42,476
以便充分利用你们的文本分类器

268
00:10:45,086 --> 0:10:47,876
现在 选择适合

269
00:10:47,876 --> 0:10:49,206
你们所用例子的算法

270
00:10:50,296 --> 0:10:51,836
迁移学习

271
00:10:51,836 --> 0:10:53,966
只是文本分类器支持的

272
00:10:53,966 --> 0:10:55,256
三种算法之一

273
00:10:57,656 --> 0:10:58,726
不同的算法有

274
00:10:58,806 --> 0:10:59,556
不同的侧重点

275
00:11:00,676 --> 0:11:02,236
要找出哪一个最适合

276
00:11:02,236 --> 0:11:04,596
你的所选例子

277
00:11:04,596 --> 0:11:05,926
请看看这之后举行的

278
00:11:05,926 --> 0:11:10,156
Natural Language 会议

279
00:11:10,346 --> 0:11:11,816
提供均衡的分类

280
00:11:12,196 --> 0:11:13,256
这是非常重要的

281
00:11:14,376 --> 0:11:15,686
在我向你们展示的特定示例中

282
00:11:15,686 --> 0:11:17,606
因为每个文本文件

283
00:11:17,606 --> 0:11:19,756
都是一个训练示例

284
00:11:20,526 --> 0:11:22,076
所以 我大致在每个文件夹中

285
00:11:22,076 --> 0:11:24,646
保留了相同数量的文本文件

286
00:11:28,086 --> 0:11:29,126
数据一致性

287
00:11:29,626 --> 0:11:31,256
如果你希望你的文本分类器

288
00:11:31,256 --> 0:11:33,226
主要用于短句

289
00:11:33,226 --> 0:11:35,876
就像我一样

290
00:11:35,876 --> 0:11:37,336
你的训练数据应该

291
00:11:37,336 --> 0:11:39,026
主要由这些示例组成

292
00:11:39,906 --> 0:11:42,876
如果你希望你的文本分类器

293
00:11:42,876 --> 0:11:44,196
能够处理

294
00:11:44,196 --> 0:11:47,076
几句话 段落 甚至整篇文章

295
00:11:47,076 --> 0:11:49,866
你也需要确保

296
00:11:49,866 --> 0:11:51,236
你的训练数据

297
00:11:51,236 --> 0:11:52,626
同样包括这些例子

298
00:11:53,516 --> 0:11:58,506
[掌声]
