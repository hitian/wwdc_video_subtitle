1
00:00:06,473 --> 0:00:09,710
（用METAL进行光线追踪）

2
00:00:14,982 --> 0:00:15,949
大家早上好

3
00:00:16,250 --> 0:00:19,686
我叫Sean 我是Apple

4
00:00:20,854 --> 0:00:22,890
在这场演讲中我们要讲光线追踪

5
00:00:23,390 --> 0:00:25,325
让我们先回顾一下什么是光线追踪

6
00:00:26,927 --> 0:00:30,063
光线追踪app基于追踪

7
00:00:30,130 --> 0:00:31,331
光线与场景进行交互时所采取的路径

8
00:00:32,432 --> 0:00:34,401
因此光线追踪的app有渲染、

9
00:00:34,768 --> 0:00:36,937
音频、物理模拟等等

10
00:00:37,971 --> 0:00:41,842
特别是光线追踪经常用于

11
00:00:42,142 --> 0:00:44,811
用于模拟单条光线在场景中的反弹

12
00:00:46,079 --> 0:00:49,082
这就允许这些app渲染照片的

13
00:00:49,149 --> 0:00:52,486
折射、阴影、全局照明等等

14
00:00:56,590 --> 0:01:00,127
最近光线追踪已经开始

15
00:00:56,590 --> 0:01:00,127
最近光线追踪已经开始

16
00:01:00,194 --> 0:01:01,295
比如游戏

17
00:01:01,662 --> 0:01:03,730
这实际上引入了一些新需求

18
00:01:05,098 --> 0:01:08,268
首先在实时app中物体要四处移动

19
00:01:08,802 --> 0:01:11,305
因此我们要既支持摄像头

20
00:01:12,940 --> 0:01:15,042
第二性能现在变得更加至关重要了

21
00:01:15,108 --> 0:01:15,943
（实时光线追踪）

22
00:01:16,009 --> 0:01:19,179
这意味着光线交叉自身

23
00:01:19,913 --> 0:01:22,549
并且我们还要高效地使用

24
00:01:23,984 --> 0:01:25,853
因此我们需要当心采样策略、

25
00:01:25,919 --> 0:01:27,654
随机数生成等等

26
00:01:29,590 --> 0:01:31,358
最后即使使用这些技术

27
00:01:31,425 --> 0:01:33,760
我们也不能投射足够的光线

28
00:01:34,461 --> 0:01:36,530
因此我们需要一个复杂的

29
00:01:37,531 --> 0:01:41,535
幸运的是Metal内嵌

30
00:01:41,869 --> 0:01:42,970
这样就容易多了

31
00:01:44,004 --> 0:01:46,106
首先让我们回顾一下光线追踪

32
00:01:46,607 --> 0:01:48,542
然后我们继续了解一些更先进的话题

33
00:01:50,677 --> 0:01:52,679
如果你看一下典型的光线追踪app

34
00:01:53,046 --> 0:01:54,681
它们都遵循一个大致相同的大纲

35
00:01:55,716 --> 0:01:56,950
首先我们生成一些光线

36
00:01:57,684 --> 0:02:00,587
每条光线都由它的起点和方向矢量

37
00:01:57,684 --> 0:02:00,587
每条光线都由它的起点和方向矢量

38
00:02:01,889 --> 0:02:04,625
然后那些光线在场景中的几何图形上

39
00:02:04,691 --> 0:02:06,026
这通常会构成三角形

40
00:02:07,194 --> 0:02:10,097
交叉数据可以是到交叉点的距离

41
00:02:10,364 --> 0:02:12,232
但一般包含额外数据

42
00:02:12,299 --> 0:02:14,067
比如被击中的三角的索引

43
00:02:14,501 --> 0:02:16,737
以及交叉点的中心坐标

44
00:02:19,006 --> 0:02:20,908
下一步将使用交叉点结果

45
00:02:21,175 --> 0:02:22,876
比如在渲染app中

46
00:02:23,243 --> 0:02:25,746
这一般是着色过程 输出一张图片

47
00:02:26,680 --> 0:02:28,815
这个步骤可能也生成额外光线

48
00:02:29,183 --> 0:02:32,219
然后我们就重复这个过程

49
00:02:34,254 --> 0:02:36,490
app的每一帧的场景中

50
00:02:36,557 --> 0:02:37,724
一般都交叉无数条光线

51
00:02:38,792 --> 0:02:42,196
并且这个核心交叉步骤对于所有

52
00:02:42,996 --> 0:02:45,699
因此我们在Metal中加速了这个

53
00:02:47,568 --> 0:02:50,637
去年我们引入了

54
00:02:51,238 --> 0:02:53,473
它是Metal性能着色器框架的

55
00:02:54,308 --> 0:02:57,311
这个API在我们所有的

56
00:02:57,744 --> 0:02:59,346
加速GPU上的光线交叉

57
00:03:00,414 --> 0:03:02,616
我们在去年的演讲中

58
00:03:02,683 --> 0:03:05,519
我们推荐你们参考去年的这场演讲

59
00:03:06,587 --> 0:03:10,190
从高层级上说API通过Metal

60
00:03:11,024 --> 0:03:13,160
它查找每条光线上最近的交叉点

61
00:03:13,427 --> 0:03:15,062
并把结果返回到另一个缓冲区中

62
00:03:16,997 --> 0:03:19,633
所有这些操作都被编码到

63
00:03:20,000 --> 0:03:22,936
就是你在app中

64
00:03:24,905 --> 0:03:26,874
许多加速都来自于创建一种

65
00:03:26,940 --> 0:03:28,442
叫做加速结构的数据结构

66
00:03:29,243 --> 0:03:32,045
这种数据结构在空间中递归地

67
00:03:33,080 --> 0:03:35,682
从而我们可以在交叉搜索过程中

68
00:03:35,749 --> 0:03:38,151
迅速消除不可能与给定光线

69
00:03:40,254 --> 0:03:42,456
Metal会替你创建这种数据结构

70
00:03:42,856 --> 0:03:44,057
你所要做的就是指定

71
00:03:44,124 --> 0:03:46,193
何时创建加速结构

72
00:03:46,527 --> 0:03:49,062
再把它传给intersector

73
00:03:50,764 --> 0:03:53,166
现在创建这种数据结构一般是

74
00:03:53,233 --> 0:03:54,434
在app启动时的固定消耗

75
00:03:55,669 --> 0:03:57,237
在去年的API版本中

76
00:03:57,304 --> 0:03:59,306
总是在CPU上创建这种数据结构

77
00:04:00,107 --> 0:04:02,442
今年我们把加速结构的创建

78
00:04:02,709 --> 0:04:03,777
移到了GPU上

79
00:04:03,844 --> 0:04:06,079
这样可以极大地减少启动消耗

80
00:04:06,713 --> 0:04:09,650
更好的是 无论何时只要可能的话

81
00:04:10,184 --> 0:04:12,953
因此你不需要做任何事

82
00:04:14,488 --> 0:04:17,324
现在让我们回顾一下典型的

83
00:04:17,391 --> 0:04:20,360
看看我们需要执行哪些操作才能把它

84
00:04:22,329 --> 0:04:24,198
正如我所说过的 我们先生成光线

85
00:04:24,898 --> 0:04:27,000
这一般是使用计算内核完成

86
00:04:27,067 --> 0:04:28,869
但也可以从片段着色器中实现

87
00:04:29,236 --> 0:04:31,572
或可以写入Metal缓冲区的

88
00:04:32,673 --> 0:04:34,575
然后我们把光线缓冲区传给

89
00:04:35,709 --> 0:04:36,844
它会查找交叉

90
00:04:37,211 --> 0:04:39,112
并把结果返回到我们的交叉缓冲区中

91
00:04:40,013 --> 0:04:41,615
请记住 要使用

92
00:04:41,949 --> 0:04:43,750
我们需要提供一个加速结构

93
00:04:44,451 --> 0:04:47,120
我们通常只需要创建一次

94
00:04:48,589 --> 0:04:50,791
最后我们要启动最后一个计算内核

95
00:04:51,291 --> 0:04:55,028
它将使用交叉数据

96
00:04:56,029 --> 0:04:57,197
并且在迭代的app中

97
00:04:57,264 --> 0:05:00,801
这个计算内核还会把额外光线

98
00:04:57,264 --> 0:05:00,801
这个计算内核还会把额外光线

99
00:05:02,336 --> 0:05:04,271
让我们在一个实际的app中看一下

100
00:05:05,606 --> 0:05:08,342
在这个例子中 我们要讲

101
00:05:08,408 --> 0:05:09,543
如何在AR Quick Look

102
00:05:10,177 --> 0:05:11,879
AR Quick Look

103
00:05:11,945 --> 0:05:14,848
可以让你在增强现实中预览3D资产

104
00:05:15,983 --> 0:05:18,452
我们在今早的演讲中具体讲了

105
00:05:18,519 --> 0:05:20,354
我也推荐你们观看那场演讲

106
00:05:21,154 --> 0:05:23,257
在本场演讲中 我们主要讲

107
00:05:23,323 --> 0:05:26,093
如何使用光线追踪来渲染

108
00:05:27,160 --> 0:05:29,763
我们稍后再具体讲环境光遮蔽

109
00:05:29,830 --> 0:05:31,999
你需要了解环境光遮蔽

110
00:05:32,065 --> 0:05:35,736
计算一个近似值 即有多少光可以

111
00:05:36,703 --> 0:05:39,540
这导致机器人模型下的地面变暗

112
00:05:39,873 --> 0:05:43,143
以及机器人的腿和地面之间的

113
00:05:45,112 --> 0:05:47,314
效果有点微不足道

114
00:05:47,381 --> 0:05:48,949
我们可以看到它实际上花了很久

115
00:05:49,016 --> 0:05:50,617
才把机器人放在场景中的地面上

116
00:05:51,318 --> 0:05:53,453
这对于AR app来说非常重要

117
00:05:53,854 --> 0:05:56,623
可以防止物体看起来像是漂浮在

118
00:05:58,859 --> 0:06:00,494
在去年的

119
00:05:58,859 --> 0:06:00,494
在去年的

120
00:06:00,561 --> 0:06:02,196
阴影实际上是预先计算的

121
00:06:02,696 --> 0:06:04,531
因此它们不会随着物体的移动而移动

122
00:06:06,300 --> 0:06:09,336
今年我们使用了

123
00:06:09,403 --> 0:06:10,938
对这些阴影进行实时渲染

124
00:06:11,505 --> 0:06:14,174
因此现在随着物体的移动

125
00:06:16,310 --> 0:06:19,246
这甚至对于变形的物体也起作用

126
00:06:19,746 --> 0:06:21,882
我们可以看到阴影

127
00:06:21,949 --> 0:06:23,250
随着鱼在场景中的游动而移动

128
00:06:26,320 --> 0:06:28,856
正在发生的有三种类型的动画

129
00:06:29,623 --> 0:06:31,258
如果我们只使用光栅化程序

130
00:06:31,325 --> 0:06:33,460
我们可以在三角的新位置上

131
00:06:33,527 --> 0:06:34,361
（动态场景）

132
00:06:34,428 --> 0:06:35,796
但因为我们使用了光线追踪

133
00:06:35,863 --> 0:06:37,798
我们需要维持加速结构

134
00:06:39,299 --> 0:06:41,702
因此动画的第一种类型是简单的

135
00:06:41,969 --> 0:06:44,404
这种移动是由于

136
00:06:45,506 --> 0:06:47,241
我们不需要更新加速结构

137
00:06:47,307 --> 0:06:48,642
仅仅因为摄像头移动了

138
00:06:48,942 --> 0:06:50,911
因此我们实际上是免费获得了

139
00:06:51,678 --> 0:06:54,014
我们可以开始从新摄像头的位置上

140
00:06:55,349 --> 0:06:56,483
其它两种动画类型

141
00:06:56,550 --> 0:06:58,485
都要求更新加速结构

142
00:06:59,887 --> 0:07:01,388
第一种是顶点动画

143
00:06:59,887 --> 0:07:01,388
第一种是顶点动画

144
00:07:02,256 --> 0:07:04,191
这可以是蒙皮模型 比如鱼

145
00:07:04,258 --> 0:07:06,393
但也可以是风中摇曳的植物、

146
00:07:06,460 --> 0:07:08,395
衣服或其它变形类型

147
00:07:09,363 --> 0:07:12,199
Metal包含一种特殊的加速结构

148
00:07:12,266 --> 0:07:13,600
针对这样的类进行了优化

149
00:07:15,402 --> 0:07:17,504
最后一种动画类型是刚体动画

150
00:07:18,405 --> 0:07:20,974
物体可以移动、旋转和缩放

151
00:07:21,041 --> 0:07:22,910
但完全维持它们的形状

152
00:07:23,710 --> 0:07:26,680
因此一大部分加速结构实际上

153
00:07:27,347 --> 0:07:29,416
Metal还包含一种特殊机制

154
00:07:29,483 --> 0:07:32,319
用于重新利用

155
00:07:33,554 --> 0:07:35,255
首先让我们讲一下顶点动画

156
00:07:35,322 --> 0:07:36,623
（顶点动画）

157
00:07:36,690 --> 0:07:37,891
随着几何图形的变更

158
00:07:37,958 --> 0:07:39,760
我们需要更新加速结构

159
00:07:40,661 --> 0:07:42,729
我们要给每一帧从头开始

160
00:07:42,796 --> 0:07:43,997
但我们实际上可以做的更好

161
00:07:45,432 --> 0:07:47,167
在顶点动画用例中

162
00:07:47,467 --> 0:07:49,303
物体往往保持大体形状

163
00:07:49,736 --> 0:07:52,339
比如角色的手将保持与胳膊相连接

164
00:07:52,573 --> 0:07:54,875
他们的胳膊将保持与身体相连接等等

165
00:07:55,776 --> 0:07:58,946
因此编码到加速结构中的空间谱系

166
00:07:59,246 --> 0:08:00,447
大部分仍然有效

167
00:07:59,246 --> 0:08:00,447
大部分仍然有效

168
00:08:00,881 --> 0:08:02,850
只需要调整到新几何图形即可

169
00:08:03,750 --> 0:08:04,718
让我们看一个例子

170
00:08:06,086 --> 0:08:08,188
这是我们之前看到过的加速结构

171
00:08:09,356 --> 0:08:10,457
如果三角移动

172
00:08:10,524 --> 0:08:13,193
我们可以看到边界区域

173
00:08:13,894 --> 0:08:16,230
但树形结构自身绝大部分仍然有意义

174
00:08:16,930 --> 0:08:18,599
因此我们与其从头重新创建加速结构

175
00:08:18,665 --> 0:08:21,702
不如把边界区域对齐到三角的新位置

176
00:08:21,768 --> 0:08:22,736
从底部到顶部

177
00:08:24,505 --> 0:08:25,973
我们把这个操作叫做再安置

178
00:08:26,874 --> 0:08:29,676
我们可以看到

179
00:08:30,244 --> 0:08:32,312
但比从头开始创建要快多了

180
00:08:32,379 --> 0:08:34,114
因为我们可以重新使用现有的

181
00:08:35,916 --> 0:08:37,683
这也是完全在GPU上运行的

182
00:08:38,051 --> 0:08:39,318
从而让这个过程变得更快了

183
00:08:39,385 --> 0:08:42,289
但也意味着我们可以安全地编码

184
00:08:42,356 --> 0:08:45,526
在比如说计算内核更新顶点之后

185
00:08:47,394 --> 0:08:49,863
坏消息是我们不能添加或移除

186
00:08:49,930 --> 0:08:52,599
因为树形结构仍将编码

187
00:08:54,568 --> 0:08:57,371
这还潜在地降低了加速结构的品质

188
00:08:57,437 --> 0:08:59,139
那可能会影响光线追踪的性能

189
00:08:59,973 --> 0:09:02,242
这是因为三角形最初是使用一套

190
00:08:59,973 --> 0:09:02,242
这是因为三角形最初是使用一套

191
00:09:02,309 --> 0:09:05,479
在三角移动之后不会进行加速

192
00:09:06,780 --> 0:09:08,148
影响通常都很微小

193
00:09:08,215 --> 0:09:11,818
但极端情况下 比如远距离传送

194
00:09:12,686 --> 0:09:15,189
尽管如此 这对于典型的变形用例

195
00:09:15,255 --> 0:09:16,790
和角色蒙皮用例来说非常棒

196
00:09:17,724 --> 0:09:18,926
让我们看一下如何在代码中进行设置

197
00:09:20,494 --> 0:09:22,596
首先在我们创建加速结构之前

198
00:09:22,663 --> 0:09:24,331
我们需要先启动对重新安置的支持

199
00:09:24,998 --> 0:09:26,767
请注意仅仅启动重新安置

200
00:09:26,834 --> 0:09:29,136
就已经可能会降低加速结构的品质了

201
00:09:29,636 --> 0:09:31,071
因此如果你真的需要再安置加速结构

202
00:09:31,138 --> 0:09:33,106
请一定要开启这个功能

203
00:09:33,173 --> 0:09:34,508
（再安置）

204
00:09:34,575 --> 0:09:37,578
然后我们把encodeRefit调用到

205
00:09:38,946 --> 0:09:40,814
对于顶点动画来说

206
00:09:41,715 --> 0:09:43,951
接下来我们讲刚体动画

207
00:09:45,385 --> 0:09:46,320
正如它的名字所暗示的那样

208
00:09:46,386 --> 0:09:49,189
在这种动画中 物体可以移动、

209
00:09:49,256 --> 0:09:51,225
但要完全维持它们的形状

210
00:09:51,959 --> 0:09:53,393
在右侧的例子中

211
00:09:53,460 --> 0:09:55,295
即使机器人看起来正在变形

212
00:09:55,362 --> 0:09:57,464
实际上它所有的关节都在僵硬地移动

213
00:09:57,831 --> 0:10:00,067
这也是一个刚体动画的例子

214
00:09:57,831 --> 0:10:00,067
这也是一个刚体动画的例子

215
00:10:01,401 --> 0:10:02,469
在一个典型场景中

216
00:10:02,536 --> 0:10:04,972
大部分几何图形很可能只是

217
00:10:05,606 --> 0:10:08,342
事实上大部分几何图形很可能

218
00:10:10,010 --> 0:10:13,013
我们还可以在场景中多次复制

219
00:10:13,914 --> 0:10:16,483
在加速结构中多次复制这些物体

220
00:10:16,550 --> 0:10:17,885
消耗很大

221
00:10:18,352 --> 0:10:20,554
仅仅因为几何图形的一部分

222
00:10:20,621 --> 0:10:22,122
就再安置或重建整个加速结构

223
00:10:22,456 --> 0:10:24,491
效率也很低

224
00:10:25,993 --> 0:10:27,461
因此为了解决这两个问题

225
00:10:27,528 --> 0:10:29,930
我们可以使用一种叫做

226
00:10:32,432 --> 0:10:33,600
我们要做的就是首先

227
00:10:33,667 --> 0:10:35,802
给场景中的每个唯一物体

228
00:10:35,869 --> 0:10:37,671
创建一个高品质的三角加速结构

229
00:10:37,738 --> 0:10:39,873
我们只需要在app启动时

230
00:10:41,441 --> 0:10:43,243
然后我们要使用第二加速结构

231
00:10:43,710 --> 0:10:47,214
两次复制那些三角加速结构

232
00:10:48,015 --> 0:10:49,850
每次复制

233
00:10:49,917 --> 0:10:52,252
都是原始三角加速结构的一个实例

234
00:10:53,887 --> 0:10:56,290
每个实例都与一个转换矩阵相关联

235
00:10:57,124 --> 0:10:58,792
描述要把它放在场景中的哪个位置

236
00:10:59,760 --> 0:11:01,428
我们使用两个缓冲区来实现

237
00:10:59,760 --> 0:11:01,428
我们使用两个缓冲区来实现

238
00:11:01,495 --> 0:11:04,464
每个缓冲区都包含场景中

239
00:11:05,832 --> 0:11:08,035
第一个缓冲区包含

240
00:11:08,101 --> 0:11:09,203
所有实例的转换矩阵

241
00:11:10,404 --> 0:11:12,472
第二个缓冲区包含

242
00:11:12,539 --> 0:11:14,875
对三角加速结构数组的索引

243
00:11:15,209 --> 0:11:18,078
描述每个实例使用哪个加速结构

244
00:11:20,414 --> 0:11:22,516
然后我们要在场景中的实例上

245
00:11:22,583 --> 0:11:24,451
创建第二加速结构

246
00:11:25,586 --> 0:11:28,488
然后随着物体的移动

247
00:11:28,555 --> 0:11:29,623
我们只需要快速重建实例的

248
00:11:30,557 --> 0:11:31,725
让我们看一下如何进行设置

249
00:11:32,926 --> 0:11:35,529
首先我们要创建一个

250
00:11:36,396 --> 0:11:38,565
实例的等级中的所有加速结构

251
00:11:38,632 --> 0:11:39,833
都必须属于同一个群组

252
00:11:40,267 --> 0:11:42,336
这就允许它们在内部分享资源

253
00:11:43,971 --> 0:11:47,007
接下来我们要创建一个数组

254
00:11:47,908 --> 0:11:50,711
最后我们要循环场景中的

255
00:11:51,111 --> 0:11:53,447
给每个唯一物体都创建一个

256
00:11:53,514 --> 0:11:54,982
并在结束时把它们添加到数组中

257
00:11:57,251 --> 0:11:59,853
我们现在已经准备好创建

258
00:12:00,187 --> 0:12:03,423
我们通过使用NPSInstance

259
00:12:04,358 --> 0:12:07,361
先附加我们的三角加速结构数组

260
00:12:08,128 --> 0:12:10,130
以及我之前讲过的两个缓冲区

261
00:12:10,931 --> 0:12:13,767
最后我们要指定场景中的实例的编号

262
00:12:15,369 --> 0:12:18,005
然后无论何时当物体移动时

263
00:12:18,071 --> 0:12:19,239
或场景中增加或移除一个物体时

264
00:12:19,706 --> 0:12:22,242
我们可以使用实例加速结构

265
00:12:23,243 --> 0:12:25,379
一般来说这种加速结构

266
00:12:25,445 --> 0:12:27,047
比三角加速结构要小多了

267
00:12:27,381 --> 0:12:28,849
我们可以给每一帧都执行这种操作

268
00:12:29,316 --> 0:12:31,051
请注意 与再安置类似

269
00:12:31,118 --> 0:12:33,053
当使用实例时有一些消耗

270
00:12:33,720 --> 0:12:36,456
因此如果你的场景仅有一个物体

271
00:12:36,523 --> 0:12:38,392
或特别是如果没有物体发生移动

272
00:12:38,792 --> 0:12:42,162
可能值得把那些物体放到单个

273
00:12:43,030 --> 0:12:44,598
这将增加你的内存占用

274
00:12:44,665 --> 0:12:46,967
但也会回馈给你更好的性能

275
00:12:47,668 --> 0:12:50,537
因此你需要进行试验来找到

276
00:12:52,239 --> 0:12:53,540
那么这就是动态场景

277
00:12:53,841 --> 0:12:56,076
我们讲了如何使用再安置

278
00:12:56,143 --> 0:12:57,177
支持顶点动画和蒙皮动画

279
00:12:57,678 --> 0:12:59,513
以及如何使用二级加速结构

280
00:12:59,580 --> 0:13:01,381
支持刚体动画

281
00:12:59,580 --> 0:13:01,381
支持刚体动画

282
00:13:02,249 --> 0:13:04,618
接下来我们谈谈降噪

283
00:13:07,287 --> 0:13:09,890
目前我们所看到的所有图片

284
00:13:10,390 --> 0:13:12,793
那是因为它们都使用了降噪过滤器

285
00:13:13,727 --> 0:13:14,661
如果我们把它关掉

286
00:13:14,728 --> 0:13:17,197
我们可以看到如果没有降噪程序

287
00:13:17,898 --> 0:13:20,901
我们可以看到这些图片如果用在

288
00:13:21,568 --> 0:13:23,971
那是因为我们仅对每个像素使用了

289
00:13:25,272 --> 0:13:27,307
通常我们会随时间

290
00:13:27,374 --> 0:13:28,542
一起平均更多的样本来解决

291
00:13:28,976 --> 0:13:30,777
但如果摄像头或物体正在移动

292
00:13:30,844 --> 0:13:31,945
就没有那么简单了

293
00:13:32,613 --> 0:13:35,916
幸运的是Metal现在包含

294
00:13:36,783 --> 0:13:37,751
让我们看看它是如何运作的

295
00:13:39,186 --> 0:13:42,155
理想情况是我们可以轻松地

296
00:13:42,222 --> 0:13:43,290
使用渲染器输出噪声图像

297
00:13:43,357 --> 0:13:45,592
通过降噪器运行它并返回一张

298
00:13:46,293 --> 0:13:49,196
在实践中

299
00:13:50,397 --> 0:13:52,199
我们从提供直接可见的

300
00:13:52,266 --> 0:13:53,667
几何图形的深度和法线开始

301
00:13:54,401 --> 0:13:56,603
许多渲染器周围都有这样的纹理

302
00:13:56,904 --> 0:13:58,438
如果没有 那也很容易生成

303
00:14:00,107 --> 0:14:02,576
然后降噪器将运行一堆图像处理操作

304
00:14:02,643 --> 0:14:03,810
并输入一个较干净的图片

305
00:14:04,411 --> 0:14:06,780
但因为我们的起点是每个像素仅有的

306
00:14:06,847 --> 0:14:08,315
因此最后得到的图片仍会有一些噪声

307
00:14:09,016 --> 0:14:12,286
因此我们要重新查看在多个帧上

308
00:14:13,754 --> 0:14:16,690
我们首先要留出干净的图片

309
00:14:17,791 --> 0:14:19,660
我们还要留出深度和法线

310
00:14:19,726 --> 0:14:21,261
从而我们可以与下一帧中的

311
00:14:22,262 --> 0:14:24,498
最后我们要提供一个动作矢量纹理

312
00:14:24,765 --> 0:14:27,434
描述每个像素在帧之间移动了多少

313
00:14:29,603 --> 0:14:31,672
在下一帧中 降噪器将穿过

314
00:14:31,738 --> 0:14:34,074
所有纹理并产生一张更好的图片

315
00:14:34,808 --> 0:14:36,877
这个图片将随时间变得更好

316
00:14:37,177 --> 0:14:38,645
即使摄像头或物体移动了也一样

317
00:14:40,080 --> 0:14:42,683
降噪器将使用深度和法线来检测

318
00:14:43,016 --> 0:14:45,152
像素的历史记录是否

319
00:14:45,586 --> 0:14:47,588
由于物体移动或物体被阻碍

320
00:14:49,289 --> 0:14:52,426
这些都要使用MPSSVGF类家族

321
00:14:53,827 --> 0:14:56,697
这是对很流行的

322
00:14:57,431 --> 0:14:59,499
这个算法在高品质

323
00:14:59,566 --> 0:15:00,734
和实时性能之间做出很好的权衡

324
00:14:59,566 --> 0:15:00,734
和实时性能之间做出很好的权衡

325
00:15:01,902 --> 0:15:03,770
因此降噪的整个过程

326
00:15:03,837 --> 0:15:06,206
都由MPSSVGFDenoiser类调节

327
00:15:07,241 --> 0:15:11,245
与此同时还使用MPSSVGF类

328
00:15:12,246 --> 0:15:14,314
这个类提供单一计算内核

329
00:15:14,381 --> 0:15:15,415
供降噪器使用

330
00:15:15,682 --> 0:15:17,918
并暴露许多参数 你可以用于调整

331
00:15:17,985 --> 0:15:19,319
app中的降噪处理

332
00:15:20,087 --> 0:15:22,222
你只需要直接调用这个类的方法

333
00:15:22,289 --> 0:15:23,624
就可以创建一个自定义降噪器

334
00:15:25,225 --> 0:15:26,260
降噪器

335
00:15:26,326 --> 0:15:28,262
在降噪过程中

336
00:15:28,328 --> 0:15:29,663
创建并销毁相当多的临时纹理

337
00:15:30,297 --> 0:15:33,000
因此MPSSVGF纹理分配器协议

338
00:15:33,367 --> 0:15:35,302
充当了这些内存分配的缓存

339
00:15:36,603 --> 0:15:38,438
你可以使用默认实施

340
00:15:38,705 --> 0:15:41,909
或自己实施这个协议

341
00:15:43,343 --> 0:15:46,580
一般来说 我们会对所有

342
00:15:47,614 --> 0:15:50,517
降噪器可以同时处理两张独立的图片

343
00:15:50,984 --> 0:15:54,087
比如你可能想把直接和间接照明

344
00:15:54,154 --> 0:15:55,189
分到不同的纹理中

345
00:15:56,089 --> 0:15:58,425
还有单个通道纹理的快速路径

346
00:15:58,492 --> 0:16:00,727
比如环境光遮蔽或阴影纹理

347
00:15:58,492 --> 0:16:00,727
比如环境光遮蔽或阴影纹理

348
00:16:00,794 --> 0:16:03,197
这比降噪一张完整的

349
00:16:04,264 --> 0:16:05,365
让我们看看该如何创建快速路径

350
00:16:06,700 --> 0:16:09,336
首先我们要创建MPSSVGF物体

351
00:16:09,403 --> 0:16:10,637
并配置其属性

352
00:16:11,238 --> 0:16:13,841
我们所要提供的就是

353
00:16:15,576 --> 0:16:17,211
接下来我们要创建

354
00:16:17,277 --> 0:16:19,379
在这个例子中我们仅使用默认实施

355
00:16:20,614 --> 0:16:23,083
最后我们要创建高级降噪器对象

356
00:16:23,150 --> 0:16:24,852
管理降噪过程

357
00:16:26,186 --> 0:16:27,721
现在我们已经准备好执行降噪了

358
00:16:28,255 --> 0:16:30,858
我们先给降噪器附加全部的输入纹理

359
00:16:31,592 --> 0:16:33,794
现在我们把整个降噪进程编码到

360
00:16:33,861 --> 0:16:35,195
Metal commandBuffer中

361
00:16:35,929 --> 0:16:38,465
最后我们可以从降噪器中取回

362
00:16:39,533 --> 0:16:42,102
这就是给app启动降噪过程

363
00:16:44,137 --> 0:16:46,173
目前我们讲了Metal中

364
00:16:46,240 --> 0:16:48,308
用于光线追踪和降噪的所有基本知识

365
00:16:49,142 --> 0:16:51,812
我们回顾了如何使用

366
00:16:52,145 --> 0:16:54,081
执行基本的光线/三角交叉测试

367
00:16:54,982 --> 0:16:57,251
然后我们讲了如何使用再安置

368
00:16:57,317 --> 0:17:00,020
把这个测试扩展到动态场景中

369
00:16:57,317 --> 0:17:00,020
把这个测试扩展到动态场景中

370
00:17:00,921 --> 0:17:03,123
最后我们讲了如何使用

371
00:17:03,190 --> 0:17:05,959
移除图片中的噪声

372
00:17:07,194 --> 0:17:09,329
不要担心信息量太大

373
00:17:09,396 --> 0:17:10,396
我们编写了一个样本

374
00:17:10,464 --> 0:17:12,432
演示如何使用所有这些概念

375
00:17:12,499 --> 0:17:13,634
这个样本在线可用

376
00:17:15,169 --> 0:17:17,771
我之前提到过我们需要注意性能

377
00:17:17,838 --> 0:17:19,173
特别是在实时情况下

378
00:17:19,705 --> 0:17:21,407
因此接下来我要邀请我同事

379
00:17:21,808 --> 0:17:24,211
介绍如何在满足

380
00:17:24,478 --> 0:17:25,746
在实际设备上实现这些功能

381
00:17:31,985 --> 0:17:32,953
大家好

382
00:17:33,720 --> 0:17:36,023
在这部分的演讲中

383
00:17:36,089 --> 0:17:38,358
我要讲的是如何使用

384
00:17:38,425 --> 0:17:39,493
Metal中的光线追踪功能

385
00:17:39,993 --> 0:17:43,197
在你的app中实施一些不同的

386
00:17:44,298 --> 0:17:46,934
特别是我主要讲软硬阴影、

387
00:17:47,467 --> 0:17:49,703
环境光遮蔽和全局照明

388
00:17:51,505 --> 0:17:52,840
先从硬阴影开始讲

389
00:17:53,974 --> 0:17:55,809
我们用光线追踪

390
00:17:55,876 --> 0:17:57,744
让表面上的点

391
00:17:57,811 --> 0:17:59,980
朝着太阳的方向形成光线

392
00:18:01,348 --> 0:18:02,549
如果某条光线击中了某个东西

393
00:18:02,616 --> 0:18:04,251
那么相关联的点就处于阴影中

394
00:18:04,918 --> 0:18:06,453
反之就处于太阳光下

395
00:18:08,388 --> 0:18:11,425
要把硬阴影集成到现有app中

396
00:18:11,725 --> 0:18:14,461
我假设你已经有了这样一个东西

397
00:18:15,095 --> 0:18:16,430
你已经栅格化一个G-Buffer

398
00:18:16,897 --> 0:18:18,432
并对照明运行了计算过程

399
00:18:18,832 --> 0:18:21,034
它的输出就是你最终得到的

400
00:18:22,836 --> 0:18:25,005
要利用光线追踪

401
00:18:25,072 --> 0:18:26,640
在这里我们先获取G-Buffer

402
00:18:27,040 --> 0:18:29,443
然后运行一个计算着色器

403
00:18:30,844 --> 0:18:32,513
然后我们把那些光线

404
00:18:32,579 --> 0:18:34,448
以一种加速结构进行交叉

405
00:18:35,082 --> 0:18:37,551
Metal将把结果输出到一个

406
00:18:38,852 --> 0:18:40,954
现在你可以在着色内核中使用

407
00:18:41,021 --> 0:18:43,023
用于决定表面的点是否处于阴影中

408
00:18:44,858 --> 0:18:47,928
我想让你们重点关注的是光线生成

409
00:18:48,762 --> 0:18:52,165
让我们快速回顾一下Metal中

410
00:18:54,368 --> 0:18:57,037
Metal提供一些不同的光线结构

411
00:18:57,471 --> 0:19:00,340
至少包含光线原点

412
00:18:57,471 --> 0:19:00,340
至少包含光线原点

413
00:19:00,407 --> 0:19:01,575
和光线方向的字段

414
00:19:02,776 --> 0:19:05,779
你只需要给你想要追踪的每条光线

415
00:19:05,846 --> 0:19:07,314
并把这种结构写入光线缓冲区即可

416
00:19:10,017 --> 0:19:12,653
你在光线缓冲区中安排光线的方式

417
00:19:13,153 --> 0:19:14,555
对性能有影响

418
00:19:15,556 --> 0:19:16,890
通常你可能像这样开始

419
00:19:17,257 --> 0:19:18,692
我们以线性次序调用这行

420
00:19:20,627 --> 0:19:24,064
这里的问题是随着Metal

421
00:19:24,531 --> 0:19:27,935
光线可能会击中

422
00:19:28,001 --> 0:19:30,103
内部数据结构中不同的节点

423
00:19:31,371 --> 0:19:33,841
这反过来可能会刷新底层硬件缓存

424
00:19:35,709 --> 0:19:38,378
因此更好的方式是使用像素块

425
00:19:39,746 --> 0:19:41,548
因此来自屏幕上相邻像素的光线

426
00:19:41,615 --> 0:19:44,251
可以击中加速结构的同一个部分

427
00:19:44,985 --> 0:19:46,720
并像这样存储光线

428
00:19:46,787 --> 0:19:49,356
让Metal更高效地驱动硬件

429
00:19:50,991 --> 0:19:54,561
在这里的可视化中我要给你演示

430
00:19:55,162 --> 0:19:57,464
在实践中我们发现8乘8尺寸

431
00:20:00,200 --> 0:20:03,504
因此优化光线存储

432
00:20:03,804 --> 0:20:07,341
但如果可能的话

433
00:20:09,243 --> 0:20:10,644
在阴影情境中

434
00:20:11,144 --> 0:20:12,546
你想要这样做的原因可能是

435
00:20:12,613 --> 0:20:14,781
并不是所有的像素都需要阴影光线

436
00:20:15,749 --> 0:20:18,485
比如背景上的像素

437
00:20:18,552 --> 0:20:20,654
或背向太阳的表面上的像素

438
00:20:22,756 --> 0:20:25,993
你的光线缓冲区很可能包含一种

439
00:20:26,059 --> 0:20:27,494
应用于屏幕上的每一个像素

440
00:20:28,228 --> 0:20:30,364
我们需要的是一种方法

441
00:20:30,430 --> 0:20:33,333
告诉Metal跳过我们毫不在乎的

442
00:20:34,801 --> 0:20:36,103
有几种方法可以实现

443
00:20:36,537 --> 0:20:37,838
我在这里要给你们展示的方式是

444
00:20:37,905 --> 0:20:40,641
把光线结构中的

445
00:20:41,008 --> 0:20:42,075
设为一个负值

446
00:20:44,344 --> 0:20:46,613
这就是你需要了解的

447
00:20:47,581 --> 0:20:49,917
你可以看到

448
00:20:50,217 --> 0:20:52,252
阴影非常清晰并且非常精确

449
00:20:54,354 --> 0:20:56,990
但在现实中

450
00:20:57,925 --> 0:20:59,259
看起来不那么尖锐…

451
00:20:59,993 --> 0:21:01,061
它们看起来可能更像是这样的效果

452
00:20:59,993 --> 0:21:01,061
它们看起来可能更像是这样的效果

453
00:21:01,795 --> 0:21:04,798
它们的边界比较柔和

454
00:21:06,233 --> 0:21:08,635
你可以在左侧看到一个很棒的例子

455
00:21:09,403 --> 0:21:11,839
灯柱的阴影在底座处是硬的

456
00:21:11,905 --> 0:21:14,341
随着到地面距离的增加

457
00:21:16,276 --> 0:21:17,811
要使用光线追踪

458
00:21:18,178 --> 0:21:20,681
我们不采用我刚才展示过的平行光线

459
00:21:21,081 --> 0:21:23,483
而是延伸椎体

460
00:21:23,750 --> 0:21:24,885
从表面点一直延伸到太阳

461
00:21:26,420 --> 0:21:29,189
然后在这个椎体内随机生成一些

462
00:21:31,291 --> 0:21:33,827
现在你可以看到一些光线交叉

463
00:21:33,894 --> 0:21:34,995
而一些不交叉

464
00:21:35,262 --> 0:21:37,998
就是这个比率控制着阴影的柔和度

465
00:21:39,933 --> 0:21:41,201
看起来就像是这样

466
00:21:43,237 --> 0:21:45,939
我在这里所展示的是

467
00:21:46,473 --> 0:21:48,008
通过每个像素一条光线来追踪光线

468
00:21:49,276 --> 0:21:53,780
在这个图片中 所有其它效果

469
00:21:54,448 --> 0:21:56,917
都被禁用了

470
00:21:58,752 --> 0:22:01,388
你可以看到结果是非常非常嘈杂的

471
00:21:58,752 --> 0:22:01,388
你可以看到结果是非常非常嘈杂的

472
00:22:03,624 --> 0:22:06,360
为了解决这个问题

473
00:22:07,160 --> 0:22:09,162
因为这是我们要在实时app中

474
00:22:09,229 --> 0:22:10,597
很想避免的事

475
00:22:11,298 --> 0:22:13,667
我们可以使用降噪器来替换这种方式

476
00:22:13,734 --> 0:22:15,269
Sean之前给我们介绍过降噪器

477
00:22:16,870 --> 0:22:18,071
这就是使用降噪器之后的效果

478
00:22:19,373 --> 0:22:20,807
绝大多数噪声都被过滤掉了

479
00:22:21,141 --> 0:22:24,011
我们可以获得看起来很不错的软阴影

480
00:22:25,612 --> 0:22:28,582
稍后我会在现场演示中为你实际演示

481
00:22:32,019 --> 0:22:33,954
现在让我们讲讲环境光遮蔽

482
00:22:35,923 --> 0:22:37,991
从根本上说这是一个近似值

483
00:22:38,058 --> 0:22:40,360
是关于有多少环境光可以到达

484
00:22:41,295 --> 0:22:43,764
正如你之前在我们的AR Quick Look

485
00:22:44,164 --> 0:22:47,167
在环境中把物体放在地面上

486
00:22:49,303 --> 0:22:51,305
因此让我们使用光线追踪

487
00:22:52,873 --> 0:22:54,775
屏幕中间有一个表面点

488
00:22:55,609 --> 0:22:57,611
在右侧有一个蓝块

489
00:22:57,678 --> 0:22:59,413
它的作用是遮光板

490
00:23:00,681 --> 0:23:03,584
我们在表面点周围定义一个

491
00:23:04,284 --> 0:23:05,385
然后我们发射一些光线

492
00:23:07,421 --> 0:23:08,622
如果某条光线击中了某些东西

493
00:23:08,922 --> 0:23:11,859
我们就会发现那个物体阻挡了

494
00:23:14,728 --> 0:23:16,763
正如我几分钟之前所提到的那样

495
00:23:16,830 --> 0:23:18,165
在实时app中

496
00:23:18,232 --> 0:23:21,235
我们真的很想避免把我们自己局限于

497
00:23:22,236 --> 0:23:24,605
因此我们需要尽可能有效地使用

498
00:23:26,707 --> 0:23:29,209
其中一种方式就是重要性采样

499
00:23:29,843 --> 0:23:33,213
这里的总体思路是以我们认为

500
00:23:33,280 --> 0:23:35,983
最有利于最终图片效果的方向

501
00:23:38,151 --> 0:23:39,453
通过环境光遮蔽

502
00:23:39,520 --> 0:23:41,822
最重要的光线就是距法线较近的光线

503
00:23:43,123 --> 0:23:46,093
因此我们不像你在这里看到的那样

504
00:23:46,493 --> 0:23:47,961
而是使用余弦采样

505
00:23:49,730 --> 0:23:52,165
这在地平线周围分配了较少的光线

506
00:23:52,232 --> 0:23:53,867
并在表面法线周围分配了较多的光线

507
00:23:54,368 --> 0:23:56,370
这很棒

508
00:23:59,173 --> 0:24:01,074
除角衰减之外

509
00:23:59,173 --> 0:24:01,074
除角衰减之外

510
00:24:01,441 --> 0:24:03,777
环境光遮蔽还有一个距离的概念

511
00:24:04,411 --> 0:24:07,281
因此距离表面近的物体会遮挡

512
00:24:08,415 --> 0:24:10,284
那里通常还存在一个脱落函数

513
00:24:10,350 --> 0:24:12,219
与距离的平方成比例

514
00:24:14,221 --> 0:24:15,722
现在有意思的是

515
00:24:15,989 --> 0:24:19,359
我们可以把那个脱落函数直接放到

516
00:24:20,460 --> 0:24:23,330
我们的实现方式是

517
00:24:25,465 --> 0:24:26,433
你可以在这里看到

518
00:24:26,500 --> 0:24:28,902
因为我告诉过你的那个

519
00:24:28,969 --> 0:24:29,970
距离平方脱落函数

520
00:24:30,370 --> 0:24:32,372
绝大多数光线都非常非常短

521
00:24:33,207 --> 0:24:34,575
这对于性能来说很棒

522
00:24:34,875 --> 0:24:36,276
短光线更易于

523
00:24:36,343 --> 0:24:38,545
Metal在加速结构中进行追踪

524
00:24:42,216 --> 0:24:43,283
我已经提过几次了

525
00:24:43,350 --> 0:24:46,019
关于生成不同形状的光线

526
00:24:46,086 --> 0:24:47,554
以及不同的分配

527
00:24:47,855 --> 0:24:49,823
比如我们针对软阴影所使用的椎体

528
00:24:50,090 --> 0:24:52,459
以及我们针对环境光遮蔽

529
00:24:54,561 --> 0:24:56,396
在实践中

530
00:24:56,463 --> 0:24:59,700
我们先在2D参数空间生成点

531
00:25:00,100 --> 0:25:03,504
然后我们通过你想使用的任何一种

532
00:25:05,606 --> 0:25:07,908
现在参数空间中的那些点的位置

533
00:25:08,175 --> 0:25:09,710
对图片品质有重大影响

534
00:25:11,311 --> 0:25:12,513
如果你随机选择点

535
00:25:12,846 --> 0:25:15,415
往往会出现采样点聚集在一起的区域

536
00:25:17,317 --> 0:25:20,654
这就导致我们

537
00:25:20,721 --> 0:25:22,055
而那些光线是多余的

538
00:25:24,558 --> 0:25:27,494
你还会得到完全没有采样点的区域

539
00:25:28,762 --> 0:25:30,330
这会影响图片品质

540
00:25:30,397 --> 0:25:32,499
因为我们这些区域中的场景欠采样

541
00:25:34,368 --> 0:25:36,537
生成采样点的一种更好的方式是

542
00:25:36,603 --> 0:25:39,072
使用一种叫做低差异序列的东西

543
00:25:40,040 --> 0:25:41,441
我正在屏幕上展示的这个

544
00:25:41,508 --> 0:25:43,177
是Halton 2 3序列

545
00:25:44,745 --> 0:25:47,347
你可以看到以这种方式生成的采样点

546
00:25:47,781 --> 0:25:50,651
更均匀地覆盖了这个空间

547
00:25:50,717 --> 0:25:52,486
并且我们可以通过放大和欠采样

548
00:25:56,390 --> 0:25:59,326
这就是对单个像素

549
00:26:00,227 --> 0:26:02,863
现在我们需要做的就是把这种方式

550
00:26:02,930 --> 0:26:04,264
从而使所有像素点都生成良好的光线

551
00:26:06,099 --> 0:26:07,267
我们的实现方式是

552
00:26:07,334 --> 0:26:10,170
获取我刚刚所展示的

553
00:26:10,237 --> 0:26:11,305
其中一个低差异采样点

554
00:26:11,939 --> 0:26:14,041
然后给每个像素应用

555
00:26:16,610 --> 0:26:17,945
所产生的效果是

556
00:26:18,345 --> 0:26:21,582
每个像素仍以低差异序列运行

557
00:26:22,482 --> 0:26:24,451
但采样点的具体位置发生了偏移

558
00:26:24,518 --> 0:26:26,587
不是屏幕上相邻的像素

559
00:26:29,423 --> 0:26:31,925
还有几种不同的方式可以生成

560
00:26:32,659 --> 0:26:36,730
其中一种方式是采样一个完全是

561
00:26:38,699 --> 0:26:40,901
但我们之前看到过

562
00:26:40,968 --> 0:26:42,703
随机数并不是用于光线追踪的

563
00:26:43,370 --> 0:26:46,473
对于环境光遮蔽来说

564
00:26:46,540 --> 0:26:47,608
有一个不错的替代方案 即蓝噪声

565
00:26:49,276 --> 0:26:50,611
你可以在右侧看到

566
00:26:50,777 --> 0:26:53,080
但蓝噪声纹理中的随机性

567
00:26:53,146 --> 0:26:56,783
它的分布更加均匀

568
00:26:57,084 --> 0:27:00,254
特别是当我们局限于每个像素

569
00:26:57,084 --> 0:27:00,254
特别是当我们局限于每个像素

570
00:27:02,823 --> 0:27:04,525
让我们看一下这些

571
00:27:04,591 --> 0:27:07,227
对我们尝试要生成的

572
00:27:08,929 --> 0:27:10,130
我们要从这儿开始

573
00:27:11,031 --> 0:27:14,735
这是对全部像素使用半球采样

574
00:27:17,204 --> 0:27:19,606
这是使用我讲过的椎体采样

575
00:27:19,673 --> 0:27:21,475
和蓝噪声所得到的结果

576
00:27:22,776 --> 0:27:24,645
我可以在这两张图片之间切换

577
00:27:25,879 --> 0:27:29,283
现在这两张图片都是通过每个像素

578
00:27:30,651 --> 0:27:33,954
但你可以看到根据我们选择使用

579
00:27:34,821 --> 0:27:36,990
噪声的数量很明显地有所下降

580
00:27:37,257 --> 0:27:40,260
我们努力捕捉更多的表面细节

581
00:27:42,296 --> 0:27:43,864
如果我们持续发射光线

582
00:27:44,631 --> 0:27:47,601
最终这两种方法会产生

583
00:27:48,135 --> 0:27:51,038
但使用重要性采样会让我们速度更快

584
00:27:53,941 --> 0:27:55,843
那么这就是阴影和环境光遮蔽

585
00:27:56,677 --> 0:27:59,346
对于这些效果 我们仅对光线

586
00:27:59,413 --> 0:28:02,115
是否击中或是否错过某些东西感兴趣

587
00:27:59,413 --> 0:28:02,115
是否击中或是否错过某些东西感兴趣

588
00:28:04,017 --> 0:28:07,421
对于我们通常与光线追踪相关联的

589
00:28:07,487 --> 0:28:08,989
比如全局照明

590
00:28:09,590 --> 0:28:11,959
你需要随着光线在场景中的反弹

591
00:28:12,860 --> 0:28:15,329
为了让你们了解更多相关信息

592
00:28:17,898 --> 0:28:19,233
（全局照明）

593
00:28:23,837 --> 0:28:24,805
谢谢Wayne

594
00:28:27,908 --> 0:28:30,010
在这部分中 我们要讲几个话题

595
00:28:30,077 --> 0:28:32,212
先简要概述一下全局照明

596
00:28:32,913 --> 0:28:35,716
然后看一些关于内存和光线管理的

597
00:28:36,850 --> 0:28:39,119
最后讲

598
00:28:39,186 --> 0:28:40,420
调试光线追踪app的一些策略

599
00:28:42,055 --> 0:28:43,323
那么什么是全局照明？

600
00:28:44,892 --> 0:28:46,193
从概念上说非常简单

601
00:28:46,660 --> 0:28:49,863
光进入场景并直接照亮

602
00:28:50,697 --> 0:28:51,732
并光栅化

603
00:28:51,798 --> 0:28:53,333
这一般是渲染过程的结束

604
00:28:53,867 --> 0:28:56,336
但在现实世界中

605
00:28:56,670 --> 0:28:59,139
然后光线会弹开并继续在场景中穿梭

606
00:28:59,740 --> 0:29:02,342
随着光线四处反弹会浮现一些

607
00:28:59,740 --> 0:29:02,342
随着光线四处反弹会浮现一些

608
00:29:04,411 --> 0:29:05,846
当光反弹一次之后

609
00:29:05,913 --> 0:29:08,515
我们就会在镜像表面上看到镜面反射

610
00:29:08,582 --> 0:29:09,883
就像右边的球和墙一样

611
00:29:11,852 --> 0:29:14,021
你还可以看到随着物体和阴影获取

612
00:29:14,087 --> 0:29:16,557
由附近表面所反射的光

613
00:29:18,525 --> 0:29:19,760
在光反弹两次之后

614
00:29:19,826 --> 0:29:22,162
我们会在镜像表面之间看到反射

615
00:29:23,096 --> 0:29:26,366
最终一些光线一直折射穿过透明物体

616
00:29:26,934 --> 0:29:28,502
它们显示除了它们背后的表面

617
00:29:28,569 --> 0:29:30,037
为我们提供了盒子的玻璃效果

618
00:29:31,705 --> 0:29:34,107
如果我们尝试给场景周围所有的

619
00:29:34,675 --> 0:29:37,611
只有一小部分光能反弹回摄像头

620
00:29:37,678 --> 0:29:39,146
那样效率很低

621
00:29:39,580 --> 0:29:43,183
所以我们要从反方向进行处理

622
00:29:44,785 --> 0:29:47,621
我们从摄像头向图片中的像素

623
00:29:49,957 --> 0:29:53,160
那些光线的交叉点会告诉我们

624
00:29:53,627 --> 0:29:55,429
但我们还需要计算有多少光到达了

625
00:29:55,495 --> 0:29:58,065
以便了解它们在最终图片中的颜色

626
00:29:59,099 --> 0:30:01,635
之前Wayne

627
00:29:59,099 --> 0:30:01,635
之前Wayne

628
00:30:01,902 --> 0:30:04,505
在这里我们要实施完全相同的过程

629
00:30:05,973 --> 0:30:08,242
我们从交叉点

630
00:30:08,308 --> 0:30:09,409
向场景中的光源投射阴影光线

631
00:30:09,476 --> 0:30:11,612
从而估计有多少光到达了光源

632
00:30:12,646 --> 0:30:15,048
这将用作最终图片的光照效果

633
00:30:17,918 --> 0:30:19,786
接下来我们从交叉点

634
00:30:19,853 --> 0:30:22,022
向随机方向再次投射光线

635
00:30:23,190 --> 0:30:25,192
我们使用Metal来了解那些光线

636
00:30:25,259 --> 0:30:27,594
然后投射阴影光线以确定它们的

637
00:30:27,794 --> 0:30:29,630
然后使用直接光照给最终图片

638
00:30:30,464 --> 0:30:31,698
重复这个过程

639
00:30:31,765 --> 0:30:33,600
我们可以模拟光在房间中的反弹

640
00:30:34,501 --> 0:30:36,703
我们在去年的演讲中做了具体的描述

641
00:30:36,770 --> 0:30:39,606
我推荐你参看去年的演讲获取如何

642
00:30:41,441 --> 0:30:43,343
在这个过程中使用的管道看起来

643
00:30:43,410 --> 0:30:45,279
与我们目前所见过的混合管道

644
00:30:46,313 --> 0:30:48,749
首先我们发射光线并使用Metal

645
00:30:48,815 --> 0:30:49,650
找到它们在场景中的交叉点

646
00:30:52,019 --> 0:30:55,222
然后我们编写一个着色器来处理

647
00:30:55,589 --> 0:30:56,990
从而了解我们击中了哪个表面

648
00:30:59,860 --> 0:31:02,596
然后我们生成阴影光线

649
00:30:59,860 --> 0:31:02,596
然后我们生成阴影光线

650
00:31:02,663 --> 0:31:03,897
向场景中的光源生成阴影光线

651
00:31:04,464 --> 0:31:06,333
我编写了一个着色器

652
00:31:06,400 --> 0:31:08,535
击中了光源 然后把它们的光添加到

653
00:31:10,137 --> 0:31:12,539
最后我们使用所击中的表面

654
00:31:12,606 --> 0:31:13,640
作为下一组光线的发起点

655
00:31:14,341 --> 0:31:16,043
我们一次又一次地重复这个过程

656
00:31:16,109 --> 0:31:18,045
直到我们创建了我们想要创建的

657
00:31:20,380 --> 0:31:21,949
这就是全局照明的运作方式

658
00:31:23,483 --> 0:31:25,519
现在我们要讨论

659
00:31:25,586 --> 0:31:27,688
为这个模型提供内存的一些最佳实践

660
00:31:29,723 --> 0:31:31,325
因为任意光线都在场景中发生反弹

661
00:31:31,859 --> 0:31:33,994
光线的状态随着

662
00:31:34,061 --> 0:31:35,229
光与它所击中的物体的交互而改变

663
00:31:36,129 --> 0:31:37,965
比如 如果光线击中了一种红色材料

664
00:31:38,398 --> 0:31:41,335
那个红色表面会吸收除红光以外的

665
00:31:41,935 --> 0:31:44,304
因此从那个表面上反射的二级光

666
00:31:44,371 --> 0:31:45,772
将只包含红光

667
00:31:46,773 --> 0:31:48,375
因此我们要持续追踪那个信息

668
00:31:48,442 --> 0:31:50,544
以便把它传给管道的下一次迭代

669
00:31:51,378 --> 0:31:53,280
那意味着我们得分配一些资源

670
00:31:53,347 --> 0:31:55,315
用于持续追踪光线和场景属性

671
00:31:56,617 --> 0:31:59,319
在右侧我列出了

672
00:31:59,386 --> 0:32:00,487
你可能想要追踪的

673
00:31:59,386 --> 0:32:00,487
你可能想要追踪的

674
00:32:03,156 --> 0:32:04,758
要重定位所有这些新缓冲区

675
00:32:05,225 --> 0:32:06,660
我们将占用大量内存

676
00:32:07,494 --> 0:32:10,664
对于一张4K图片来说

677
00:32:11,465 --> 0:32:13,867
在我们的一个演示中

678
00:32:14,601 --> 0:32:17,538
这种方式可以迅速超出可用的

679
00:32:19,773 --> 0:32:21,842
其中一种解决方案就是把光线分批

680
00:32:21,909 --> 0:32:23,177
放到较小的群组或平铺中

681
00:32:23,944 --> 0:32:26,713
通过限制你同时发射的光线的数量

682
00:32:26,780 --> 0:32:29,383
你可以极大地减少资源的内存占用

683
00:32:31,485 --> 0:32:33,420
因为这些缓冲区中的数据

684
00:32:33,487 --> 0:32:35,189
将在管道迭代之间传递

685
00:32:36,390 --> 0:32:38,725
把那个数据存在外面

686
00:32:38,792 --> 0:32:40,260
这将成为主要的受限因素

687
00:32:41,395 --> 0:32:43,630
对于4K图片来说

688
00:32:44,331 --> 0:32:45,532
对于这个数字

689
00:32:45,599 --> 0:32:48,402
每次迭代要读写大约5GB的数据

690
00:32:50,370 --> 0:32:52,339
每个带宽问题都没有任何解决方案

691
00:32:52,406 --> 0:32:54,741
但我们可以给你提供一些

692
00:32:55,742 --> 0:32:57,845
第一 不要随机索引到数据缓冲区中

693
00:32:59,012 --> 0:33:02,015
如果你按线程ID索引可能效率更高

694
00:32:59,012 --> 0:33:02,015
如果你按线程ID索引可能效率更高

695
00:33:02,082 --> 0:33:04,685
从而编译器可以合并全部加载和存储

696
00:33:05,285 --> 0:33:06,854
因为线程要访问的内存

697
00:33:06,920 --> 0:33:08,555
位于相邻的缓冲区中

698
00:33:09,823 --> 0:33:11,959
这真的会改善你的缓存一致性

699
00:33:13,260 --> 0:33:15,796
下一个

700
00:33:16,463 --> 0:33:18,498
尽可能使用较小的数据类型

701
00:33:19,433 --> 0:33:22,035
如果可以的话

702
00:33:22,102 --> 0:33:23,170
请试着用half替代

703
00:33:24,905 --> 0:33:27,040
最后如果可能的话 请分离结构

704
00:33:27,107 --> 0:33:29,343
以避免加载或存储你不会用到的数据

705
00:33:30,177 --> 0:33:33,113
比如我们有一个结构包含材料属性

706
00:33:33,780 --> 0:33:36,884
我们通过去除透明度变量得到了

707
00:33:37,150 --> 0:33:39,453
因为并不是每条光线都会击中

708
00:33:39,520 --> 0:33:41,588
我们不希望那些没有击中

709
00:33:41,655 --> 0:33:42,856
为了读写透明度数据而付出代价

710
00:33:43,657 --> 0:33:45,893
我们稍后会在GPU调试部分

711
00:33:45,959 --> 0:33:47,127
看到一个更具体的例子

712
00:33:50,297 --> 0:33:51,565
分配自己的缓冲区

713
00:33:51,632 --> 0:33:53,834
存储起点和方向数据可能有违常规

714
00:33:53,901 --> 0:33:56,069
但这样更有效率

715
00:33:56,403 --> 0:33:58,438
而不是重复使用

716
00:33:59,873 --> 0:34:01,475
这是因为Metal光线缓冲区

717
00:33:59,873 --> 0:34:01,475
这是因为Metal光线缓冲区

718
00:34:01,542 --> 0:34:04,778
可能包含你不希望对可能获取光线的

719
00:34:05,145 --> 0:34:06,747
每一个着色器加载和存储的额外数据

720
00:34:09,949 --> 0:34:11,351
为了最大化GPU的使用

721
00:34:12,085 --> 0:34:13,920
你需要注意着色器占用

722
00:34:14,621 --> 0:34:16,123
占用是一个很大的话题

723
00:34:16,190 --> 0:34:17,724
我们不会在这里深入地介绍

724
00:34:18,292 --> 0:34:20,092
但如果你存在占用问题

725
00:34:20,159 --> 0:34:22,829
最简单的改善方式就是减少注册压力

726
00:34:24,331 --> 0:34:27,201
请注意着色器中

727
00:34:27,266 --> 0:34:28,368
同时活跃的变量数量

728
00:34:28,869 --> 0:34:31,138
请注意循环计数器、函数调用

729
00:34:31,972 --> 0:34:34,107
如果可以避免

730
00:34:37,244 --> 0:34:39,179
当我们处理光线交叉点时

731
00:34:39,679 --> 0:34:41,447
我们需要评估

732
00:34:41,514 --> 0:34:42,850
光线所击中的任何物体的表面属性

733
00:34:43,750 --> 0:34:46,587
图形app一般会在纹理中

734
00:34:46,652 --> 0:34:47,621
保存大量材料属性

735
00:34:48,522 --> 0:34:51,824
这里的问题在于

736
00:34:51,891 --> 0:34:53,092
物体所引用的任意纹理

737
00:34:53,627 --> 0:34:57,197
我们不能提前了解光线会击中

738
00:34:57,631 --> 0:34:59,733
潜在地 我们可能需要访问每一个

739
00:35:00,033 --> 0:35:01,368
场景中的每一个纹理

740
00:35:02,102 --> 0:35:03,470
这样很快就会脱离我们的掌控

741
00:35:04,271 --> 0:35:07,808
如常用Sponza Atrium

742
00:35:08,308 --> 0:35:10,611
比可用的捆绑插槽的数量多两倍还多

743
00:35:11,512 --> 0:35:13,714
因此我们很快就会用完全部的

744
00:35:16,683 --> 0:35:19,286
其中一种解决方式是使用

745
00:35:19,987 --> 0:35:22,489
Metal参数缓冲区代表一组资源

746
00:35:22,556 --> 0:35:25,325
可以作为单个参数被集体分配到

747
00:35:26,527 --> 0:35:28,929
我们在两年前的WWDC做了一个

748
00:35:29,730 --> 0:35:32,132
我推荐你参考那个演讲获取

749
00:35:33,600 --> 0:35:35,469
假设每个基元有一个纹理

750
00:35:35,936 --> 0:35:39,006
参数缓冲区将是

751
00:35:40,440 --> 0:35:42,676
在这里我们创建了一个结构

752
00:35:42,743 --> 0:35:44,077
它包含一个纹理引用

753
00:35:44,144 --> 0:35:46,079
和我们想要访问的其它信息

754
00:35:47,648 --> 0:35:49,917
接下来我们把参数缓冲区绑定到

755
00:35:50,651 --> 0:35:52,653
它将显示为材料结构的一个数组

756
00:35:54,521 --> 0:35:57,724
我们从交叉缓冲区中读取它

757
00:35:59,092 --> 0:36:01,862
然后我们就使用那个索引

758
00:35:59,092 --> 0:36:01,862
然后我们就使用那个索引

759
00:36:02,729 --> 0:36:05,532
这可以让我们访问

760
00:36:08,702 --> 0:36:09,937
这就是我们今天要讲的

761
00:36:11,238 --> 0:36:13,307
现在我们要讨论管理光线的生命周期

762
00:36:15,108 --> 0:36:16,443
随着光线在场景中的反弹

763
00:36:16,844 --> 0:36:19,513
光线可能由于各种原因

764
00:36:20,581 --> 0:36:22,115
第一 它可能完全离开了场景

765
00:36:22,783 --> 0:36:23,784
与现实世界不同

766
00:36:23,851 --> 0:36:25,719
你的场景占用的空间有限

767
00:36:26,086 --> 0:36:28,856
如果光线退出了

768
00:36:30,123 --> 0:36:32,659
如果发生那种情况

769
00:36:32,726 --> 0:36:34,027
来获取背景颜色

770
00:36:34,094 --> 0:36:35,362
但那个光线实际上

771
00:36:36,897 --> 0:36:38,365
第二 随着光线的反弹

772
00:36:39,166 --> 0:36:42,436
它所携带的光

773
00:36:43,470 --> 0:36:46,974
如果光线丢失了足够多的光

774
00:36:47,040 --> 0:36:48,041
再对最终图片的品质产生

775
00:36:49,176 --> 0:36:50,844
最后对于透明表面

776
00:36:50,911 --> 0:36:53,480
有一些光可能会被困在某些位置上

777
00:36:53,547 --> 0:36:55,315
这样它们就永远都不能返回到摄像头

778
00:36:57,618 --> 0:36:59,253
光线变得不活跃的速度有多快？

779
00:37:00,120 --> 0:37:02,589
取决于场景类型 速度可能非常快

780
00:37:03,824 --> 0:37:05,726
比如这个场景有个开放的世界

781
00:37:05,792 --> 0:37:08,428
大量光线很快就会因为击中环境贴图

782
00:37:09,396 --> 0:37:11,465
在右侧我们展示的是

783
00:37:11,532 --> 0:37:13,066
完全活跃的光线缓冲区

784
00:37:13,433 --> 0:37:15,936
随着它在管道的第一次迭代中的

785
00:37:16,837 --> 0:37:19,640
我们就是在这个步骤中从摄像头

786
00:37:22,109 --> 0:37:24,711
其中一些光线会击中环境贴图

787
00:37:25,279 --> 0:37:27,281
在这里我们把不活跃的光线

788
00:37:27,347 --> 0:37:29,016
我们已经把它们从光线缓冲区中移除

789
00:37:29,983 --> 0:37:32,986
在第一次迭代之后

790
00:37:35,055 --> 0:37:36,657
我们让光线继续穿梭

791
00:37:36,723 --> 0:37:38,458
最初击中地面的一些光线

792
00:37:38,725 --> 0:37:40,194
发生反弹并击中环境贴图

793
00:37:40,661 --> 0:37:43,063
现在余下的活跃光线降到了43%

794
00:37:45,365 --> 0:37:48,268
其中有些光线一直穿过了透明物体

795
00:37:48,335 --> 0:37:49,536
并最终退出了场景

796
00:37:50,037 --> 0:37:51,839
我们的活跃光线只剩下三分之一了

797
00:37:53,073 --> 0:37:55,576
当然了 我们迭代的次数越多

798
00:37:57,544 --> 0:37:59,980
在这个例子中

799
00:38:00,047 --> 0:38:02,115
都将变得不活跃 我们用于处理

800
00:38:02,182 --> 0:38:03,116
这些不活跃的光线的时间是一种浪费

801
00:38:03,851 --> 0:38:05,419
但因为我们不能提前了解到

802
00:38:05,485 --> 0:38:06,854
哪些光线会变得不活跃

803
00:38:07,321 --> 0:38:08,522
处理这个结果的

804
00:38:08,889 --> 0:38:10,991
以及全部着色器

805
00:38:11,058 --> 0:38:13,093
仍要在全部光线上运行

806
00:38:13,694 --> 0:38:15,629
那意味着我们得分配线程组内存

807
00:38:15,696 --> 0:38:17,364
编译器可能会预取数据

808
00:38:17,431 --> 0:38:21,134
我们可能要添加控制流语句

809
00:38:22,169 --> 0:38:24,071
我们的占用保持不变

810
00:38:24,605 --> 0:38:27,074
但线程组的利用率却很低

811
00:38:27,674 --> 0:38:29,676
我们浪费了所有的处理器容量

812
00:38:32,379 --> 0:38:34,615
我们的解决方案是压缩光线缓冲区

813
00:38:36,049 --> 0:38:39,653
对于每次迭代 我们仅向下一个

814
00:38:40,554 --> 0:38:41,688
这增加了一些消耗

815
00:38:41,755 --> 0:38:44,625
但却会提高缓存线和线程组的利用率

816
00:38:45,192 --> 0:38:48,028
因此处理浪费少了

817
00:38:49,296 --> 0:38:52,132
还有一个重点要注意

818
00:38:52,900 --> 0:38:55,235
有些光线会击中背光的表面

819
00:38:55,569 --> 0:38:56,637
或可能会击中背景

820
00:38:56,703 --> 0:38:58,405
因此我们不想缓存

821
00:39:00,741 --> 0:39:03,143
这个方法的缺点是

822
00:39:03,210 --> 0:39:04,311
因为我们在光线缓冲区内

823
00:39:04,778 --> 0:39:08,749
我们的光线缓冲区中的索引

824
00:39:09,483 --> 0:39:11,985
因此我们需要分配一个缓冲区

825
00:39:12,052 --> 0:39:13,086
用于沿着每条光线追踪像素坐标

826
00:39:14,321 --> 0:39:16,056
虽然我们使用了额外缓冲区

827
00:39:16,123 --> 0:39:17,991
但我们实际上所使用的内存变少了

828
00:39:18,058 --> 0:39:20,527
如果我们把所有不需要处理的光线

829
00:39:22,696 --> 0:39:23,964
当我们压缩光线时

830
00:39:24,364 --> 0:39:27,501
我们不希望两个着色器

831
00:39:27,568 --> 0:39:28,669
同一个位置添加光线

832
00:39:29,336 --> 0:39:31,438
因此我们需要在光线缓冲区中

833
00:39:31,505 --> 0:39:34,875
为每一条在迭代之间保持活跃的光线

834
00:39:36,076 --> 0:39:37,644
我们使用原子计数器来实现

835
00:39:38,545 --> 0:39:40,914
在这里原子整数

836
00:39:40,981 --> 0:39:43,717
在新光线缓冲区中包含光线的

837
00:39:45,419 --> 0:39:48,689
我们使用atomic_fetch_add

838
00:39:48,755 --> 0:39:50,858
流出光线的当前值并增加一

839
00:39:52,693 --> 0:39:55,395
我们把这个值用作

840
00:39:55,462 --> 0:39:56,997
以确保不会发生冲突

841
00:39:57,598 --> 0:39:59,867
它还有一个额外的好处

842
00:39:59,933 --> 0:40:01,935
即在流出光线计数中保留

843
00:39:59,933 --> 0:40:01,935
即在流出光线计数中保留

844
00:40:04,104 --> 0:40:06,607
如果你不能限制你所启动的线程数

845
00:40:06,673 --> 0:40:07,975
光线压缩也不会提供太多的帮助

846
00:40:08,242 --> 0:40:10,177
我们刚生产的流出光线计数缓冲区

847
00:40:10,244 --> 0:40:13,680
包含流出光线缓冲区中的

848
00:40:14,915 --> 0:40:17,618
我们可以用这个数来填充

849
00:40:17,684 --> 0:40:18,952
IndirectArguments对象

850
00:40:20,020 --> 0:40:23,023
那正好指明了

851
00:40:24,191 --> 0:40:27,060
然后通过对indirectBuffer对象

852
00:40:27,528 --> 0:40:29,496
我们可以限制

853
00:40:29,563 --> 0:40:31,698
使线程仅处理保持活跃的光线

854
00:40:33,500 --> 0:40:35,335
还有一个与此相对应的

855
00:40:35,402 --> 0:40:36,503
光线交叉函数

856
00:40:38,272 --> 0:40:41,375
这里的重点是我们可以通过缓冲区

857
00:40:41,708 --> 0:40:43,911
从而我们可以把结果填充到

858
00:40:43,977 --> 0:40:45,879
作为要启动的线程的数量

859
00:40:47,915 --> 0:40:49,082
在压缩光线之后

860
00:40:49,516 --> 0:40:52,152
在这个场景中我们获得了大约

861
00:40:52,686 --> 0:40:55,856
但当然了 这个结果取决于

862
00:40:55,923 --> 0:40:57,925
你所使用的场景的复杂程度

863
00:41:00,727 --> 0:41:02,396
那么这就是光线的生命周期

864
00:41:04,331 --> 0:41:07,167
现在我们要讲使用Xcode

865
00:41:09,469 --> 0:41:12,072
众所周知 在GPU上调试非常困难

866
00:41:12,840 --> 0:41:14,675
特别是对于光线追踪来说尤其困难

867
00:41:15,409 --> 0:41:17,945
每条光线可能会多次调用

868
00:41:18,545 --> 0:41:21,348
并且你可能需要在算法的不同阶段

869
00:41:21,648 --> 0:41:23,584
编写大量代码来卸载缓冲区和纹理

870
00:41:23,851 --> 0:41:25,853
从而了解哪里产生了报错

871
00:41:26,753 --> 0:41:29,723
Xcode的帧捕捉工具

872
00:41:29,790 --> 0:41:31,158
对于调试这些问题来说非常好用

873
00:41:31,959 --> 0:41:33,827
它是个很强大的工具

874
00:41:35,329 --> 0:41:37,865
因此我要和你们一起调试

875
00:41:37,931 --> 0:41:40,968
当我们在光线追踪器中实施

876
00:41:42,202 --> 0:41:45,539
我们对每帧都实施了对单个像素

877
00:41:45,939 --> 0:41:48,642
然后突然 我们的光线追踪器开始

878
00:41:50,744 --> 0:41:54,414
第一步是在app运行时执行帧捕捉

879
00:41:55,782 --> 0:41:58,552
这会记录在一帧的过程中

880
00:41:58,619 --> 0:42:00,053
和着色器的GPU状态

881
00:41:58,619 --> 0:42:00,053
和着色器的GPU状态

882
00:42:01,688 --> 0:42:02,856
通过选择任意着色器

883
00:42:02,923 --> 0:42:04,892
我们可以检验绑定到它的资源

884
00:42:05,659 --> 0:42:08,462
从而我们可以非常快速地减少

885
00:42:08,862 --> 0:42:11,431
通过选择写入帧缓冲区的

886
00:42:11,498 --> 0:42:13,467
并可以直接检验帧缓冲区的内容

887
00:42:14,434 --> 0:42:16,303
在这里我们可以看到第一张图片很亮

888
00:42:17,070 --> 0:42:18,572
第二张照片褪色很严重

889
00:42:18,639 --> 0:42:19,806
第三张照片几乎是白色的

890
00:42:22,509 --> 0:42:25,078
但在这里我们要选择输出

891
00:42:25,612 --> 0:42:27,848
并查看用于计算

892
00:42:27,915 --> 0:42:29,716
帧缓冲区的两个输入缓冲区

893
00:42:30,617 --> 0:42:34,621
第一个缓冲区仅包含

894
00:42:37,191 --> 0:42:38,926
第二个缓冲区包含我们的新变量

895
00:42:39,526 --> 0:42:41,895
也就是我们对指定像素的采样次数

896
00:42:42,930 --> 0:42:45,032
这两个缓冲区看起来都包含有效数据

897
00:42:45,098 --> 0:42:46,767
因此我们可以直接进入着色器调试器

898
00:42:46,834 --> 0:42:48,735
来检验我们的着色器会如何处理

899
00:42:50,737 --> 0:42:52,773
我们的颜色计算只是

900
00:42:52,840 --> 0:42:54,942
为指定像素发射的全部光线的亮度

901
00:42:56,109 --> 0:42:58,745
当每个像素仅有一条光线时

902
00:42:59,680 --> 0:43:01,148
但现在我们无法补偿这一事实

903
00:42:59,680 --> 0:43:01,148
但现在我们无法补偿这一事实

904
00:43:01,215 --> 0:43:03,584
即我们需要对每个像素进行多次采样

905
00:43:04,718 --> 0:43:06,720
因此我们要在着色器调试器中

906
00:43:06,787 --> 0:43:09,656
将总亮度除以输入样本数

907
00:43:10,724 --> 0:43:12,826
我们直接在着色器调试器中进行

908
00:43:13,427 --> 0:43:16,129
我们可以立即看到我们的输出图像

909
00:43:16,663 --> 0:43:17,664
就是那么简单

910
00:43:19,533 --> 0:43:20,467
（用Xcode进行性能调整）

911
00:43:20,534 --> 0:43:21,702
我们频繁遇到的另一个问题是

912
00:43:21,768 --> 0:43:24,238
我们尝试了解我们所做的修改

913
00:43:25,005 --> 0:43:27,774
Xcode帧捕捉工具

914
00:43:29,209 --> 0:43:31,745
这是一个在光线反弹时

915
00:43:31,812 --> 0:43:32,980
追踪表面特征的结构的示例

916
00:43:33,881 --> 0:43:36,149
在我们的场景中

917
00:43:36,216 --> 0:43:39,186
最终的两个值 透射和折射率

918
00:43:39,486 --> 0:43:40,854
对于某些光线来说没有用

919
00:43:41,622 --> 0:43:44,458
但因为我们把那种数据

920
00:43:45,025 --> 0:43:47,027
没有击中透明表面的光线

921
00:43:47,094 --> 0:43:48,795
仍需要在迭代中

922
00:43:49,062 --> 0:43:51,465
读写那些字段

923
00:43:53,934 --> 0:43:56,870
在这里我们把折射变量

924
00:43:56,937 --> 0:43:58,038
重构到它们自己的结构中

925
00:43:58,605 --> 0:44:01,575
仅在结构中保留击中透明表面的光线

926
00:43:58,605 --> 0:44:01,575
仅在结构中保留击中透明表面的光线

927
00:44:01,642 --> 0:44:03,310
这必须存在折射率数据

928
00:44:06,813 --> 0:44:07,915
但我们仍可以做得更好

929
00:44:08,649 --> 0:44:11,185
现在我们把变量的数据类型

930
00:44:11,251 --> 0:44:12,252
从而节约更多的空间

931
00:44:13,120 --> 0:44:15,589
我们已经把内存占用从40字节

932
00:44:15,923 --> 0:44:18,625
没有击中透明物体的光线

933
00:44:20,694 --> 0:44:22,663
我们该如何了解对性能所产生的

934
00:44:23,430 --> 0:44:26,567
在这里我们使用帧捕捉工具

935
00:44:26,633 --> 0:44:28,302
分别在修改前后抓取GPU追踪

936
00:44:29,703 --> 0:44:31,872
我们可以做的最基本的性能分析

937
00:44:31,939 --> 0:44:33,106
就发生在这个阶段

938
00:44:34,074 --> 0:44:35,442
通过比较

939
00:44:35,876 --> 0:44:37,578
修改前后的着色器计时

940
00:44:37,978 --> 0:44:40,013
我们可以隔离性能发生变化的着色器

941
00:44:40,848 --> 0:44:42,583
在这里我们可以看到

942
00:44:42,649 --> 0:44:46,620
计时从5.5毫秒降低到了4毫秒

943
00:44:47,421 --> 0:44:50,457
这对于其中消耗较大的着色器来说

944
00:44:52,259 --> 0:44:55,195
如果我们想量化具体为何提升了性能

945
00:44:55,696 --> 0:44:58,498
当Xcode执行帧捕捉时

946
00:44:58,565 --> 0:45:00,267
它所插入的所有性能计数器的结果

947
00:44:58,565 --> 0:45:00,267
它所插入的所有性能计数器的结果

948
00:45:01,134 --> 0:45:03,637
因为我们有兴趣了解我们如何影响

949
00:45:04,438 --> 0:45:06,707
我们可以看一下纹理单位统计

950
00:45:07,107 --> 0:45:10,043
我们可以看到我们的纹理单位

951
00:45:10,110 --> 0:45:11,845
已经从70%降到了54%

952
00:45:12,479 --> 0:45:15,282
并且我们已经把L2吞吐量减少了

953
00:45:17,518 --> 0:45:20,120
更有帮助的是Xcode

954
00:45:20,187 --> 0:45:21,688
并把潜在的问题报告给你

955
00:45:22,623 --> 0:45:24,491
在这里它告诉我们说我们的初始版本

956
00:45:24,558 --> 0:45:25,993
存在很大的内存问题

957
00:45:26,260 --> 0:45:28,228
而新版本的性能好多了

958
00:45:30,497 --> 0:45:31,965
还有一个技巧你可能会用得上

959
00:45:32,399 --> 0:45:35,335
就是计算管道状态也有一些

960
00:45:36,370 --> 0:45:38,071
请看

961
00:45:38,705 --> 0:45:40,941
这是着色器占用情况的指示

962
00:45:41,608 --> 0:45:43,310
你应该以1024为最大目标

963
00:45:43,377 --> 0:45:46,313
小于1024说明可能存在占用问题

964
00:45:49,016 --> 0:45:50,150
那么这就是Xcode中的调试

965
00:45:50,717 --> 0:45:53,554
这使在Mac平台上开发光线追踪

966
00:45:53,620 --> 0:45:55,289
和全局照明算法变得异常简单

967
00:45:55,956 --> 0:45:58,325
现在Wayne会为大家现场演示

968
00:46:01,628 --> 0:46:02,696
谢谢Matt

969
00:46:04,398 --> 0:46:06,166
你可能认出这个场景来了

970
00:46:06,233 --> 0:46:09,703
来自我们平台本周稍早些时候的

971
00:46:10,871 --> 0:46:11,738
为了在这里对它进行渲染

972
00:46:11,805 --> 0:46:15,342
我要使用MacBook Pro

973
00:46:16,910 --> 0:46:20,547
你在屏幕上看到的一切都是

974
00:46:21,248 --> 0:46:24,117
我可以拿着摄像头在场景中四处移动

975
00:46:26,353 --> 0:46:27,421
让我们从这里开始吧

976
00:46:28,222 --> 0:46:30,824
你可以看到我们通过光线追踪

977
00:46:31,458 --> 0:46:34,461
它们在接触点上是硬阴影

978
00:46:34,528 --> 0:46:36,496
并随着到地面的距离增加而变得

979
00:46:38,832 --> 0:46:42,135
请记住 对于这些阴影

980
00:46:42,469 --> 0:46:44,972
然后我们使用了

981
00:46:45,305 --> 0:46:46,640
才最终得到了这个

982
00:46:48,408 --> 0:46:50,010
这些都是动态地计算的

983
00:46:50,077 --> 0:46:52,980
我可以四处移动灯

984
00:46:54,114 --> 0:46:56,917
我可以立即看到这种效果

985
00:46:59,453 --> 0:47:01,188
这里也有一个很棒的效果

986
00:46:59,453 --> 0:47:01,188
这里也有一个很棒的效果

987
00:47:01,255 --> 0:47:04,191
如果我们飞过去从电车窗户向里看

988
00:47:04,258 --> 0:47:06,560
你实际上可以看到我们影子的反光

989
00:47:06,960 --> 0:47:10,264
再一次 你可以看到

990
00:47:13,634 --> 0:47:16,069
如果我们现在前往场景的这部分

991
00:47:16,136 --> 0:47:18,639
这里也有一个很棒的反射效果

992
00:47:20,741 --> 0:47:22,242
如果我们看最左侧的电车

993
00:47:23,043 --> 0:47:25,345
你可以看到后面有电车的倒影

994
00:47:26,413 --> 0:47:30,217
但你还可以在我们后面的

995
00:47:30,517 --> 0:47:33,120
因此这里的反光内又有反光

996
00:47:33,854 --> 0:47:36,223
我们需要对每个像素模拟几次

997
00:47:36,290 --> 0:47:37,491
才能达到那种效果

998
00:47:40,360 --> 0:47:41,828
我要稍微把这里缩小一些

999
00:47:42,496 --> 0:47:45,199
当然了在这个场景中并不是只有

1000
00:47:45,265 --> 0:47:46,733
灯也可以移动

1001
00:47:47,568 --> 0:47:50,804
Sean之前讲过Metal的

1002
00:47:51,171 --> 0:47:54,141
我们在这里使用二级加速结构

1003
00:47:57,010 --> 0:47:58,512
然而我现在想给你展示的是

1004
00:47:58,579 --> 0:48:01,648
我们在房顶上实现的这个极好的

1005
00:47:58,579 --> 0:48:01,648
我们在房顶上实现的这个极好的

1006
00:48:03,650 --> 0:48:06,019
如果我们注意右侧的墙壁

1007
00:48:06,653 --> 0:48:10,190
你可以看到目前

1008
00:48:11,892 --> 0:48:14,995
但随着我控制太阳的旋转

1009
00:48:15,062 --> 0:48:17,064
你可以看到墙壁陷入了阴影中

1010
00:48:17,431 --> 0:48:21,201
现在它由这个非常棒的

1011
00:48:22,870 --> 0:48:23,770
这里所发生的就是

1012
00:48:24,071 --> 0:48:26,540
太阳光击中了左侧的屋顶

1013
00:48:27,074 --> 0:48:29,510
它反弹并照亮了右侧的墙壁

1014
00:48:29,576 --> 0:48:31,411
从而为我们提供了这个非常棒的

1015
00:48:33,714 --> 0:48:35,782
如果我继续旋转太阳

1016
00:48:35,849 --> 0:48:38,285
你可以逐渐看到

1017
00:48:38,352 --> 0:48:40,487
它们穿过了屋顶的表面

1018
00:48:42,356 --> 0:48:43,790
如果我稍微旋转一下摄像头

1019
00:48:43,857 --> 0:48:46,693
你实际上可以看到

1020
00:48:48,395 --> 0:48:49,830
因此这是——我真的很喜欢这个拍摄

1021
00:48:50,564 --> 0:48:53,500
同时在这里还有许多光线追踪的效果

1022
00:48:53,767 --> 0:48:55,435
我们有非直接照明

1023
00:48:55,502 --> 0:48:57,337
我们有阴影 我们有反射

1024
00:48:58,238 --> 0:49:01,909
这些都由Metal和多GPU进行

1025
00:48:58,238 --> 0:49:01,909
这些都由Metal和多GPU进行

1026
00:49:03,544 --> 0:49:04,945
现在我们要回到我们的演讲

1027
00:49:05,012 --> 0:49:08,215
我要稍微讲一下多GPU

1028
00:49:17,024 --> 0:49:18,659
对于我们刚才看到的演示

1029
00:49:19,560 --> 0:49:21,962
我们实施多GPU的方式

1030
00:49:22,029 --> 0:49:25,732
是通过把屏幕分成几个小的平铺

1031
00:49:26,567 --> 0:49:29,102
然后把这些小平铺映射到

1032
00:49:31,004 --> 0:49:33,740
在这个可视化中 我使用不同的颜色

1033
00:49:33,807 --> 0:49:35,642
来演示这些平铺是如何分配的

1034
00:49:36,310 --> 0:49:38,545
一个GPU渲染红色平铺

1035
00:49:39,346 --> 0:49:40,681
另一个渲染黄色平铺

1036
00:49:41,014 --> 0:49:41,882
以此类推

1037
00:49:43,050 --> 0:49:46,420
在所有GPU完成之后

1038
00:49:46,486 --> 0:49:47,588
从而构成我们的最终图片

1039
00:49:50,357 --> 0:49:51,625
如果我们后退一步

1040
00:49:51,925 --> 0:49:53,193
看看这里有什么

1041
00:49:53,260 --> 0:49:54,728
有两样东西很显眼

1042
00:49:55,996 --> 0:49:58,232
第一 在左侧的图片中

1043
00:49:58,599 --> 0:50:02,803
我们给GPU分配平铺的方式

1044
00:49:58,599 --> 0:50:02,803
我们给GPU分配平铺的方式

1045
00:50:03,337 --> 0:50:04,638
我们为什么那样做呢？

1046
00:50:04,705 --> 0:50:06,707
（交错平铺）

1047
00:50:06,773 --> 0:50:08,709
第二 对于那些小平铺

1048
00:50:09,510 --> 0:50:12,913
所隐含的是每个GPU将在那里

1049
00:50:12,980 --> 0:50:15,682
然后再在别处渲染一个像素块

1050
00:50:16,517 --> 0:50:18,318
那感觉就像对光线一致性、

1051
00:50:18,652 --> 0:50:21,255
缓存击中率这样的东西不利一样

1052
00:50:21,321 --> 0:50:22,322
所有诸如此类的东西

1053
00:50:23,190 --> 0:50:24,491
让我们依次来处理这些问题

1054
00:50:25,259 --> 0:50:27,327
（负载平衡）

1055
00:50:27,394 --> 0:50:29,229
假如我们有四个GPU

1056
00:50:30,230 --> 0:50:33,834
执行多GPU的最简单的方式就是

1057
00:50:33,901 --> 0:50:34,968
把屏幕分为四块

1058
00:50:36,703 --> 0:50:39,206
现在问题是场景中的某些部分

1059
00:50:39,273 --> 0:50:41,275
可能比其它部分更容易渲染

1060
00:50:42,442 --> 0:50:45,612
如果我们假设左侧的街道和建筑物

1061
00:50:45,679 --> 0:50:48,282
比右侧的电车要更容易渲染

1062
00:50:49,383 --> 0:50:51,785
这就表明了为什么红色和黄色GPU

1063
00:50:51,852 --> 0:50:54,655
会比绿色和紫色GPU早完成的原因

1064
00:50:56,456 --> 0:50:59,826
我们可以通过把屏幕分成较小的平铺

1065
00:51:01,628 --> 0:51:03,897
然后我们可以把每个小平铺再分成

1066
00:51:04,531 --> 0:51:05,532
以此类推

1067
00:51:05,599 --> 0:51:07,267
直到我们达到某个最小的平铺尺寸

1068
00:51:09,369 --> 0:51:13,874
这就产生了在GPU上

1069
00:51:15,008 --> 0:51:18,212
如果屏幕的某一部分特别难以渲染

1070
00:51:18,278 --> 0:51:19,613
也没有关系

1071
00:51:19,680 --> 0:51:23,417
因为将从那部分屏幕中给每个GPU

1072
00:51:25,953 --> 0:51:28,956
在实践中你在这里看到的这个常规的

1073
00:51:29,389 --> 0:51:30,624
很可能不适用

1074
00:51:31,225 --> 0:51:34,828
因为你可能会遇到这种情况

1075
00:51:36,396 --> 0:51:37,598
因此我们稍微随机化一点儿

1076
00:51:38,198 --> 0:51:41,134
我马上会与大家分享一些

1077
00:51:41,635 --> 0:51:42,970
（负载平衡）

1078
00:51:43,971 --> 0:51:46,540
关于这个方法

1079
00:51:46,807 --> 0:51:49,376
平铺到GPU的映射

1080
00:51:49,443 --> 0:51:50,611
并没有发生改变

1081
00:51:51,979 --> 0:51:55,582
同一个GPU将处理每帧中

1082
00:51:56,850 --> 0:51:57,718
这很棒

1083
00:51:58,118 --> 0:52:01,622
你只需要在app初始化时

1084
00:51:58,118 --> 0:52:01,622
你只需要在app初始化时

1085
00:52:01,688 --> 0:52:04,157
或你重新调整窗口尺寸时

1086
00:52:04,992 --> 0:52:07,895
你再也不用考虑多GPU负载平衡了

1087
00:52:07,961 --> 0:52:08,996
因为没什么可监控的

1088
00:52:09,062 --> 0:52:11,765
在app的主循环中不需要重新计算

1089
00:52:15,736 --> 0:52:19,106
如果我们知道小平铺会更均匀地

1090
00:52:19,640 --> 0:52:22,276
为什么不把它推到极端

1091
00:52:24,778 --> 0:52:27,447
那么问题是我们需要为

1092
00:52:27,781 --> 0:52:30,083
很好的连贯像素块

1093
00:52:31,418 --> 0:52:32,619
你需要在

1094
00:52:33,220 --> 0:52:36,657
均匀地平衡负载和确保每个GPU

1095
00:52:36,723 --> 0:52:38,158
都尽可能高效地运行之间做出权衡

1096
00:52:40,527 --> 0:52:43,864
为了更好的了解这个权衡

1097
00:52:44,598 --> 0:52:49,603
我们采用了一台新Mac Pro

1098
00:52:49,670 --> 0:52:51,572
这样一共有四个GPU了

1099
00:52:52,372 --> 0:52:55,475
我们试着以各种平铺尺寸

1100
00:52:55,542 --> 0:52:57,211
从而了解平铺尺寸如何影响性能

1101
00:52:59,413 --> 0:53:01,481
当然了 每个人状况可能不同

1102
00:52:59,413 --> 0:53:01,481
当然了 每个人状况可能不同

1103
00:53:02,015 --> 0:53:06,153
但我们发现性能窗口实际上很宽

1104
00:53:07,688 --> 0:53:10,791
因此如果平铺很小

1105
00:53:11,291 --> 0:53:12,860
或如果平铺非常非常大

1106
00:53:13,894 --> 0:53:17,164
但中间的部分非常接近性能峰值

1107
00:53:18,899 --> 0:53:20,200
（平铺分配）

1108
00:53:21,301 --> 0:53:23,036
现在我们已经确定了平铺尺寸

1109
00:53:23,437 --> 0:53:26,773
我们接下来要做的是

1110
00:53:28,575 --> 0:53:31,879
为此 我们先给每个平铺

1111
00:53:31,945 --> 0:53:33,013
生成一个随机编号

1112
00:53:33,547 --> 0:53:36,683
然后把这些随机编号与一组临界值

1113
00:53:38,051 --> 0:53:40,287
随机编号无论处于哪个范围内

1114
00:53:40,554 --> 0:53:42,923
该范围就为我们提供

1115
00:53:44,858 --> 0:53:46,093
举个例子

1116
00:53:46,159 --> 0:53:48,161
如果平铺编号是.4

1117
00:53:48,695 --> 0:53:49,796
我们把它分配给GPU 1

1118
00:53:50,931 --> 0:53:53,734
如果编号是.55

1119
00:53:54,134 --> 0:53:55,169
以此类推

1120
00:53:57,204 --> 0:53:59,139
一旦我们分配好每个平铺

1121
00:53:59,206 --> 0:54:02,276
所得到的输出就是

1122
00:53:59,206 --> 0:54:02,276
所得到的输出就是

1123
00:54:05,512 --> 0:54:07,014
你可以在底部看到

1124
00:54:07,281 --> 0:54:10,350
我们为每个GPU所使用的范围

1125
00:54:11,752 --> 0:54:15,422
当向GPU分配平铺时

1126
00:54:17,991 --> 0:54:20,727
但在实践中 你当然不希望这样

1127
00:54:22,029 --> 0:54:25,699
比如你可能需要在其中一个GPU上

1128
00:54:25,766 --> 0:54:27,301
为非光线追踪任务保留容量

1129
00:54:27,935 --> 0:54:30,137
比如诊断或色调映射

1130
00:54:32,005 --> 0:54:34,408
或你可能使用具有不同性能的GPU

1131
00:54:34,908 --> 0:54:38,245
在那种情况下 你可能希望

1132
00:54:40,280 --> 0:54:42,015
你可以非常轻松地解决这个问题

1133
00:54:42,316 --> 0:54:43,684
只需要调整范围即可

1134
00:54:45,052 --> 0:54:48,422
现在如果我们继续并重新分配

1135
00:54:49,122 --> 0:54:52,759
你可以看到GPU 2

1136
00:54:56,530 --> 0:54:58,432
对于实际实施

1137
00:54:59,166 --> 0:55:00,934
在本周稍早些时候Pro app中

1138
00:54:59,166 --> 0:55:00,934
在本周稍早些时候Pro app中

1139
00:55:01,001 --> 0:55:03,437
有许多非常有用的信息

1140
00:55:03,937 --> 0:55:05,506
因此我就不再这里赘述了

1141
00:55:07,207 --> 0:55:10,043
但强调几个

1142
00:55:10,110 --> 0:55:12,279
对性能有很大影响的方面

1143
00:55:14,715 --> 0:55:17,918
首先你很可能想

1144
00:55:17,985 --> 0:55:19,853
把平铺合成到一起

1145
00:55:21,221 --> 0:55:24,024
重要的是找到具体是哪个GPU

1146
00:55:24,291 --> 0:55:28,328
然后反向找到高效地把数据

1147
00:55:30,063 --> 0:55:31,965
如果GPU属于同一个对等组

1148
00:55:32,533 --> 0:55:36,203
你可以使用我们的新对等组APIs

1149
00:55:37,337 --> 0:55:39,206
否则你就需要通过CPU实现

1150
00:55:42,309 --> 0:55:43,477
其次

1151
00:55:43,544 --> 0:55:47,114
在GPU之间复制数据通常需要

1152
00:55:47,381 --> 0:55:51,118
我们一定不希望停滞并等待

1153
00:55:53,420 --> 0:55:55,622
这里有一个例子展示了

1154
00:55:56,390 --> 0:55:57,858
我们在这里有两个GPU

1155
00:55:57,925 --> 0:56:00,661
并且我们使用了我刚谈到的平铺机制

1156
00:55:57,925 --> 0:56:00,661
并且我们使用了我刚谈到的平铺机制

1157
00:56:00,727 --> 0:56:02,930
用于在两个GPU上展开渲染

1158
00:56:05,032 --> 0:56:07,901
在GPU 0中 在顶部有两个队列

1159
00:56:08,836 --> 0:56:11,138
其中一个只是简单地进行

1160
00:56:11,872 --> 0:56:13,106
然后第二个队列

1161
00:56:13,607 --> 0:56:16,977
异步地把已完成的平铺

1162
00:56:20,280 --> 0:56:22,583
现在我们假设底部的GPU 1

1163
00:56:22,649 --> 0:56:24,218
是驱动显示屏的那个GPU

1164
00:56:24,885 --> 0:56:26,587
这里的情况有点不同

1165
00:56:28,455 --> 0:56:31,725
这个GPU也分担了一部分

1166
00:56:32,559 --> 0:56:34,628
但我们不能继续并呈现那个帧

1167
00:56:35,095 --> 0:56:38,465
除非其余的平铺都已经

1168
00:56:40,267 --> 0:56:41,435
因此与其等待

1169
00:56:41,935 --> 0:56:43,237
我们不如开始处理下一帧

1170
00:56:44,905 --> 0:56:47,975
稍后当我们收到来自其它GPU的

1171
00:56:48,909 --> 0:56:51,311
我们就可以继续

1172
00:56:53,080 --> 0:56:54,281
我再给你们看一次

1173
00:56:56,450 --> 0:56:58,619
你可以看到我们最终处于这种

1174
00:56:59,019 --> 0:57:02,890
我们正在渲染帧N

1175
00:56:59,019 --> 0:57:02,890
我们正在渲染帧N

1176
00:57:04,791 --> 0:57:07,661
因此从根本上说

1177
00:57:08,862 --> 0:57:11,698
这与我刚展示给你们的平铺一起

1178
00:57:11,765 --> 0:57:13,367
在GPU之间负载平衡

1179
00:57:14,268 --> 0:57:16,803
这就在多GPU系统上针对光线追踪

1180
00:57:16,870 --> 0:57:19,773
为我们提供了非常棒的性能

1181
00:57:22,042 --> 0:57:23,677
就这样了 我们的演讲结束了

1182
00:57:24,978 --> 0:57:28,715
我们开始先快速回顾了光线追踪

1183
00:57:29,750 --> 0:57:33,053
然后我们介绍了

1184
00:57:33,120 --> 0:57:35,289
可以帮助我们处理动态场景

1185
00:57:35,923 --> 0:57:38,125
也就是二级加速结构

1186
00:57:38,725 --> 0:57:41,762
以及由GPU加速的重建和再安置

1187
00:57:43,830 --> 0:57:45,866
我们还介绍了新Metal降噪器

1188
00:57:46,633 --> 0:57:49,136
然后我们讲了几个光线追踪的用例

1189
00:57:49,436 --> 0:57:52,573
比如阴影、环境光遮蔽和全局照明

1190
00:57:54,908 --> 0:57:58,212
然后演示了如何使用Xcode

1191
00:57:58,278 --> 0:57:59,279
光线追踪

1192
00:57:59,680 --> 0:58:01,281
最后我们又稍微提了一下

1193
00:57:59,680 --> 0:58:01,281
最后我们又稍微提了一下

1194
00:58:01,348 --> 0:58:06,019
如何在你的光线追踪app中

1195
00:58:06,920 --> 0:58:09,857
要获取更多信息 请访问

1196
00:58:10,757 --> 0:58:12,626
你还可以在网站上找到一些新样本

1197
00:58:12,693 --> 0:58:15,195
演示我们今天所讲到的功能

1198
00:58:16,763 --> 0:58:17,865
如果你不熟悉光线追踪

1199
00:58:18,265 --> 0:58:20,100
请一定要参看我们去年的演讲

1200
00:58:20,667 --> 0:58:23,303
最后 接下来中午12点

1201
00:58:23,570 --> 0:58:24,872
希望大家能加入我们

1202
00:58:26,440 --> 0:58:28,842
非常感谢你们的参与
