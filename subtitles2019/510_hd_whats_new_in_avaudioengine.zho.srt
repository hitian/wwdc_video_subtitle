1
00:00:01,516 --> 0:00:04,500
[音乐]

2
00:00:07,796 --> 0:00:09,296
&gt;&gt; 大家好 欢迎来到

3
00:00:09,296 --> 0:00:11,706
Audio API Updates 会场

4
00:00:12,116 --> 0:00:14,116
我是 Peter Vasil

5
00:00:14,116 --> 0:00:16,276
是 Core Audio 团队的一名软件工程师

6
00:00:18,426 --> 0:00:21,186
我们先来介绍 AVAudioEngine 中的新内容

7
00:00:24,206 --> 0:00:25,226
我们在 AVAudioEngine 中

8
00:00:25,226 --> 0:00:26,976
进行了一些改进

9
00:00:26,976 --> 0:00:27,996
添加了新 API

10
00:00:28,946 --> 0:00:30,946
现在支持语音处理

11
00:00:31,946 --> 0:00:33,486
我们添加了两个新的节点

12
00:00:33,726 --> 0:00:35,346
即 AVAudioSourceNode 和

13
00:00:35,346 --> 0:00:37,646
AVAudioSinkNode 并且

14
00:00:37,646 --> 0:00:40,256
我们还改进了空间音频渲染

15
00:00:41,616 --> 0:00:46,516
现在 我们来谈谈其中的细节

16
00:00:46,516 --> 0:00:49,156
AVAudioEngine 现在拥有语音处理模式

17
00:00:49,726 --> 0:00:51,916
该模式的主要用例

18
00:00:51,916 --> 0:00:54,926
为回音消除和 VoIP App

19
00:00:55,956 --> 0:00:56,836
这意味着什么

20
00:00:57,836 --> 0:00:59,346
启用时将对输入音频

21
00:00:59,346 --> 0:01:00,826
进行额外信号处理

22
00:00:59,346 --> 0:01:00,826
进行额外信号处理

23
00:01:00,826 --> 0:01:03,286
任何设备本身

24
00:01:03,286 --> 0:01:06,046
产生的音频将被剔除

25
00:01:06,816 --> 0:01:10,506
这需要输入和输出节点均处于

26
00:01:10,506 --> 0:01:11,686
语音处理模式

27
00:01:13,126 --> 0:01:15,236
因此 在输入或

28
00:01:15,236 --> 0:01:16,966
输出节点上启用该模式后

29
00:01:17,536 --> 0:01:19,556
引擎便可确保

30
00:01:19,556 --> 0:01:21,406
输入输出节点均已存在

31
00:01:21,406 --> 0:01:23,336
并已切换至语音处理模式

32
00:01:24,966 --> 0:01:26,296
语音处理仅发生在

33
00:01:26,296 --> 0:01:27,886
渲染至音频设备时

34
00:01:27,886 --> 0:01:30,746
而不是在手动渲染

35
00:01:34,326 --> 0:01:35,966
要启用或禁用

36
00:01:35,966 --> 0:01:38,456
语音处理 我们可以在输入

37
00:01:38,496 --> 0:01:40,616
或输出节点启用

38
00:01:40,616 --> 0:01:42,066
setVoiceProcessingEnabled

39
00:01:43,406 --> 0:01:44,826
语音处理无法

40
00:01:44,826 --> 0:01:47,046
动态启用 也就是说

41
00:01:47,106 --> 0:01:48,586
启用该模式时

42
00:01:48,586 --> 0:01:50,466
引擎须处于停止状态

43
00:01:50,466 --> 0:01:54,296
AVEchoTouch 示例代码项目

44
00:01:54,296 --> 0:01:56,726
详细展示了

45
00:01:56,726 --> 0:01:57,826
如何运用 AVAudioEngine

46
00:01:57,826 --> 0:01:59,396
使用语音处理

47
00:01:59,846 --> 0:02:03,616
我们再来看看 AVAudioEngine

48
00:01:59,846 --> 0:02:03,616
我们再来看看 AVAudioEngine

49
00:02:03,616 --> 0:02:06,376
中的新节点 AVAudioSourceNode

50
00:02:06,376 --> 0:02:07,766
和 AVAudioSinkNode

51
00:02:08,955 --> 0:02:10,826
两种节点都封装了用户定义的块

52
00:02:10,826 --> 0:02:13,006
App 可以借此

53
00:02:13,006 --> 0:02:15,006
从 AVAudioEngine 收发音频

54
00:02:16,176 --> 0:02:17,646
渲染至音频设备时

55
00:02:17,646 --> 0:02:20,056
块操作受到实时限制

56
00:02:20,056 --> 0:02:22,796
实时限制 在块内部

57
00:02:22,796 --> 0:02:24,156
不应存在任何阻塞调用

58
00:02:24,156 --> 0:02:26,106
包括内存分配

59
00:02:26,566 --> 0:02:28,066
调用 libdispatch 或

60
00:02:28,066 --> 0:02:28,946
使用互斥锁阻塞

61
00:02:32,936 --> 0:02:35,176
我们使用 AVAudioSourceNode

62
00:02:35,176 --> 0:02:36,566
将块传递或渲染至节点

63
00:02:36,566 --> 0:02:38,736
节点将音频数据传递至输出

64
00:02:40,066 --> 0:02:41,626
这就可以很方便地

65
00:02:41,626 --> 0:02:43,446
创建生成节点 而无需

66
00:02:43,446 --> 0:02:45,406
实现完整的音频单元

67
00:02:45,406 --> 0:02:47,486
并将其与 AVAudio 单元封装

68
00:02:49,046 --> 0:02:51,306
节点可用于

69
00:02:51,306 --> 0:02:53,246
实时渲染和手动渲染两种模式

70
00:02:54,476 --> 0:02:56,726
AVAudioSourceNode 支持

71
00:02:56,726 --> 0:02:59,316
线性 PCM 转换 例如采样率

72
00:02:59,316 --> 0:03:01,056
或位深转换

73
00:02:59,316 --> 0:03:01,056
或位深转换

74
00:03:01,616 --> 0:03:04,996
仅有一个输出且没有输入

75
00:03:09,436 --> 0:03:11,476
这段代码片段展示了

76
00:03:11,476 --> 0:03:13,366
如何使用 AVAudioSourceNode

77
00:03:14,056 --> 0:03:16,096
可见 这个块

78
00:03:16,096 --> 0:03:18,126
作为初始化参数值被传递

79
00:03:18,126 --> 0:03:19,986
节点创建后

80
00:03:19,986 --> 0:03:22,906
便可以像其他节点一样建立连接

81
00:03:23,936 --> 0:03:25,676
更细致的示例

82
00:03:25,676 --> 0:03:27,306
可以在我们的 Signal Generator

83
00:03:27,306 --> 0:03:28,536
示例代码项目中找到

84
00:03:32,356 --> 0:03:34,166
我们来看看 AVAudioSinkNode

85
00:03:34,866 --> 0:03:37,156
AVAudioSinkNode

86
00:03:37,156 --> 0:03:39,256
与 AVAudioSourceNode 对应

87
00:03:40,086 --> 0:03:41,916
它封装了用户定义的块

88
00:03:41,966 --> 0:03:43,636
从节点链接收

89
00:03:43,636 --> 0:03:45,086
输入音频

90
00:03:45,086 --> 0:03:46,446
并连接至输出

91
00:03:47,516 --> 0:03:50,776
AVAudioSinkNode 仅可用于输入链

92
00:03:51,176 --> 0:03:52,746
换言之 它必须

93
00:03:52,746 --> 0:03:54,796
连接至输入节点的下游

94
00:03:56,076 --> 0:03:59,306
它不支持格式转换

95
00:03:59,306 --> 0:04:00,916
块内的格式必须与

96
00:03:59,306 --> 0:04:00,916
块内的格式必须与

97
00:04:00,916 --> 0:04:02,836
硬件输入格式一致

98
00:04:04,236 --> 0:04:06,436
这个节点可以用于

99
00:04:06,436 --> 0:04:09,086
VoIP App

100
00:04:09,086 --> 0:04:10,756
因为此时输入需要实时处理

101
00:04:10,756 --> 0:04:12,596
这种情形下

102
00:04:12,596 --> 0:04:14,256
安装常规的 Tap

103
00:04:14,256 --> 0:04:18,815
并不够 因为 Tap 无法实时运行

104
00:04:21,076 --> 0:04:22,746
这段代码片段

105
00:04:22,746 --> 0:04:24,636
展示了如何创建

106
00:04:24,636 --> 0:04:25,826
AVAudioSinkNode

107
00:04:26,466 --> 0:04:29,206
与创建 AVAudioSourceNode 非常类似

108
00:04:29,976 --> 0:04:32,096
需要注意的主要步骤是

109
00:04:32,096 --> 0:04:33,606
用一个块初始化节点

110
00:04:33,606 --> 0:04:35,836
将其附加在 Engine 上

111
00:04:36,146 --> 0:04:37,676
再将其连接至输入节点

112
00:04:37,676 --> 0:04:39,266
下游的节点上

113
00:04:42,996 --> 0:04:45,576
我们来看看空间渲染的改进

114
00:04:46,666 --> 0:04:48,426
我们引入了自动

115
00:04:48,426 --> 0:04:51,256
空间渲染算法

116
00:04:51,256 --> 0:04:53,486
而且 AVAudioPlayerNode 现在支持

117
00:04:53,486 --> 0:04:56,546
多声道音频内容空间化

118
00:05:00,716 --> 0:05:02,076
自动空间

119
00:05:02,076 --> 0:05:03,806
渲染算法是

120
00:05:03,806 --> 0:05:07,786
当前路由下最适合的空间化算法

121
00:05:08,626 --> 0:05:10,576
这意味着 开发者不需要

122
00:05:10,576 --> 0:05:12,396
专门针对耳机

123
00:05:12,396 --> 0:05:14,066
或不同的扬声器设置

124
00:05:14,066 --> 0:05:15,816
找出最适合的算法

125
00:05:16,896 --> 0:05:18,846
算法为耳机加入了

126
00:05:18,846 --> 0:05:20,856
近场渲染和头内渲染

127
00:05:20,856 --> 0:05:22,426
为内置扬声器加入了虚拟环绕

128
00:05:22,426 --> 0:05:24,546
可以在 2018 年及之后的

129
00:05:24,546 --> 0:05:26,466
iOS 设备和 MacBook 上

130
00:05:26,466 --> 0:05:28,646
提供使用

131
00:05:32,096 --> 0:05:34,026
这是 AVAudio3DMixing

132
00:05:34,026 --> 0:05:36,126
协议中的新 API

133
00:05:36,746 --> 0:05:39,656
AVAudio3DMixingRenderingAlgorithm enum

134
00:05:39,656 --> 0:05:43,006
有了新的条目 auto

135
00:05:44,056 --> 0:05:45,926
此外 我们可以用 outputType 属性

136
00:05:45,926 --> 0:05:48,576
指定输出类型

137
00:05:49,076 --> 0:05:52,346
将属性设定为 auto 时

138
00:05:52,636 --> 0:05:54,146
输出类型可以在

139
00:05:54,146 --> 0:05:56,346
实时模式下被自动检测

140
00:05:56,346 --> 0:05:59,076
但在手动渲染模式中则不然

141
00:06:03,056 --> 0:06:05,116
能够空间化

142
00:06:05,116 --> 0:06:07,546
多声道流

143
00:06:07,546 --> 0:06:09,916
我们便可支持点声源渲染和环境声效渲染

144
00:06:10,816 --> 0:06:12,476
我们也支持基于声道的格式

145
00:06:12,476 --> 0:06:14,066
以及更高阶的

146
00:06:14,066 --> 0:06:15,996
Ambisonics 最高可达三阶

147
00:06:19,616 --> 0:06:20,786
我们为 AVAudio3DMixing 协议

148
00:06:20,786 --> 0:06:22,706
添加了两个新的空间化属性

149
00:06:22,706 --> 0:06:25,946
sourceMode

150
00:06:25,946 --> 0:06:27,996
以及 pointSourceInHeadMode

151
00:06:29,936 --> 0:06:33,056
spatializeIfMono 是过时行为

152
00:06:33,246 --> 0:06:35,416
这与多声道流的

153
00:06:35,416 --> 0:06:37,546
bypass 相同

154
00:06:37,546 --> 0:06:39,596
代表直通或缩混至

155
00:06:39,596 --> 0:06:40,806
输出格式

156
00:06:41,906 --> 0:06:44,016
pointSource 下

157
00:06:44,016 --> 0:06:45,826
音频被归为单声道

158
00:06:45,826 --> 0:06:47,366
并在播放器节点渲染

159
00:06:47,446 --> 0:06:50,096
ambienceBed 下

160
00:06:50,096 --> 0:06:52,246
音频被锚定在三维世界中

161
00:06:52,246 --> 0:06:53,596
并可根据播放器节点

162
00:06:53,596 --> 0:06:55,506
相对听众朝向

163
00:06:55,506 --> 0:06:56,716
所处的位置旋转

164
00:06:59,326 --> 0:07:00,856
这个例子是

165
00:06:59,326 --> 0:07:00,856
这个例子是

166
00:07:00,856 --> 0:07:02,616
环境声效声源模式

167
00:07:02,616 --> 0:07:04,376
自动渲染算法

168
00:07:05,476 --> 0:07:07,496
设定属性后

169
00:07:07,496 --> 0:07:09,156
很重要的一点是确保

170
00:07:09,156 --> 0:07:10,666
连接播放器节点

171
00:07:10,666 --> 0:07:12,426
和环境节点

172
00:07:12,606 --> 0:07:13,836
所用的格式

173
00:07:14,106 --> 0:07:15,936
要包含多声道布局

174
00:07:19,176 --> 0:07:21,546
接下来 我们来看

175
00:07:21,546 --> 0:07:22,606
AVAudioSession 中的新内容

176
00:07:25,316 --> 0:07:27,906
AVAudioSessionPromptStyle 用于

177
00:07:27,906 --> 0:07:30,576
播放语音提示的 App

178
00:07:30,616 --> 0:07:32,366
可以修改

179
00:07:32,366 --> 0:07:34,076
语音提示的样式

180
00:07:35,036 --> 0:07:37,596
例如 如果 Siri 正在讲话

181
00:07:37,596 --> 0:07:39,116
或者通话正在进行

182
00:07:39,506 --> 0:07:41,116
言语导航提示便会

183
00:07:41,116 --> 0:07:42,756
干扰用户体验

184
00:07:43,696 --> 0:07:45,366
我们也不希望 Siri

185
00:07:45,366 --> 0:07:47,046
录下导航提示

186
00:07:47,946 --> 0:07:49,526
比方说 导航 App

187
00:07:49,526 --> 0:07:53,016
应当多关注提示样式的变化

188
00:07:53,016 --> 0:07:55,566
并修改提示 以改善用户体验

189
00:07:56,276 --> 0:07:57,746
我们有三种提示样式

190
00:07:57,916 --> 0:08:00,066
.none .short 和 .normal

191
00:07:57,916 --> 0:08:00,066
.none .short 和 .normal

192
00:08:00,756 --> 0:08:02,676
我们可以指明

193
00:08:02,676 --> 0:08:04,446
完全不播放提示

194
00:08:04,446 --> 0:08:06,496
播放简短提示

195
00:08:06,496 --> 0:08:07,446
或播放常规提示

196
00:08:10,026 --> 0:08:11,126
我们再来看看

197
00:08:11,126 --> 0:08:12,946
AVAudioSession 的其他改进

198
00:08:14,176 --> 0:08:15,766
默认策略是 

199
00:08:15,766 --> 0:08:17,406
音频录制激活时

200
00:08:17,406 --> 0:08:21,766
禁用触觉反馈和系统音效新属性

201
00:08:21,766 --> 0:08:23,076
allowHapticsAndSystemSoundsDuringRecording

202
00:08:23,076 --> 0:08:25,436
可以在会话正在

203
00:08:25,826 --> 0:08:27,186
使用音频录制时

204
00:08:27,186 --> 0:08:28,836
允许播放系统音效

205
00:08:28,836 --> 0:08:29,566
和触觉反馈

206
00:08:30,366 --> 0:08:32,126
它可以使用

207
00:08:32,336 --> 0:08:33,466
set allowHapticsAndSystemSoundsDuringRecording

208
00:08:33,466 --> 0:08:35,376
来设置

209
00:08:37,976 --> 0:08:40,096
欲知更多信息

210
00:08:40,096 --> 0:08:41,846
请访问开发者网站

211
00:08:43,196 --> 0:08:44,936
谢谢收看
