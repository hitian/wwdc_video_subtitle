1
00:00:00,506 --> 0:00:05,500
[ Music ]

2
00:00:09,516 --> 0:00:16,096
[ Applause ]

3
00:00:16,596 --> 0:00:17,216
&gt;&gt; Good morning.

4
00:00:18,406 --> 0:00:21,606
I'm Alex Brown, an Engineer in

5
00:00:21,606 --> 0:00:22,146
Core ML.

6
00:00:23,206 --> 0:00:24,736
And today, we are going to

7
00:00:24,736 --> 0:00:26,816
present Create ML for Object

8
00:00:26,816 --> 0:00:27,366
Detection.

9
00:00:27,786 --> 0:00:30,726
In the What's New in Machine

10
00:00:30,726 --> 0:00:32,235
Learning session, you were

11
00:00:32,235 --> 0:00:34,666
introduced to the new Create ML

12
00:00:34,936 --> 0:00:35,003
app.

13
00:00:36,076 --> 0:00:37,206
It provides a really

14
00:00:37,206 --> 0:00:39,296
approachable way to build custom

15
00:00:39,296 --> 0:00:40,786
machine learning models to add

16
00:00:41,286 --> 0:00:42,466
to your applications.

17
00:00:43,496 --> 0:00:45,906
In this session, we're going to

18
00:00:45,906 --> 0:00:47,756
dig a little deeper into two

19
00:00:47,756 --> 0:00:49,086
specific templates.

20
00:00:49,886 --> 0:00:51,796
Object detection, which works

21
00:00:51,796 --> 0:00:53,606
with images, and sound

22
00:00:53,606 --> 0:00:54,456
classification.

23
00:00:55,056 --> 0:00:59,456
Let's get started with object

24
00:00:59,456 --> 0:01:00,046
detection.

25
00:00:59,456 --> 0:01:00,046
detection.

26
00:01:02,506 --> 0:01:05,506
Object detection enables your

27
00:01:05,506 --> 0:01:07,316
application to identify

28
00:01:07,316 --> 0:01:09,076
real-world objects captured by

29
00:01:09,076 --> 0:01:10,856
your device's camera, and

30
00:01:10,856 --> 0:01:13,226
respond based on their presence,

31
00:01:13,806 --> 0:01:16,246
position, and relationship.

32
00:01:17,116 --> 0:01:19,406
You can download object

33
00:01:19,406 --> 0:01:21,026
detectors from the web which

34
00:01:21,026 --> 0:01:22,176
know the difference between

35
00:01:22,176 --> 0:01:23,756
broad categories of objects.

36
00:01:25,386 --> 0:01:27,086
But by training a custom machine

37
00:01:27,086 --> 0:01:29,046
learning model on your own data,

38
00:01:29,636 --> 0:01:31,166
you can teach your application

39
00:01:31,166 --> 0:01:32,506
about the subtle differences

40
00:01:33,046 --> 0:01:35,306
between individual animals, hand

41
00:01:35,306 --> 0:01:38,146
gestures, street signs, or game

42
00:01:38,146 --> 0:01:38,816
tokens.

43
00:01:39,396 --> 0:01:43,056
If you've used machine learning

44
00:01:43,316 --> 0:01:45,086
with Apple before, you may

45
00:01:45,086 --> 0:01:47,036
already be familiar with image

46
00:01:47,036 --> 0:01:47,936
classification.

47
00:01:49,456 --> 0:01:51,896
With image classification, you

48
00:01:51,896 --> 0:01:53,636
build a model which can provide

49
00:01:53,636 --> 0:01:55,596
a single simple description of

50
00:01:55,596 --> 0:01:56,146
an image.

51
00:01:57,656 --> 0:01:59,626
This image we might describe as

52
00:02:00,166 --> 0:02:02,976
outdoors or park, or for a

53
00:02:02,976 --> 0:02:05,476
particular application, dog.

54
00:02:08,056 --> 0:02:10,346
But what if we're interested in

55
00:02:10,346 --> 0:02:11,526
more than one object in the

56
00:02:11,526 --> 0:02:11,936
scene?

57
00:02:12,306 --> 0:02:16,286
In this case, object detection

58
00:02:16,466 --> 0:02:18,086
can come to the rescue.

59
00:02:18,586 --> 0:02:20,616
It can identify multiple objects

60
00:02:20,826 --> 0:02:22,596
within your photograph, and

61
00:02:22,596 --> 0:02:25,456
provide the location, size, and

62
00:02:25,456 --> 0:02:26,726
label for each one.

63
00:02:27,646 --> 0:02:29,966
This can enable your application

64
00:02:29,966 --> 0:02:31,806
to do more sophisticated things

65
00:02:32,096 --> 0:02:34,436
using your camera, but in order

66
00:02:34,436 --> 0:02:36,136
to do that, we need to go into

67
00:02:36,136 --> 0:02:37,776
more detail when teaching the

68
00:02:37,776 --> 0:02:39,676
model about your images.

69
00:02:41,756 --> 0:02:45,296
To train an object detector, you

70
00:02:45,296 --> 0:02:47,796
need to annotate each image with

71
00:02:47,796 --> 0:02:49,326
labeled regions that you would

72
00:02:49,326 --> 0:02:50,836
like the model to recognize.

73
00:02:51,606 --> 0:02:53,786
The bounding box for your

74
00:02:53,786 --> 0:02:56,266
annotated objects starting at

75
00:02:56,266 --> 0:02:57,576
the center of each object of

76
00:02:57,576 --> 0:03:00,116
interest and having a size,

77
00:02:57,576 --> 0:03:00,116
interest and having a size,

78
00:03:00,206 --> 0:03:03,066
height, and width, this is

79
00:03:03,156 --> 0:03:05,376
measured in pixels from the top

80
00:03:05,376 --> 0:03:07,306
left-hand corner of your image

81
00:03:08,136 --> 0:03:11,066
to the center of each object of

82
00:03:11,956 --> 0:03:12,436
interest.

83
00:03:12,886 --> 0:03:14,806
You bundle together all of these

84
00:03:14,806 --> 0:03:17,736
annotations, label, position,

85
00:03:17,736 --> 0:03:20,356
and size, in a JSON file in the

86
00:03:20,356 --> 0:03:21,226
following format.

87
00:03:21,946 --> 0:03:26,986
You can download tools from the

88
00:03:26,986 --> 0:03:29,176
web to help you build these, but

89
00:03:29,466 --> 0:03:31,016
make sure they use the same

90
00:03:31,016 --> 0:03:33,206
coordinate system the Create ML

91
00:03:34,506 --> 0:03:35,646
app expects.

92
00:03:35,966 --> 0:03:37,216
Once you've assembled your

93
00:03:37,256 --> 0:03:40,256
annotations, simply drop them

94
00:03:40,256 --> 0:03:41,716
into the same folder as the

95
00:03:41,776 --> 0:03:44,446
images they describe, and that's

96
00:03:44,446 --> 0:03:44,686
it.

97
00:03:45,896 --> 0:03:50,176
Your training data is ready.

98
00:03:50,336 --> 0:03:52,576
So now we know how to create

99
00:03:52,576 --> 0:03:53,886
training data for object

100
00:03:53,886 --> 0:03:54,436
detection.

101
00:03:55,176 --> 0:03:56,656
Let's consider a real case.

102
00:03:58,266 --> 0:03:59,736
My colleague, Scott, has got a

103
00:03:59,736 --> 0:04:01,876
great idea for building a math

104
00:03:59,736 --> 0:04:01,876
great idea for building a math

105
00:04:01,876 --> 0:04:03,786
game that is really engaging for

106
00:04:03,786 --> 0:04:06,676
kids, and uses real-world dice

107
00:04:07,066 --> 0:04:08,376
to provide the questions.

108
00:04:10,116 --> 0:04:11,346
You can hear more about this

109
00:04:11,346 --> 0:04:13,546
application in session 228,

110
00:04:14,046 --> 0:04:16,616
Creating Great Apps Using Core

111
00:04:16,616 --> 0:04:18,685
ML and AR Kit.

112
00:04:19,236 --> 0:04:21,106
So, Scott asked me to help build

113
00:04:21,106 --> 0:04:23,436
a model for his game, and I

114
00:04:23,436 --> 0:04:25,576
suggested using Apple's Create

115
00:04:25,576 --> 0:04:27,716
ML application to train an

116
00:04:27,716 --> 0:04:28,546
object detector.

117
00:04:29,136 --> 0:04:33,316
Scott has already sent me the

118
00:04:33,316 --> 0:04:34,036
training data.

119
00:04:35,346 --> 0:04:36,706
He took a bunch of images of

120
00:04:36,736 --> 0:04:38,816
dice from different angles and

121
00:04:38,816 --> 0:04:39,776
with different values on the

122
00:04:39,776 --> 0:04:41,976
top, and he's annotated them,

123
00:04:42,406 --> 0:04:44,636
drawing bounding boxes around

124
00:04:44,636 --> 0:04:47,056
the top face and adding a label,

125
00:04:47,056 --> 0:04:48,766
counting the number of pips on

126
00:04:50,016 --> 0:04:51,816
each dice.

127
00:04:52,476 --> 0:04:54,066
So, now we've got our data

128
00:04:54,066 --> 0:04:54,336
ready.

129
00:04:54,906 --> 0:04:56,266
Let's take a look at how we can

130
00:04:56,266 --> 0:04:57,866
use the Create ML application to

131
00:04:57,866 --> 0:04:58,566
build our model.

132
00:05:07,056 --> 0:05:10,146
So first of all, let's just

133
00:05:10,146 --> 0:05:10,796
check the data.

134
00:05:12,326 --> 0:05:13,646
You can see we've put all of our

135
00:05:13,646 --> 0:05:18,766
images in a folder, and each one

136
00:05:18,856 --> 0:05:22,236
contains multiple dice, and

137
00:05:23,286 --> 0:05:24,416
we've gathered together the

138
00:05:24,416 --> 0:05:26,176
annotations in a single JSON

139
00:05:26,176 --> 0:05:26,486
file.

140
00:05:28,276 --> 0:05:30,626
So now, I'll open the Create ML

141
00:05:30,626 --> 0:05:31,286
application.

142
00:05:31,836 --> 0:05:33,786
I can do this from inside X

143
00:05:33,786 --> 0:05:35,766
code's menu, or I can just use

144
00:05:35,766 --> 0:05:36,286
Spotlight.

145
00:05:40,696 --> 0:05:42,106
When the Create ML application

146
00:05:42,106 --> 0:05:44,226
opens, it gives us the option to

147
00:05:44,226 --> 0:05:45,446
access documents we already

148
00:05:45,446 --> 0:05:45,976
created.

149
00:05:46,586 --> 0:05:50,666
Here, we want a new project.

150
00:05:50,756 --> 0:05:52,376
First, you'll see the template

151
00:05:52,376 --> 0:05:54,076
picker, which give you a

152
00:05:54,076 --> 0:05:55,586
collection of machine learning

153
00:05:55,586 --> 0:05:57,056
model types to select from.

154
00:05:57,646 --> 0:05:59,756
In this case, we want an image

155
00:06:00,006 --> 0:06:01,596
object detector.

156
00:06:04,476 --> 0:06:06,156
I give it a name, so we can

157
00:06:06,156 --> 0:06:08,116
identify it later on, and fill

158
00:06:08,116 --> 0:06:09,246
in a few details.

159
00:06:15,666 --> 0:06:17,976
Here, you can see the main

160
00:06:17,976 --> 0:06:20,196
window with the training view on

161
00:06:20,196 --> 0:06:20,956
the right-hand side.

162
00:06:20,956 --> 0:06:22,706
It has already selected the

163
00:06:22,706 --> 0:06:24,516
input tab, ready for our

164
00:06:24,516 --> 0:06:25,196
training data.

165
00:06:25,926 --> 0:06:27,816
I can drag that straight into

166
00:06:27,816 --> 0:06:30,606
the training data well.

167
00:06:31,166 --> 0:06:32,676
Even before training the model,

168
00:06:33,266 --> 0:06:34,686
the application takes a look at

169
00:06:34,686 --> 0:06:36,416
the data, and checks it's in the

170
00:06:36,416 --> 0:06:38,566
right format, contains images

171
00:06:38,656 --> 0:06:40,236
rather than sound, for instance,

172
00:06:40,506 --> 0:06:41,886
and has a JSON file, which

173
00:06:41,886 --> 0:06:43,626
correctly describes them.

174
00:06:43,926 --> 0:06:45,536
It also provides some initial

175
00:06:45,536 --> 0:06:46,376
statistics.

176
00:06:46,916 --> 0:06:48,226
Here, we can see we have around

177
00:06:48,226 --> 0:06:51,526
1,000 images, and there are six

178
00:06:51,526 --> 0:06:54,236
classes, six, for the six sides

179
00:06:54,236 --> 0:06:55,476
of a six-sided dice.

180
00:06:56,556 --> 0:06:57,356
That's perfect.

181
00:06:59,576 --> 0:07:00,716
We can do some other things on

182
00:06:59,576 --> 0:07:00,716
We can do some other things on

183
00:07:00,716 --> 0:07:01,296
this screen.

184
00:07:01,446 --> 0:07:03,006
For instance, we can supply

185
00:07:03,006 --> 0:07:04,786
testing data, to allow us to

186
00:07:04,786 --> 0:07:06,226
compare the performance of two

187
00:07:06,226 --> 0:07:07,036
different models.

188
00:07:07,686 --> 0:07:09,816
Also, we can set some advanced

189
00:07:09,816 --> 0:07:11,276
parameters, tuning the way the

190
00:07:11,276 --> 0:07:12,216
model trains.

191
00:07:12,716 --> 0:07:13,956
But we don't need to worry about

192
00:07:13,956 --> 0:07:15,266
any of that right now, we're

193
00:07:15,266 --> 0:07:16,296
actually ready to train.

194
00:07:17,466 --> 0:07:19,036
Let's hit the play button, and

195
00:07:19,036 --> 0:07:19,856
see what happens.

196
00:07:21,616 --> 0:07:22,976
Training has begun.

197
00:07:23,826 --> 0:07:25,546
It takes us instantly to the

198
00:07:25,546 --> 0:07:28,086
Training tab, where we can see

199
00:07:28,086 --> 0:07:29,216
the progress of the model

200
00:07:29,216 --> 0:07:29,706
training.

201
00:07:30,006 --> 0:07:32,316
This is a graph of loss.

202
00:07:32,506 --> 0:07:34,426
Loss decreases as the model gets

203
00:07:34,426 --> 0:07:35,136
better and better.

204
00:07:35,486 --> 0:07:36,936
So we should see this converge

205
00:07:37,076 --> 0:07:41,226
down to the bottom of the graph.

206
00:07:42,016 --> 0:07:43,906
Object detection takes a lot

207
00:07:43,906 --> 0:07:45,136
longer to train than image

208
00:07:45,136 --> 0:07:45,896
classification.

209
00:07:46,506 --> 0:07:47,776
I estimate this is probably

210
00:07:47,776 --> 0:07:49,336
going to take an hour or more.

211
00:07:49,726 --> 0:07:51,466
We don't want to wait for that,

212
00:07:51,466 --> 0:07:53,236
so I've already trained a model

213
00:07:53,346 --> 0:07:53,976
using this data.

214
00:08:03,496 --> 0:08:05,486
Here we are, and I can jump to

215
00:08:05,486 --> 0:08:06,966
the same training tab that we

216
00:08:06,966 --> 0:08:07,636
just looked at.

217
00:08:08,706 --> 0:08:10,396
You can see that the loss has

218
00:08:10,396 --> 0:08:11,996
neatly declined, showing the

219
00:08:11,996 --> 0:08:13,106
performance of the model has

220
00:08:13,106 --> 0:08:14,706
really increased over the time

221
00:08:14,706 --> 0:08:15,466
it took to train.

222
00:08:16,506 --> 0:08:17,636
There's a couple of other things

223
00:08:17,636 --> 0:08:18,416
that you should really have a

224
00:08:18,416 --> 0:08:19,546
look at on this screen.

225
00:08:20,416 --> 0:08:22,546
First of all, the overall

226
00:08:22,546 --> 0:08:23,336
performance.

227
00:08:23,686 --> 0:08:25,396
Ninety-two percent, which is a

228
00:08:25,396 --> 0:08:26,606
really great number for an

229
00:08:26,606 --> 0:08:27,436
object detector.

230
00:08:29,116 --> 0:08:30,746
We also want to have a look and

231
00:08:30,746 --> 0:08:32,456
check that we have consistent

232
00:08:32,456 --> 0:08:33,946
performance across all of the

233
00:08:33,946 --> 0:08:34,676
classes.

234
00:08:35,746 --> 0:08:38,446
The classes, 1 to 6, each here

235
00:08:38,546 --> 0:08:41,015
has 90% or more, and they're

236
00:08:41,015 --> 0:08:42,056
about the same value.

237
00:08:42,645 --> 0:08:45,036
This is important because it

238
00:08:45,036 --> 0:08:46,096
shows that it is performing

239
00:08:46,096 --> 0:08:47,486
equally well on the six sides of

240
00:08:47,486 --> 0:08:48,076
the dice.

241
00:08:48,806 --> 0:08:50,086
For a game of dice, where

242
00:08:50,086 --> 0:08:51,826
fairness is important, that's

243
00:08:51,826 --> 0:08:52,586
pretty important.

244
00:08:53,136 --> 0:08:57,796
So, the model has told us

245
00:08:57,946 --> 0:08:59,396
mathematically that it's pretty

246
00:08:59,396 --> 0:09:00,696
good, but how do we get

247
00:08:59,396 --> 0:09:00,696
good, but how do we get

248
00:09:00,696 --> 0:09:01,886
confidence that it's going to

249
00:09:01,886 --> 0:09:03,446
work for our cases?

250
00:09:04,316 --> 0:09:06,266
Well, we can use the output tab.

251
00:09:07,816 --> 0:09:09,416
Scott sent me a test image to

252
00:09:09,416 --> 0:09:11,106
try out before I send the model

253
00:09:11,106 --> 0:09:12,746
back to him, so let's drag that

254
00:09:12,746 --> 0:09:12,976
in now.

255
00:09:20,036 --> 0:09:21,256
That's looking pretty great.

256
00:09:21,896 --> 0:09:22,766
You can see that it is

257
00:09:22,766 --> 0:09:24,546
identified, the five dice in the

258
00:09:24,546 --> 0:09:24,966
scene.

259
00:09:25,196 --> 0:09:27,146
It has correctly drawn the box

260
00:09:27,146 --> 0:09:29,746
around their top faces, and by

261
00:09:29,746 --> 0:09:34,526
clicking through, 6, 1, 5, we

262
00:09:34,526 --> 0:09:36,386
can see each label, and the

263
00:09:36,386 --> 0:09:37,546
confidence is assigned.

264
00:09:39,456 --> 0:09:41,086
That's performing really well.

265
00:09:41,786 --> 0:09:43,726
So, if I was building my own

266
00:09:44,556 --> 0:09:46,436
app, I could go ahead and drag

267
00:09:46,466 --> 0:09:47,756
the model that has been produced

268
00:09:48,136 --> 0:09:49,456
and use it within Xcode.

269
00:09:50,316 --> 0:09:51,926
I think Scott is probably

270
00:09:51,926 --> 0:09:53,196
waiting for this model to build

271
00:09:53,196 --> 0:09:53,976
his application.

272
00:09:55,306 --> 0:09:57,396
But before we go there, there's

273
00:09:57,396 --> 0:09:58,336
something I want to try.

274
00:10:00,556 --> 0:10:01,816
While I was preparing for this

275
00:10:01,846 --> 0:10:03,936
demo, playing with dice, and a

276
00:10:03,936 --> 0:10:06,146
camera, and my computer, my son,

277
00:10:06,146 --> 0:10:07,886
who is 9, came over and asked

278
00:10:07,886 --> 0:10:09,116
what I was doing.

279
00:10:10,276 --> 0:10:11,826
Once I'd explained it, he got

280
00:10:11,826 --> 0:10:13,226
pretty excited, and already

281
00:10:13,226 --> 0:10:14,586
started coming up with an idea

282
00:10:14,586 --> 0:10:17,056
for a game which had animals,

283
00:10:17,056 --> 0:10:18,446
bears, and bats, and they

284
00:10:18,686 --> 0:10:20,456
cooperate to collect bolts to

285
00:10:20,456 --> 0:10:21,226
build a space ship.

286
00:10:21,476 --> 0:10:23,586
And they use dice, colored dice,

287
00:10:23,586 --> 0:10:24,836
to level up for each different

288
00:10:24,836 --> 0:10:25,436
kind of monster.

289
00:10:26,946 --> 0:10:28,716
So we got his dice, and I

290
00:10:28,716 --> 0:10:30,506
decided to try them with Scott's

291
00:10:30,506 --> 0:10:30,786
model.

292
00:10:31,236 --> 0:10:33,806
So the dice he's using are a

293
00:10:33,806 --> 0:10:34,636
little bit different.

294
00:10:35,206 --> 0:10:36,506
They're role-playing dice,

295
00:10:36,896 --> 0:10:40,556
so let's see how the model

296
00:10:40,556 --> 0:10:41,196
performs.

297
00:10:42,126 --> 0:10:43,816
Using the Max Continuity Camera

298
00:10:43,816 --> 0:10:46,336
feature, I can import an image

299
00:10:47,316 --> 0:10:49,036
directly from my phone.

300
00:10:49,436 --> 0:10:50,546
This is really great because it

301
00:10:50,596 --> 0:10:52,186
means it's using the same glass,

302
00:10:52,296 --> 0:10:53,536
the same camera that your

303
00:10:53,536 --> 0:10:54,736
application will use.

304
00:10:57,176 --> 0:10:59,286
I take the photo and click Use

305
00:10:59,286 --> 0:10:59,796
Photo.

306
00:11:00,346 --> 0:11:04,716
And it's instantly analyzed it.

307
00:11:04,876 --> 0:11:06,276
So let's take a moment to have a

308
00:11:06,376 --> 0:11:07,556
look at what is going on here.

309
00:11:08,216 --> 0:11:11,876
It has correctly spotted the two

310
00:11:12,026 --> 0:11:15,376
six-sided dice with pips, and it

311
00:11:15,376 --> 0:11:18,056
has given them the right labels.

312
00:11:18,476 --> 0:11:20,966
It has ignored most of the other

313
00:11:20,966 --> 0:11:23,306
dice in the picture, except for

314
00:11:23,306 --> 0:11:24,246
a couple over here.

315
00:11:28,156 --> 0:11:29,596
It has given those the wrong

316
00:11:29,596 --> 0:11:30,206
numbers.

317
00:11:30,436 --> 0:11:31,986
So why is this?

318
00:11:32,336 --> 0:11:34,806
The problem here is a difference

319
00:11:34,806 --> 0:11:35,726
in expectation.

320
00:11:36,596 --> 0:11:37,896
Scott knows the dice that are

321
00:11:37,896 --> 0:11:39,726
going to be used are six-sided

322
00:11:39,806 --> 0:11:41,036
white dice with pips.

323
00:11:41,686 --> 0:11:43,226
My son's idea of dice is quite

324
00:11:43,226 --> 0:11:43,636
different.

325
00:11:44,006 --> 0:11:44,956
They're colored.

326
00:11:44,956 --> 0:11:46,406
They don't just have six sides.

327
00:11:47,266 --> 0:11:49,246
So how might we address this in

328
00:11:49,246 --> 0:11:50,006
our application?

329
00:11:51,006 --> 0:11:52,926
Well, either we can insist on

330
00:11:52,926 --> 0:11:54,206
using the dice that maybe are

331
00:11:54,206 --> 0:11:56,316
supplied with the game in the

332
00:11:56,316 --> 0:11:58,806
classroom, or we can train the

333
00:11:58,806 --> 0:12:00,536
model with these dice.

334
00:11:58,806 --> 0:12:00,536
model with these dice.

335
00:12:00,836 --> 0:12:02,016
There are two ways we can

336
00:12:02,016 --> 0:12:02,766
approach this.

337
00:12:03,366 --> 0:12:05,166
Either we can decide that only

338
00:12:05,166 --> 0:12:06,726
the six-sided dice with pips are

339
00:12:06,726 --> 0:12:08,556
valid, but we want to exclude

340
00:12:08,556 --> 0:12:11,026
the other dice, in which case,

341
00:12:11,276 --> 0:12:13,096
we just need to take photographs

342
00:12:13,096 --> 0:12:14,666
containing both kinds of dice,

343
00:12:15,326 --> 0:12:16,836
and just label the six-sided

344
00:12:16,836 --> 0:12:17,286
ones.

345
00:12:18,246 --> 0:12:20,466
Or if we were building a bear

346
00:12:20,776 --> 0:12:23,516
and bat game, we might like to

347
00:12:23,516 --> 0:12:25,096
add the other kinds of dice into

348
00:12:25,096 --> 0:12:26,546
our model, and label those too,

349
00:12:27,386 --> 0:12:28,916
either just using their numbers

350
00:12:29,236 --> 0:12:30,946
or adding extra labels to

351
00:12:30,946 --> 0:12:32,076
distinguish the colors.

352
00:12:32,806 --> 0:12:35,576
Red 6, black 4, etc.

353
00:12:38,466 --> 0:12:40,626
So let's send this model on to

354
00:12:40,626 --> 0:12:42,656
Scott, so he can build his demo.

355
00:12:43,266 --> 0:12:45,556
I can use the Share button to

356
00:12:45,556 --> 0:12:47,000
simply mail the model.

357
00:12:54,226 --> 0:12:55,176
And there we have it.

358
00:12:57,516 --> 0:13:01,500
[ Applause ]

359
00:12:57,516 --> 0:13:01,500
[ Applause ]

360
00:13:07,256 --> 0:13:08,396
&gt;&gt; So, we've seen how you can

361
00:13:08,396 --> 0:13:10,696
use the Create ML application to

362
00:13:10,696 --> 0:13:12,726
train your object detector on

363
00:13:12,726 --> 0:13:13,776
training data that you've

364
00:13:13,776 --> 0:13:14,336
collected.

365
00:13:14,746 --> 0:13:16,526
There are some things I'd like

366
00:13:16,526 --> 0:13:17,896
you to consider when building

367
00:13:17,896 --> 0:13:18,726
that training data.

368
00:13:19,626 --> 0:13:21,496
Firstly, you should have a

369
00:13:21,496 --> 0:13:23,376
balanced number of images with

370
00:13:23,376 --> 0:13:25,116
annotations for each class.

371
00:13:26,416 --> 0:13:28,266
This tells the algorithm that

372
00:13:28,266 --> 0:13:29,646
you consider each of these to be

373
00:13:29,646 --> 0:13:31,276
equally important, and we can

374
00:13:31,276 --> 0:13:32,556
build a model which performs

375
00:13:32,556 --> 0:13:35,106
equally well on all of the

376
00:13:35,146 --> 0:13:35,746
classes.

377
00:13:37,456 --> 0:13:39,196
Secondly, you are going to need

378
00:13:39,196 --> 0:13:40,096
a bunch of images.

379
00:13:40,266 --> 0:13:42,036
I recommend you start with 30

380
00:13:42,036 --> 0:13:44,206
images with annotations for each

381
00:13:44,246 --> 0:13:45,346
class you want the model to

382
00:13:45,346 --> 0:13:47,546
recognize, and increase that

383
00:13:47,546 --> 0:13:49,256
number if you find performance

384
00:13:49,256 --> 0:13:51,086
isn't good enough, or if your

385
00:13:51,086 --> 0:13:52,236
subjects are particularly

386
00:13:52,236 --> 0:13:52,906
complicated.

387
00:13:53,186 --> 0:13:54,196
For instance, they look

388
00:13:54,196 --> 0:13:56,000
different on different sides.

389
00:13:59,376 --> 0:14:00,566
What about the issue we

390
00:13:59,376 --> 0:14:00,566
What about the issue we

391
00:14:00,566 --> 0:14:01,626
encountered with the different

392
00:14:01,626 --> 0:14:02,376
colored dice?

393
00:14:02,946 --> 0:14:04,716
Well, that's not the only way

394
00:14:04,716 --> 0:14:05,626
pictures might differ.

395
00:14:06,696 --> 0:14:09,036
We recommend you consider how

396
00:14:09,036 --> 0:14:10,406
the application will be used in

397
00:14:10,406 --> 0:14:11,086
the real world.

398
00:14:11,776 --> 0:14:13,696
Your users may not have studio

399
00:14:13,696 --> 0:14:15,656
lighting, standard dice, and a

400
00:14:15,656 --> 0:14:16,956
beautiful wooden desk to work

401
00:14:16,956 --> 0:14:17,126
with.

402
00:14:18,176 --> 0:14:20,486
Perhaps ask your friends to

403
00:14:20,486 --> 0:14:21,956
collect additional data in

404
00:14:21,956 --> 0:14:23,896
different scenarios, such as

405
00:14:24,226 --> 0:14:26,296
indoor lighting, outdoors in the

406
00:14:26,296 --> 0:14:28,826
sun, different backgrounds, and

407
00:14:28,906 --> 0:14:30,406
add in different objects that

408
00:14:30,406 --> 0:14:31,956
you aren't using for your model.

409
00:14:32,796 --> 0:14:34,336
This helps the model generalize

410
00:14:34,336 --> 0:14:34,856
really well.

411
00:14:39,046 --> 0:14:40,146
Something that may be surprising

412
00:14:40,146 --> 0:14:42,326
to you, if you've used an image

413
00:14:42,326 --> 0:14:44,376
classifier before, is that one

414
00:14:44,376 --> 0:14:45,156
label is enough.

415
00:14:46,316 --> 0:14:48,186
This is because by explaining a

416
00:14:48,186 --> 0:14:49,686
part of your image that is a

417
00:14:49,686 --> 0:14:51,676
dog, you're also saying that the

418
00:14:51,676 --> 0:14:53,516
rest of it isn't, and the model

419
00:14:53,516 --> 0:14:54,416
trains accordingly.

420
00:14:55,506 --> 0:14:57,506
So, for example, if you were

421
00:14:57,506 --> 0:14:59,156
building an application to count

422
00:14:59,156 --> 0:15:00,576
the number of pickle jars in

423
00:14:59,156 --> 0:15:00,576
the number of pickle jars in

424
00:15:00,576 --> 0:15:02,366
your fridge, you don't need to

425
00:15:02,366 --> 0:15:03,166
label all of the other

426
00:15:03,166 --> 0:15:03,816
condiments.

427
00:15:03,986 --> 0:15:05,476
It automatically infers that

428
00:15:05,476 --> 0:15:06,616
they're not pickle jars.

429
00:15:08,656 --> 0:15:12,646
Once you've built your model,

430
00:15:12,646 --> 0:15:14,616
and you want to add the

431
00:15:14,616 --> 0:15:15,716
functionality into your

432
00:15:15,716 --> 0:15:18,326
application, we recommend you

433
00:15:18,326 --> 0:15:19,416
use the vision framework.

434
00:15:20,216 --> 0:15:21,926
The vision framework can

435
00:15:21,926 --> 0:15:24,016
seamlessly integrate live camera

436
00:15:24,396 --> 0:15:26,566
as well as video into your model

437
00:15:26,566 --> 0:15:27,000
flow.

438
00:15:29,346 --> 0:15:30,996
And that's all there is to

439
00:15:30,996 --> 0:15:32,446
training object detectors.

440
00:15:33,516 --> 0:15:39,960
[ Applause ]
