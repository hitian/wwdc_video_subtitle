1
00:00:00,506 --> 0:00:05,500
[音乐]

2
00:00:10,976 --> 0:00:12,336
[掌声]

3
00:00:12,336 --> 0:00:12,786
&gt;&gt; 早上好

4
00:00:14,756 --> 0:00:15,836
欢迎来到有关 Turi Create 里

5
00:00:15,836 --> 0:00:17,266
绘画分类和

6
00:00:17,266 --> 0:00:19,276
单样本目标检测的分会场

7
00:00:19,956 --> 0:00:21,416
我叫 Sam 接下来

8
00:00:21,416 --> 0:00:22,406
我会和我的同事

9
00:00:22,536 --> 0:00:24,306
Shantanu 和 Abhishek 一起来

10
00:00:24,306 --> 0:00:25,166
和你聊聊我们为了

11
00:00:25,166 --> 0:00:27,036
让你的 App 的体验更丰富

12
00:00:27,036 --> 0:00:29,836
做出的努力

13
00:00:29,986 --> 0:00:30,746
那我们开始吧

14
00:00:32,206 --> 0:00:35,546
首先 我们复习一下 Turi Create 是什么

15
00:00:36,646 --> 0:00:38,656
Turi Create 是一个用来创建

16
00:00:38,986 --> 0:00:40,846
Core ML 模型的 Python 库

17
00:00:41,406 --> 0:00:44,286
它具有简单易用的

18
00:00:44,476 --> 0:00:45,826
任务导向的 API

19
00:00:46,966 --> 0:00:49,136
所谓任务 是指

20
00:00:49,136 --> 0:00:50,756
复杂的机器学习算法集合

21
00:00:50,756 --> 0:00:52,606
被抽象成一种

22
00:00:52,606 --> 0:00:55,056
简单易用的解决方案

23
00:00:55,056 --> 0:00:57,066
便于你们构建模型

24
00:00:57,616 --> 0:01:00,326
它是跨平台的

25
00:00:57,616 --> 0:01:00,326
它是跨平台的

26
00:01:00,326 --> 0:01:02,966
能同时在 Mac OS 和 Linux 上工作

27
00:01:02,966 --> 0:01:04,296
我们很骄傲骄傲能将它开源

28
00:01:04,355 --> 0:01:05,936
与社区一起开发功能

29
00:01:05,936 --> 0:01:08,286
修复错误

30
00:01:08,896 --> 0:01:12,246
我们打造 Turi Create

31
00:01:12,246 --> 0:01:14,596
是为了方便你们为智能应用

32
00:01:14,596 --> 0:01:16,416
构建 Core ML 模型

33
00:01:17,646 --> 0:01:19,946
为了构建这些模型

34
00:01:19,946 --> 0:01:21,286
我们整合了诸多

35
00:01:21,286 --> 0:01:22,956
系统构架

36
00:01:22,956 --> 0:01:25,276
从 PencilKit 和 Core Motion 之类的

37
00:01:25,366 --> 0:01:26,976
构架中采集数据

38
00:01:28,496 --> 0:01:30,476
模型构建好之后

39
00:01:30,476 --> 0:01:31,756
我们将它与其他系统构架进行整合

40
00:01:31,756 --> 0:01:34,676
例如 Vision 和 Sound Analysis 

41
00:01:34,676 --> 0:01:36,526
创造出超乎想象的

42
00:01:36,526 --> 0:01:38,196
App 体验

43
00:01:39,956 --> 0:01:41,696
假如你想做一个 App

44
00:01:41,696 --> 0:01:43,776
用来检测各种乐器

45
00:01:45,066 --> 0:01:47,066
[吉他音效]

46
00:01:47,156 --> 0:01:49,156
使用麦克风的数据

47
00:01:49,156 --> 0:01:50,576
你可以得知正在演奏的乐器

48
00:01:50,676 --> 0:01:55,176
也可以为乐器调音

49
00:01:55,176 --> 0:01:57,036
或者假如你想使用

50
00:01:57,066 --> 0:01:58,876
Apple Watch 传感器的原始数据

51
00:01:59,276 --> 0:02:01,096
来判别某用户

52
00:01:59,276 --> 0:02:01,096
来判别某用户

53
00:02:01,096 --> 0:02:04,966
在健身房的训练类型

54
00:02:05,166 --> 0:02:07,466
或者假如你想通过

55
00:02:07,466 --> 0:02:09,996
图像数据来判别

56
00:02:09,996 --> 0:02:12,006
用户手上正拿着何种食材

57
00:02:12,006 --> 0:02:15,636
从而给出推荐的食谱

58
00:02:16,096 --> 0:02:18,476
这些统统可行

59
00:02:18,916 --> 0:02:20,256
因为我们做了一个

60
00:02:20,256 --> 0:02:22,126
智能的 Core ML 模型

61
00:02:23,196 --> 0:02:25,396
要构建这些模型

62
00:02:25,396 --> 0:02:28,116
我们总结出了五步的工作流程

63
00:02:29,276 --> 0:02:31,246
第一步

64
00:02:31,246 --> 0:02:32,946
明确任务 或者说

65
00:02:32,946 --> 0:02:34,926
需要解决的问题是什么

66
00:02:35,476 --> 0:02:38,746
第二步 收集数据

67
00:02:38,746 --> 0:02:41,246
有时候是海量的数据

68
00:02:42,136 --> 0:02:44,506
接着 训练模型

69
00:02:46,316 --> 0:02:48,656
下一步 评估模型

70
00:02:49,036 --> 0:02:50,386
试图理解

71
00:02:50,436 --> 0:02:51,516
真实情况下的表现特征

72
00:02:51,516 --> 0:02:52,776
并尽可能改进模型

73
00:02:56,726 --> 0:02:58,866
最后 部署模型

74
00:02:59,116 --> 0:03:01,976
使其能在 Core ML 和 App 中运行

75
00:02:59,116 --> 0:03:01,976
使其能在 Core ML 和 App 中运行

76
00:03:03,436 --> 0:03:04,806
现在 我们来看看

77
00:03:04,806 --> 0:03:06,966
这五步的代码

78
00:03:07,816 --> 0:03:11,606
导入 TuriCreate 之后

79
00:03:11,606 --> 0:03:15,126
我们从盘里的 SFrame 加载数据

80
00:03:15,126 --> 0:03:16,366
SFrame 后面

81
00:03:16,366 --> 0:03:18,746
Shantanu 会详细讲解

82
00:03:19,816 --> 0:03:23,036
接着 我们把数据

83
00:03:23,036 --> 0:03:25,036
分成两组 

84
00:03:25,036 --> 0:03:26,476
一组用于测试

85
00:03:26,476 --> 0:03:27,426
一组用于训练模型

86
00:03:28,966 --> 0:03:31,606
然后 我们仅用一行代码

87
00:03:31,606 --> 0:03:33,486
就能创建一个模型

88
00:03:33,486 --> 0:03:35,756
用来运行复杂的机器学习算法

89
00:03:38,536 --> 0:03:40,686
接下来 我们看一下

90
00:03:40,686 --> 0:03:42,206
这个模型的指标

91
00:03:42,246 --> 0:03:46,536
最后 我们把它存盘

92
00:03:46,636 --> 0:03:50,286
用来在 Xcode 和你的 App 中使用

93
00:03:51,366 --> 0:03:53,366
我们认为 Turi Create 的

94
00:03:53,366 --> 0:03:55,056
优点之一是它的

95
00:03:55,056 --> 0:03:56,716
简单而统一的 API

96
00:03:57,726 --> 0:03:58,536
所以无论你是

97
00:03:58,536 --> 0:04:01,446
使用目标检测器

98
00:03:58,536 --> 0:04:01,446
使用目标检测器

99
00:04:01,446 --> 0:04:04,146
声音分类器 行为分类器

100
00:04:04,146 --> 0:04:06,096
或是任何其他任务

101
00:04:06,096 --> 0:04:08,006
API 始终是

102
00:04:08,036 --> 0:04:11,516
统一而易用的

103
00:04:11,716 --> 0:04:13,246
我已经多次提到了

104
00:04:13,296 --> 0:04:15,066
这些任务 我想把 

105
00:04:15,116 --> 0:04:16,375
Turi Create 提供的整个系列

106
00:04:16,375 --> 0:04:17,456
介绍一遍

107
00:04:17,606 --> 0:04:21,076
我们提供处理

108
00:04:21,185 --> 0:04:25,646
图像与声音的任务

109
00:04:25,646 --> 0:04:29,636
也有处理用户行为与文本的任务

110
00:04:29,796 --> 0:04:31,266
我们提供处理

111
00:04:31,316 --> 0:04:33,976
用户偏好和数值数据的任务

112
00:04:34,506 --> 0:04:37,276
今天我们无比激动地

113
00:04:37,276 --> 0:04:39,106
与你们分享两款

114
00:04:39,106 --> 0:04:42,306
新任务

115
00:04:42,306 --> 0:04:44,446
第一个 我们有了单样本

116
00:04:44,566 --> 0:04:45,786
目标检测任务

117
00:04:46,356 --> 0:04:49,266
现在你也许已经很熟悉目标检测了

118
00:04:50,626 --> 0:04:52,086
目标检测是指检测

119
00:04:52,086 --> 0:04:54,076
一帧图像中特定目标

120
00:04:54,076 --> 0:04:56,886
是否存在和其位置的能力

121
00:04:58,176 --> 0:05:00,056
单样本目标检测

122
00:04:58,176 --> 0:05:00,056
单样本目标检测

123
00:05:00,056 --> 0:05:01,226
是这个现存框架的一个变体

124
00:05:01,226 --> 0:05:03,366
根据你在尝试

125
00:05:03,366 --> 0:05:04,806
检测的数据

126
00:05:04,806 --> 0:05:06,526
的类型 能够

127
00:05:06,526 --> 0:05:07,866
极大地减少训练

128
00:05:07,866 --> 0:05:09,776
一个模型所需要的数据量

129
00:05:12,186 --> 0:05:13,516
第二 我们有了

130
00:05:13,516 --> 0:05:14,616
绘画分类任务

131
00:05:15,656 --> 0:05:20,816
用户的手指在屏幕上滑动

132
00:05:20,816 --> 0:05:23,616
或者使用 Apple Pencil 都可以作为输入

133
00:05:23,616 --> 0:05:25,636
你现在可以分类并理解

134
00:05:25,636 --> 0:05:28,446
用户在你的 App 中绘制的图形

135
00:05:29,016 --> 0:05:31,436
现在我想先深入讲一讲

136
00:05:31,576 --> 0:05:34,426
单样本目标检测任务

137
00:05:35,036 --> 0:05:36,296
假如说你想做一个 App

138
00:05:36,296 --> 0:05:38,936
通过拍一张扑克牌局中

139
00:05:38,936 --> 0:05:40,316
玩家手牌的照片

140
00:05:40,356 --> 0:05:42,446
为玩家提供

141
00:05:42,486 --> 0:05:43,566
这幅手牌的各种可能性

142
00:05:45,246 --> 0:05:46,976
或者说你想做一个 App

143
00:05:46,976 --> 0:05:49,046
可以拍一张

144
00:05:49,046 --> 0:05:50,386
汽车仪表盘的照片

145
00:05:50,386 --> 0:05:52,156
然后去理解那些令人费解的图标

146
00:05:52,156 --> 0:05:53,566
都是什么意思

147
00:05:54,176 --> 0:05:56,796
或者说你想做一个 App

148
00:05:56,796 --> 0:05:58,946
能够通过检测公司的标识

149
00:05:58,946 --> 0:06:00,426
来为用户提供

150
00:05:58,946 --> 0:06:00,426
来为用户提供

151
00:06:00,426 --> 0:06:02,396
有关这个公司的更多信息

152
00:06:03,516 --> 0:06:04,686
这三个 App 的

153
00:06:04,686 --> 0:06:06,146
共同点是什么呢

154
00:06:07,106 --> 0:06:09,606
它们都在检测

155
00:06:09,976 --> 0:06:11,186
规则的 2D 图形

156
00:06:12,616 --> 0:06:14,356
单样本目标检测能够

157
00:06:14,356 --> 0:06:15,776
利用规律

158
00:06:15,776 --> 0:06:17,606
和一致性等特征

159
00:06:17,606 --> 0:06:19,666
来极大减少

160
00:06:19,666 --> 0:06:21,536
创建精确模型

161
00:06:21,536 --> 0:06:22,706
所需的数据量

162
00:06:23,916 --> 0:06:25,586
所以我们来用用这个

163
00:06:25,586 --> 0:06:27,076
卡片计数的 App

164
00:06:27,076 --> 0:06:28,886
一会 Shantanu 会给我们写一个

165
00:06:28,886 --> 0:06:30,766
来看看这一切是如何工作的

166
00:06:32,626 --> 0:06:34,856
之前想要创建一个

167
00:06:34,856 --> 0:06:36,736
目标检测的模型

168
00:06:36,736 --> 0:06:38,226
你需要在现实世界中

169
00:06:38,226 --> 0:06:40,846
收集对应目标的大量数据

170
00:06:41,456 --> 0:06:44,566
除此以外

171
00:06:44,566 --> 0:06:46,246
你还需要给每一张

172
00:06:46,246 --> 0:06:48,066
源数据图片标上

173
00:06:48,066 --> 0:06:50,586
对应的坐标值

174
00:06:51,136 --> 0:06:53,646
如你所看到的

175
00:06:53,646 --> 0:06:55,556
这是一个涉及巨大数据量

176
00:06:55,556 --> 0:06:58,636
并且耗时的事

177
00:06:58,636 --> 0:07:00,916
所以我们有了一个更好的方式

178
00:06:58,636 --> 0:07:00,916
所以我们有了一个更好的方式

179
00:07:02,416 --> 0:07:04,096
有了单样本目标检测

180
00:07:04,366 --> 0:07:06,096
现在每个需要

181
00:07:06,096 --> 0:07:07,966
检测的类

182
00:07:07,966 --> 0:07:08,896
只需要一张图

183
00:07:09,806 --> 0:07:11,606
所以用不着数十张

184
00:07:11,966 --> 0:07:14,046
梅花 A 的图

185
00:07:14,046 --> 0:07:16,036
你只需要一张

186
00:07:16,036 --> 0:07:17,976
就可以创建一个可靠且精准的模型

187
00:07:18,196 --> 0:07:20,196
[掌声]

188
00:07:20,376 --> 0:07:23,466
谢谢 [掌声]

189
00:07:23,916 --> 0:07:24,926
现在我们来聊聊

190
00:07:24,926 --> 0:07:26,066
背后的故事

191
00:07:26,966 --> 0:07:28,486
这些之所以成为可能

192
00:07:28,486 --> 0:07:30,356
是因为合成数据增强

193
00:07:31,356 --> 0:07:32,566
Turi Create 自带

194
00:07:32,606 --> 0:07:34,976
现实世界的图片集

195
00:07:35,906 --> 0:07:37,806
然后我们把你提供的

196
00:07:37,876 --> 0:07:39,566
源图片叠加在

197
00:07:39,566 --> 0:07:41,616
这些现实世界的图片上

198
00:07:41,616 --> 0:07:43,676
再加上不同的

199
00:07:43,676 --> 0:07:45,876
颜色变化和扭曲

200
00:07:45,916 --> 0:07:47,736
来模拟现实世界的效果

201
00:07:49,186 --> 0:07:52,846
另外 完全不需要

202
00:07:53,046 --> 0:07:54,916
去标注这些图片

203
00:07:54,916 --> 0:07:56,456
因为我们的算法会自动帮你完成

204
00:07:58,936 --> 0:08:01,276
目前 单样本目标检测

205
00:07:58,936 --> 0:08:01,276
目前 单样本目标检测

206
00:08:01,516 --> 0:08:03,256
只能用在 2D 目标上

207
00:08:04,076 --> 0:08:06,306
它只需要非常少的数据量

208
00:08:06,306 --> 0:08:08,026
而且完全无需标注

209
00:08:08,846 --> 0:08:10,276
但是 如果你要检测的

210
00:08:10,276 --> 0:08:12,316
目标是 3D

211
00:08:12,316 --> 0:08:14,036
或者更不规则

212
00:08:14,036 --> 0:08:15,876
你可能还是

213
00:08:15,876 --> 0:08:18,176
需要试试我们传统的目标检测框架

214
00:08:18,686 --> 0:08:21,986
现在 让我们来看看这里的代码

215
00:08:22,886 --> 0:08:24,916
正如你所期待的

216
00:08:24,916 --> 0:08:26,776
我们的 API

217
00:08:26,776 --> 0:08:29,286
和其他任务类似

218
00:08:29,286 --> 0:08:31,286
只需要一行 .create 代码

219
00:08:31,286 --> 0:08:34,066
就可以训练一个无比精确的模型

220
00:08:34,066 --> 0:08:37,326
那么对于屏幕上的这些代码

221
00:08:37,366 --> 0:08:38,866
我想要邀请我的同事

222
00:08:38,866 --> 0:08:40,576
Shantanu 来跟你们讲讲

223
00:08:40,576 --> 0:08:42,296
Three Card Poker 这个 App

224
00:08:42,296 --> 0:08:43,166
在现实世界中

225
00:08:43,166 --> 0:08:44,566
演示一下这些

226
00:08:45,166 --> 0:08:45,976
有请 Shantanu

227
00:08:46,516 --> 0:08:51,646
[掌声]

228
00:08:52,146 --> 0:08:52,746
&gt;&gt; 谢谢 Sam

229
00:08:53,646 --> 0:08:54,606
大家早上好

230
00:08:54,736 --> 0:08:58,276
欢迎来到 WWDC 的最后一天

231
00:08:58,436 --> 0:09:02,336
现在我很兴奋

232
00:08:58,436 --> 0:09:02,336
现在我很兴奋

233
00:09:02,336 --> 0:09:03,466
能让你们先看看

234
00:09:03,466 --> 0:09:04,836
单样本目标检测器

235
00:09:05,966 --> 0:09:08,616
其实我和 Sam

236
00:09:08,616 --> 0:09:10,206
上班的时候总打 Three Card Poker

237
00:09:11,106 --> 0:09:12,706
老实说 每次都赢

238
00:09:12,706 --> 0:09:14,526
我都有点不耐烦了

239
00:09:15,126 --> 0:09:17,276
所以我在想

240
00:09:17,276 --> 0:09:18,796
现在在台上 我们不如来

241
00:09:19,046 --> 0:09:21,486
给 Sam 写一个 App

242
00:09:21,486 --> 0:09:23,916
能够告诉他他的手牌如何

243
00:09:23,916 --> 0:09:25,446
帮他更好地做决定

244
00:09:26,356 --> 0:09:28,326
想要写一个这样的 App

245
00:09:28,326 --> 0:09:30,126
我们需要一个 Core ML 模型

246
00:09:30,126 --> 0:09:32,136
可以检测到台面上的所有卡片

247
00:09:33,536 --> 0:09:35,076
那么我们不如直接

248
00:09:35,076 --> 0:09:36,786
写一些代码来实现吧

249
00:09:37,406 --> 0:09:39,866
好 这里我有一个

250
00:09:39,866 --> 0:09:41,146
空的 Jupyter Notebook

251
00:09:41,146 --> 0:09:42,756
它是一个可交互的 Python 环境

252
00:09:42,756 --> 0:09:44,286
我们可以写一些代码

253
00:09:44,286 --> 0:09:45,966
然后直接看到

254
00:09:45,966 --> 0:09:47,786
代码输出的结果

255
00:09:47,786 --> 0:09:49,986
我们现在来用这个写一些代码

256
00:09:50,866 --> 0:09:52,376
我们要写的第一行代码

257
00:09:52,376 --> 0:09:54,096
是我们最喜欢的

258
00:09:54,096 --> 0:09:55,926
一行代码

259
00:09:56,156 --> 0:09:59,586
就是 import turicreate as tc

260
00:10:00,046 --> 0:10:01,206
我需要在我写之前

261
00:10:01,206 --> 0:10:04,506
选择这个 cell

262
00:10:04,506 --> 0:10:06,706
听完这个讲座

263
00:10:06,706 --> 0:10:09,236
这行代码也会成为你的最爱

264
00:10:09,236 --> 0:10:10,506
接下来 我要切换到访达

265
00:10:10,616 --> 0:10:12,606
来看看我们的

266
00:10:12,876 --> 0:10:15,846
原始图像

267
00:10:15,846 --> 0:10:17,376
看起来我们有一堆牌

268
00:10:17,376 --> 0:10:19,026
这些卡牌占据了

269
00:10:19,026 --> 0:10:20,316
整个图像

270
00:10:20,316 --> 0:10:22,226
我们有一张梅花 A

271
00:10:22,226 --> 0:10:24,936
一张方片 A 红桃 A

272
00:10:24,936 --> 0:10:27,916
红桃五 而且我们这有很多图片

273
00:10:29,026 --> 0:10:30,916
那么接下来我们把

274
00:10:30,916 --> 0:10:32,466
这些图片加载到 SFrame 里吧

275
00:10:33,446 --> 0:10:35,506
SFrame 是 Turi Create 结构

276
00:10:35,706 --> 0:10:37,276
可扩展的数据结构

277
00:10:37,276 --> 0:10:38,706
以表格形式显示

278
00:10:38,806 --> 0:10:40,476
它可以表示你所有的数据

279
00:10:41,616 --> 0:10:42,766
所以我们要创造一个变量

280
00:10:42,766 --> 0:10:44,486
叫做 starter_images

281
00:10:44,806 --> 0:10:46,056
Turi Create 载入图像时

282
00:10:46,056 --> 0:10:47,646
有这样一个功能

283
00:10:48,036 --> 0:10:49,846
你可以直接把

284
00:10:50,096 --> 0:10:51,786
包含图片的路径传进去

285
00:10:51,786 --> 0:10:53,416
然后它自己就能基于这个路径

286
00:10:53,416 --> 0:10:54,466
创建一个 SFrame

287
00:10:54,876 --> 0:10:57,556
现在我们来看看

288
00:10:57,556 --> 0:10:59,286
原始图像的 SFrame 是什么样的

289
00:11:00,376 --> 0:11:02,886
好吧 这个 SFrame 里有两栏

290
00:11:02,886 --> 0:11:05,026
一栏是 path 和一栏是 image

291
00:11:05,026 --> 0:11:07,386
path 栏包含

292
00:11:07,386 --> 0:11:09,986
image 栏里对应图片的相对路径

293
00:11:10,986 --> 0:11:12,406
看起来还不错 不过 path 栏里的

294
00:11:12,406 --> 0:11:13,906
字符有点冗余

295
00:11:14,616 --> 0:11:15,696
./ 和 .png

296
00:11:16,016 --> 0:11:18,126
所以我们快速写一段代码

297
00:11:18,126 --> 0:11:19,826
把那些去掉

298
00:11:20,476 --> 0:11:22,576
那么我们在原始图片的

299
00:11:22,576 --> 0:11:24,436
SFrame 里新建一栏

300
00:11:24,486 --> 0:11:26,236
并命名为 label

301
00:11:26,416 --> 0:11:27,736
我会写一些代码

302
00:11:27,736 --> 0:11:31,746
用来从路径中获取 label

303
00:11:31,746 --> 0:11:33,296
我会拿类似 Python slice 的东西

304
00:11:33,296 --> 0:11:36,806
应用在 SFrame 的

305
00:11:37,106 --> 0:11:38,406
列里的所有元素里

306
00:11:39,506 --> 0:11:41,306
所以我们用一个 element_slice

307
00:11:41,306 --> 0:11:42,956
索引从 2 到 -4

308
00:11:42,956 --> 0:11:45,016
类似 Python slice

309
00:11:46,606 --> 0:11:48,876
接下来 我们调用 SFrame 的 explore 函数

310
00:11:49,826 --> 0:11:51,166
Turi Create 对于 SFrame

311
00:11:51,166 --> 0:11:52,866
有一个 explore 功能

312
00:11:52,976 --> 0:11:54,296
我们现在来试一试

313
00:11:54,996 --> 0:11:56,216
这里会弹出

314
00:11:56,216 --> 0:11:57,866
一个新的可视化的窗口

315
00:11:57,866 --> 0:11:59,716
为我们提供了一种可交互的

316
00:11:59,716 --> 0:12:02,086
探索我们的 SFrame 中所有数据的方式

317
00:11:59,716 --> 0:12:02,086
探索我们的 SFrame 中所有数据的方式

318
00:12:03,196 --> 0:12:05,726
如我们所看到的 这里有第三栏了

319
00:12:05,906 --> 0:12:07,626
现在有了 path image 和 label

320
00:12:08,096 --> 0:12:09,046
看来我们从路径里

321
00:12:09,046 --> 0:12:11,746
提取 label 提取得很成功

322
00:12:11,746 --> 0:12:13,776
我们确实去掉了 ./ 和 .png

323
00:12:14,136 --> 0:12:15,336
我们也可以看一下

324
00:12:15,336 --> 0:12:16,816
这个 SFrame 里图片的缩略图

325
00:12:16,816 --> 0:12:18,116
如果我们以后要把它打印出来的话

326
00:12:18,116 --> 0:12:19,396
会进行相应处理

327
00:12:20,316 --> 0:12:23,876
那这个 SFrame 里有多少行呢

328
00:12:24,276 --> 0:12:26,696
我们来看一眼

329
00:12:26,696 --> 0:12:28,086
嗯 看起来有 52 行

330
00:12:28,086 --> 0:12:31,186
刚好等于牌桌上

331
00:12:31,256 --> 0:12:32,546
扑克牌的数量

332
00:12:32,546 --> 0:12:33,566
所以看起来一切都很好

333
00:12:33,566 --> 0:12:36,486
但是这里需要特别注意的是

334
00:12:36,486 --> 0:12:39,646
对于每个要检测的目标的类

335
00:12:39,646 --> 0:12:42,416
这里只有一张图片

336
00:12:43,846 --> 0:12:45,476
我们看过了数据

337
00:12:45,476 --> 0:12:46,516
我们看过了任务

338
00:12:46,516 --> 0:12:48,446
我们知道任务是 单样本目标检测

339
00:12:49,006 --> 0:12:50,506
我们五步里的下一步

340
00:12:50,556 --> 0:12:53,576
是模型创建流程

341
00:12:54,696 --> 0:12:56,206
和我们其他的 toolkit 一样

342
00:12:56,206 --> 0:12:59,466
模型创建流程看来是这样的

343
00:12:59,976 --> 0:13:02,186
tc.one_shot_object_ detector.create

344
00:12:59,976 --> 0:13:02,186
tc.one_shot_object_ detector.create

345
00:13:03,656 --> 0:13:05,046
我们传入原始图片的 SFrame

346
00:13:05,046 --> 0:13:07,336
以及目标栏

347
00:13:07,336 --> 0:13:09,436
在这个例子中 也就是 label

348
00:13:10,286 --> 0:13:11,336
但是我现在不会运行这行代码

349
00:13:11,336 --> 0:13:13,996
因为会花一些时间

350
00:13:13,996 --> 0:13:15,566
而且还有很多幕后工作

351
00:13:15,566 --> 0:13:17,776
包含把不同的推测

352
00:13:17,776 --> 0:13:19,596
应用到你的

353
00:13:19,596 --> 0:13:21,306
原始图像上

354
00:13:21,306 --> 0:13:22,566
生成合成数据

355
00:13:22,916 --> 0:13:24,326
再把它们叠加

356
00:13:24,326 --> 0:13:25,586
到随机的背景上

357
00:13:25,586 --> 0:13:27,296
并加入颜色增强

358
00:13:27,296 --> 0:13:28,986
最后还会训练出一个模型

359
00:13:29,576 --> 0:13:31,586
所以 我们会切换到

360
00:13:31,586 --> 0:13:33,256
演示结果模式

361
00:13:33,366 --> 0:13:34,456
我们直接加载

362
00:13:34,456 --> 0:13:37,456
一个已经训练好的模型

363
00:13:38,036 --> 0:13:39,696
那么我们用这个加载模型的函数

364
00:13:39,696 --> 0:13:43,996
模型叫 card_detector.model

365
00:13:43,996 --> 0:13:47,186
我们来看看这个模型长什么样

366
00:13:48,276 --> 0:13:49,606
看起来像是

367
00:13:49,606 --> 0:13:52,406
单样本目标检测器在 52 个类里训练出的样子

368
00:13:53,306 --> 0:13:54,246
不过等一下

369
00:13:54,386 --> 0:13:55,626
合成出的例子的

370
00:13:55,626 --> 0:13:58,616
数量是 104,000

371
00:13:58,616 --> 0:14:00,696
这挺奇怪的

372
00:13:58,616 --> 0:14:00,696
这挺奇怪的

373
00:14:00,846 --> 0:14:02,576
我们只提供了 52 张图

374
00:14:04,056 --> 0:14:06,636
Toolkit 自动

375
00:14:06,716 --> 0:14:08,876
给每一类合成了

376
00:14:08,876 --> 0:14:12,506
2000 张图 并且创建了

377
00:14:12,506 --> 0:14:14,836
一个 104,000 的训练库

378
00:14:14,836 --> 0:14:16,556
而且不止这些

379
00:14:17,476 --> 0:14:19,466
它还为所有生成的

380
00:14:19,466 --> 0:14:21,406
数据生成了

381
00:14:21,406 --> 0:14:22,876
边界框 因为

382
00:14:22,876 --> 0:14:24,616
Toolkit 自己生成了数据

383
00:14:25,786 --> 0:14:26,796
这还挺厉害的

384
00:14:27,516 --> 0:14:32,116
[掌声]

385
00:14:32,616 --> 0:14:35,146
我们已经看了模型

386
00:14:35,296 --> 0:14:37,096
下一步我们

387
00:14:37,096 --> 0:14:39,056
用这个模型在

388
00:14:39,056 --> 0:14:40,176
一张模型里没有的图片上小试一下

389
00:14:41,506 --> 0:14:43,256
现在我要加载一张测试图片

390
00:14:43,566 --> 0:14:47,266
我有一个测试路径

391
00:14:47,896 --> 0:14:49,316
包含一张测试图片

392
00:14:49,826 --> 0:14:51,846
而且图里肯定不是 Sam 的手牌

393
00:14:51,846 --> 0:14:53,146
当你看到这张测试图片的时候

394
00:14:53,146 --> 0:14:55,686
你就知道为什么我这么说了

395
00:14:56,176 --> 0:14:59,906
对吧 Sam 从来没有这么幸运过

396
00:14:59,906 --> 0:15:03,346
这可能是我的手牌

397
00:14:59,906 --> 0:15:03,346
这可能是我的手牌

398
00:15:03,666 --> 0:15:04,296
这是一手同花牌

399
00:15:04,646 --> 0:15:06,926
我们看到图里有张梅花 8

400
00:15:06,926 --> 0:15:08,066
一张梅花 9

401
00:15:08,116 --> 0:15:09,066
还有一张梅花 10

402
00:15:09,936 --> 0:15:13,626
我们看看模型是不是也这么认为

403
00:15:14,776 --> 0:15:16,286
我们要调用

404
00:15:16,286 --> 0:15:18,096
模型里的预测方法

405
00:15:18,096 --> 0:15:19,576
并且传入我们的测试图片

406
00:15:19,756 --> 0:15:21,736
那么我们把结果保存在

407
00:15:21,736 --> 0:15:23,016
这个叫 prediction 的变量里

408
00:15:25,106 --> 0:15:28,746
接下来 我们把 prediction 打印出来

409
00:15:29,016 --> 0:15:30,766
好 我们来看一下

410
00:15:31,456 --> 0:15:33,166
看起来这个列表里

411
00:15:33,166 --> 0:15:35,326
有三个字典

412
00:15:35,376 --> 0:15:37,136
每个字典代表一个边界框

413
00:15:37,136 --> 0:15:39,286
也是 prediction 的一部分

414
00:15:40,036 --> 0:15:41,716
我们过一遍每个 prediction 里的字段

415
00:15:41,716 --> 0:15:42,376
看来这里有一个置信度

416
00:15:42,376 --> 0:15:43,526
一个坐标

417
00:15:43,566 --> 0:15:46,216
一个标签和一个类型

418
00:15:47,366 --> 0:15:49,116
confidence 代表模型

419
00:15:49,116 --> 0:15:52,416
预测的这个边界框里的自信程度

420
00:15:52,916 --> 0:15:54,036
coordinate 代表

421
00:15:54,036 --> 0:15:56,116
边界框的坐标

422
00:15:56,766 --> 0:15:58,886
label 是这个边界框

423
00:15:58,886 --> 0:16:00,366
属于哪一类的标签

424
00:15:58,886 --> 0:16:00,366
属于哪一类的标签

425
00:16:00,366 --> 0:16:01,366
type 是指边界框的类型

426
00:16:01,366 --> 0:16:02,996
这里是矩形

427
00:16:03,256 --> 0:16:05,126
看起来不错

428
00:16:05,476 --> 0:16:07,286
我们看到模型

429
00:16:07,286 --> 0:16:08,606
确实检测到了梅花 10

430
00:16:08,606 --> 0:16:09,956
梅花 8 和梅花 9

431
00:16:10,676 --> 0:16:12,096
但是它并没有告诉我们

432
00:16:12,316 --> 0:16:15,066
是在哪些坐标检测到的

433
00:16:15,786 --> 0:16:17,686
所以我们用一个

434
00:16:17,686 --> 0:16:20,106
单样本目标检测器提供的工具

435
00:16:20,106 --> 0:16:22,646
能够画边界框

436
00:16:22,646 --> 0:16:24,296
然后把 test_image

437
00:16:24,296 --> 0:16:25,636
和标注一起传进去

438
00:16:25,706 --> 0:16:26,716
也就是 prediction

439
00:16:28,366 --> 0:16:31,766
然后我们把它命名为 annotated_image

440
00:16:34,566 --> 0:16:37,686
接下来 我们把 annotated_image 打印出来

441
00:16:38,516 --> 0:16:40,956
[掌声]

442
00:16:41,456 --> 0:16:42,546
是的 看起来相当不错

443
00:16:43,406 --> 0:16:44,876
对于一张模型从来没有

444
00:16:44,876 --> 0:16:46,876
见过的照片

445
00:16:46,876 --> 0:16:48,036
模型有 70% 信心判定为

446
00:16:48,036 --> 0:16:49,366
梅花 8 判定为 梅花 10 的

447
00:16:49,366 --> 0:16:51,676
信心有 91% 梅花 9 则为 69%

448
00:16:52,256 --> 0:16:54,036
而且注意看所有的边界框

449
00:16:54,036 --> 0:16:57,406
完美地框住所有牌的梅花

450
00:17:00,146 --> 0:17:02,446
所以我们用一张

451
00:17:02,656 --> 0:17:04,146
模型从未见过的图片

452
00:17:04,146 --> 0:17:05,066
对模型做了冒烟测试

453
00:17:05,606 --> 0:17:08,066
最后一步就是在设备上部署

454
00:17:08,566 --> 0:17:10,506
而且像我们其他的 toolkit 一样

455
00:17:10,566 --> 0:17:12,976
这个模型有方法能够输出 Core ML

456
00:17:13,516 --> 0:17:14,935
那么我们把这个 Core ML

457
00:17:14,935 --> 0:17:17,986
模型命名为 CardDetector.mlmodel

458
00:17:20,316 --> 0:17:22,205
接下来 我们在 Xcode 中

459
00:17:22,286 --> 0:17:27,935
打开这个 CardDetector.mlmodel

460
00:17:28,006 --> 0:17:30,496
好了 我们可以看到

461
00:17:30,496 --> 0:17:32,386
我们有了一个由 Turi Create 5.6

462
00:17:32,386 --> 0:17:35,076
训练的 CardDetector 模型

463
00:17:35,886 --> 0:17:37,436
输入是 image

464
00:17:37,436 --> 0:17:40,126
是一张 416 x 416 的彩色图像

465
00:17:40,126 --> 0:17:42,146
confidence 代表着

466
00:17:42,146 --> 0:17:43,796
此模型在多少个类上

467
00:17:43,796 --> 0:17:45,506
训练过

468
00:17:45,656 --> 0:17:46,776
coordinates 代表这些类的

469
00:17:46,776 --> 0:17:48,436
边界框坐标

470
00:17:49,906 --> 0:17:50,526
看起来很好

471
00:17:50,526 --> 0:17:53,326
看起来是个非常好的 Core ML 模型

472
00:17:54,006 --> 0:17:56,246
我们搞点有意思的事

473
00:17:56,306 --> 0:17:58,486
把这个模型

474
00:17:58,756 --> 0:18:00,626
放在 Sam 下次跟我玩

475
00:17:58,756 --> 0:18:00,626
放在 Sam 下次跟我玩

476
00:18:00,626 --> 0:18:02,806
三张牌扑克时可以用的 App 里

477
00:18:03,976 --> 0:18:07,106
好了 这就是我的 Three Card Poker App

478
00:18:07,426 --> 0:18:09,746
它说添加一张照片以评估手牌

479
00:18:09,976 --> 0:18:11,246
我这里有一副牌

480
00:18:11,246 --> 0:18:12,836
我从里面随机抽三张

481
00:18:12,986 --> 0:18:17,706
这就是 Sam 的手牌

482
00:18:19,216 --> 0:18:21,146
所以我们来拍一张照片

483
00:18:22,436 --> 0:18:24,776
那么看起来这里有

484
00:18:24,776 --> 0:18:26,126
嗯 看起来是 Sam 最近

485
00:18:26,126 --> 0:18:27,356
拿到的好牌之一

486
00:18:31,656 --> 0:18:33,196
好了 看起来

487
00:18:33,196 --> 0:18:34,426
模型认为这里有

488
00:18:34,486 --> 0:18:35,826
梅花 5 红桃 3

489
00:18:35,826 --> 0:18:36,426
和红桃 K

490
00:18:36,936 --> 0:18:38,746
它也检测到是一手散牌

491
00:18:38,786 --> 0:18:40,976
概率是 74.39%

492
00:18:41,391 --> 0:18:43,391
[掌声]

493
00:18:43,766 --> 0:18:48,166
考虑到这是一手散牌

494
00:18:48,166 --> 0:18:50,146
Sam 可能会过掉这一回合

495
00:18:50,146 --> 0:18:52,036
因为确实很有可能拿到一手散牌

496
00:18:59,056 --> 0:19:01,316
噢 这是 好吧

497
00:18:59,056 --> 0:19:01,316
噢 这是 好吧

498
00:19:01,316 --> 0:19:02,816
我们拍张照然后再来聊聊我的手牌

499
00:19:07,316 --> 0:19:08,616
我有一组同花

500
00:19:08,686 --> 0:19:09,976
红桃 9 红桃 6

501
00:19:09,976 --> 0:19:13,066
还有红桃 4

502
00:19:13,066 --> 0:19:14,476
所以虽然我为了 Sam

503
00:19:14,586 --> 0:19:17,786
写了这个 App 但好像

504
00:19:17,786 --> 0:19:20,056
我才是从中获利的人

505
00:19:21,166 --> 0:19:23,826
好吧 这就是 Card Detector 的全部演示

506
00:19:23,826 --> 0:19:28,946
回忆一下

507
00:19:28,946 --> 0:19:32,766
我们用每一类一张图开始

508
00:19:33,976 --> 0:19:35,746
我们只调用了一行代码

509
00:19:36,466 --> 0:19:37,606
就自动地为我们

510
00:19:37,696 --> 0:19:40,166
合成了一套训练数据

511
00:19:40,226 --> 0:19:41,006
训练出了一个模型

512
00:19:41,916 --> 0:19:44,196
然后我们小范围地用一张

513
00:19:44,196 --> 0:19:46,176
模型从未见过的随机图片里进行了冒烟测试

514
00:19:46,176 --> 0:19:49,346
然后我们就在 App 里看到了结果

515
00:19:49,346 --> 0:19:51,126
而且这只是你能创造的

516
00:19:51,126 --> 0:19:53,846
用户体验中的一个例子

517
00:19:54,966 --> 0:19:57,046
看到你们这一年

518
00:19:57,046 --> 0:19:58,316
用 Object Detector 创造的东西

519
00:19:58,316 --> 0:20:00,256
我们非常兴奋

520
00:19:58,316 --> 0:20:00,256
我们非常兴奋

521
00:20:00,496 --> 0:20:02,556
所以我们做了

522
00:20:02,556 --> 0:20:04,716
这个 toolkit 因为我们想要

523
00:20:04,716 --> 0:20:07,866
减少你们在数据收集和标注上的工作量

524
00:20:08,256 --> 0:20:09,316
对于 2D 对象

525
00:20:09,316 --> 0:20:10,436
时长已经从

526
00:20:10,436 --> 0:20:13,886
差不多好几天减少到了

527
00:20:13,886 --> 0:20:14,926
五分钟左右

528
00:20:15,916 --> 0:20:17,856
我们迫不及待地想看到

529
00:20:17,856 --> 0:20:19,506
你们会用 单样本目标检测器 创造些什么了

530
00:20:19,966 --> 0:20:21,636
而且如果你愿意的话

531
00:20:21,666 --> 0:20:23,026
你可以来实验室试试这个测试

532
00:20:23,196 --> 0:20:25,936
我们会很乐意接待你

533
00:20:25,936 --> 0:20:29,066
现在我来讲讲

534
00:20:29,066 --> 0:20:32,936
今天的下一个 Toolkit

535
00:20:33,106 --> 0:20:34,556
我感到很激动

536
00:20:34,556 --> 0:20:35,656
要跟你们聊聊绘画分类

537
00:20:37,516 --> 0:20:40,836
到目前为止 Turi Create

538
00:20:40,836 --> 0:20:42,726
允许你创建能够处理声音输入

539
00:20:42,726 --> 0:20:49,456
原始传感器数据输入和图像的 App

540
00:20:52,116 --> 0:20:55,046
今天 我们新增一种输入形式

541
00:20:55,046 --> 0:20:56,966
Apple Pencil

542
00:20:57,516 --> 0:21:00,566
[掌声]

543
00:20:57,516 --> 0:21:00,566
[掌声]

544
00:21:01,066 --> 0:21:03,076
想象一下 创造一个 App

545
00:21:03,076 --> 0:21:04,676
能够通过检测笔触

546
00:21:04,676 --> 0:21:06,656
并自动替换成专业的图画

547
00:21:06,656 --> 0:21:08,706
来帮助用户

548
00:21:08,706 --> 0:21:10,586
制作漂亮的欢迎卡片

549
00:21:11,876 --> 0:21:12,866
把能力赋予用户

550
00:21:14,246 --> 0:21:15,556
或者想象如果有个 App

551
00:21:15,556 --> 0:21:17,826
通过检测学生的笔触

552
00:21:18,216 --> 0:21:19,926
来帮助教授们

553
00:21:19,926 --> 0:21:21,636
给学生的试卷打分

554
00:21:21,636 --> 0:21:22,896
在教育领域会是多么大的突破

555
00:21:23,456 --> 0:21:25,836
实际上 我们真的会做这样一个 App

556
00:21:26,136 --> 0:21:29,736
不过在那之前 我们先聊聊数据

557
00:21:30,596 --> 0:21:32,556
绘画分类任务

558
00:21:32,676 --> 0:21:34,116
能够接受基于位图的图画

559
00:21:34,116 --> 0:21:36,336
也就是 Turi Create 图像

560
00:21:36,336 --> 0:21:39,326
但不止如此

561
00:21:39,326 --> 0:21:44,346
这个任务也能处理

562
00:21:44,346 --> 0:21:45,996
基于笔触的图画

563
00:21:45,996 --> 0:21:47,746
也就是一系列按照时序的

564
00:21:47,746 --> 0:21:50,336
x 和 y 的坐标点

565
00:21:51,546 --> 0:21:53,086
我们想为你的数据

566
00:21:53,126 --> 0:21:58,196
提供尽可能多的灵活性

567
00:21:58,196 --> 0:21:59,776
创建模型的 API 也跟

568
00:21:59,776 --> 0:22:01,086
我们的其他 Toolkit 一样

569
00:21:59,776 --> 0:22:01,086
我们的其他 Toolkit 一样

570
00:22:01,086 --> 0:22:02,846
调用 turicreate 的 

571
00:22:02,846 --> 0:22:04,846
drawing_classifier.create 

572
00:22:04,846 --> 0:22:07,046
训练 SFrame 和目标栏

573
00:22:07,046 --> 0:22:09,626
你在这里得到的模型

574
00:22:09,626 --> 0:22:10,656
可以说的是艺术的化身

575
00:22:11,386 --> 0:22:12,956
你得到的 Core ML 模型

576
00:22:12,956 --> 0:22:15,156
在设备上只有不到 500 KB

577
00:22:15,556 --> 0:22:17,826
而且有 GPU 加速

578
00:22:18,516 --> 0:22:22,596
[掌声]

579
00:22:23,096 --> 0:22:24,286
而且不止这些

580
00:22:25,556 --> 0:22:27,256
我们还用数以百万计的

581
00:22:27,256 --> 0:22:29,216
图画上训练了一个模型

582
00:22:29,216 --> 0:22:30,886
用来创建你自己的模型

583
00:22:31,136 --> 0:22:33,536
这不仅帮你

584
00:22:33,536 --> 0:22:36,366
创建更精准的模型

585
00:22:36,366 --> 0:22:38,126
还能让你可以在每个类下

586
00:22:38,126 --> 0:22:39,796
只需要训练 30 个图形

587
00:22:40,486 --> 0:22:42,236
30 个 想想吧

588
00:22:42,236 --> 0:22:46,296
那么这个代码看起来如何呢

589
00:22:47,246 --> 0:22:48,826
只有五行代码 五步

590
00:22:49,176 --> 0:22:50,986
第一步 导入 turicreate

591
00:22:50,986 --> 0:22:52,816
看看我们的数据

592
00:22:52,816 --> 0:22:54,796
调用创建模型

593
00:22:54,796 --> 0:22:56,396
评估我们的数据 然后输出给 Core ML

594
00:22:56,626 --> 0:22:59,776
那么 还记得

595
00:22:59,776 --> 0:23:01,336
我们看过的那个打分 App

596
00:22:59,776 --> 0:23:01,336
我们看过的那个打分 App

597
00:23:01,336 --> 0:23:02,936
可以检测勾和叉

598
00:23:02,936 --> 0:23:05,736
还能做更多很酷的事的那个吗

599
00:23:06,466 --> 0:23:07,926
我们现在就来写一个吧

600
00:23:08,056 --> 0:23:10,096
所以我们先看看

601
00:23:10,686 --> 0:23:14,316
iPad 上的这个 App

602
00:23:15,016 --> 0:23:16,436
能帮我们批卷子

603
00:23:17,136 --> 0:23:18,806
假如说我是个教授

604
00:23:18,806 --> 0:23:20,806
我拿着我的 Apple Pencil

605
00:23:20,806 --> 0:23:21,816
我准备来批阅学生的试卷

606
00:23:21,816 --> 0:23:24,246
但我想批得特别快

607
00:23:25,096 --> 0:23:26,706
那我们先从添加一张照片开始

608
00:23:27,086 --> 0:23:29,276
这是我某个学生的试卷

609
00:23:29,276 --> 0:23:31,366
Jane Appleseed 数学 101

610
00:23:31,366 --> 0:23:32,806
还挺难的

611
00:23:35,886 --> 0:23:36,786
那我们看一眼这张考卷

612
00:23:36,786 --> 0:23:38,776
开始批卷子吧

613
00:23:39,646 --> 0:23:41,476
嗯 1 加 1 等于 2 对吧

614
00:23:41,476 --> 0:23:42,866
至少我的老师是这么教我的

615
00:23:43,506 --> 0:23:44,706
那么我们把这题标为正确

616
00:23:44,836 --> 0:23:46,336
正如你所看到的

617
00:23:46,336 --> 0:23:48,416
模型检测了这个对号

618
00:23:48,416 --> 0:23:49,596
在右侧记录了 10 分

619
00:23:49,596 --> 0:23:51,556
这道题满分 10 分

620
00:23:51,556 --> 0:23:52,696
给了学生 10 分

621
00:23:53,766 --> 0:23:54,716
1 加 2 等于 4

622
00:23:54,716 --> 0:23:57,056
也答对了

623
00:23:57,296 --> 0:23:58,246
哦不对

624
00:23:58,326 --> 0:24:01,236
那我擦掉

625
00:23:58,326 --> 0:24:01,236
那我擦掉

626
00:24:01,236 --> 0:24:02,686
也许我需要重新学一下数学 101

627
00:24:04,466 --> 0:24:05,806
那么我们把这道题标为错误

628
00:24:06,456 --> 0:24:08,486
因为模型检测错误

629
00:24:08,486 --> 0:24:09,666
所以我们再擦掉一次

630
00:24:10,186 --> 0:24:12,316
过一会 Abhishek

631
00:24:12,316 --> 0:24:13,886
就会上台

632
00:24:13,886 --> 0:24:14,956
跟你们简述

633
00:24:14,956 --> 0:24:16,036
如何改善你们的模型

634
00:24:16,616 --> 0:24:18,966
这款 App 也能

635
00:24:18,966 --> 0:24:20,246
在建模失败时提供帮助

636
00:24:20,556 --> 0:24:21,676
如果你感兴趣

637
00:24:21,676 --> 0:24:22,946
11 点的讲座是关于

638
00:24:22,946 --> 0:24:24,726
为机器学习设计 App

639
00:24:25,266 --> 0:24:26,076
好 我们继续来批卷子

640
00:24:26,616 --> 0:24:27,646
1 加 2 等于 4

641
00:24:27,646 --> 0:24:28,576
那是错的

642
00:24:28,576 --> 0:24:31,976
模型检测到一个代表错误的叉

643
00:24:31,976 --> 0:24:33,566
在数学 101 课堂上

644
00:24:33,566 --> 0:24:35,726
这是个严重的错误

645
00:24:36,186 --> 0:24:37,816
我们给它扣 7 分

646
00:24:37,816 --> 0:24:40,176
如你所见

647
00:24:40,176 --> 0:24:41,766
模型录入了 - 7

648
00:24:42,016 --> 0:24:43,406
给了这个学生 10 分里的 3 分

649
00:24:43,406 --> 0:24:44,996
可以看到就在右边

650
00:24:46,186 --> 0:24:47,126
3 加 2 等于 5

651
00:24:47,126 --> 0:24:48,786
那是正确的

652
00:24:49,646 --> 0:24:51,426
需要向你们深入介绍下

653
00:24:51,426 --> 0:24:53,216
驱动这款 App 的模型

654
00:24:53,216 --> 0:24:55,386
它经历过这些训练

655
00:24:55,386 --> 0:24:58,316
勾 叉 

656
00:24:58,356 --> 0:24:59,796
从 -1 到 -10 的十种

657
00:24:59,796 --> 0:25:00,716
扣分方式

658
00:24:59,796 --> 0:25:00,716
扣分方式

659
00:25:01,466 --> 0:25:02,566
我们继续批卷子

660
00:25:03,226 --> 0:25:04,856
1 加 99 等于

661
00:25:06,686 --> 0:25:07,716
100 没错

662
00:25:08,356 --> 0:25:09,266
那这题就错了

663
00:25:09,266 --> 0:25:11,966
模型又犯了一次错误

664
00:25:12,456 --> 0:25:15,086
我来修正一下 标记这个错误

665
00:25:16,126 --> 0:25:17,306
这次我们给它

666
00:25:17,306 --> 0:25:19,836
扣 5 分吧

667
00:25:19,836 --> 0:25:21,376
模型又录入了 -5

668
00:25:21,376 --> 0:25:23,146
存到了右边

669
00:25:23,146 --> 0:25:25,946
最后一道题 有点难度 

670
00:25:25,946 --> 0:25:29,926
我不知道学生是怎么

671
00:25:29,926 --> 0:25:31,856
答对这题的 他们明明

672
00:25:31,856 --> 0:25:32,886
算错了 1 加 2

673
00:25:33,626 --> 0:25:35,346
管他呢 我们算他对了

674
00:25:36,476 --> 0:25:39,286
所以这就是你可以让

675
00:25:39,286 --> 0:25:41,146
绘图分类

676
00:25:41,786 --> 0:25:43,186
积累的经验

677
00:25:43,186 --> 0:25:47,456
我们为什么不直接上手

678
00:25:47,456 --> 0:25:48,996
写一些代码

679
00:25:48,996 --> 0:25:50,256
真正地构建一个 Core ML 模型

680
00:25:50,256 --> 0:25:51,726
来驱动这款 App 呢

681
00:25:56,076 --> 0:25:58,096
这里新建了一个空的

682
00:25:58,096 --> 0:26:00,516
Jupyter notebook

683
00:25:58,096 --> 0:26:00,516
Jupyter notebook

684
00:26:00,516 --> 0:26:01,516
我们跟着五步的工作流程

685
00:26:01,516 --> 0:26:02,416
再来一次

686
00:26:03,136 --> 0:26:07,516
第一步 明确任务

687
00:26:07,516 --> 0:26:09,306
这里的任务是绘图分类

688
00:26:09,436 --> 0:26:11,636
我们已经建好了

689
00:26:11,636 --> 0:26:13,196
第二步是数据

690
00:26:14,396 --> 0:26:15,886
但在那之前 先写上

691
00:26:15,886 --> 0:26:19,096
我们最爱的那条代码

692
00:26:19,096 --> 0:26:20,806
import turicreate as tc

693
00:26:22,026 --> 0:26:23,466
再回来看数据

694
00:26:23,466 --> 0:26:25,136
我们要加载一个 SFrame

695
00:26:25,346 --> 0:26:27,286
里面包含我们已经积累的一些数据

696
00:26:28,246 --> 0:26:32,006
我们命名为 train

697
00:26:32,136 --> 0:26:34,256
所以叫做 train.sframe

698
00:26:34,726 --> 0:26:37,566
接下来 我们在 train SFrame 上

699
00:26:37,596 --> 0:26:39,136
使用 explore 函数

700
00:26:39,326 --> 0:26:43,226
看看是什么样的

701
00:26:43,226 --> 0:26:44,876
棒 看起来我们有

702
00:26:44,876 --> 0:26:46,706
不少数据了

703
00:26:46,706 --> 0:26:47,896
我们有 -3

704
00:26:48,096 --> 0:26:49,396
标签是 -3

705
00:26:49,736 --> 0:26:51,026
勾的标签也是勾

706
00:26:51,386 --> 0:26:52,816
SFrame 有两列

707
00:26:52,816 --> 0:26:54,446
位图和标签

708
00:26:54,936 --> 0:26:56,216
在这个演示中

709
00:26:56,216 --> 0:26:57,536
我们使用基于位图的绘图

710
00:26:57,536 --> 0:26:58,916
但你也可以使用

711
00:26:58,916 --> 0:27:00,326
基于笔触的绘图

712
00:26:58,916 --> 0:27:00,326
基于笔触的绘图

713
00:27:00,326 --> 0:27:01,026
代替位图这一列

714
00:27:02,516 --> 0:27:04,086
这里我们有一堆绘图

715
00:27:04,286 --> 0:27:05,946
滚动看看

716
00:27:05,946 --> 0:27:07,526
我们有叉 另一个勾

717
00:27:07,526 --> 0:27:08,696
一些扣分的图

718
00:27:09,096 --> 0:27:09,896
看上去很不错

719
00:27:09,896 --> 0:27:11,206
这里有多少例子

720
00:27:11,906 --> 0:27:13,466
4436 个

721
00:27:13,846 --> 0:27:16,666
很好 已经不少了

722
00:27:16,836 --> 0:27:17,826
有人要发问了

723
00:27:17,826 --> 0:27:19,586
这么些数据是从哪收集的

724
00:27:19,586 --> 0:27:20,966
你怎么拿到这些数据的

725
00:27:21,506 --> 0:27:23,386
我们三个

726
00:27:23,386 --> 0:27:25,226
在会议室

727
00:27:25,226 --> 0:27:27,146
用 Apple Pencil 在 iPad 上

728
00:27:27,146 --> 0:27:28,676
画这些图形

729
00:27:28,676 --> 0:27:32,146
画了将近一个小时 然后转入SFrame

730
00:27:32,666 --> 0:27:34,656
用这个工具进行数据收集

731
00:27:34,656 --> 0:27:36,376
成本是很低的

732
00:27:38,936 --> 0:27:40,006
既然已经检查过数据了

733
00:27:40,006 --> 0:27:43,576
我们接着来看

734
00:27:43,576 --> 0:27:44,976
模型创建过程

735
00:27:44,976 --> 0:27:46,026
是怎样的

736
00:27:47,236 --> 0:27:48,346
所以我们有了

737
00:27:48,716 --> 0:27:50,226
drawingclassifier.create

738
00:27:50,226 --> 0:27:53,066
我们传入训练 SFrame

739
00:27:53,066 --> 0:27:54,166
再传入目标栏

740
00:27:54,166 --> 0:27:55,826
在这个例子中就是 label

741
00:27:56,216 --> 0:27:57,756
而且我还准备传入

742
00:27:57,756 --> 0:27:59,586
最大重复量 1

743
00:27:59,586 --> 0:28:02,006
让你们感受一下

744
00:27:59,586 --> 0:28:02,006
让你们感受一下

745
00:28:02,006 --> 0:28:03,396
训练过程是怎样的

746
00:28:04,876 --> 0:28:06,306
背后的原理是

747
00:28:06,306 --> 0:28:08,426
它正在把我们所有的

748
00:28:08,426 --> 0:28:11,426
图片都缩小到 28 x 28

749
00:28:11,476 --> 0:28:12,616
然后再在神经网络中

750
00:28:12,616 --> 0:28:14,106
做一次解析

751
00:28:16,036 --> 0:28:17,736
看起来完成了

752
00:28:17,816 --> 0:28:19,066
但是这个模型

753
00:28:19,066 --> 0:28:20,966
对我们的用例来说不够好

754
00:28:21,496 --> 0:28:24,096
所以再一次 我们切换

755
00:28:24,096 --> 0:28:25,686
到成果演示模式

756
00:28:25,686 --> 0:28:28,166
取一个训练好的模型

757
00:28:29,276 --> 0:28:30,846
所以我们用这个

758
00:28:30,846 --> 0:28:34,536
加载模型函数加载打分模型

759
00:28:34,996 --> 0:28:38,066
好了 如果我们来看一眼

760
00:28:38,066 --> 0:28:40,106
这个模型 我们有了一个

761
00:28:40,106 --> 0:28:42,136
基于 12 个类训练

762
00:28:42,136 --> 0:28:44,146
绘图分类器模型

763
00:28:44,146 --> 0:28:45,516
feature 栏是位图

764
00:28:45,516 --> 0:28:47,036
目标栏是标签

765
00:28:47,036 --> 0:28:48,756
训练了 300 次

766
00:28:48,756 --> 0:28:49,816
只用了 30 分钟

767
00:28:50,936 --> 0:28:53,506
所以仅仅用 30 分钟的训练

768
00:28:53,506 --> 0:28:54,776
我们得到了一个

769
00:28:54,776 --> 0:28:56,096
有着高训练精确度的模型

770
00:28:56,316 --> 0:28:56,976
这非常好

771
00:28:56,976 --> 0:29:00,516
所以现在我们有了模型

772
00:28:56,976 --> 0:29:00,516
所以现在我们有了模型

773
00:29:00,516 --> 0:29:04,276
下一步就是评估这个模型

774
00:29:05,416 --> 0:29:07,316
不过我准备跳过这一步

775
00:29:07,316 --> 0:29:08,426
因为我的同事 Abhishek

776
00:29:08,426 --> 0:29:09,706
马上会来到台上

777
00:29:10,126 --> 0:29:11,986
他不仅会演示

778
00:29:11,986 --> 0:29:13,356
如何可视化模型的错误

779
00:29:13,356 --> 0:29:15,726
他还会演示

780
00:29:15,836 --> 0:29:17,546
如果建立一个模型的

781
00:29:17,546 --> 0:29:19,576
反馈循环并且证明它

782
00:29:20,066 --> 0:29:22,436
所以让我们直接跳到

783
00:29:22,436 --> 0:29:23,716
导出到 Core ML 这一步

784
00:29:25,576 --> 0:29:28,016
和我们其他的 toolkit 一样

785
00:29:28,016 --> 0:29:30,886
我们在模型上调用

786
00:29:30,886 --> 0:29:32,426
export_coreml

787
00:29:32,426 --> 0:29:34,406
这里不是卡牌检测

788
00:29:34,406 --> 0:29:35,106
而是打分

789
00:29:35,616 --> 0:29:37,506
所以我们叫它 Grading.mlmodel

790
00:29:37,966 --> 0:29:39,796
然后我们在 Xcode 里看一下

791
00:29:44,466 --> 0:29:48,496
很棒 这个模型用位图

792
00:29:48,596 --> 0:29:49,716
作为输入

793
00:29:49,716 --> 0:29:51,816
是 28 x 28 的灰阶图像

794
00:29:52,276 --> 0:29:53,346
输出是标签的

795
00:29:53,346 --> 0:29:55,126
可能性以及类标签

796
00:29:55,486 --> 0:29:56,876
标签可能性是

797
00:29:56,876 --> 0:29:58,736
用于模型训练的

798
00:29:58,736 --> 0:30:00,056
所有类的可能性

799
00:29:58,736 --> 0:30:00,056
所有类的可能性

800
00:30:00,386 --> 0:30:01,976
类标签则是

801
00:30:01,976 --> 0:30:03,056
最佳预测的类的标签

802
00:30:04,536 --> 0:30:05,276
所以这个看起来不错

803
00:30:06,766 --> 0:30:08,526
我们为了尽可能地减少

804
00:30:08,526 --> 0:30:10,946
Core ML 的大小

805
00:30:10,946 --> 0:30:12,496
做出了很大的努力

806
00:30:12,496 --> 0:30:14,466
因为我们想让你在你的场景中

807
00:30:14,576 --> 0:30:16,486
使用的时候尽可能地适用于移动设备

808
00:30:16,486 --> 0:30:20,876
我们把它减少到了 396 KB

809
00:30:20,876 --> 0:30:21,966
是 KB 哦

810
00:30:22,516 --> 0:30:27,596
[掌声]

811
00:30:28,096 --> 0:30:29,716
那么现在既然我们已经

812
00:30:29,716 --> 0:30:31,916
看到了 Core ML 模型

813
00:30:31,916 --> 0:30:35,546
也看到了最终

814
00:30:35,546 --> 0:30:37,616
做出来的 App

815
00:30:37,616 --> 0:30:39,306
我们也来看看你需要

816
00:30:39,306 --> 0:30:40,386
写什么样的 Swift 代码

817
00:30:40,386 --> 0:30:42,556
来把模型整合到你的 App 里

818
00:30:43,806 --> 0:30:45,406
PencilKit 过去的这周

819
00:30:45,406 --> 0:30:47,036
发布了 API

820
00:30:47,036 --> 0:30:50,136
在 Canvas 视图中瞥见绘图

821
00:30:50,136 --> 0:30:51,156
也就是绘图数据模型

822
00:30:51,536 --> 0:30:53,436
使用那行代码

823
00:30:53,436 --> 0:30:55,816
你可以从 Canvas 视图中

824
00:30:56,056 --> 0:30:57,506
把绘图作为 UI image 提取出来

825
00:30:57,506 --> 0:31:02,176
然后接下来 你可以再一次

826
00:30:57,506 --> 0:31:02,176
然后接下来 你可以再一次

827
00:31:02,436 --> 0:31:04,386
使用 PencilKit 中的 API

828
00:31:04,386 --> 0:31:05,786
把它裁剪到

829
00:31:05,786 --> 0:31:07,666
用户画图的边界处

830
00:31:08,136 --> 0:31:09,526
现在你裁剪过的

831
00:31:09,656 --> 0:31:12,066
图像已经可以

832
00:31:12,126 --> 0:31:14,156
被 Core ML 处理了

833
00:31:14,156 --> 0:31:16,406
你可以使用 Vision API

834
00:31:16,406 --> 0:31:18,946
这就是你需要的所有东西了

835
00:31:19,876 --> 0:31:23,686
总结一下 一开始

836
00:31:23,686 --> 0:31:25,186
有一些绘图和对应的标签

837
00:31:25,876 --> 0:31:28,866
我们交互性地探索了这些数据

838
00:31:28,866 --> 0:31:30,496
我们看到了这些数据的样子

839
00:31:31,606 --> 0:31:33,016
然后我们训练了一个模型

840
00:31:33,016 --> 0:31:34,196
又直接取了个训练好的模型

841
00:31:35,676 --> 0:31:38,296
导出到 Core ML

842
00:31:38,296 --> 0:31:40,016
然后使用 PencilKit 和 Vision 部署

843
00:31:41,486 --> 0:31:42,786
但是我确实漏了一件事

844
00:31:43,096 --> 0:31:44,476
我是故意漏掉的

845
00:31:45,456 --> 0:31:47,086
我确实跳过了评估 而这应该是

846
00:31:47,086 --> 0:31:50,786
你们工作流程中相当重要的一步

847
00:31:51,306 --> 0:31:52,576
如果你真的评估

848
00:31:52,576 --> 0:31:53,766
你的模型并且改善它们

849
00:31:53,766 --> 0:31:55,146
就不会有今天这个 App 里

850
00:31:55,146 --> 0:31:56,216
你看到的这些错误

851
00:31:57,006 --> 0:31:58,276
那么 我邀请

852
00:31:58,276 --> 0:31:59,986
我的同事 Abhishek 来到台上

853
00:31:59,986 --> 0:32:01,206
带我们进行一场

854
00:31:59,986 --> 0:32:01,206
带我们进行一场

855
00:32:01,206 --> 0:32:02,356
评估模型的激动旅程

856
00:32:02,496 --> 0:32:02,976
有请 Abhishek

857
00:32:03,516 --> 0:32:08,226
[掌声]

858
00:32:08,726 --> 0:32:11,136
&gt;&gt; 谢谢

859
00:32:11,136 --> 0:32:12,396
今天我想跟你们讲讲

860
00:32:12,396 --> 0:32:15,216
模型评估

861
00:32:15,216 --> 0:32:16,636
以及尽可能优化

862
00:32:16,636 --> 0:32:19,206
用户体验的重要性

863
00:32:19,826 --> 0:32:23,856
但首先 我们需要理解

864
00:32:23,856 --> 0:32:25,656
评估是如何工作的

865
00:32:27,046 --> 0:32:28,036
之前演示用的

866
00:32:28,036 --> 0:32:29,446
绘图分类模型

867
00:32:29,446 --> 0:32:30,276
以它为例

868
00:32:31,076 --> 0:32:32,586
如果我们让一副绘图通过这个模型

869
00:32:32,586 --> 0:32:34,006
我们可以得到一个预测

870
00:32:35,546 --> 0:32:38,086
使用真实值数据

871
00:32:38,086 --> 0:32:39,706
我们可以判定该预测

872
00:32:39,706 --> 0:32:43,196
准确与否

873
00:32:43,876 --> 0:32:45,686
但是仅使用一个数据点来

874
00:32:45,686 --> 0:32:48,186
评估模型 并不能

875
00:32:48,186 --> 0:32:50,136
反映模型运作的全景

876
00:32:50,606 --> 0:32:51,606
那我们怎么办呢

877
00:32:52,506 --> 0:32:54,146
答案是用更多的数据

878
00:32:55,496 --> 0:32:57,046
这是我们的测试数据组

879
00:32:58,276 --> 0:33:00,206
我们可以把所有数据放进模型跑一遍

880
00:32:58,276 --> 0:33:00,206
我们可以把所有数据放进模型跑一遍

881
00:33:00,206 --> 0:33:02,766
让每一副绘图

882
00:33:02,766 --> 0:33:05,116
得出正确和错误的预测

883
00:33:06,476 --> 0:33:07,776
将正确与错误的

884
00:33:07,846 --> 0:33:09,156
绘图分成两组

885
00:33:09,156 --> 0:33:11,676
我们就可以

886
00:33:11,676 --> 0:33:13,296
对模型的表现有个概念

887
00:33:14,716 --> 0:33:16,516
这类似于准确性指标

888
00:33:16,516 --> 0:33:18,436
将正确预测的绘图

889
00:33:18,436 --> 0:33:21,096
与数据中绘图的总量

890
00:33:21,096 --> 0:33:22,936
进行量化比较

891
00:33:23,496 --> 0:33:25,906
还有一些其他指标

892
00:33:25,906 --> 0:33:28,836
可以用来量化模型表现

893
00:33:30,256 --> 0:33:32,226
为了在 Turi Create 中使用这些

894
00:33:32,226 --> 0:33:33,996
只需要调用 evaluate 方法

895
00:33:34,586 --> 0:33:35,906
并在模型对象上使用

896
00:33:35,906 --> 0:33:39,326
同时把测试数据组传进去

897
00:33:39,996 --> 0:33:41,856
一个有着这些指标的字典

898
00:33:41,896 --> 0:33:43,866
会被返回

899
00:33:43,866 --> 0:33:47,976
让我们得以评价模型

900
00:33:48,256 --> 0:33:51,196
然而这并不能

901
00:33:51,196 --> 0:33:52,266
告诉我们全部

902
00:33:53,426 --> 0:33:55,786
比方说 一个模型

903
00:33:55,786 --> 0:33:57,576
它的准确度是 85%

904
00:33:58,366 --> 0:34:00,236
乍看之下已经很不错了 对不对

905
00:33:58,366 --> 0:34:00,236
乍看之下已经很不错了 对不对

906
00:34:01,486 --> 0:34:04,166
然而 如果我们深究

907
00:34:04,246 --> 0:34:06,996
每一种类型的准确性

908
00:34:06,996 --> 0:34:08,856
4 这个种类

909
00:34:08,856 --> 0:34:11,536
准确性远低于其他种类

910
00:34:12,116 --> 0:34:14,656
这种情况你们或许

911
00:34:14,656 --> 0:34:16,025
经常会遇到

912
00:34:17,485 --> 0:34:20,335
那么是什么造成了准确性偏低

913
00:34:20,946 --> 0:34:22,596
一种可能性

914
00:34:22,596 --> 0:34:24,436
是那一类的样本

915
00:34:24,436 --> 0:34:27,346
数量偏少

916
00:34:28,295 --> 0:34:30,146
要修正这个问题 我们或许应该

917
00:34:30,146 --> 0:34:31,126
增加更多样本

918
00:34:31,766 --> 0:34:34,226
但或许还有其他因素

919
00:34:34,226 --> 0:34:34,946
影响这个结果

920
00:34:36,085 --> 0:34:38,376
比如 我们注意到

921
00:34:38,376 --> 0:34:40,186
某些数据组的标注

922
00:34:40,186 --> 0:34:41,466
是错误的

923
00:34:42,116 --> 0:34:45,136
左边那幅图

924
00:34:45,136 --> 0:34:46,556
你可以发现

925
00:34:46,876 --> 0:34:48,326
模型的预测结果是 1

926
00:34:48,326 --> 0:34:49,446
但标注却是 7 

927
00:34:50,596 --> 0:34:52,016
当我们亲眼去检查这幅图

928
00:34:52,016 --> 0:34:53,926
我们会发现

929
00:34:53,926 --> 0:34:56,166
标注大概确实应该是 1

930
00:34:57,276 --> 0:34:59,596
我们可以把标注改过来

931
00:35:00,666 --> 0:35:02,306
但是在右边

932
00:35:02,306 --> 0:35:04,466
这个例子里

933
00:35:04,466 --> 0:35:05,906
模型的预测结果是 4

934
00:35:05,906 --> 0:35:08,106
而标注是 1

935
00:35:08,106 --> 0:35:10,386
这种情况很难说是标注错了

936
00:35:10,476 --> 0:35:11,996
还是模型错了

937
00:35:14,676 --> 0:35:16,256
同时你的模型中或许

938
00:35:16,256 --> 0:35:17,776
存在系统性偏差

939
00:35:18,206 --> 0:35:19,886
比如在这个例子里

940
00:35:20,506 --> 0:35:22,026
模型错误地将

941
00:35:22,026 --> 0:35:24,736
带杠的 7 检测为了 3

942
00:35:24,866 --> 0:35:27,586
但正确地检测了

943
00:35:27,586 --> 0:35:28,646
不带杠的 7

944
00:35:28,716 --> 0:35:33,566
为了帮助你找出这些问题

945
00:35:33,636 --> 0:35:35,766
我们创造了一款

946
00:35:35,766 --> 0:35:37,436
可交互的可视化工具

947
00:35:37,436 --> 0:35:40,546
我来展示一下如何使用

948
00:35:40,706 --> 0:35:42,806
我们回到 Jupyter Notebook

949
00:35:42,806 --> 0:35:44,266
就是之前 Shantanu 一直在演示的

950
00:35:44,266 --> 0:35:46,256
我们载入一组

951
00:35:46,366 --> 0:35:48,816
测试数据

952
00:35:48,816 --> 0:35:49,736
来评估模型

953
00:35:57,436 --> 0:35:58,846
我们已经载入了

954
00:35:58,846 --> 0:36:00,546
测试数据组

955
00:35:58,846 --> 0:36:00,546
测试数据组

956
00:36:00,546 --> 0:36:06,816
我们调用评估方法

957
00:36:06,936 --> 0:36:11,696
传入测试数据组

958
00:36:11,916 --> 0:36:13,886
所以现在我们有了 metrics 对象

959
00:36:13,976 --> 0:36:16,776
我们可以直接对 metric 对象

960
00:36:16,776 --> 0:36:18,856
调用 explore 函数

961
00:36:18,936 --> 0:36:21,766
然后来看看

962
00:36:21,766 --> 0:36:23,006
可交互的可视化结果

963
00:36:23,636 --> 0:36:27,356
如你所看到的

964
00:36:27,356 --> 0:36:30,736
这里弹出了一个窗口

965
00:36:30,736 --> 0:36:33,666
有 3 个部分

966
00:36:33,666 --> 0:36:35,436
第一个是 Overview

967
00:36:35,436 --> 0:36:37,346
显示模型的整体准确度

968
00:36:37,346 --> 0:36:38,916
以及模型训练

969
00:36:39,456 --> 0:36:40,756
迭代的次数

970
00:36:40,856 --> 0:36:42,186
绘图分类模型

971
00:36:43,396 --> 0:36:45,426
第二部分是

972
00:36:45,426 --> 0:36:47,466
各个 metrics 的按类的分解

973
00:36:47,786 --> 0:36:49,216
以及一些已经

974
00:36:49,216 --> 0:36:51,396
被模型正确预测的

975
00:36:51,396 --> 0:36:52,596
示例图片

976
00:36:53,596 --> 0:36:55,956
最后是 Error 部分

977
00:36:55,956 --> 0:36:57,826
用来显示模型

978
00:36:57,826 --> 0:37:01,086
做的所有的错误

979
00:36:57,826 --> 0:37:01,086
做的所有的错误

980
00:37:01,286 --> 0:37:02,926
那么我们来看一眼第一类

981
00:37:03,016 --> 0:37:04,446
-4

982
00:37:04,776 --> 0:37:06,816
我们可以看到

983
00:37:06,816 --> 0:37:08,466
这一类的准确度为 20%

984
00:37:09,646 --> 0:37:11,486
如果我们点击的话

985
00:37:11,486 --> 0:37:13,286
可以看到模型做的

986
00:37:13,476 --> 0:37:14,926
四个错误

987
00:37:15,966 --> 0:37:17,276
但是另外我们还能看到

988
00:37:17,276 --> 0:37:18,826
我们测试过的

989
00:37:18,826 --> 0:37:20,366
元素的数量是 5

990
00:37:21,036 --> 0:37:22,706
这是个非常小的数字

991
00:37:23,306 --> 0:37:25,676
想要大致判断

992
00:37:25,676 --> 0:37:27,036
究竟是模型

993
00:37:27,036 --> 0:37:29,006
在这一类别下表现失常

994
00:37:29,006 --> 0:37:30,676
还是用于测试的

995
00:37:30,676 --> 0:37:33,126
样本数量不足

996
00:37:33,126 --> 0:37:34,466
我们得回头添加

997
00:37:34,516 --> 0:37:36,136
更多该类型的样本

998
00:37:36,136 --> 0:37:38,026
才能更好地判断

999
00:37:38,026 --> 0:37:39,636
是模型出了问题

1000
00:37:39,636 --> 0:37:42,676
或是仅仅因为

1001
00:37:42,706 --> 0:37:43,766
样本不足

1002
00:37:44,366 --> 0:37:49,786
我们来看 -2 这个类别

1003
00:37:50,006 --> 0:37:51,596
当我们筛选至这一类别时

1004
00:37:51,596 --> 0:37:53,106
就发现了一些异常

1005
00:37:53,606 --> 0:37:55,506
这一类存在 11 个

1006
00:37:55,506 --> 0:37:57,156
错误的预测

1007
00:37:58,176 --> 0:37:59,556
事实上

1008
00:37:59,556 --> 0:38:01,046
标注写着 -2

1009
00:37:59,556 --> 0:38:01,046
标注写着 -2

1010
00:38:01,046 --> 0:38:02,566
而模型对这些样本的

1011
00:38:02,566 --> 0:38:04,316
预测结果都是 -7

1012
00:38:05,196 --> 0:38:06,396
但当我们检查

1013
00:38:06,396 --> 0:38:07,396
这些错误分类的样本时

1014
00:38:07,396 --> 0:38:09,896
我们发现

1015
00:38:09,896 --> 0:38:12,216
某些样本事实上就是 - 7

1016
00:38:12,736 --> 0:38:14,116
这种情况是因为

1017
00:38:14,116 --> 0:38:16,576
数据组中存在标注错误的数据点

1018
00:38:17,306 --> 0:38:19,196
所以我们得回过头去

1019
00:38:19,196 --> 0:38:21,036
改正这些标注

1020
00:38:21,036 --> 0:38:22,296
来得到更佳的

1021
00:38:22,296 --> 0:38:23,426
模型表现

1022
00:38:23,976 --> 0:38:27,956
我们也加入一些

1023
00:38:27,956 --> 0:38:30,546
其他的 metrics 比如 F1 分数

1024
00:38:30,546 --> 0:38:32,266
精准度和召回率

1025
00:38:32,266 --> 0:38:33,986
这些可能当你评估你的模型时

1026
00:38:33,986 --> 0:38:36,126
相关性更强

1027
00:38:38,536 --> 0:38:42,826
我们来总结一下

1028
00:38:44,556 --> 0:38:45,776
现在你可以进行

1029
00:38:45,776 --> 0:38:47,946
可交互的可视化模型预测

1030
00:38:49,496 --> 0:38:51,256
这可以帮助我们轻松地发现

1031
00:38:51,556 --> 0:38:53,346
标注错误

1032
00:38:53,346 --> 0:38:55,336
以及分辨之前提到过的

1033
00:38:55,336 --> 0:38:56,646
系统性偏差

1034
00:38:57,936 --> 0:38:59,416
当我们找出了问题所在

1035
00:38:59,416 --> 0:39:01,516
有哪几步能让我们

1036
00:38:59,416 --> 0:39:01,516
有哪几步能让我们

1037
00:39:01,586 --> 0:39:03,816
改善模型表现呢

1038
00:39:03,816 --> 0:39:07,876
我们来看一眼工作流程

1039
00:39:09,836 --> 0:39:12,586
首先我们有了测试数据组

1040
00:39:14,006 --> 0:39:15,456
把它传入

1041
00:39:15,456 --> 0:39:17,006
绘图分类模型

1042
00:39:17,006 --> 0:39:18,586
然后使用

1043
00:39:18,586 --> 0:39:20,906
可交互可视化工具来找出问题

1044
00:39:22,746 --> 0:39:25,416
我们可能需要添加

1045
00:39:25,416 --> 0:39:28,096
更多样本来解决某些问题

1046
00:39:29,556 --> 0:39:31,136
也可能需要删除一些

1047
00:39:31,136 --> 0:39:34,236
错误的训练数据

1048
00:39:34,236 --> 0:39:37,056
或是更新错误的标注

1049
00:39:37,476 --> 0:39:39,856
在 Turi Create 中

1050
00:39:39,856 --> 0:39:42,806
你可以载入数据 同样也能

1051
00:39:42,846 --> 0:39:44,576
分类和筛选数据

1052
00:39:44,576 --> 0:39:46,716
来帮你删除错误的训练数据

1053
00:39:48,496 --> 0:39:50,196
如果你想添加更多数据

1054
00:39:51,046 --> 0:39:52,616
可以使用附加指令轻松完成

1055
00:39:53,266 --> 0:39:57,746
我们在最新的 Turi Create 6.0 中

1056
00:39:57,746 --> 0:40:00,976
加入了标注工具

1057
00:39:57,746 --> 0:40:00,976
加入了标注工具

1058
00:40:01,046 --> 0:40:03,176
当你传入一个你想标注的数据组

1059
00:40:03,176 --> 0:40:05,646
会弹出一个图形用户界面

1060
00:40:05,646 --> 0:40:07,856
它由两个部分组成

1061
00:40:08,846 --> 0:40:10,576
在你的左边

1062
00:40:10,576 --> 0:40:11,756
是你想要标注的图像

1063
00:40:11,806 --> 0:40:13,336
在你的右边

1064
00:40:13,336 --> 0:40:14,066
是一个标签列

1065
00:40:15,466 --> 0:40:17,436
你可以添加标签

1066
00:40:17,436 --> 0:40:18,286
来标注你的数据点

1067
00:40:19,786 --> 0:40:21,576
但是我们也意识到了

1068
00:40:21,576 --> 0:40:22,976
如果你正在处理的

1069
00:40:23,026 --> 0:40:25,796
是一个庞大的数据组

1070
00:40:25,866 --> 0:40:29,366
花费时间来检查整个数据组

1071
00:40:29,426 --> 0:40:30,546
该有多烦

1072
00:40:30,546 --> 0:40:31,426
所以我们添加了

1073
00:40:31,426 --> 0:40:32,366
图片相似性 而且

1074
00:40:32,406 --> 0:40:34,526
我们来快速过一下你的数据组

1075
00:40:35,776 --> 0:40:37,996
我们也加入了 Table 视图

1076
00:40:38,066 --> 0:40:39,676
能让你快速在

1077
00:40:39,676 --> 0:40:41,336
数据组中滑动

1078
00:40:41,336 --> 0:40:43,376
看看标注

1079
00:40:43,376 --> 0:40:44,806
或许能看到一些

1080
00:40:44,866 --> 0:40:47,076
我们刚才聊到的系统性偏差

1081
00:40:47,076 --> 0:40:48,936
还有为多个图片添加多个标注

1082
00:40:49,516 --> 0:40:57,546
[掌声]

1083
00:40:58,046 --> 0:40:59,546
给这次讲座来个总结

1084
00:41:00,206 --> 0:41:03,416
Sam 和 Shantanu 向我们展示了

1085
00:41:03,416 --> 0:41:06,046
新的单样本目标检测器 Toolkit

1086
00:41:06,946 --> 0:41:08,616
Shantanu 为 Sam 的牌局

1087
00:41:08,616 --> 0:41:10,656
做了一个 Three Card Poker App

1088
00:41:10,656 --> 0:41:12,586
而且基于一个类一张图

1089
00:41:12,586 --> 0:41:16,566
就建造了一个鲁棒性高的模型

1090
00:41:16,736 --> 0:41:18,086
接着我们见识了新的

1091
00:41:18,086 --> 0:41:19,896
绘图分类 Toolkit

1092
00:41:20,516 --> 0:41:24,536
它整合了 Apple Pencil

1093
00:41:26,716 --> 0:41:28,986
可交互可视化工具

1094
00:41:29,296 --> 0:41:32,216
向我们展示了如何

1095
00:41:32,216 --> 0:41:34,886
可交互地评估模型

1096
00:41:34,946 --> 0:41:37,046
希望你们也能体会到

1097
00:41:37,176 --> 0:41:39,816
它对用户体验的优化

1098
00:41:40,406 --> 0:41:43,326
最后 我们介绍了一款新的

1099
00:41:43,326 --> 0:41:45,136
标注工具

1100
00:41:45,136 --> 0:41:46,876
不仅能让你做数据标注

1101
00:41:46,876 --> 0:41:48,006
还能通过图像相似性

1102
00:41:48,006 --> 0:41:49,796
让你快速浏览数据组

1103
00:41:50,816 --> 0:41:52,656
请试一试 Turi Create

1104
00:41:52,946 --> 0:41:54,016
希望你们喜欢这个环节

1105
00:41:54,016 --> 0:41:56,156
如果你想观看更多演示

1106
00:41:56,246 --> 0:41:57,366
或是有任何疑问

1107
00:41:57,366 --> 0:41:59,456
欢迎来参加下午两点的实验室环节

1108
00:42:00,726 --> 0:42:01,886
欢迎你们来参加

1109
00:42:01,886 --> 0:42:03,066
这些相关会议

1110
00:42:04,536 --> 0:42:05,976
感谢来到 WWDC 2019

1111
00:42:06,516 --> 0:42:09,500
[掌声]
