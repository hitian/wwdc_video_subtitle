1
00:00:00,506 --> 0:00:05,516
[ Music ]

2
00:00:06,516 --> 0:00:13,566
[ Applause ]

3
00:00:14,066 --> 0:00:15,986
&gt;&gt; Hey, everyone.

4
00:00:16,436 --> 0:00:17,476
My name is Michael Brennan.

5
00:00:17,576 --> 0:00:19,116
I'm a software engineer here at

6
00:00:19,116 --> 0:00:20,386
Apple working on Core ML.

7
00:00:21,336 --> 0:00:23,026
And I'm thrilled to be able to

8
00:00:23,026 --> 0:00:23,996
share with you some of the

9
00:00:23,996 --> 0:00:25,636
amazing new features we've

10
00:00:25,636 --> 0:00:27,726
introduced this year for Core ML

11
00:00:27,776 --> 0:00:27,976
3.

12
00:00:30,336 --> 0:00:31,856
Core ML makes it as easy as

13
00:00:31,856 --> 0:00:33,946
possible to seamlessly integrate

14
00:00:33,946 --> 0:00:35,076
machine learning into your

15
00:00:35,076 --> 0:00:37,156
application allowing you to

16
00:00:37,156 --> 0:00:38,686
create a wide variety of novel

17
00:00:39,136 --> 0:00:40,336
and compelling experiences.

18
00:00:41,376 --> 0:00:43,156
At the center of all of this is

19
00:00:43,246 --> 0:00:46,856
the model itself.

20
00:00:47,046 --> 0:00:48,716
You can get a model from a

21
00:00:48,716 --> 0:00:49,776
number of supported training

22
00:00:49,776 --> 0:00:51,736
libraries by converting them

23
00:00:51,736 --> 0:00:53,026
using the converters we have as

24
00:00:53,546 --> 0:00:55,066
a part of our Core ML tools

25
00:00:55,226 --> 0:00:57,146
which we provide.

26
00:00:57,276 --> 0:00:59,966
And with the addition of the new

27
00:00:59,966 --> 0:01:01,716
Create ML app, we've made it

28
00:00:59,966 --> 0:01:01,716
Create ML app, we've made it

29
00:01:01,716 --> 0:01:03,906
even easier than before to get a

30
00:01:03,906 --> 0:01:04,256
model.

31
00:01:06,596 --> 0:01:07,816
So in this session we're going

32
00:01:07,816 --> 0:01:09,926
to cover a number of topics from

33
00:01:10,006 --> 0:01:11,276
personalizing those models on

34
00:01:11,276 --> 0:01:13,106
device to additional support

35
00:01:13,106 --> 0:01:14,296
we've added for neural networks

36
00:01:14,936 --> 0:01:16,196
and even more.

37
00:01:17,476 --> 0:01:18,436
So let's get started by talking

38
00:01:18,436 --> 0:01:20,116
a little bit about personalizing

39
00:01:20,116 --> 0:01:21,496
your models on-device.

40
00:01:24,396 --> 0:01:27,046
Traditionally, these models are

41
00:01:27,046 --> 0:01:28,196
either bundled with or

42
00:01:28,196 --> 0:01:29,506
downloaded to your application.

43
00:01:30,066 --> 0:01:31,206
And once on your device are

44
00:01:31,206 --> 0:01:33,136
completely mutable being

45
00:01:33,136 --> 0:01:34,426
optimized heavily for

46
00:01:34,426 --> 0:01:36,306
performance within your app.

47
00:01:38,596 --> 0:01:39,506
The great thing about

48
00:01:39,506 --> 0:01:40,596
associating a model with your

49
00:01:40,596 --> 0:01:42,036
app is it means you can provide

50
00:01:42,036 --> 0:01:43,756
the same great experience across

51
00:01:43,756 --> 0:01:44,776
all of your users.

52
00:01:45,326 --> 0:01:47,626
But each user is unique.

53
00:01:48,206 --> 0:01:49,856
They each have their own

54
00:01:49,856 --> 0:01:51,696
specialized needs, their own

55
00:01:51,736 --> 0:01:53,526
individual ways of interacting

56
00:01:53,526 --> 0:01:54,256
with your application.

57
00:01:55,416 --> 0:01:56,366
I think this creates an

58
00:01:56,366 --> 0:01:56,946
opportunity.

59
00:01:57,506 --> 0:02:00,626
What if each user could get a

60
00:01:57,506 --> 0:02:00,626
What if each user could get a

61
00:02:00,626 --> 0:02:02,746
model personalized specifically

62
00:02:02,836 --> 0:02:03,356
for them?

63
00:02:03,906 --> 0:02:06,746
Well, let's look at the case of

64
00:02:06,746 --> 0:02:07,966
one user on how to do this.

65
00:02:08,955 --> 0:02:10,306
We can take data from that user,

66
00:02:11,156 --> 0:02:12,226
set up some sort of cloud

67
00:02:12,226 --> 0:02:14,636
service, send that data to that

68
00:02:14,636 --> 0:02:17,026
cloud service, and in the cloud

69
00:02:17,126 --> 0:02:18,216
create that new model

70
00:02:18,446 --> 0:02:20,056
personalized on that data which

71
00:02:20,056 --> 0:02:21,096
will then deploy back to that

72
00:02:21,096 --> 0:02:21,386
user.

73
00:02:23,276 --> 0:02:23,956
This creates a number of

74
00:02:23,956 --> 0:02:25,076
challenges, both to you, the

75
00:02:25,076 --> 0:02:26,956
developers, and to our users.

76
00:02:28,486 --> 0:02:30,086
For you, it creates the

77
00:02:30,086 --> 0:02:32,756
challenge of added expenses with

78
00:02:32,756 --> 0:02:33,976
making these cloud services

79
00:02:34,026 --> 0:02:35,886
managing that service and

80
00:02:35,886 --> 0:02:36,836
creating an infrastructure that

81
00:02:36,836 --> 0:02:38,316
could scale to million of users.

82
00:02:38,976 --> 0:02:41,036
And for the user, obviously they

83
00:02:41,036 --> 0:02:43,266
have to expose all their data.

84
00:02:43,266 --> 0:02:43,976
It's unwanted.

85
00:02:44,146 --> 0:02:44,856
It's invasive.

86
00:02:44,856 --> 0:02:46,346
They have to expose this and

87
00:02:46,346 --> 0:02:47,116
send it up to the cloud where

88
00:02:47,116 --> 0:02:48,766
it'll be managed by some other

89
00:02:48,766 --> 0:02:49,116
party.

90
00:02:49,716 --> 0:02:53,786
On Core ML 3, you can do this

91
00:02:53,786 --> 0:02:55,946
kind of personalization all on

92
00:02:55,946 --> 0:02:56,376
device.

93
00:02:57,516 --> 0:03:03,176
[ Applause ]

94
00:02:57,516 --> 0:03:03,176
[ Applause ]

95
00:03:03,676 --> 0:03:05,006
Simply take that general model

96
00:03:05,566 --> 0:03:06,806
and with the data the users

97
00:03:06,806 --> 0:03:09,186
created or regenerated, you can

98
00:03:09,186 --> 0:03:10,676
personalize that model with that

99
00:03:11,276 --> 0:03:14,756
data for that user.

100
00:03:14,906 --> 0:03:16,376
This means that the data stays

101
00:03:16,476 --> 0:03:16,816
private.

102
00:03:17,426 --> 0:03:18,686
It never leaves the device.

103
00:03:19,676 --> 0:03:20,856
This means there's no need for a

104
00:03:20,856 --> 0:03:21,946
server to do this kind of

105
00:03:21,946 --> 0:03:22,616
interactivity.

106
00:03:22,616 --> 0:03:24,566
And this means you can do it

107
00:03:24,566 --> 0:03:24,896
anywhere.

108
00:03:25,356 --> 0:03:26,956
You're not tying your users down

109
00:03:26,956 --> 0:03:29,426
to Wi-Fi or some data plan just

110
00:03:29,426 --> 0:03:30,106
to update their model.

111
00:03:33,306 --> 0:03:34,376
Before we continue, let's look

112
00:03:34,376 --> 0:03:36,056
inside one of these models and

113
00:03:36,496 --> 0:03:38,706
see what's there today.

114
00:03:38,876 --> 0:03:40,176
Currently, your model consists

115
00:03:40,176 --> 0:03:42,046
of mostly parameters, things

116
00:03:42,046 --> 0:03:43,506
like the weights of the layers

117
00:03:43,506 --> 0:03:44,346
if it's a neural network for

118
00:03:44,346 --> 0:03:44,776
example.

119
00:03:45,396 --> 0:03:46,556
And some metadata describing

120
00:03:46,556 --> 0:03:48,196
things like licensing and

121
00:03:48,196 --> 0:03:50,056
authors, as well as an

122
00:03:50,056 --> 0:03:50,716
interface.

123
00:03:50,716 --> 0:03:51,736
And this where your app concerns

124
00:03:51,736 --> 0:03:52,226
itself with.

125
00:03:52,776 --> 0:03:53,756
It describes how you can

126
00:03:53,756 --> 0:03:55,736
interact with this model.

127
00:03:56,516 --> 0:03:58,396
On Core ML 3, we've added a new

128
00:03:58,436 --> 0:04:00,026
set of parameters to help

129
00:03:58,436 --> 0:04:00,026
set of parameters to help

130
00:04:00,026 --> 0:04:00,496
updating.

131
00:04:00,496 --> 0:04:01,496
It describes what parts of the

132
00:04:01,496 --> 0:04:02,986
model are updatable and how it's

133
00:04:02,986 --> 0:04:03,446
updatable.

134
00:04:03,976 --> 0:04:04,966
We've added a new update

135
00:04:04,966 --> 0:04:06,146
interface your app can leverage

136
00:04:06,146 --> 0:04:07,096
to make these updates happen.

137
00:04:10,216 --> 0:04:11,396
This means that all the

138
00:04:11,396 --> 0:04:13,206
functionality is accessed

139
00:04:13,206 --> 0:04:14,396
directly through that interface.

140
00:04:14,686 --> 0:04:16,136
We encapsulate away a lot of

141
00:04:16,136 --> 0:04:18,366
those heavy details and it's all

142
00:04:18,366 --> 0:04:19,755
contained within that one model

143
00:04:19,755 --> 0:04:20,096
file.

144
00:04:20,726 --> 0:04:23,166
So just like in making a

145
00:04:23,166 --> 0:04:24,616
prediction, we supply a set of

146
00:04:24,616 --> 0:04:25,446
inputs and you get a

147
00:04:25,446 --> 0:04:26,756
corresponding set of outputs.

148
00:04:27,756 --> 0:04:29,146
Making an update is easy, you

149
00:04:29,146 --> 0:04:30,216
just supply a set of training

150
00:04:30,216 --> 0:04:31,796
examples and you'll get out a

151
00:04:31,796 --> 0:04:33,006
new variant of that model that

152
00:04:33,106 --> 0:04:34,636
was fit or fine-tuned to that

153
00:04:34,636 --> 0:04:34,856
data.

154
00:04:38,096 --> 0:04:40,356
For Core ML 3, we support making

155
00:04:40,356 --> 0:04:41,736
updatable models of nearest

156
00:04:41,736 --> 0:04:43,586
neighbor classifiers as well as

157
00:04:43,586 --> 0:04:44,416
neural networks.

158
00:04:44,646 --> 0:04:45,496
And we're going to support

159
00:04:45,496 --> 0:04:46,706
embedding an updatable model

160
00:04:46,706 --> 0:04:48,296
within your pipeline, meaning

161
00:04:48,296 --> 0:04:49,626
your pipelines are updatable

162
00:04:49,626 --> 0:04:49,896
too.

163
00:04:50,486 --> 0:04:54,576
And with that, I think we should

164
00:04:54,576 --> 0:04:55,386
see this in action.

165
00:04:55,746 --> 0:04:56,976
So I'd like to hand it over to

166
00:04:56,976 --> 0:04:58,286
my colleague Anil Katti.

167
00:04:59,016 --> 0:04:59,336
Anil.

168
00:05:00,516 --> 0:05:06,176
[ Applause ]

169
00:05:06,676 --> 0:05:07,516
&gt;&gt; Thanks, Michael.

170
00:05:07,896 --> 0:05:11,756
Hello. Today I show how I build

171
00:05:11,756 --> 0:05:12,846
an experience that was

172
00:05:12,916 --> 0:05:15,536
customized for my users using

173
00:05:15,906 --> 0:05:17,126
model personalization.

174
00:05:17,716 --> 0:05:19,486
For this I have an app that

175
00:05:19,486 --> 0:05:21,216
helps teachers grade students'

176
00:05:21,216 --> 0:05:21,616
homework.

177
00:05:22,536 --> 0:05:23,846
I added a cool new feature to

178
00:05:23,846 --> 0:05:25,176
this app using model

179
00:05:25,176 --> 0:05:25,826
personalization.

180
00:05:26,046 --> 0:05:27,186
But before we talk about the

181
00:05:27,186 --> 0:05:28,426
feature, let's see what the app

182
00:05:28,426 --> 0:05:28,946
does first.

183
00:05:28,946 --> 0:05:30,456
Let me switch over to the demo

184
00:05:30,456 --> 0:05:30,976
screen.

185
00:05:37,376 --> 0:05:40,136
Great. So here's the app.

186
00:05:40,136 --> 0:05:41,306
It's called a Personalized

187
00:05:41,306 --> 0:05:41,886
Grading App.

188
00:05:42,396 --> 0:05:44,356
What it allows you to do is take

189
00:05:44,356 --> 0:05:47,626
a picture of the homework and

190
00:05:47,626 --> 0:05:49,896
start grading the way our

191
00:05:49,896 --> 0:05:51,006
teacher would on a sheet of

192
00:05:51,006 --> 0:05:51,396
paper.

193
00:05:52,266 --> 0:05:53,846
You'd mark something as correct

194
00:05:53,846 --> 0:05:55,556
like that and something as wrong

195
00:05:55,856 --> 0:05:56,436
like that.

196
00:05:56,736 --> 0:05:58,166
It's pretty straightforward.

197
00:05:58,356 --> 0:05:59,626
Pretty simple.

198
00:06:00,186 --> 0:06:02,416
The app uses PencilKit to

199
00:06:02,416 --> 0:06:04,126
capture the input and the

200
00:06:04,126 --> 0:06:05,736
pretrained Core ML model to

201
00:06:05,736 --> 0:06:07,746
recognize the grading samples.

202
00:06:08,856 --> 0:06:10,726
Now recently, I added a new

203
00:06:10,726 --> 0:06:12,686
feature that allows teachers

204
00:06:13,086 --> 0:06:14,556
give something special for the

205
00:06:14,556 --> 0:06:16,026
kids for encouragement.

206
00:06:17,216 --> 0:06:18,066
And that is stickers.

207
00:06:19,136 --> 0:06:21,026
Kids absolutely love collecting

208
00:06:21,026 --> 0:06:22,026
stickers on their homework.

209
00:06:22,436 --> 0:06:23,306
So we thought it might be a

210
00:06:23,306 --> 0:06:24,816
really nice enhancement to the

211
00:06:25,006 --> 0:06:26,736
app if they could allow-- if we

212
00:06:26,736 --> 0:06:27,566
could allow them to give

213
00:06:27,566 --> 0:06:27,936
stickers.

214
00:06:29,356 --> 0:06:31,056
So to give a sticker, I could

215
00:06:31,056 --> 0:06:32,596
tap on this plus button up here.

216
00:06:32,596 --> 0:06:35,396
Scroll through the list of

217
00:06:35,396 --> 0:06:38,236
stickers, maybe pick one, and

218
00:06:38,236 --> 0:06:40,466
drag it to the right location

219
00:06:40,466 --> 0:06:40,726
[inaudible].

220
00:06:40,726 --> 0:06:41,146
This works.

221
00:06:41,146 --> 0:06:46,396
But I think we can make the flow

222
00:06:46,396 --> 0:06:48,356
even better and absolutely

223
00:06:48,356 --> 0:06:49,576
magical for our users.

224
00:06:49,846 --> 0:06:52,266
Let's think about it a little

225
00:06:52,766 --> 0:06:52,866
bit.

226
00:06:53,776 --> 0:06:55,786
The user is only using an Apple

227
00:06:55,786 --> 0:06:57,156
Pencil for grading.

228
00:06:57,156 --> 0:06:59,296
How cool would it be if they

229
00:06:59,296 --> 0:07:00,646
could quickly sketch something

230
00:06:59,296 --> 0:07:00,646
could quickly sketch something

231
00:07:01,046 --> 0:07:03,246
anywhere on the entire screen

232
00:07:03,476 --> 0:07:04,936
and the app automatically pick

233
00:07:04,936 --> 0:07:06,316
the right sticker of the correct

234
00:07:06,316 --> 0:07:07,766
size and place it at the right

235
00:07:07,766 --> 0:07:09,876
location for them.

236
00:07:10,096 --> 0:07:11,656
Well, we can definitely do

237
00:07:11,656 --> 0:07:12,806
something like that with machine

238
00:07:12,806 --> 0:07:13,306
learning, right?

239
00:07:13,306 --> 0:07:15,036
So let's explore some options.

240
00:07:15,296 --> 0:07:16,686
Let me switch over to the

241
00:07:16,686 --> 0:07:16,956
slides.

242
00:07:17,666 --> 0:07:18,496
Well, some of you who have

243
00:07:18,496 --> 0:07:20,646
already worked on Core ML might

244
00:07:20,646 --> 0:07:21,826
be thinking, well, we could

245
00:07:21,826 --> 0:07:25,426
actually pre-train a model that

246
00:07:25,426 --> 0:07:27,286
can recognize stickers and ship

247
00:07:27,286 --> 0:07:29,316
it as part of the app.

248
00:07:29,406 --> 0:07:30,496
Well, we could do that but there

249
00:07:30,496 --> 0:07:31,476
are a few issues with this

250
00:07:31,476 --> 0:07:31,966
approach.

251
00:07:32,586 --> 0:07:34,836
For one, there are a lot of

252
00:07:34,836 --> 0:07:36,556
stickers out there and we might

253
00:07:36,556 --> 0:07:37,746
have to collect a lot of

254
00:07:37,746 --> 0:07:39,176
training data in order to

255
00:07:39,176 --> 0:07:41,966
pre-train these models, although

256
00:07:41,966 --> 0:07:43,326
a particular user might only be

257
00:07:43,326 --> 0:07:46,026
interested in a small subset of

258
00:07:46,756 --> 0:07:47,336
these stickers.

259
00:07:47,336 --> 0:07:50,436
Second, how does this pretrained

260
00:07:50,436 --> 0:07:52,196
model work if I plan to

261
00:07:52,196 --> 0:07:53,426
introduce a bunch of new

262
00:07:53,426 --> 0:07:55,826
stickers in the future?

263
00:07:56,006 --> 0:07:57,386
Well, I might have to re-train

264
00:07:57,386 --> 0:07:59,666
the model and ship it as an app

265
00:07:59,666 --> 0:08:01,716
update or maybe allow the app to

266
00:07:59,666 --> 0:08:01,716
update or maybe allow the app to

267
00:08:01,716 --> 0:08:02,986
download it.

268
00:08:04,136 --> 0:08:05,766
Lastly, and I think this is the

269
00:08:05,766 --> 0:08:07,706
most crucial point, how does

270
00:08:07,706 --> 0:08:08,956
this pretrained model work for

271
00:08:08,956 --> 0:08:09,786
different users?

272
00:08:12,316 --> 0:08:14,496
Different users have different

273
00:08:14,496 --> 0:08:15,326
ways of sketching.

274
00:08:16,376 --> 0:08:18,076
If I went out and I asked a

275
00:08:18,076 --> 0:08:19,516
hundred different people to

276
00:08:19,516 --> 0:08:20,896
quickly sketch this mind-blowing

277
00:08:20,896 --> 0:08:22,606
sticker, I'll get at least 50

278
00:08:22,606 --> 0:08:23,276
different answers.

279
00:08:24,006 --> 0:08:25,476
Now, it's truly mind-blowing how

280
00:08:25,476 --> 0:08:26,376
different people are.

281
00:08:26,906 --> 0:08:28,546
So what should the app do in

282
00:08:28,546 --> 0:08:29,626
this case?

283
00:08:30,616 --> 0:08:32,856
Should we-- Should the app train

284
00:08:32,856 --> 0:08:35,655
the users on how to sketch

285
00:08:35,655 --> 0:08:39,626
something, or should the users

286
00:08:39,626 --> 0:08:41,666
train the app, enhance the model

287
00:08:41,876 --> 0:08:43,816
how to recognize your sketches?

288
00:08:44,826 --> 0:08:46,516
Well, that's exactly what model

289
00:08:46,516 --> 0:08:49,556
personalization is all about.

290
00:08:49,756 --> 0:08:51,626
What I did was use model

291
00:08:51,626 --> 0:08:53,926
personalization to train-- to

292
00:08:53,926 --> 0:08:55,856
define a model using the data

293
00:08:55,856 --> 0:08:56,866
that I collected about the

294
00:08:56,866 --> 0:08:59,206
user-- from the user to suit

295
00:08:59,206 --> 0:08:59,816
their needs.

296
00:08:59,966 --> 0:09:01,246
Let me show how that translates

297
00:08:59,966 --> 0:09:01,246
Let me show how that translates

298
00:09:01,246 --> 0:09:02,536
to user experience.

299
00:09:08,516 --> 0:09:09,636
I'll switch back to the demo

300
00:09:09,636 --> 0:09:11,286
screen to continue my grading.

301
00:09:12,046 --> 0:09:13,336
So the third answer-- third

302
00:09:13,336 --> 0:09:14,666
question there is pretty tricky

303
00:09:14,666 --> 0:09:15,846
for kindergarten care, but I

304
00:09:15,846 --> 0:09:17,246
think Jane got it spot on.

305
00:09:17,396 --> 0:09:18,796
There are four triangles in that

306
00:09:18,796 --> 0:09:19,646
diagram.

307
00:09:20,016 --> 0:09:20,996
So, good job, Jane.

308
00:09:21,896 --> 0:09:23,856
Well, now I want to give her a

309
00:09:23,856 --> 0:09:25,476
sticker to recognize the

310
00:09:25,476 --> 0:09:26,716
attention to detail, but I want

311
00:09:26,716 --> 0:09:27,946
to do it by quickly sketching

312
00:09:27,946 --> 0:09:28,286
something.

313
00:09:28,886 --> 0:09:29,956
Let's try doing that.

314
00:09:30,466 --> 0:09:35,526
So the app seems to tell me that

315
00:09:35,526 --> 0:09:36,826
it could not recognize what I

316
00:09:36,826 --> 0:09:38,406
sketch, which is pretty fair

317
00:09:38,406 --> 0:09:39,396
because this is the first time

318
00:09:39,396 --> 0:09:40,176
I'm using this app.

319
00:09:40,616 --> 0:09:42,406
So let me try to add a sticker,

320
00:09:42,666 --> 0:09:43,946
but this time I'll say I want to

321
00:09:43,946 --> 0:09:45,966
create a shortcut, right.

322
00:09:45,966 --> 0:09:47,146
And I'll pick the same sticker

323
00:09:47,146 --> 0:09:48,836
that I used last time.

324
00:09:49,876 --> 0:09:52,446
So now the app is asking me to

325
00:09:52,446 --> 0:09:54,646
give an example of how I would

326
00:09:54,646 --> 0:09:55,896
sketch this particular sticker.

327
00:09:56,616 --> 0:09:57,876
It doesn't have to be perfect.

328
00:09:57,876 --> 0:09:59,466
It doesn't even have to resemble

329
00:09:59,466 --> 0:09:59,926
the sticker.

330
00:10:00,296 --> 0:10:02,566
It's just my own representation

331
00:10:02,916 --> 0:10:05,336
of how I would want to sketch

332
00:10:05,336 --> 0:10:05,976
that sticker, right?

333
00:10:06,286 --> 0:10:09,516
So I'll just use a single star

334
00:10:10,136 --> 0:10:13,576
to represent that particular

335
00:10:13,576 --> 0:10:13,996
sticker.

336
00:10:13,996 --> 0:10:16,926
The app asked me for a couple of

337
00:10:16,926 --> 0:10:18,226
more examples, which is pretty

338
00:10:18,226 --> 0:10:19,726
fair, and it just took a few

339
00:10:19,726 --> 0:10:21,726
seconds but now it looks like

340
00:10:21,726 --> 0:10:23,126
the app-- the shortcut has been

341
00:10:23,126 --> 0:10:23,916
registered.

342
00:10:24,586 --> 0:10:26,516
Now I see the sticker as well as

343
00:10:26,516 --> 0:10:28,186
examples I provided in the

344
00:10:28,186 --> 0:10:28,736
screen.

345
00:10:29,866 --> 0:10:31,356
Before I go back, let me add one

346
00:10:31,356 --> 0:10:33,416
more sticker to my library.

347
00:10:34,536 --> 0:10:35,806
So, there was this really nice

348
00:10:35,966 --> 0:10:37,616
high five sticker that I wanted

349
00:10:37,616 --> 0:10:39,026
to use, which is right here.

350
00:10:39,676 --> 0:10:42,236
I wonder what I should use as

351
00:10:42,236 --> 0:10:42,976
shortcut for this.

352
00:10:43,706 --> 0:10:45,186
I wanted-- I want something that

353
00:10:45,186 --> 0:10:46,596
is easy to remember, easy to

354
00:10:46,596 --> 0:10:47,076
sketch.

355
00:10:47,426 --> 0:10:49,236
How about the number 5, which

356
00:10:49,236 --> 0:10:52,406
kind of says high five?

357
00:10:53,276 --> 0:10:55,926
Great. So just two more examples

358
00:10:55,926 --> 0:10:56,576
and I'm done.

359
00:10:58,006 --> 0:11:00,006
Let's go back to the screen and

360
00:10:58,006 --> 0:11:00,006
Let's go back to the screen and

361
00:11:00,006 --> 0:11:01,166
try giving that sticker that

362
00:11:01,166 --> 0:11:02,456
Jane has been desperately

363
00:11:02,456 --> 0:11:03,156
waiting for.

364
00:11:04,626 --> 0:11:05,826
Isn't that cool?

365
00:11:06,516 --> 0:11:10,966
[ Applause ]

366
00:11:11,466 --> 0:11:12,986
I'm so glad I didn't have the go

367
00:11:12,986 --> 0:11:14,656
through the sticker picker and

368
00:11:14,656 --> 0:11:15,756
move the sticker around and all

369
00:11:15,756 --> 0:11:16,746
those mess.

370
00:11:17,736 --> 0:11:19,256
Great. For the next one-- yeah,

371
00:11:19,256 --> 0:11:20,166
that's right as well.

372
00:11:20,166 --> 0:11:21,526
So let me give another small

373
00:11:21,526 --> 0:11:22,416
star there.

374
00:11:23,176 --> 0:11:24,456
I'm super happy with the way the

375
00:11:24,456 --> 0:11:26,256
app behaves, so a big high five

376
00:11:26,256 --> 0:11:27,026
at the top.

377
00:11:27,446 --> 0:11:28,976
How about that?

378
00:11:29,516 --> 0:11:35,786
[ Applause ]

379
00:11:36,286 --> 0:11:38,166
So this was just an example.

380
00:11:38,166 --> 0:11:39,316
You guys can think about really

381
00:11:39,316 --> 0:11:41,566
amazing experiences that you can

382
00:11:41,566 --> 0:11:42,856
kind of solve using this new

383
00:11:42,856 --> 0:11:43,226
feature.

384
00:11:43,876 --> 0:11:45,516
So before I wrap up, let me

385
00:11:45,516 --> 0:11:46,696
quickly go with the things that

386
00:11:46,696 --> 0:11:47,856
I had to do in order to

387
00:11:47,856 --> 0:11:48,736
implement this feature.

388
00:11:49,856 --> 0:11:51,376
So the first thing I had to do

389
00:11:51,866 --> 0:11:54,416
was import an updatable Core ML

390
00:11:54,416 --> 0:11:56,366
model into my project.

391
00:11:57,096 --> 0:11:58,186
And this is how it looks in

392
00:11:58,186 --> 0:11:58,856
Xcode.

393
00:12:00,656 --> 0:12:01,626
Since I was trying to

394
00:12:01,626 --> 0:12:03,396
personalize the model by adding

395
00:12:03,396 --> 0:12:05,776
new stickers or classes, using

396
00:12:05,776 --> 0:12:07,046
the nearest neighbor classifier

397
00:12:07,046 --> 0:12:10,356
made a lot of sense, although

398
00:12:10,356 --> 0:12:12,176
that is a pretrained neural

399
00:12:12,176 --> 0:12:14,046
network feature extractor, that

400
00:12:14,046 --> 0:12:15,216
is filling in into the nearest

401
00:12:15,216 --> 0:12:16,676
neighbor classifier to help

402
00:12:16,676 --> 0:12:18,096
improve the prediction

403
00:12:18,096 --> 0:12:19,116
efficiency and robustness.

404
00:12:20,016 --> 0:12:21,696
But that's it, you don't have to

405
00:12:21,696 --> 0:12:23,306
worry about any of model details

406
00:12:23,666 --> 0:12:25,466
since Core ML abstracts the way

407
00:12:25,866 --> 0:12:27,026
all the model details from the

408
00:12:27,026 --> 0:12:27,946
API surface.

409
00:12:31,576 --> 0:12:32,906
You can use this model for

410
00:12:32,906 --> 0:12:33,276
prediction.

411
00:12:33,276 --> 0:12:34,586
There is no change there.

412
00:12:35,486 --> 0:12:36,606
In Xcode you will see the

413
00:12:36,606 --> 0:12:37,976
prediction inputs and outputs

414
00:12:37,976 --> 0:12:38,636
like before.

415
00:12:40,096 --> 0:12:42,276
But what's new this year is an

416
00:12:42,276 --> 0:12:43,066
update section.

417
00:12:44,366 --> 0:12:45,666
This describes the set of

418
00:12:45,666 --> 0:12:47,446
inputs, yeah, this model

419
00:12:47,446 --> 0:12:48,656
requires for personalization.

420
00:12:49,226 --> 0:12:50,646
And as expected, it requires a

421
00:12:50,646 --> 0:12:51,896
sticker which is a grayscale

422
00:12:51,896 --> 0:12:54,066
image, and a corresponding

423
00:12:54,066 --> 0:12:55,086
sketch which is a grayscale

424
00:12:55,086 --> 0:12:56,496
image, and a corresponding

425
00:12:56,496 --> 0:12:57,856
sticker which serves as a true

426
00:12:57,856 --> 0:12:59,346
label in order to personalize.

427
00:13:00,326 --> 0:13:02,206
In terms of code, you may recall

428
00:13:02,206 --> 0:13:04,326
that Core ML auto-generates a

429
00:13:04,326 --> 0:13:06,196
set of classes to help you with

430
00:13:06,196 --> 0:13:06,786
the prediction.

431
00:13:07,296 --> 0:13:09,086
And now it generates new class

432
00:13:09,596 --> 0:13:10,716
that helps you provide the

433
00:13:10,716 --> 0:13:11,896
training data in a [inaudible]

434
00:13:11,896 --> 0:13:12,246
manner.

435
00:13:13,336 --> 0:13:14,606
If you peek into this class,

436
00:13:14,986 --> 0:13:16,466
you'll see a set of properties

437
00:13:16,676 --> 0:13:17,906
which are in line with what you

438
00:13:17,906 --> 0:13:19,156
saw in Xcode, right?

439
00:13:19,156 --> 0:13:21,646
So we see the sketch and the

440
00:13:21,646 --> 0:13:22,596
sticker here.

441
00:13:24,556 --> 0:13:26,986
So once you have collected all

442
00:13:26,986 --> 0:13:29,056
the training data from the user

443
00:13:29,556 --> 0:13:31,596
that is required to personalize

444
00:13:31,596 --> 0:13:34,016
a model for-- or for the user,

445
00:13:34,746 --> 0:13:36,076
the actual personalization

446
00:13:36,076 --> 0:13:37,746
itself can happen in three easy

447
00:13:37,746 --> 0:13:38,106
steps.

448
00:13:38,106 --> 0:13:40,206
First, you need to get the

449
00:13:40,206 --> 0:13:43,356
updatable model URL that you

450
00:13:43,356 --> 0:13:44,886
could get either from the bundle

451
00:13:45,136 --> 0:13:46,526
or from a previous snapshot of

452
00:13:46,526 --> 0:13:47,576
the updated model.

453
00:13:47,876 --> 0:13:50,616
Next, you would prepare the

454
00:13:50,616 --> 0:13:52,056
training data in the expected

455
00:13:52,056 --> 0:13:52,556
format.

456
00:13:53,176 --> 0:13:55,236
For this, you could either use

457
00:13:55,666 --> 0:13:57,786
the origin rated class that I

458
00:13:57,786 --> 0:13:59,336
showed or build a feature

459
00:13:59,336 --> 0:14:00,416
provider of your own.

460
00:13:59,336 --> 0:14:00,416
provider of your own.

461
00:14:01,616 --> 0:14:03,766
And lastly, you would kick off

462
00:14:03,766 --> 0:14:04,596
an update task.

463
00:14:05,176 --> 0:14:07,736
Once the update is complete,

464
00:14:08,146 --> 0:14:09,686
completion handler gets invoked

465
00:14:10,176 --> 0:14:11,636
which provides you the updated

466
00:14:11,636 --> 0:14:13,666
model that you can use for

467
00:14:13,666 --> 0:14:14,766
predictions immediately.

468
00:14:15,236 --> 0:14:16,026
It's that simple.

469
00:14:16,026 --> 0:14:18,246
I can't wait to see all the cool

470
00:14:18,246 --> 0:14:19,446
things that you will build on

471
00:14:19,446 --> 0:14:21,006
top of this in your apps and

472
00:14:21,006 --> 0:14:21,576
frameworks.

473
00:14:21,916 --> 0:14:23,016
With that, let me hand it back

474
00:14:23,046 --> 0:14:24,756
to Michael to recap and cover

475
00:14:24,756 --> 0:14:26,036
some more complex scenarios and

476
00:14:26,036 --> 0:14:26,976
model personalization.

477
00:14:27,236 --> 0:14:27,586
Thank you.

478
00:14:28,516 --> 0:14:32,500
[ Applause ]

479
00:14:36,526 --> 0:14:37,506
&gt;&gt; All right.

480
00:14:37,586 --> 0:14:38,156
Thanks, Anil.

481
00:14:41,436 --> 0:14:43,476
So just a recap, Anil just

482
00:14:43,476 --> 0:14:44,396
showed us, we took our base

483
00:14:44,396 --> 0:14:46,886
model and we tried to make a

484
00:14:46,886 --> 0:14:48,066
personal experience out of that

485
00:14:48,676 --> 0:14:50,306
by supplying some drawings which

486
00:14:50,396 --> 0:14:52,706
were just beautiful to our model

487
00:14:52,706 --> 0:14:53,566
and seeing what we got as an

488
00:14:53,566 --> 0:14:53,936
output.

489
00:14:54,946 --> 0:14:56,936
Initially, we didn't get much.

490
00:14:58,016 --> 0:14:59,546
That's because internally, even

491
00:14:59,546 --> 0:15:00,446
though we have that pretrained

492
00:14:59,546 --> 0:15:00,446
though we have that pretrained

493
00:15:00,446 --> 0:15:02,216
neural network, it feeds into a

494
00:15:02,216 --> 0:15:02,996
K-nearest neighbor base

495
00:15:02,996 --> 0:15:04,816
classifier which is actually

496
00:15:04,816 --> 0:15:05,146
empty.

497
00:15:05,146 --> 0:15:06,476
It has no neighbors to classify

498
00:15:06,476 --> 0:15:06,596
on.

499
00:15:10,046 --> 0:15:11,156
So we actually update this and

500
00:15:11,156 --> 0:15:11,936
give us some neighbors.

501
00:15:11,936 --> 0:15:13,896
Well, as Anil showed us, we took

502
00:15:13,896 --> 0:15:15,516
our training data, the stickers

503
00:15:15,516 --> 0:15:16,656
we chose and the drawings we

504
00:15:16,656 --> 0:15:17,916
drew to correspond with that,

505
00:15:17,916 --> 0:15:19,896
and we feed those along with our

506
00:15:19,896 --> 0:15:22,186
base model, with that updatable

507
00:15:22,186 --> 0:15:23,256
K-nearest neighbor base model in

508
00:15:23,256 --> 0:15:24,696
it to our update task.

509
00:15:25,966 --> 0:15:27,056
And this gives us that new

510
00:15:27,056 --> 0:15:27,916
variant of our model.

511
00:15:31,046 --> 0:15:32,216
And this new variant can more

512
00:15:32,216 --> 0:15:34,136
reliably recognize what it was

513
00:15:34,136 --> 0:15:36,866
trained on while internally the

514
00:15:36,866 --> 0:15:38,196
only thing that's changed was

515
00:15:38,196 --> 0:15:39,426
that updatable K-nearest

516
00:15:39,426 --> 0:15:43,896
neighbor base model.

517
00:15:44,056 --> 0:15:45,106
So let's look at the ML update

518
00:15:45,106 --> 0:15:45,976
task class, which we've

519
00:15:45,976 --> 0:15:47,576
introduced this year to help

520
00:15:47,576 --> 0:15:48,536
with managing these update

521
00:15:48,566 --> 0:15:49,146
processes.

522
00:15:50,606 --> 0:15:52,066
So it has a state associated

523
00:15:52,066 --> 0:15:53,006
with it where it's at in the

524
00:15:53,006 --> 0:15:54,326
process as well as the ability

525
00:15:54,326 --> 0:15:56,066
to resume and cancel that task.

526
00:15:56,596 --> 0:15:58,566
And to construct one you just

527
00:15:58,566 --> 0:16:00,756
pass in that base URL for your

528
00:15:58,566 --> 0:16:00,756
pass in that base URL for your

529
00:16:00,756 --> 0:16:03,246
model along with configuration

530
00:16:03,416 --> 0:16:05,076
and the training data.

531
00:16:05,656 --> 0:16:07,086
And as Anil showed, you need to

532
00:16:07,086 --> 0:16:08,336
pass in a completion handler as

533
00:16:08,336 --> 0:16:08,556
well.

534
00:16:09,526 --> 0:16:11,096
As completion handler, we'll

535
00:16:11,096 --> 0:16:11,926
call when you're done with the

536
00:16:11,926 --> 0:16:13,106
update task and it gives you an

537
00:16:13,106 --> 0:16:14,046
update context.

538
00:16:14,736 --> 0:16:16,376
And you can use this to write

539
00:16:16,376 --> 0:16:17,426
out that model when you're done

540
00:16:17,426 --> 0:16:19,076
with your update, to make

541
00:16:19,076 --> 0:16:20,746
predictions on it, and query

542
00:16:20,746 --> 0:16:22,006
other parts of that task which

543
00:16:22,006 --> 0:16:23,206
allows us to get part of this

544
00:16:24,126 --> 0:16:26,436
update context.

545
00:16:26,436 --> 0:16:27,616
In code, as Anil showed us,

546
00:16:27,886 --> 0:16:28,696
really straightforward to

547
00:16:28,696 --> 0:16:29,046
implement.

548
00:16:29,746 --> 0:16:31,036
You just construct an

549
00:16:31,036 --> 0:16:33,586
MLupdateTask provided that URL,

550
00:16:33,636 --> 0:16:35,106
your configuration, and your

551
00:16:35,106 --> 0:16:36,636
completion handler, which here

552
00:16:36,636 --> 0:16:38,166
we use to check for accuracy,

553
00:16:38,766 --> 0:16:40,056
retain the model outside the

554
00:16:40,056 --> 0:16:42,266
scope of this block and save out

555
00:16:42,266 --> 0:16:42,606
that model.

556
00:16:43,286 --> 0:16:43,776
This is great.

557
00:16:44,056 --> 0:16:45,556
It works really well and it got

558
00:16:45,556 --> 0:16:46,216
us through this demo.

559
00:16:46,766 --> 0:16:49,096
But what about the more complex

560
00:16:49,096 --> 0:16:49,916
use cases, right?

561
00:16:49,916 --> 0:16:51,146
What about neural networks?

562
00:16:51,686 --> 0:16:53,756
Well, a neural network in its

563
00:16:53,756 --> 0:16:55,066
simplest case is just a

564
00:16:55,066 --> 0:16:57,046
collection of layers, each with

565
00:16:57,096 --> 0:16:58,426
some inputs and some weights

566
00:16:58,776 --> 0:17:00,146
that it uses in combination to

567
00:16:58,776 --> 0:17:00,146
that it uses in combination to

568
00:17:00,146 --> 0:17:02,376
create an output.

569
00:17:02,556 --> 0:17:03,766
To adjust that output, we'll

570
00:17:03,766 --> 0:17:04,836
need to adjust the weights in

571
00:17:04,836 --> 0:17:05,536
those layers.

572
00:17:05,786 --> 0:17:07,036
And to do that, we need to mark

573
00:17:07,036 --> 0:17:08,215
these layers as updatable.

574
00:17:08,726 --> 0:17:11,556
And we need some way of telling

575
00:17:11,556 --> 0:17:12,886
it by how much our output was

576
00:17:12,886 --> 0:17:13,215
off.

577
00:17:13,715 --> 0:17:15,415
If we expected a star smiley

578
00:17:15,415 --> 0:17:17,146
face and we got a high five, we

579
00:17:17,146 --> 0:17:17,915
need to correct for that.

580
00:17:17,915 --> 0:17:18,945
And that's going to be done to

581
00:17:18,945 --> 0:17:20,366
our loss functions, which

582
00:17:20,366 --> 0:17:21,586
describes that delta there.

583
00:17:22,796 --> 0:17:23,816
And finally we need to provide

584
00:17:23,816 --> 0:17:25,026
this to our optimizer.

585
00:17:25,026 --> 0:17:26,536
And this takes that loss, our

586
00:17:26,536 --> 0:17:27,876
output, and it figures out by

587
00:17:27,876 --> 0:17:29,146
how much to actually adjust the

588
00:17:29,146 --> 0:17:30,086
weights in these layers.

589
00:17:30,616 --> 0:17:35,316
On Core ML 3, we support

590
00:17:35,316 --> 0:17:37,406
updating of convolution and

591
00:17:37,406 --> 0:17:38,956
fully collect-- fully connected

592
00:17:38,956 --> 0:17:40,906
layers as well as having the

593
00:17:40,906 --> 0:17:42,016
ability to back-propagate

594
00:17:42,016 --> 0:17:42,606
through many more.

595
00:17:43,166 --> 0:17:44,426
And we support categorical

596
00:17:44,426 --> 0:17:46,256
cross-entropy and mean squared

597
00:17:46,256 --> 0:17:46,986
error loss types.

598
00:17:48,036 --> 0:17:49,436
In addition, we support

599
00:17:49,436 --> 0:17:51,166
stochastic gradient descent and

600
00:17:51,166 --> 0:17:52,646
Adam optimization strategies.

601
00:17:53,166 --> 0:17:56,076
This is awesome, right?

602
00:17:56,516 --> 0:17:58,316
But there's other parameters

603
00:17:58,316 --> 0:17:59,536
associated with neural networks,

604
00:17:59,946 --> 0:18:00,766
like learning rate and the

605
00:17:59,946 --> 0:18:00,766
like learning rate and the

606
00:18:00,766 --> 0:18:01,936
number of epoch to run for.

607
00:18:02,816 --> 0:18:03,556
This is all are going to be

608
00:18:03,556 --> 0:18:05,036
encapsulated within that model.

609
00:18:06,436 --> 0:18:07,796
We understand that some of you

610
00:18:07,796 --> 0:18:08,676
may want to change that at

611
00:18:08,676 --> 0:18:09,746
runtime though.

612
00:18:10,536 --> 0:18:12,126
And you can do that.

613
00:18:12,206 --> 0:18:13,286
By overriding the update

614
00:18:13,316 --> 0:18:14,866
parameters dictionary and your

615
00:18:14,866 --> 0:18:16,476
model configuration, you can

616
00:18:16,476 --> 0:18:17,736
override those values within,

617
00:18:18,606 --> 0:18:20,096
using MLParameterKey and just

618
00:18:20,096 --> 0:18:21,216
specifying values for them,

619
00:18:21,746 --> 0:18:23,406
giving you a lot of flexibility

620
00:18:24,006 --> 0:18:24,096
here.

621
00:18:26,216 --> 0:18:27,936
In addition, if you're wondering

622
00:18:27,936 --> 0:18:28,956
what parameters are actually

623
00:18:28,956 --> 0:18:30,436
embedded within my model anyway,

624
00:18:31,026 --> 0:18:32,136
you can check out the parameter

625
00:18:32,136 --> 0:18:33,716
section of that model view in

626
00:18:33,766 --> 0:18:35,106
Xcode and it will give you

627
00:18:35,106 --> 0:18:36,606
details for the values of those

628
00:18:36,636 --> 0:18:37,826
parameters as well as what

629
00:18:37,826 --> 0:18:39,056
parameters are actually defined

630
00:18:39,056 --> 0:18:39,646
within that model.

631
00:18:43,676 --> 0:18:45,766
You may want more flexibility

632
00:18:45,766 --> 0:18:47,136
than the API we showed earlier

633
00:18:47,776 --> 0:18:48,576
and we provide that.

634
00:18:49,666 --> 0:18:50,986
In your MLUpdateTask, you can

635
00:18:50,986 --> 0:18:51,486
provide an

636
00:18:51,486 --> 0:18:53,896
MLupdateProgressHandler instead

637
00:18:53,896 --> 0:18:55,566
of the completion handler and

638
00:18:55,566 --> 0:18:56,756
supply progress handlers and

639
00:18:56,756 --> 0:18:58,356
that completion handler that

640
00:18:58,356 --> 0:18:59,246
will allow you to key in

641
00:18:59,246 --> 0:19:00,096
specific events.

642
00:18:59,246 --> 0:19:00,096
specific events.

643
00:19:00,176 --> 0:19:01,626
So when your training began or

644
00:19:01,626 --> 0:19:03,896
when an epoch ended, we'll call

645
00:19:03,896 --> 0:19:06,066
your progress handler and we'll

646
00:19:06,066 --> 0:19:07,316
provide you that update context

647
00:19:07,316 --> 0:19:08,536
just as we did in the completion

648
00:19:09,006 --> 0:19:09,236
handler.

649
00:19:10,696 --> 0:19:12,526
In addition, we'll tell you what

650
00:19:12,526 --> 0:19:13,976
event caused us to call that

651
00:19:13,976 --> 0:19:16,176
callback as well as giving you

652
00:19:16,176 --> 0:19:17,416
key metrics, so you can query

653
00:19:17,416 --> 0:19:19,126
for your training loss as each

654
00:19:19,126 --> 0:19:20,446
mini batch or each epoch gets

655
00:19:20,476 --> 0:19:20,936
processed.

656
00:19:21,416 --> 0:19:24,546
And in code, still really

657
00:19:24,546 --> 0:19:25,186
straightforward.

658
00:19:25,536 --> 0:19:26,186
You construct this

659
00:19:26,246 --> 0:19:28,126
MLupdateProgressHandler, tell it

660
00:19:28,126 --> 0:19:29,046
what events you're interested

661
00:19:29,046 --> 0:19:30,596
in, and supply a block to be

662
00:19:30,596 --> 0:19:30,926
called.

663
00:19:31,476 --> 0:19:33,666
In addition, you'll just provide

664
00:19:33,666 --> 0:19:34,656
the completion handler there as

665
00:19:34,656 --> 0:19:37,246
well and the MLUpdateTask you

666
00:19:37,246 --> 0:19:38,696
just provide the set of progress

667
00:19:38,696 --> 0:19:39,086
handlers.

668
00:19:43,276 --> 0:19:44,456
So we've talked about how to

669
00:19:44,456 --> 0:19:45,696
update your models and what it

670
00:19:45,696 --> 0:19:46,556
means to update them.

671
00:19:46,926 --> 0:19:47,746
Well, we haven't really

672
00:19:47,746 --> 0:19:49,446
discussed yet so far is when

673
00:19:49,446 --> 0:19:50,356
it's appropriate to do that.

674
00:19:51,506 --> 0:19:52,446
Now, on the grading app we

675
00:19:52,446 --> 0:19:53,666
showed earlier, we're doing it

676
00:19:54,156 --> 0:19:55,246
the second he interacted with

677
00:19:55,286 --> 0:19:56,756
the app and drew a drawing.

678
00:19:57,126 --> 0:19:58,686
And we took that data and sent

679
00:19:58,686 --> 0:19:59,266
it off to the model.

680
00:19:59,266 --> 0:20:00,976
But that may not be appropriate.

681
00:19:59,266 --> 0:20:00,976
But that may not be appropriate.

682
00:20:01,116 --> 0:20:02,886
What if you have thousands or

683
00:20:02,886 --> 0:20:03,936
millions of data points?

684
00:20:04,946 --> 0:20:05,826
And what if your model's

685
00:20:05,826 --> 0:20:06,896
incredibly complicated?

686
00:20:07,966 --> 0:20:09,406
Well, I'm thrilled to say that

687
00:20:09,406 --> 0:20:10,596
using the BackgroundTask

688
00:20:10,596 --> 0:20:12,876
framework will allot several

689
00:20:12,876 --> 0:20:13,956
minutes of runtime to your

690
00:20:13,956 --> 0:20:14,566
application.

691
00:20:15,076 --> 0:20:16,336
Even if the user isn't using

692
00:20:16,336 --> 0:20:17,566
your app or even if they're not

693
00:20:17,596 --> 0:20:19,636
interacting with the device, you

694
00:20:19,636 --> 0:20:21,666
just use the BGTaskScheduler and

695
00:20:21,666 --> 0:20:23,566
make a BGProcessingTaskRequest

696
00:20:24,046 --> 0:20:24,726
and we'll give you several

697
00:20:24,726 --> 0:20:26,216
minutes to do further updates

698
00:20:26,586 --> 0:20:27,696
and further computations.

699
00:20:29,016 --> 0:20:29,916
And to see more about this--

700
00:20:29,916 --> 0:20:29,983
Yeah

701
00:20:30,516 --> 0:20:33,506
[ Applause ]

702
00:20:34,006 --> 0:20:34,726
It's great.

703
00:20:34,796 --> 0:20:35,846
And to see more about this, I

704
00:20:35,846 --> 0:20:37,746
highly recommend you check out

705
00:20:37,746 --> 0:20:39,046
Advances in App Background

706
00:20:39,046 --> 0:20:39,636
Execution.

707
00:20:42,976 --> 0:20:44,276
In addition, how do you get an

708
00:20:44,276 --> 0:20:44,956
updatable model?

709
00:20:44,956 --> 0:20:46,246
Well, as we talked about earlier

710
00:20:46,246 --> 0:20:47,766
in the session, you can get a

711
00:20:47,766 --> 0:20:49,156
model by converting them from a

712
00:20:49,156 --> 0:20:50,296
number of supported training

713
00:20:50,296 --> 0:20:52,216
libraries, that story has not

714
00:20:52,216 --> 0:20:52,586
changed.

715
00:20:53,986 --> 0:20:55,186
You simply pass the respect

716
00:20:55,186 --> 0:20:56,886
trainable flag in when you're

717
00:20:56,886 --> 0:20:58,616
converting your model and it'll

718
00:20:58,616 --> 0:20:59,986
take those trainable parameters

719
00:20:59,986 --> 0:21:00,636
- the things like what

720
00:20:59,986 --> 0:21:00,636
- the things like what

721
00:21:00,636 --> 0:21:01,936
optimization strategy you want,

722
00:21:02,376 --> 0:21:04,136
what layers are updatable -- and

723
00:21:04,136 --> 0:21:05,366
we'll take that and embed that

724
00:21:05,366 --> 0:21:06,096
within your model.

725
00:21:06,516 --> 0:21:07,336
And then the rest of it, it's

726
00:21:07,336 --> 0:21:08,256
just as what it was before.

727
00:21:08,786 --> 0:21:11,036
And for those of you who want to

728
00:21:11,036 --> 0:21:12,226
modify the model itself

729
00:21:12,226 --> 0:21:13,886
directly, that's still fully

730
00:21:13,886 --> 0:21:17,646
supported as well.

731
00:21:18,056 --> 0:21:19,056
So we've talked about how to

732
00:21:19,056 --> 0:21:20,496
make a more personal experience

733
00:21:20,496 --> 0:21:22,386
for a user in your application,

734
00:21:22,766 --> 0:21:24,066
using on-device model

735
00:21:24,066 --> 0:21:26,376
personalization, and you can do

736
00:21:26,376 --> 0:21:27,366
that through our new flexible

737
00:21:27,366 --> 0:21:28,026
yet simple API.

738
00:21:29,276 --> 0:21:29,716
It's great.

739
00:21:30,046 --> 0:21:30,966
You can do this completely

740
00:21:30,966 --> 0:21:31,546
on-device.

741
00:21:32,206 --> 0:21:34,346
And with that, I'd like to hand

742
00:21:34,346 --> 0:21:35,796
it over to my colleague Aseem

743
00:21:35,796 --> 0:21:36,906
Wadhwa to tell you more about

744
00:21:36,906 --> 0:21:37,906
some of the amazing new features

745
00:21:37,906 --> 0:21:39,226
we've added this year for neural

746
00:21:39,516 --> 0:21:39,976
networks.

747
00:21:40,516 --> 0:21:47,376
[ Applause ]

748
00:21:47,876 --> 0:21:49,566
&gt;&gt; OK. So I'm very excited to

749
00:21:49,566 --> 0:21:52,256
talk about what's new in Core ML

750
00:21:52,256 --> 0:21:53,906
this year for neural networks.

751
00:21:54,676 --> 0:21:57,126
But before we jump into that, I

752
00:21:57,126 --> 0:21:58,946
do want to spend a few minutes

753
00:21:58,976 --> 0:22:01,016
talking about neural networks in

754
00:21:58,976 --> 0:22:01,016
talking about neural networks in

755
00:22:02,096 --> 0:22:02,346
general.

756
00:22:02,866 --> 0:22:04,686
Well, we all know that neural

757
00:22:04,686 --> 0:22:06,816
networks are great at solving

758
00:22:06,816 --> 0:22:08,906
challenging task, such as

759
00:22:08,906 --> 0:22:10,176
understanding the content of an

760
00:22:10,176 --> 0:22:12,786
image or a document or an audio

761
00:22:12,786 --> 0:22:13,096
clip.

762
00:22:14,516 --> 0:22:17,006
And we can use this capability

763
00:22:17,006 --> 0:22:18,436
to build some amazing apps

764
00:22:18,436 --> 0:22:20,806
around them.

765
00:22:21,836 --> 0:22:23,726
Now, if you look inside a neural

766
00:22:23,726 --> 0:22:25,416
network and try to see its

767
00:22:25,416 --> 0:22:27,646
structure, we can maybe get a

768
00:22:27,646 --> 0:22:28,926
better understanding about it.

769
00:22:29,746 --> 0:22:31,666
So let's try to do that.

770
00:22:31,826 --> 0:22:33,176
But instead of looking from a

771
00:22:33,176 --> 0:22:35,066
point of view of a researcher,

772
00:22:35,416 --> 0:22:36,396
let's try a different

773
00:22:36,396 --> 0:22:36,866
perspective.

774
00:22:37,286 --> 0:22:39,276
Let's try to look at it from a

775
00:22:39,636 --> 0:22:40,716
programmer's perspective.

776
00:22:41,316 --> 0:22:43,576
So if you visualize inside a

777
00:22:43,576 --> 0:22:45,966
Core ML model, what we see is

778
00:22:45,966 --> 0:22:47,466
something like a graph.

779
00:22:47,856 --> 0:22:50,056
And if you look closely, we

780
00:22:50,056 --> 0:22:52,286
realize that graph is just

781
00:22:52,286 --> 0:22:54,116
another representation of a

782
00:22:54,116 --> 0:22:54,526
program.

783
00:22:55,386 --> 0:22:57,766
Let's look at it again.

784
00:22:58,446 --> 0:23:00,406
So here is a very simple code

785
00:22:58,446 --> 0:23:00,406
So here is a very simple code

786
00:23:00,406 --> 0:23:02,056
snippet that we all understand.

787
00:23:02,766 --> 0:23:04,456
And here is its corresponding

788
00:23:04,596 --> 0:23:05,536
graph representation.

789
00:23:06,016 --> 0:23:07,806
So as you might have noticed

790
00:23:07,806 --> 0:23:09,356
that the operations in the code

791
00:23:09,736 --> 0:23:11,386
have become these notes in the

792
00:23:11,386 --> 0:23:13,846
graph and the readable such as

793
00:23:13,846 --> 0:23:16,786
X, Y, Z, are these edges in the

794
00:23:16,786 --> 0:23:17,196
graph.

795
00:23:18,026 --> 0:23:19,416
Now, if you go back to a neural

796
00:23:19,416 --> 0:23:22,236
network graph and now show a

797
00:23:22,236 --> 0:23:24,216
corresponding code snippet, it

798
00:23:24,216 --> 0:23:25,616
looks pretty similar to what we

799
00:23:25,616 --> 0:23:26,166
had before.

800
00:23:26,586 --> 0:23:27,856
But there are a couple of

801
00:23:27,886 --> 0:23:32,286
differences I want to point out.

802
00:23:32,326 --> 0:23:35,206
One, instead of those simple

803
00:23:35,396 --> 0:23:37,156
numeric variables, we now have

804
00:23:37,186 --> 0:23:39,236
these multidimensional variables

805
00:23:39,646 --> 0:23:41,096
that have couple of attributes.

806
00:23:41,166 --> 0:23:43,226
So it has an attribute called

807
00:23:43,226 --> 0:23:46,276
shape and something called rank,

808
00:23:46,436 --> 0:23:47,596
which is a number of dimensions

809
00:23:47,596 --> 0:23:48,056
that it has.

810
00:23:48,476 --> 0:23:50,526
And the second thing is the

811
00:23:50,526 --> 0:23:52,246
functions operating on these

812
00:23:52,246 --> 0:23:53,866
multidimensional variables are

813
00:23:53,866 --> 0:23:55,626
now these specialized math

814
00:23:55,626 --> 0:23:57,276
functions, which is sometimes

815
00:23:57,336 --> 0:23:59,236
called as layers or operations.

816
00:24:00,546 --> 0:24:06,646
So if you really look at the

817
00:24:07,406 --> 0:24:09,056
neural network, we see that it's

818
00:24:09,056 --> 0:24:12,206
essentially either a graph or a

819
00:24:12,206 --> 0:24:15,506
program that involves these very

820
00:24:15,506 --> 0:24:17,426
large multidimensional variables

821
00:24:17,746 --> 0:24:19,226
and these very heavy

822
00:24:19,366 --> 0:24:20,336
mathematical functions.

823
00:24:20,656 --> 0:24:21,806
So essentially it's a very

824
00:24:21,806 --> 0:24:23,646
compute and memory intensive

825
00:24:24,006 --> 0:24:24,986
program.

826
00:24:24,986 --> 0:24:27,276
And the nice thing about Core ML

827
00:24:27,276 --> 0:24:30,306
is that it encapsulates all

828
00:24:30,306 --> 0:24:32,236
these complexity into a single

829
00:24:32,236 --> 0:24:34,526
file format, which the Core ML

830
00:24:34,526 --> 0:24:35,796
framework and then sort of

831
00:24:35,796 --> 0:24:37,626
optimize and execute very

832
00:24:37,626 --> 0:24:38,246
efficiently.

833
00:24:39,516 --> 0:24:41,906
So if we go back last year and

834
00:24:41,906 --> 0:24:43,286
see what we had in Core ML 2,

835
00:24:43,286 --> 0:24:45,766
well, we could easily represent

836
00:24:45,956 --> 0:24:47,856
straight-line code using acyclic

837
00:24:47,856 --> 0:24:48,246
graphs.

838
00:24:48,846 --> 0:24:50,976
And we had about 40 different

839
00:24:50,976 --> 0:24:52,526
layer types using which we could

840
00:24:52,526 --> 0:24:54,246
represent most of the common

841
00:24:54,396 --> 0:24:56,436
convolutional and recurrent

842
00:24:56,816 --> 0:24:57,726
architectures.

843
00:24:58,496 --> 0:24:59,666
So what's new this year?

844
00:25:00,356 --> 0:25:02,086
Well, as you might have noticed

845
00:25:02,506 --> 0:25:05,806
with my analogy to program, we

846
00:25:05,806 --> 0:25:07,376
all know that code can be much

847
00:25:07,376 --> 0:25:08,516
more complex than simple

848
00:25:08,516 --> 0:25:09,546
straight-line code, right?

849
00:25:09,886 --> 0:25:12,556
For instance, it's quite common

850
00:25:12,556 --> 0:25:14,996
to use a control flow like a

851
00:25:14,996 --> 0:25:16,946
branch as shown in the code

852
00:25:16,976 --> 0:25:17,636
snippet here.

853
00:25:18,106 --> 0:25:19,966
And now, in Core ML 3, what's

854
00:25:19,966 --> 0:25:21,356
new is that we can represent the

855
00:25:21,446 --> 0:25:23,466
same concept of a branch within

856
00:25:23,466 --> 0:25:24,006
the neural network

857
00:25:24,006 --> 0:25:24,696
specification.

858
00:25:25,516 --> 0:25:30,346
[ Applause ]

859
00:25:30,846 --> 0:25:32,546
So another common form of

860
00:25:32,576 --> 0:25:34,566
control flow is obviously loops,

861
00:25:34,856 --> 0:25:36,356
and that too can be really

862
00:25:36,356 --> 0:25:38,496
easily expressed within a Core

863
00:25:38,496 --> 0:25:39,366
ML network.

864
00:25:40,116 --> 0:25:42,046
Moving on to another complex

865
00:25:42,046 --> 0:25:44,586
feature of code, something we do

866
00:25:44,586 --> 0:25:45,806
often when we're writing a

867
00:25:45,806 --> 0:25:49,026
dynamic code is allocate memory

868
00:25:49,026 --> 0:25:49,646
at runtime.

869
00:25:50,056 --> 0:25:51,356
As shown in this code snippet,

870
00:25:51,356 --> 0:25:52,836
we are allocating a memory that

871
00:25:52,836 --> 0:25:54,466
depends on the input of the

872
00:25:54,466 --> 0:25:56,026
program so it can change at

873
00:25:56,026 --> 0:25:56,406
runtime.

874
00:25:56,856 --> 0:25:58,406
Now we can do exactly the same

875
00:25:58,406 --> 0:26:00,696
in Core ML this year using what

876
00:25:58,406 --> 0:26:00,696
in Core ML this year using what

877
00:26:00,696 --> 0:26:03,796
we call dynamic layers, which

878
00:26:03,796 --> 0:26:05,686
allows us to change the shape of

879
00:26:05,686 --> 0:26:07,116
the multi array based on the

880
00:26:07,116 --> 0:26:08,296
input of the graph.

881
00:26:08,296 --> 0:26:09,486
So you might be thinking that

882
00:26:09,486 --> 0:26:11,476
why are we adding sort of these

883
00:26:11,476 --> 0:26:14,446
new complex code constructs

884
00:26:14,446 --> 0:26:15,896
within the Core ML graph, and

885
00:26:15,896 --> 0:26:17,336
the answer is simple, because

886
00:26:17,476 --> 0:26:18,976
neural networks research is

887
00:26:18,976 --> 0:26:20,986
actively exploring these ideas

888
00:26:21,266 --> 0:26:22,916
to make even more powerful

889
00:26:22,916 --> 0:26:24,006
neural networks.

890
00:26:24,006 --> 0:26:25,546
In fact, many state of the art

891
00:26:25,546 --> 0:26:28,286
neural networks sort of-- have

892
00:26:28,286 --> 0:26:30,036
some sort of control flow built

893
00:26:30,036 --> 0:26:31,346
into them.

894
00:26:31,656 --> 0:26:33,136
Another aspect that researchers

895
00:26:33,486 --> 0:26:36,376
are constantly exploring is sort

896
00:26:36,376 --> 0:26:38,076
of new operations.

897
00:26:38,436 --> 0:26:41,186
And for that, we have added lots

898
00:26:41,186 --> 0:26:43,076
of new layers to Core ML this

899
00:26:43,136 --> 0:26:43,356
year.

900
00:26:43,986 --> 0:26:45,736
Not only have we made the

901
00:26:45,736 --> 0:26:47,606
existing layers more generic but

902
00:26:47,606 --> 0:26:49,756
we have added lots of new basic

903
00:26:49,756 --> 0:26:50,876
mathematical operations.

904
00:26:51,336 --> 0:26:53,186
So, if you come across a new

905
00:26:53,186 --> 0:26:55,046
layer, it's highly likely that

906
00:26:55,046 --> 0:26:56,556
it can be expressed in terms of

907
00:26:56,556 --> 0:26:58,416
the layers that are there in

908
00:26:58,416 --> 0:26:58,976
Core ML 3.

909
00:26:59,516 --> 0:27:06,186
[ Applause ]

910
00:26:59,516 --> 0:27:06,186
[ Applause ]

911
00:27:06,686 --> 0:27:08,646
So with all these features of

912
00:27:08,646 --> 0:27:11,076
control flow, dynamic behavior,

913
00:27:11,076 --> 0:27:13,306
and new layers, the Core ML

914
00:27:13,306 --> 0:27:14,826
model has become much more

915
00:27:14,826 --> 0:27:16,006
expressive than before.

916
00:27:16,586 --> 0:27:18,406
And the great part of it is that

917
00:27:18,776 --> 0:27:20,466
most of the popular

918
00:27:20,466 --> 0:27:21,816
architectures out there can now

919
00:27:21,816 --> 0:27:23,686
be easily expressed in the Core

920
00:27:23,686 --> 0:27:24,176
ML format.

921
00:27:24,766 --> 0:27:26,006
So as you can see on this slide,

922
00:27:26,006 --> 0:27:27,736
we have listed a few of those.

923
00:27:28,066 --> 0:27:29,956
And the ones highlighted have

924
00:27:29,956 --> 0:27:31,996
really come in the last few

925
00:27:31,996 --> 0:27:33,016
months and they're really

926
00:27:33,016 --> 0:27:33,956
pushing the boundaries of

927
00:27:33,956 --> 0:27:34,996
machine learning research.

928
00:27:35,296 --> 0:27:36,976
And now you can easily express

929
00:27:37,026 --> 0:27:39,176
them in Core ML and integrate

930
00:27:39,176 --> 0:27:40,636
them in your apps.

931
00:27:40,756 --> 0:27:41,356
So that's great.

932
00:27:42,516 --> 0:27:47,476
[ Applause ]

933
00:27:47,976 --> 0:27:49,156
So now you might be wondering

934
00:27:49,156 --> 0:27:50,836
that how do I make use of these

935
00:27:51,066 --> 0:27:52,976
new features within a Core ML

936
00:27:53,016 --> 0:27:53,416
model.

937
00:27:53,656 --> 0:27:55,146
Well, the answer is same as it

938
00:27:55,146 --> 0:27:55,876
was last year.

939
00:27:56,326 --> 0:27:58,076
There are two options to build a

940
00:27:58,076 --> 0:27:59,876
Core ML model.

941
00:28:00,326 --> 0:28:02,626
One, since Core ML is an open

942
00:28:02,626 --> 0:28:04,366
source Protobuf specification,

943
00:28:04,746 --> 0:28:06,836
we can always specify a model

944
00:28:06,976 --> 0:28:08,556
programmatically using any

945
00:28:08,556 --> 0:28:09,536
programming language of your

946
00:28:09,536 --> 0:28:09,946
choice.

947
00:28:10,126 --> 0:28:12,026
So that option is always

948
00:28:12,026 --> 0:28:13,066
available to us.

949
00:28:13,506 --> 0:28:14,786
But in the majority of the

950
00:28:14,786 --> 0:28:16,596
cases, we like to use converters

951
00:28:16,666 --> 0:28:18,086
that can automatically do that

952
00:28:18,086 --> 0:28:20,486
for us by translating a graph

953
00:28:20,586 --> 0:28:22,186
from a different representation

954
00:28:22,716 --> 0:28:24,276
into the Core ML representation.

955
00:28:24,656 --> 0:28:25,996
So let's look at both of these

956
00:28:25,996 --> 0:28:27,296
approaches a little bit in

957
00:28:27,296 --> 0:28:27,626
detail.

958
00:28:28,916 --> 0:28:30,876
So here I'm showing a simple

959
00:28:30,976 --> 0:28:33,326
neural network and how it can be

960
00:28:33,326 --> 0:28:35,996
easily expressed using Core ML

961
00:28:35,996 --> 0:28:38,336
tools, which is a simple Python

962
00:28:38,336 --> 0:28:40,096
wrapper around the Protobuf

963
00:28:40,096 --> 0:28:40,776
specification.

964
00:28:41,716 --> 0:28:43,366
I personally like this approach,

965
00:28:43,536 --> 0:28:44,816
especially when I'm converting a

966
00:28:44,816 --> 0:28:46,726
model whose architecture I

967
00:28:46,726 --> 0:28:47,496
understand well.

968
00:28:47,896 --> 0:28:49,616
And if I have the pretrained

969
00:28:49,616 --> 0:28:51,206
weights available to me in a

970
00:28:51,206 --> 0:28:54,166
nice data such as numbered

971
00:28:54,166 --> 0:28:54,656
arrays.

972
00:28:55,316 --> 0:28:57,316
Having said that, neural

973
00:28:57,316 --> 0:28:58,906
networks are often much more

974
00:28:58,906 --> 0:29:01,156
complex, and we are better off

975
00:28:58,906 --> 0:29:01,156
complex, and we are better off

976
00:29:01,296 --> 0:29:03,346
using converters and we have a

977
00:29:03,346 --> 0:29:03,926
few of them.

978
00:29:04,166 --> 0:29:06,256
So we have a few converters

979
00:29:06,256 --> 0:29:08,406
available on GitHub using which

980
00:29:08,406 --> 0:29:10,746
you can target most of the

981
00:29:10,746 --> 0:29:11,906
machine learning frameworks out

982
00:29:11,956 --> 0:29:12,136
there.

983
00:29:12,666 --> 0:29:14,396
And the great news is that with

984
00:29:14,396 --> 0:29:15,736
the backing of Core ML 3

985
00:29:15,736 --> 0:29:17,416
specification, all these

986
00:29:17,416 --> 0:29:19,146
converters are getting updated

987
00:29:19,386 --> 0:29:20,556
and much more robust.

988
00:29:21,316 --> 0:29:23,276
So, for some of you who have

989
00:29:23,276 --> 0:29:24,686
used our converters in the past,

990
00:29:25,186 --> 0:29:26,856
you might have come across some

991
00:29:26,916 --> 0:29:28,666
error messages like this, like

992
00:29:28,846 --> 0:29:29,956
maybe it's complaining about a

993
00:29:29,956 --> 0:29:31,266
missing layer or a missing

994
00:29:31,266 --> 0:29:32,256
attribute in the layer.

995
00:29:33,166 --> 0:29:35,476
Now, all of this will go away as

996
00:29:35,476 --> 0:29:36,986
the converters are updated and

997
00:29:36,986 --> 0:29:39,016
they make full use of the Core

998
00:29:39,016 --> 0:29:39,976
ML 3 specification.

999
00:29:40,516 --> 0:29:46,156
[ Applause ]

1000
00:29:46,656 --> 0:29:50,086
So, we went through a lot of

1001
00:29:50,086 --> 0:29:50,616
slides.

1002
00:29:50,616 --> 0:29:51,756
Now it's time to look at the

1003
00:29:51,756 --> 0:29:52,706
model in action.

1004
00:29:52,906 --> 0:29:54,026
And for that, I'll invite my

1005
00:29:54,026 --> 0:29:54,676
friend Allen.

1006
00:29:56,056 --> 0:29:58,056
[ Applause ]

1007
00:29:58,136 --> 0:29:58,466
&gt;&gt; Thank you.

1008
00:29:59,096 --> 0:30:01,076
Thank you, Aseem.

1009
00:29:59,096 --> 0:30:01,076
Thank you, Aseem.

1010
00:30:01,836 --> 0:30:03,416
Hi. I'm Allen.

1011
00:30:03,786 --> 0:30:05,526
Today, I'm going to show you how

1012
00:30:05,526 --> 0:30:07,166
to use the new features in Core

1013
00:30:07,166 --> 0:30:09,436
ML 3 to bring state of the art

1014
00:30:09,436 --> 0:30:10,606
machine learning models for

1015
00:30:10,606 --> 0:30:12,196
natural language processing into

1016
00:30:12,196 --> 0:30:12,576
our apps.

1017
00:30:15,006 --> 0:30:16,736
So, I love reading about

1018
00:30:16,736 --> 0:30:17,126
history.

1019
00:30:17,836 --> 0:30:19,176
Whenever I come across some

1020
00:30:19,176 --> 0:30:20,276
interesting articles about

1021
00:30:20,276 --> 0:30:22,326
history, I often have some

1022
00:30:22,326 --> 0:30:23,786
questions on top of my head and

1023
00:30:23,786 --> 0:30:25,416
I really like to get answers for

1024
00:30:25,416 --> 0:30:25,546
that.

1025
00:30:26,316 --> 0:30:27,546
But sometimes I'm just

1026
00:30:27,546 --> 0:30:28,026
impatient.

1027
00:30:28,416 --> 0:30:29,486
I don't want to read through the

1028
00:30:29,486 --> 0:30:30,156
entire article.

1029
00:30:30,866 --> 0:30:33,256
So, wouldn't it be nice if I can

1030
00:30:33,256 --> 0:30:35,086
build an app that scan through

1031
00:30:35,086 --> 0:30:36,826
the document and then give the

1032
00:30:36,826 --> 0:30:37,496
answers for me?

1033
00:30:38,186 --> 0:30:40,186
So then I started out build this

1034
00:30:40,186 --> 0:30:41,746
app with the new features in

1035
00:30:41,746 --> 0:30:42,266
Core ML 3.

1036
00:30:42,656 --> 0:30:43,286
And let me show you.

1037
00:30:51,416 --> 0:30:52,806
OK. So, here's my app.

1038
00:30:54,056 --> 0:30:56,266
As you can see, it shows article

1039
00:30:56,266 --> 0:30:57,866
about history of a company

1040
00:30:57,866 --> 0:30:58,306
called NeXT.

1041
00:30:59,226 --> 0:31:01,456
So, as you can see, this is a

1042
00:30:59,226 --> 0:31:01,456
So, as you can see, this is a

1043
00:31:01,456 --> 0:31:02,976
long article, and I certainly

1044
00:31:02,976 --> 0:31:03,946
don't have time to go through

1045
00:31:03,946 --> 0:31:04,096
it.

1046
00:31:04,096 --> 0:31:05,706
And I have some questions about

1047
00:31:05,706 --> 0:31:05,773
it.

1048
00:31:06,276 --> 0:31:10,326
So let me just ask this app.

1049
00:31:10,586 --> 0:31:12,306
Let's try my first question.

1050
00:31:13,416 --> 0:31:16,046
Who started NeXT?

1051
00:31:19,076 --> 0:31:20,806
&gt;&gt; Steve Jobs.

1052
00:31:21,516 --> 0:31:26,186
[ Applause ]

1053
00:31:26,686 --> 0:31:28,666
&gt;&gt; OK. I think that's right.

1054
00:31:29,276 --> 0:31:33,966
Let me try another one.

1055
00:31:34,176 --> 0:31:35,756
Where was the main office

1056
00:31:35,756 --> 0:31:36,406
located?

1057
00:31:39,546 --> 0:31:41,536
&gt;&gt; Redwood City, California

1058
00:31:42,516 --> 0:31:45,716
[ Applause ]

1059
00:31:46,216 --> 0:31:48,036
&gt;&gt; Now I also have a question

1060
00:31:48,036 --> 0:31:49,136
that I'm very interested in.

1061
00:31:49,556 --> 0:31:50,906
Let me try that.

1062
00:31:52,876 --> 0:31:55,086
How much were engineers paid?

1063
00:31:58,286 --> 0:31:59,826
&gt;&gt; Seventy-five thousand or

1064
00:31:59,826 --> 0:32:02,826
$50,000 [applause].

1065
00:31:59,826 --> 0:32:02,826
$50,000 [applause].

1066
00:32:03,136 --> 0:32:03,466
&gt;&gt; Interesting.

1067
00:32:04,016 --> 0:32:06,000
[ Applause ]

1068
00:32:09,436 --> 0:32:11,126
So, isn't this cool?

1069
00:32:11,846 --> 0:32:16,886
So now, let's get deeper into it

1070
00:32:17,076 --> 0:32:18,176
and see what the app really

1071
00:32:18,176 --> 0:32:18,386
does.

1072
00:32:20,486 --> 0:32:22,146
So, the central piece of this

1073
00:32:22,146 --> 0:32:24,026
app is a state of the art

1074
00:32:24,106 --> 0:32:25,596
machine learning model called

1075
00:32:25,986 --> 0:32:27,406
Bidirectional Encoder

1076
00:32:27,406 --> 0:32:28,566
Representation from

1077
00:32:28,566 --> 0:32:29,156
Transformers.

1078
00:32:29,666 --> 0:32:30,876
And this is a very long name.

1079
00:32:31,236 --> 0:32:32,786
So, let's just call it the BERT

1080
00:32:32,786 --> 0:32:34,426
model as other researchers do.

1081
00:32:35,216 --> 0:32:37,656
So, what does BERT model do?

1082
00:32:38,186 --> 0:32:40,636
Well, it is actually a-- it's

1083
00:32:40,776 --> 0:32:42,796
actually a neural network that

1084
00:32:42,796 --> 0:32:47,436
can perform multiple tasks for

1085
00:32:47,436 --> 0:32:48,846
natural language understanding.

1086
00:32:49,466 --> 0:32:52,986
But what's inside the BERT

1087
00:32:52,986 --> 0:32:53,326
model?

1088
00:32:54,766 --> 0:32:55,536
A bunch of modules.

1089
00:32:56,096 --> 0:32:57,466
And what's inside these modules?

1090
00:32:58,586 --> 0:33:00,296
Layers, many, many layers.

1091
00:32:58,586 --> 0:33:00,296
Layers, many, many layers.

1092
00:33:01,316 --> 0:33:02,326
So you can see, it's rather

1093
00:33:02,326 --> 0:33:04,476
complicated, but with the new

1094
00:33:04,476 --> 0:33:06,106
features and tools in Core ML 3,

1095
00:33:06,476 --> 0:33:08,256
I can easily bring this model

1096
00:33:08,256 --> 0:33:09,506
into my app.

1097
00:33:10,896 --> 0:33:13,996
But first, the question is, how

1098
00:33:13,996 --> 0:33:14,676
do I get the model?

1099
00:33:15,406 --> 0:33:19,466
Well, you can get a model on our

1100
00:33:19,626 --> 0:33:22,976
model gallery website, or you

1101
00:33:22,976 --> 0:33:25,296
can-- if you like, you can train

1102
00:33:25,296 --> 0:33:26,806
a model and then convert it.

1103
00:33:28,016 --> 0:33:30,166
For example, the other night I

1104
00:33:30,166 --> 0:33:32,046
trained my BERT model with

1105
00:33:32,046 --> 0:33:32,566
TensorFlow.

1106
00:33:33,186 --> 0:33:35,336
And here is a screenshot of my

1107
00:33:35,486 --> 0:33:35,946
workspace.

1108
00:33:36,476 --> 0:33:38,286
Sorry for me being very messy

1109
00:33:38,286 --> 0:33:38,986
with my workspace.

1110
00:33:39,686 --> 0:33:41,916
But to use new Core ML

1111
00:33:42,426 --> 0:33:44,906
converter, I just need to export

1112
00:33:44,906 --> 0:33:47,606
a model into the Protobuf format

1113
00:33:48,146 --> 0:33:49,696
right here.

1114
00:33:50,936 --> 0:33:52,826
And after that, all I need to do

1115
00:33:53,086 --> 0:33:54,586
is to type three lines of Python

1116
00:33:54,586 --> 0:33:54,826
code.

1117
00:33:55,746 --> 0:33:57,436
Import TF Core ML converter,

1118
00:33:58,046 --> 0:33:59,086
call the convert function, and

1119
00:33:59,736 --> 0:34:02,966
then save out as an ML model.

1120
00:33:59,736 --> 0:34:02,966
then save out as an ML model.

1121
00:34:03,076 --> 0:34:04,476
So as you can see, it's rather

1122
00:34:04,476 --> 0:34:06,336
easy to bring a model into the

1123
00:34:06,336 --> 0:34:06,776
app.

1124
00:34:07,066 --> 0:34:08,116
But to use the app for a

1125
00:34:08,146 --> 0:34:09,735
question and answering, there

1126
00:34:09,735 --> 0:34:11,606
are few more steps and I like to

1127
00:34:11,606 --> 0:34:12,916
explain a little further.

1128
00:34:13,315 --> 0:34:15,795
So to use the Q and A model, I

1129
00:34:15,795 --> 0:34:17,916
need to prepare a question and a

1130
00:34:17,916 --> 0:34:19,956
paragraph and then separate them

1131
00:34:19,956 --> 0:34:20,906
as work tokens.

1132
00:34:21,366 --> 0:34:23,485
What the model will predict is

1133
00:34:23,596 --> 0:34:26,556
the location of the answer

1134
00:34:27,045 --> 0:34:28,146
that's in the paragraph.

1135
00:34:28,795 --> 0:34:30,186
Think of it as a highlighter as

1136
00:34:30,186 --> 0:34:33,275
you just saw in the demo.

1137
00:34:33,436 --> 0:34:34,775
So from there, I can start

1138
00:34:34,775 --> 0:34:35,735
building up my app.

1139
00:34:36,396 --> 0:34:37,626
The model itself does not make

1140
00:34:38,036 --> 0:34:38,706
the app.

1141
00:34:39,076 --> 0:34:40,856
And in addition to that, I also

1142
00:34:40,856 --> 0:34:43,676
utilize many features from other

1143
00:34:43,676 --> 0:34:45,335
frameworks that makes this app.

1144
00:34:45,775 --> 0:34:47,516
For example, I use the

1145
00:34:47,516 --> 0:34:49,525
speech-to-text API from speech

1146
00:34:49,525 --> 0:34:51,966
framework to translate my voice

1147
00:34:51,966 --> 0:34:52,516
into text.

1148
00:34:53,505 --> 0:34:56,536
I use natural language API to

1149
00:34:56,536 --> 0:34:58,066
help me build the tokenizer.

1150
00:34:58,756 --> 0:35:01,546
And finally, I use the

1151
00:34:58,756 --> 0:35:01,546
And finally, I use the

1152
00:35:01,936 --> 0:35:03,186
text-to-speech API from the

1153
00:35:03,186 --> 0:35:05,356
AVFoundation to play out the

1154
00:35:05,356 --> 0:35:06,266
audio of an answer.

1155
00:35:06,966 --> 0:35:08,316
So, all these components

1156
00:35:08,576 --> 0:35:09,986
utilizes machine learning

1157
00:35:10,046 --> 0:35:12,066
on-device, so that to use this

1158
00:35:12,066 --> 0:35:13,946
app, no internet access is

1159
00:35:13,946 --> 0:35:14,396
required.

1160
00:35:15,516 --> 0:35:17,776
[ Applause ]

1161
00:35:18,276 --> 0:35:19,456
Thank you.

1162
00:35:19,456 --> 0:35:21,636
Just think about how much more

1163
00:35:21,636 --> 0:35:24,126
possibility of new ideas and new

1164
00:35:24,246 --> 0:35:25,606
user experience you can bring

1165
00:35:25,606 --> 0:35:26,436
into our app.

1166
00:35:27,056 --> 0:35:27,646
That's all.

1167
00:35:27,646 --> 0:35:27,976
Thank you.

1168
00:35:28,516 --> 0:35:35,516
[ Applause ]

1169
00:35:36,016 --> 0:35:38,766
&gt;&gt; OK. Thank you, Allen.

1170
00:35:40,706 --> 0:35:42,876
OK. So before we conclude the

1171
00:35:42,876 --> 0:35:44,266
session, I want to highlight

1172
00:35:44,266 --> 0:35:45,416
three more features that we

1173
00:35:45,416 --> 0:35:48,096
added this year in Core ML that

1174
00:35:48,096 --> 0:35:50,086
I'm sure a lot of Core ML users

1175
00:35:50,086 --> 0:35:51,026
will find really useful.

1176
00:35:51,766 --> 0:35:56,926
So let's look at the first one.

1177
00:35:56,926 --> 0:35:58,876
So consider a scenario shown in

1178
00:35:58,876 --> 0:36:00,606
the slide, let's say we have two

1179
00:35:58,876 --> 0:36:00,606
the slide, let's say we have two

1180
00:36:00,606 --> 0:36:02,886
models that classify different

1181
00:36:02,886 --> 0:36:03,796
breeds of animal.

1182
00:36:04,516 --> 0:36:06,556
And if you look inside, both

1183
00:36:06,556 --> 0:36:09,086
these models are pipeline models

1184
00:36:09,586 --> 0:36:10,976
that share a common feature

1185
00:36:10,976 --> 0:36:11,456
extractor.

1186
00:36:12,136 --> 0:36:13,406
Now this happens quite often.

1187
00:36:13,576 --> 0:36:15,976
It's quite common to share-- to

1188
00:36:15,976 --> 0:36:18,256
train deep neural network to get

1189
00:36:18,256 --> 0:36:20,056
features and those features can

1190
00:36:20,056 --> 0:36:21,436
be fed to different neural

1191
00:36:21,436 --> 0:36:21,956
networks.

1192
00:36:22,816 --> 0:36:25,906
So actually in the slide, we

1193
00:36:25,906 --> 0:36:27,876
note that we are using multiple

1194
00:36:27,876 --> 0:36:29,736
copies of the same model within

1195
00:36:29,736 --> 0:36:30,716
these two pipelines.

1196
00:36:31,146 --> 0:36:32,296
Now this is clearly not

1197
00:36:32,296 --> 0:36:32,756
efficient.

1198
00:36:33,446 --> 0:36:35,036
To get rid of this inefficiency,

1199
00:36:35,296 --> 0:36:36,426
we are launching a new model

1200
00:36:36,466 --> 0:36:38,596
type called linked model, as

1201
00:36:38,596 --> 0:36:38,996
shown here.

1202
00:36:38,996 --> 0:36:42,266
So just see, the idea is quite

1203
00:36:42,316 --> 0:36:42,696
simple.

1204
00:36:43,016 --> 0:36:44,936
Linked model is simply a

1205
00:36:44,936 --> 0:36:47,236
reference to a model sitting at

1206
00:36:47,236 --> 0:36:47,606
desk.

1207
00:36:48,266 --> 0:36:50,376
And this really makes it easy to

1208
00:36:50,376 --> 0:36:51,876
share a model across different

1209
00:36:52,096 --> 0:36:52,896
models.

1210
00:36:54,876 --> 0:36:56,006
Another way I like to think

1211
00:36:56,006 --> 0:36:58,146
about linked model is it behaves

1212
00:36:58,146 --> 0:36:59,806
like linking to a dynamic

1213
00:37:00,126 --> 0:37:01,296
library.

1214
00:37:01,686 --> 0:37:03,436
And it has only a couple of

1215
00:37:03,436 --> 0:37:04,166
parameters.

1216
00:37:04,166 --> 0:37:05,636
One, the name of the model that

1217
00:37:05,636 --> 0:37:07,466
it's linking to and a search

1218
00:37:07,466 --> 0:37:07,816
path.

1219
00:37:08,826 --> 0:37:10,396
So this would be very useful

1220
00:37:10,396 --> 0:37:12,126
for-- when we are using

1221
00:37:12,126 --> 0:37:13,856
updatable models or pipelines.

1222
00:37:14,676 --> 0:37:17,446
Let's look at the next feature.

1223
00:37:17,726 --> 0:37:19,296
Let's say you have a Core ML

1224
00:37:19,296 --> 0:37:21,206
model that takes an image as an

1225
00:37:21,206 --> 0:37:21,586
input.

1226
00:37:22,136 --> 0:37:23,776
Now as of now, Core ML expects

1227
00:37:23,816 --> 0:37:26,066
the image to be in the form of a

1228
00:37:26,066 --> 0:37:27,716
CVPixelBuffer.

1229
00:37:27,716 --> 0:37:29,806
But what happens if your image

1230
00:37:29,806 --> 0:37:30,786
is coming from a different

1231
00:37:30,786 --> 0:37:32,076
source and it's in a different

1232
00:37:32,076 --> 0:37:32,516
format?

1233
00:37:33,466 --> 0:37:34,706
Now, in most of the cases, you

1234
00:37:35,276 --> 0:37:36,996
could use the vision framework

1235
00:37:37,276 --> 0:37:39,746
so you can invoke Core ML via

1236
00:37:39,746 --> 0:37:41,566
the VNCoreMLRequest class.

1237
00:37:42,156 --> 0:37:43,736
And this has the advantage that

1238
00:37:43,736 --> 0:37:45,646
vision can handle many different

1239
00:37:45,646 --> 0:37:47,686
formats of images for us, and

1240
00:37:47,686 --> 0:37:49,526
they can also do preprocessing

1241
00:37:49,526 --> 0:37:51,486
like image scaling and cropping,

1242
00:37:51,486 --> 0:37:53,016
et cetera.

1243
00:37:53,216 --> 0:37:54,796
In some cases, though, we might

1244
00:37:54,796 --> 0:37:56,756
have to call the Core ML API

1245
00:37:56,756 --> 0:37:58,926
directly, for instance when we

1246
00:37:58,926 --> 0:38:01,046
are trying to invoke the update

1247
00:37:58,926 --> 0:38:01,046
are trying to invoke the update

1248
00:38:01,046 --> 0:38:01,366
APIs.

1249
00:38:01,766 --> 0:38:04,146
For such cases, we have launched

1250
00:38:04,146 --> 0:38:05,576
a couple of new initializer

1251
00:38:05,576 --> 0:38:07,186
methods, I showed on the slide.

1252
00:38:07,546 --> 0:38:09,206
So now we can directly get an

1253
00:38:09,206 --> 0:38:11,906
image from a URL or a CGimage.

1254
00:38:12,516 --> 0:38:17,776
[ Applause ]

1255
00:38:18,276 --> 0:38:19,976
So this should make it really

1256
00:38:19,976 --> 0:38:21,886
convenient to use images with

1257
00:38:21,886 --> 0:38:23,886
Core ML.

1258
00:38:24,366 --> 0:38:25,506
Moving on to the last feature I

1259
00:38:25,506 --> 0:38:26,896
want to highlight.

1260
00:38:26,896 --> 0:38:28,256
So there's a class in Core ML

1261
00:38:28,256 --> 0:38:30,486
API called MLModelConfiguration.

1262
00:38:30,486 --> 0:38:33,536
And it can be used to constrain

1263
00:38:33,536 --> 0:38:35,566
the set of devices on which a

1264
00:38:35,566 --> 0:38:36,966
Core ML model can execute.

1265
00:38:37,246 --> 0:38:39,476
For example, the default value

1266
00:38:39,476 --> 0:38:41,056
that the [inaudible] takes is

1267
00:38:41,166 --> 0:38:44,616
called all which gives all the

1268
00:38:44,616 --> 0:38:45,736
computer devices available

1269
00:38:45,876 --> 0:38:47,326
including the neural engine.

1270
00:38:48,136 --> 0:38:49,756
Now we have added a couple of

1271
00:38:49,796 --> 0:38:52,026
more options to this class.

1272
00:38:52,756 --> 0:38:55,546
The first one is the ability to

1273
00:38:55,546 --> 0:38:58,336
specify preferred metal device

1274
00:38:59,166 --> 0:39:00,696
on which the model can execute.

1275
00:38:59,166 --> 0:39:00,696
on which the model can execute.

1276
00:39:01,236 --> 0:39:02,426
So as you can imagine, this

1277
00:39:02,426 --> 0:39:03,716
would be really useful if you

1278
00:39:03,716 --> 0:39:05,436
are running a Core ML model on a

1279
00:39:05,436 --> 0:39:06,846
Mac which can have many

1280
00:39:06,846 --> 0:39:09,706
different GPUs attached to it.

1281
00:39:10,106 --> 0:39:11,036
The other option that we've

1282
00:39:11,036 --> 0:39:13,066
added this called low precision

1283
00:39:13,066 --> 0:39:13,776
accumulation.

1284
00:39:13,776 --> 0:39:15,996
And the idea here is that if

1285
00:39:15,996 --> 0:39:17,576
your model is learning on the

1286
00:39:17,576 --> 0:39:19,906
GPU, instead of doing

1287
00:39:19,906 --> 0:39:21,766
accumulation in float32, that

1288
00:39:21,766 --> 0:39:22,946
happens in float60.

1289
00:39:23,296 --> 0:39:25,026
Now this can offer some really

1290
00:39:25,026 --> 0:39:27,566
nice speed enhancement for your

1291
00:39:27,566 --> 0:39:27,906
model.

1292
00:39:28,636 --> 0:39:29,896
But whenever we reduce the

1293
00:39:29,896 --> 0:39:31,616
precision, always remember to

1294
00:39:31,656 --> 0:39:33,416
check the accuracy of the model,

1295
00:39:33,826 --> 0:39:36,056
which might degrade or not

1296
00:39:36,056 --> 0:39:37,776
degrade, depending on the model

1297
00:39:37,776 --> 0:39:37,936
type.

1298
00:39:38,246 --> 0:39:41,436
So always try to experiment

1299
00:39:41,436 --> 0:39:43,266
whenever you vary the precision

1300
00:39:43,266 --> 0:39:43,726
of the model.

1301
00:39:43,866 --> 0:39:45,136
So I would highly encourage you

1302
00:39:45,136 --> 0:39:46,676
to go and try out this option to

1303
00:39:46,676 --> 0:39:49,706
see if it helps with your model.

1304
00:39:50,346 --> 0:39:52,306
OK. So, we talked about a lot of

1305
00:39:52,306 --> 0:39:53,276
stuff in this session.

1306
00:39:53,276 --> 0:39:55,206
Let briefly summarize it for

1307
00:39:55,206 --> 0:39:55,476
you.

1308
00:39:55,996 --> 0:39:58,976
We discussed how it's really

1309
00:39:58,976 --> 0:40:00,656
easy to make a personalized

1310
00:39:58,976 --> 0:40:00,656
easy to make a personalized

1311
00:40:00,656 --> 0:40:02,426
experience for our users by

1312
00:40:02,426 --> 0:40:03,646
updating the Core ML model

1313
00:40:03,736 --> 0:40:04,346
on-device.

1314
00:40:05,126 --> 0:40:07,006
We discussed how we have added

1315
00:40:07,066 --> 0:40:08,066
many more features to our

1316
00:40:08,066 --> 0:40:09,386
specification and now we can

1317
00:40:09,386 --> 0:40:11,156
bring the state of the art

1318
00:40:11,156 --> 0:40:12,296
neural network architectures

1319
00:40:12,646 --> 0:40:14,266
into our apps.

1320
00:40:14,266 --> 0:40:15,746
And we talk about a few

1321
00:40:16,026 --> 0:40:17,466
convenience APIs and options

1322
00:40:17,466 --> 0:40:18,036
around GPU.

1323
00:40:18,536 --> 0:40:21,366
Here are a few sessions that you

1324
00:40:21,366 --> 0:40:22,796
might find interesting and

1325
00:40:22,796 --> 0:40:23,786
related to the session.

1326
00:40:24,346 --> 0:40:25,656
And thank you.

1327
00:40:26,516 --> 0:40:31,500
[ Applause ]
