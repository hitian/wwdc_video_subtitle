1
00:00:00,506 --> 0:00:04,500
[ Music ]

2
00:00:07,516 --> 0:00:14,026
[ Applause ]

3
00:00:14,526 --> 0:00:15,626
&gt;&gt; Hello, everyone.

4
00:00:15,836 --> 0:00:16,516
Good afternoon.

5
00:00:17,316 --> 0:00:18,456
Welcome to the session.

6
00:00:19,796 --> 0:00:20,836
My name is Tao.

7
00:00:21,246 --> 0:00:22,446
I'm from Core ML Team.

8
00:00:23,276 --> 0:00:25,016
Today we're super excited to

9
00:00:25,016 --> 0:00:26,916
talk about a few new features we

10
00:00:26,916 --> 0:00:28,676
added to Create ML this year.

11
00:00:29,016 --> 0:00:30,136
In What's New in Machine

12
00:00:30,136 --> 0:00:31,536
Learning Session, you were

13
00:00:31,536 --> 0:00:33,286
introduced to the brand-new

14
00:00:33,336 --> 0:00:34,986
Create ML app.

15
00:00:34,986 --> 0:00:36,336
It's a great new tool designed

16
00:00:36,336 --> 0:00:38,226
by Apple to guide you through

17
00:00:38,226 --> 0:00:40,146
the essential steps of training

18
00:00:40,146 --> 0:00:41,206
of machine learning models.

19
00:00:42,226 --> 0:00:43,806
We believe this makes your

20
00:00:43,806 --> 0:00:46,016
machine learning workflow easy

21
00:00:46,016 --> 0:00:46,756
and approachable.

22
00:00:48,206 --> 0:00:49,366
Now, let's start with Text

23
00:00:49,366 --> 0:00:49,976
Classification.

24
00:00:52,546 --> 0:00:53,956
What is Text Classification?

25
00:00:54,536 --> 0:00:55,966
It's a machine learning task

26
00:00:56,346 --> 0:00:58,796
that classifies input text to a

27
00:00:58,886 --> 0:01:00,446
set of predefined labels.

28
00:00:58,886 --> 0:01:00,446
set of predefined labels.

29
00:01:03,136 --> 0:01:04,566
You can use it for sentiment

30
00:01:04,566 --> 0:01:07,626
analysis, like classifying text

31
00:01:07,626 --> 0:01:09,936
as positive or negative.

32
00:01:11,396 --> 0:01:12,756
Or doing spam detection.

33
00:01:12,756 --> 0:01:16,096
Or more complicated things like

34
00:01:16,386 --> 0:01:18,596
topic analysis, classifying text

35
00:01:18,596 --> 0:01:21,786
as food, politics, or science.

36
00:01:23,146 --> 0:01:24,556
Now, Text Classification has

37
00:01:24,556 --> 0:01:25,976
been supported since last year,

38
00:01:26,516 --> 0:01:28,296
but this year we're adding the

39
00:01:28,296 --> 0:01:30,076
support for the state of the art

40
00:01:30,076 --> 0:01:30,776
transfer learning.

41
00:01:31,636 --> 0:01:33,156
Today, I'm going to give you a

42
00:01:33,156 --> 0:01:35,206
concrete example of how you can

43
00:01:35,206 --> 0:01:37,346
train a Text Classifier using

44
00:01:37,346 --> 0:01:38,046
Transfer Learning.

45
00:01:39,446 --> 0:01:41,336
To train such a model, the first

46
00:01:41,336 --> 0:01:42,566
thing you'll want to do is

47
00:01:42,886 --> 0:01:44,616
collect some training data.

48
00:01:46,336 --> 0:01:48,386
Once you have the data, you can

49
00:01:48,386 --> 0:01:50,066
organize in an easy way.

50
00:01:51,116 --> 0:01:53,676
I have sports, entertainment and

51
00:01:53,676 --> 0:01:54,056
nature.

52
00:01:55,166 --> 0:01:56,996
Under each folder, I have a few

53
00:01:56,996 --> 0:01:57,626
text files.

54
00:01:58,236 --> 0:02:00,316
And each one of them is a single

55
00:01:58,236 --> 0:02:00,316
And each one of them is a single

56
00:02:00,316 --> 0:02:02,996
training example, and its label

57
00:02:03,146 --> 0:02:04,996
is simply the name of the folder

58
00:02:04,996 --> 0:02:05,406
they are in.

59
00:02:05,946 --> 0:02:07,786
And that's it.

60
00:02:07,786 --> 0:02:08,806
That's all you need to do with

61
00:02:08,806 --> 0:02:09,186
the data.

62
00:02:10,156 --> 0:02:11,636
I'll give you a quick demo to

63
00:02:11,636 --> 0:02:12,576
show how you can do this.

64
00:02:12,776 --> 0:02:15,606
On my desktop, I have a training

65
00:02:15,606 --> 0:02:15,956
data folder.

66
00:02:20,386 --> 0:02:21,456
So, I decided to have a little

67
00:02:21,456 --> 0:02:22,026
bit of fun.

68
00:02:22,716 --> 0:02:24,356
Instead of using plain text as

69
00:02:24,356 --> 0:02:26,546
the label, I used a few emojis.

70
00:02:27,426 --> 0:02:29,116
For example, for entertainment I

71
00:02:29,116 --> 0:02:30,306
use a camcorder.

72
00:02:31,106 --> 0:02:33,216
For sport, I'm using an American

73
00:02:33,216 --> 0:02:33,836
football.

74
00:02:35,196 --> 0:02:36,836
For nature, I'm using this cute

75
00:02:36,836 --> 0:02:39,486
little tent besides a great pine

76
00:02:40,856 --> 0:02:40,966
tree.

77
00:02:41,186 --> 0:02:42,536
You notice there is also this

78
00:02:42,656 --> 0:02:43,306
other folder.

79
00:02:44,186 --> 0:02:45,686
This is the training data that I

80
00:02:45,686 --> 0:02:46,936
actually don't want.

81
00:02:46,936 --> 0:02:49,466
I want my model to learn such

82
00:02:49,466 --> 0:02:51,326
that anything that's not one of

83
00:02:51,326 --> 0:02:53,416
the three intended class, I want

84
00:02:53,416 --> 0:02:55,756
my model to classify them into

85
00:02:56,726 --> 0:02:58,516
this class.

86
00:02:58,686 --> 0:03:00,286
So, let's take a look at a few

87
00:02:58,686 --> 0:03:00,286
So, let's take a look at a few

88
00:03:00,286 --> 0:03:00,936
examples here.

89
00:03:01,766 --> 0:03:05,186
For example if you read this

90
00:03:05,186 --> 0:03:06,056
sentence, there's something

91
00:03:06,056 --> 0:03:07,586
about writer and IMDB.

92
00:03:07,586 --> 0:03:09,026
It's clearly something related

93
00:03:09,026 --> 0:03:09,806
to entertainment.

94
00:03:13,006 --> 0:03:15,066
If I go into other folder, this

95
00:03:15,926 --> 0:03:19,086
is not one of the three intended

96
00:03:19,856 --> 0:03:20,006
class.

97
00:03:24,536 --> 0:03:25,546
That's about data.

98
00:03:25,796 --> 0:03:32,446
Now, I'll go to Create ML app.

99
00:03:34,436 --> 0:03:36,806
To do that, I go to Developer

100
00:03:36,806 --> 0:03:39,356
Tools and find the Create ML.

101
00:03:42,116 --> 0:03:43,256
But I'm going to do a new

102
00:03:43,256 --> 0:03:48,336
document and go to text.

103
00:03:48,496 --> 0:03:49,496
I'll name it like that.

104
00:03:50,736 --> 0:03:53,906
Create. So, I'm sure you have

105
00:03:53,906 --> 0:03:56,476
seen this user interface in the

106
00:03:56,476 --> 0:03:58,096
earlier session, Object

107
00:03:58,096 --> 0:03:58,776
Connection and

108
00:03:58,846 --> 0:03:59,916
Subclassification.

109
00:04:00,226 --> 0:04:01,466
So, I'm just going to drag my

110
00:04:01,466 --> 0:04:02,826
training data in directly here.

111
00:04:03,446 --> 0:04:05,956
So, it gives you some feedback

112
00:04:05,956 --> 0:04:06,926
about your training data.

113
00:04:07,366 --> 0:04:08,606
But what's new about Text

114
00:04:08,606 --> 0:04:10,306
Classifier is this particular

115
00:04:10,306 --> 0:04:11,236
parameter section.

116
00:04:11,866 --> 0:04:15,026
So, for today's demo, I'm going

117
00:04:15,026 --> 0:04:16,296
to select Transfer Learning.

118
00:04:17,736 --> 0:04:19,065
If we take a look at it, the

119
00:04:19,065 --> 0:04:20,596
first two algorithms actually

120
00:04:20,596 --> 0:04:21,995
have been supported since last

121
00:04:21,995 --> 0:04:22,136
year.

122
00:04:22,776 --> 0:04:23,826
And this year we're adding

123
00:04:23,826 --> 0:04:24,606
Transfer Learning.

124
00:04:25,096 --> 0:04:27,086
And for the demo I'm going to

125
00:04:27,086 --> 0:04:28,546
use this feature extractor

126
00:04:28,546 --> 0:04:29,826
called Dynamic Embedding.

127
00:04:30,156 --> 0:04:32,496
I'll go into the detail about

128
00:04:32,496 --> 0:04:33,946
what is Transfer Learning a bit

129
00:04:33,946 --> 0:04:35,936
later after the demo, but all

130
00:04:35,936 --> 0:04:37,846
you need to know now is Transfer

131
00:04:37,846 --> 0:04:39,256
Learning with Dynamic Embedding

132
00:04:39,676 --> 0:04:41,686
is actually an algorithm that

133
00:04:41,686 --> 0:04:43,096
pays attention to the semantic

134
00:04:43,096 --> 0:04:45,446
meaning of your input text.

135
00:04:47,036 --> 0:04:48,216
I'll start training.

136
00:04:49,346 --> 0:04:50,506
So, in general, Transfer

137
00:04:50,506 --> 0:04:52,326
Learning takes a bit longer to

138
00:04:52,326 --> 0:04:52,726
train.

139
00:04:53,516 --> 0:04:54,716
For this particular data set,

140
00:04:55,176 --> 0:04:57,416
it'll take about five minutes on

141
00:04:57,416 --> 0:04:58,316
this particular machine.

142
00:04:59,376 --> 0:05:01,196
So, I'm not going to wait.

143
00:04:59,376 --> 0:05:01,196
So, I'm not going to wait.

144
00:05:02,666 --> 0:05:04,636
Instead, I have my pre-picked

145
00:05:04,966 --> 0:05:07,116
solution here that's trained on

146
00:05:07,116 --> 0:05:08,386
exactly the same data.

147
00:05:08,956 --> 0:05:12,286
Once the model has been trained,

148
00:05:12,286 --> 0:05:14,996
the accuracy test gives you a

149
00:05:14,996 --> 0:05:16,846
good summary about how your

150
00:05:16,846 --> 0:05:18,786
model performs on different

151
00:05:18,786 --> 0:05:21,266
data, broken down into different

152
00:05:21,266 --> 0:05:21,676
classes.

153
00:05:22,666 --> 0:05:24,216
It looks my model has done a

154
00:05:24,216 --> 0:05:26,246
good job on training validation

155
00:05:26,246 --> 0:05:26,836
and testing data.

156
00:05:27,486 --> 0:05:30,446
So, I will directly jump to the

157
00:05:30,446 --> 0:05:31,196
output tab.

158
00:05:31,946 --> 0:05:34,566
This preview pane gives you some

159
00:05:34,636 --> 0:05:37,116
summary about the model as well

160
00:05:37,116 --> 0:05:38,906
as a few different ways for you

161
00:05:38,906 --> 0:05:40,506
to do some quick experiments.

162
00:05:41,286 --> 0:05:42,836
For example, if you go to the

163
00:05:42,836 --> 0:05:44,576
lower right-hand side corner,

164
00:05:45,246 --> 0:05:47,526
you can directly add File to do

165
00:05:47,526 --> 0:05:50,166
a quick test.

166
00:05:50,336 --> 0:05:56,016
Or you can track a folder that

167
00:05:56,016 --> 0:05:57,756
the model will be able to make

168
00:05:57,756 --> 0:05:59,496
prediction of all the text file

169
00:05:59,526 --> 0:06:00,406
within that folder.

170
00:05:59,526 --> 0:06:00,406
within that folder.

171
00:06:01,256 --> 0:06:02,696
The model actually will use the

172
00:06:02,696 --> 0:06:04,856
entire body of the text in each

173
00:06:04,856 --> 0:06:06,276
file to make a single

174
00:06:06,276 --> 0:06:06,776
prediction.

175
00:06:07,306 --> 0:06:10,336
But there is another way for you

176
00:06:10,336 --> 0:06:12,416
to do quick experiment which is

177
00:06:12,826 --> 0:06:13,626
manually typing.

178
00:06:16,446 --> 0:06:19,356
So in this particular text input

179
00:06:19,506 --> 0:06:22,066
section, when you, when I type

180
00:06:22,376 --> 0:06:25,566
each space, or if I stop typing

181
00:06:25,616 --> 0:06:27,406
for a little while, the model

182
00:06:27,406 --> 0:06:28,436
will make a prediction.

183
00:06:29,186 --> 0:06:30,966
So, let's see how that works.

184
00:06:33,136 --> 0:06:35,336
What a comeback win.

185
00:06:36,076 --> 0:06:40,886
Sport. Let's try something

186
00:06:40,926 --> 0:06:41,546
different.

187
00:06:42,896 --> 0:06:46,796
The season finale adds a twist

188
00:06:47,486 --> 0:06:48,966
to the plot.

189
00:06:49,456 --> 0:06:52,076
Which seems about right.

190
00:06:52,386 --> 0:06:52,966
Entertainment.

191
00:06:53,516 --> 0:06:56,826
[ Applause ]

192
00:06:57,326 --> 0:06:58,516
I actually also want to try

193
00:06:58,516 --> 0:07:00,086
something more recent and more

194
00:06:58,516 --> 0:07:00,086
something more recent and more

195
00:07:00,086 --> 0:07:00,566
relevant.

196
00:07:01,006 --> 0:07:03,166
This just came to me last night.

197
00:07:04,266 --> 0:07:14,356
The Raptors are on top of the

198
00:07:15,616 --> 0:07:15,976
mountain.

199
00:07:18,316 --> 0:07:18,796
Nature [laughter].

200
00:07:20,476 --> 0:07:21,856
Well, if I switch context.

201
00:07:26,016 --> 0:07:27,096
[ Applause ]

202
00:07:27,096 --> 0:07:27,946
It predicts sport.

203
00:07:28,516 --> 0:07:32,926
[ Applause ]

204
00:07:33,426 --> 0:07:35,206
So, I'm pretty happy with the

205
00:07:35,206 --> 0:07:35,966
model performance.

206
00:07:36,766 --> 0:07:38,276
Now I'm ready to deploy.

207
00:07:38,556 --> 0:07:40,186
So, I just simply drag it out

208
00:07:40,536 --> 0:07:42,086
and I can put it on my iOS

209
00:07:42,146 --> 0:07:42,626
devices.

210
00:07:51,556 --> 0:07:53,186
That's how you can train a Text

211
00:07:53,186 --> 0:07:54,876
Classifier using Transfer

212
00:07:54,876 --> 0:07:55,146
Learning.

213
00:07:56,366 --> 0:07:58,286
But you might want to ask what

214
00:07:58,286 --> 0:07:59,856
is Transfer Learning?

215
00:08:02,196 --> 0:08:03,896
Transfer Learning is a powerful

216
00:08:03,896 --> 0:08:05,736
machine learning technique where

217
00:08:05,736 --> 0:08:07,526
a model trained on a huge amount

218
00:08:07,526 --> 0:08:09,516
of data for one particular task

219
00:08:10,086 --> 0:08:11,936
can be repurposed for another

220
00:08:11,936 --> 0:08:15,226
task so that you, as developers,

221
00:08:15,226 --> 0:08:17,226
only need to prepare limited

222
00:08:17,226 --> 0:08:19,486
amount of data and still get

223
00:08:19,486 --> 0:08:20,786
your customized machine learning

224
00:08:20,786 --> 0:08:21,256
model.

225
00:08:21,706 --> 0:08:25,816
Create ML actually uses Transfer

226
00:08:25,816 --> 0:08:26,646
Learning for image

227
00:08:26,646 --> 0:08:27,866
classification today.

228
00:08:28,326 --> 0:08:30,206
And now we're bringing it to

229
00:08:31,166 --> 0:08:31,536
text.

230
00:08:32,426 --> 0:08:34,296
Well, to train a good Transfer

231
00:08:34,296 --> 0:08:36,866
Learning model for text, the

232
00:08:36,866 --> 0:08:37,796
problem is a little bit

233
00:08:37,796 --> 0:08:38,256
different.

234
00:08:39,176 --> 0:08:40,796
If you read this sentence, "I

235
00:08:41,056 --> 0:08:43,856
was able to park my car near the

236
00:08:43,856 --> 0:08:44,806
park entrance."

237
00:08:46,736 --> 0:08:48,936
For a model that's trained with

238
00:08:49,506 --> 0:08:51,776
conventional technique or study

239
00:08:51,776 --> 0:08:54,726
embedding, these two parts will

240
00:08:54,726 --> 0:08:57,586
look exactly the same.

241
00:08:57,766 --> 0:08:59,386
But for a model trained with

242
00:08:59,386 --> 0:09:01,036
Transfer Learning with Dynamic

243
00:08:59,386 --> 0:09:01,036
Transfer Learning with Dynamic

244
00:09:01,036 --> 0:09:03,706
Embedding, because it pays

245
00:09:03,706 --> 0:09:04,916
attention to the semantic

246
00:09:04,916 --> 0:09:06,716
meaning of the overall context,

247
00:09:07,406 --> 0:09:09,826
it is able to figure out these

248
00:09:09,826 --> 0:09:11,216
two parts actually mean

249
00:09:11,216 --> 0:09:12,666
different things.

250
00:09:16,136 --> 0:09:18,206
To train such a good model, you

251
00:09:18,206 --> 0:09:19,586
need to do it on many texts.

252
00:09:20,056 --> 0:09:21,586
That's exactly what we did.

253
00:09:22,566 --> 0:09:26,716
We trained on billions of text

254
00:09:26,876 --> 0:09:28,096
and shipped that pretrained

255
00:09:28,096 --> 0:09:29,586
model to your mobile devices.

256
00:09:30,066 --> 0:09:31,956
And more importantly, we

257
00:09:31,956 --> 0:09:34,446
optimized its performance so

258
00:09:34,446 --> 0:09:38,316
that you only need to prepare

259
00:09:38,466 --> 0:09:40,126
your limited amount of raw text,

260
00:09:40,626 --> 0:09:43,686
send it in to Create ML app.

261
00:09:44,006 --> 0:09:46,286
Underneath it, it'll interact

262
00:09:46,286 --> 0:09:47,736
with the model that's already

263
00:09:47,736 --> 0:09:50,956
part of your OS and gives your

264
00:09:50,956 --> 0:09:52,816
customized text classifier.

265
00:09:55,696 --> 0:09:57,236
And you can deploy the same

266
00:09:57,236 --> 0:09:59,116
model on your iOS devices

267
00:09:59,436 --> 0:10:01,386
seamlessly because the

268
00:09:59,436 --> 0:10:01,386
seamlessly because the

269
00:10:01,386 --> 0:10:03,116
pretrained model is already

270
00:10:03,116 --> 0:10:06,166
there for you to use.

271
00:10:06,476 --> 0:10:09,216
Now, that's the workflow to use

272
00:10:09,216 --> 0:10:11,016
the Create ML app to train your

273
00:10:11,016 --> 0:10:12,116
Text Classifier.

274
00:10:13,216 --> 0:10:14,816
If you're also interested in

275
00:10:15,056 --> 0:10:17,396
writing code, it's also very

276
00:10:17,396 --> 0:10:17,706
easy.

277
00:10:18,816 --> 0:10:20,106
To use the Transfer Learning

278
00:10:20,106 --> 0:10:22,136
with Dynamic Embedding, the only

279
00:10:22,136 --> 0:10:23,496
thing you need to specify is

280
00:10:23,496 --> 0:10:24,816
this model parameter.

281
00:10:25,616 --> 0:10:27,096
The rest of the code is exactly

282
00:10:27,096 --> 0:10:27,976
the same as last year.

283
00:10:32,986 --> 0:10:35,246
Now, I've shown you how to train

284
00:10:35,246 --> 0:10:37,756
Text Classifier, but I'd like to

285
00:10:37,756 --> 0:10:39,866
give you a few simple tips to

286
00:10:39,866 --> 0:10:41,906
get the most out of your Text

287
00:10:41,906 --> 0:10:42,476
Classifier.

288
00:10:45,086 --> 0:10:47,876
Now, choose an algorithm which

289
00:10:47,876 --> 0:10:49,206
suits your use case.

290
00:10:50,296 --> 0:10:51,836
Transfer Learning is only one of

291
00:10:51,836 --> 0:10:53,966
the three algorithms that Text

292
00:10:53,966 --> 0:10:55,256
Classifier supports.

293
00:10:57,656 --> 0:10:58,726
Different algorithms have

294
00:10:58,806 --> 0:10:59,556
different tradeoffs.

295
00:11:00,676 --> 0:11:02,236
To find out which one fits your

296
00:11:02,236 --> 0:11:04,596
use case best, please go to the

297
00:11:04,596 --> 0:11:05,926
Natural Language session that

298
00:11:05,926 --> 0:11:10,156
happens after this.

299
00:11:10,346 --> 0:11:11,816
Provide balanced classes.

300
00:11:12,196 --> 0:11:13,256
This is very important.

301
00:11:14,376 --> 0:11:15,686
In the particular example that I

302
00:11:15,686 --> 0:11:17,606
showed you, because each text

303
00:11:17,606 --> 0:11:19,146
file is a single training

304
00:11:19,146 --> 0:11:19,756
example.

305
00:11:20,526 --> 0:11:22,076
So, I roughly kept the same

306
00:11:22,076 --> 0:11:24,146
amount of text files in each of

307
00:11:24,146 --> 0:11:24,646
the folders.

308
00:11:28,086 --> 0:11:29,126
Data consistency.

309
00:11:29,626 --> 0:11:31,256
If you expect your Text

310
00:11:31,256 --> 0:11:33,226
Classifier to mostly work on

311
00:11:33,226 --> 0:11:35,876
short sentences, like I do, your

312
00:11:35,876 --> 0:11:37,336
training data should be mostly

313
00:11:37,336 --> 0:11:39,026
consisting of such examples.

314
00:11:39,906 --> 0:11:42,876
If you expect your Text

315
00:11:42,876 --> 0:11:44,196
Classifier to work on short

316
00:11:44,196 --> 0:11:47,076
words, paragraphs, or even an

317
00:11:47,076 --> 0:11:49,866
entire article, you also want to

318
00:11:49,866 --> 0:11:51,236
make sure your training data

319
00:11:51,236 --> 0:11:52,626
cover these cases as well.

320
00:11:53,516 --> 0:11:58,506
[ Applause ]
