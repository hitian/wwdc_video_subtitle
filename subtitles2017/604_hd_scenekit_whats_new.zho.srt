1
00:00:17,551 --> 00:00:21,522
（SceneKit：新特性）

2
00:00:27,628 --> 00:00:28,962
大家早上好

3
00:00:29,029 --> 00:00:31,865
欢迎参加SceneKit新特性演讲

4
00:00:32,966 --> 00:00:36,904
你们已经知道了

5
00:00:36,970 --> 00:00:41,341
它是在Metal之上创建的

6
00:00:42,309 --> 00:00:46,280
这场演讲将会谈谈

7
00:00:46,647 --> 00:00:48,682
我们今天不讲基础知识

8
00:00:48,749 --> 00:00:50,851
所以若你刚接触SceneKit

9
00:00:50,918 --> 00:00:53,654
前几年相关的演讲

10
00:00:55,255 --> 00:00:56,990
这是我们今天的大纲

11
00:00:57,858 --> 00:01:01,495
我首先要讲一些相机改进

12
00:00:57,858 --> 00:01:01,495
我首先要讲一些相机改进

13
00:01:02,196 --> 00:01:04,397
包括一些新的相机效果

14
00:01:04,464 --> 00:01:07,634
和一些新的API以简化相机控制

15
00:01:08,602 --> 00:01:12,406
然后Amaury将上台讲一下细化和细分

16
00:01:12,706 --> 00:01:16,176
以及关于动画的一些改进和新增API

17
00:01:17,277 --> 00:01:20,414
最后我们会介绍一些新开发者工具

18
00:01:20,480 --> 00:01:24,785
并谈一些相关技术 包括ARKit

19
00:01:26,053 --> 00:01:30,057
现在让我们开始吧

20
00:01:30,123 --> 00:01:34,695
阐明我稍后要在本场演讲中

21
00:01:40,801 --> 00:01:45,072
这是一个简单的游戏示例

22
00:01:45,138 --> 00:01:46,640
通过虚拟方向键

23
00:01:46,840 --> 00:01:48,976
我可以攻击、跳跃

24
00:01:49,476 --> 00:01:51,812
我们用的是相机和虚拟方向键

25
00:01:53,113 --> 00:01:55,415
在演示中我想要强调的第一点就是

26
00:01:55,749 --> 00:01:57,551
相机的行为

27
00:01:58,018 --> 00:02:01,555
正如你所看到的

28
00:01:58,018 --> 00:02:01,555
正如你所看到的

29
00:02:02,589 --> 00:02:05,492
说到平稳 我是指它没有完全地重现

30
00:02:05,559 --> 00:02:07,261
角色的移动

31
00:02:07,327 --> 00:02:12,199
而是尝试与角色保持恒定的距离和高度

32
00:02:12,499 --> 00:02:16,170
但总是以平稳的加速度和减速度移动

33
00:02:17,104 --> 00:02:20,240
你将看到相机的行为将会适应

34
00:02:20,307 --> 00:02:22,476
根据游戏的不同分区

35
00:02:22,943 --> 00:02:26,580
比如当我接近这个战争区时

36
00:02:27,214 --> 00:02:30,450
相机就向下移动一点儿

37
00:02:30,517 --> 00:02:33,053
以聚焦于角色和敌人

38
00:02:34,388 --> 00:02:37,858
提到敌人 我们在这里有两名敌人

39
00:02:38,425 --> 00:02:40,994
一个是追我 而另一个是逃跑

40
00:02:41,061 --> 00:02:44,531
我会简单介绍一下如何通过

41
00:02:45,132 --> 00:02:46,700
现在让我们杀死他们

42
00:02:49,336 --> 00:02:50,270
还有另一个

43
00:02:52,706 --> 00:02:54,074
然后收集这里的宝石

44
00:02:55,742 --> 00:02:58,979
在这里 相机平稳地

45
00:02:59,479 --> 00:03:01,682
有很强烈的景深效果

46
00:02:59,479 --> 00:03:01,682
有很强烈的景深效果

47
00:03:01,748 --> 00:03:04,551
并且你还可以注意到背景中

48
00:03:05,219 --> 00:03:06,520
让我们收集那个钥匙

49
00:03:08,288 --> 00:03:10,357
当我[听不清]到这个新区域时

50
00:03:10,424 --> 00:03:12,826
我必须很谨慎地在平台上跳跃

51
00:03:13,060 --> 00:03:16,230
相机平稳地过渡到了一个新行为

52
00:03:16,296 --> 00:03:20,234
现在它停止旋转了 并对准平台

53
00:03:21,034 --> 00:03:25,472
以简化我在平台上的跳跃

54
00:03:26,874 --> 00:03:28,008
这是很刻意的

55
00:03:29,910 --> 00:03:31,378
让我们收集钥匙

56
00:03:32,913 --> 00:03:36,483
又是一个新区域 相机将自动适应自己

57
00:03:36,550 --> 00:03:38,685
并对准平台

58
00:03:45,058 --> 00:03:47,261
看起来那里有一些需要释放的朋友

59
00:03:47,327 --> 00:03:49,029
而我有钥匙 让我们释放他们

60
00:03:52,099 --> 00:03:58,238
最后是一个新的电影视角

61
00:03:58,505 --> 00:04:02,776
在这里我们要给

62
00:03:58,505 --> 00:04:02,776
在这里我们要给

63
00:04:02,843 --> 00:04:05,179
而我们在半毫秒内就能实现

64
00:04:05,245 --> 00:04:06,680
在这个新iPad Pro上

65
00:04:06,914 --> 00:04:08,682
速度非常快 我们主要关注

66
00:04:08,749 --> 00:04:11,418
角色动画性能 在这次发布中

67
00:04:11,485 --> 00:04:15,822
通过新API实施这些变得更加简单了

68
00:04:15,989 --> 00:04:18,291
通过我稍后要讲到的新动画API

69
00:04:19,192 --> 00:04:20,394
那么这就是这个演示

70
00:04:27,267 --> 00:04:30,637
一如既往 我们真的很高兴

71
00:04:30,704 --> 00:04:32,072
作为一段示例代码

72
00:04:32,739 --> 00:04:36,310
并且是运行在iOS、tvOS

73
00:04:36,376 --> 00:04:39,313
并在Swift和

74
00:04:41,782 --> 00:04:44,818
在演示中 我强调了相机行为

75
00:04:44,885 --> 00:04:48,188
因为这是非常非常难写的部分

76
00:04:48,622 --> 00:04:50,390
我们在开发者论坛上看到了

77
00:04:50,457 --> 00:04:53,060
和相关请求

78
00:04:53,227 --> 00:04:56,730
所以我们在本次发布中

79
00:04:57,598 --> 00:05:01,668
以简化这个问题并提高产品质量

80
00:04:57,598 --> 00:05:01,668
以简化这个问题并提高产品质量

81
00:05:03,203 --> 00:05:09,009
为此 我们过渡到了一个

82
00:05:09,076 --> 00:05:13,113
并且利用这个新API来实施

83
00:05:13,447 --> 00:05:16,083
我们还改善了运动模糊并添加了内置的

84
00:05:16,149 --> 00:05:17,818
屏幕空间环境光遮蔽支持

85
00:05:18,418 --> 00:05:22,122
然后我接下来要谈新API

86
00:05:22,189 --> 00:05:24,324
简化相机控制的

87
00:05:25,626 --> 00:05:29,496
那么过渡到基于物理原理的API

88
00:05:30,230 --> 00:05:33,667
首先我们不再支持旧系统上的投影模型

89
00:05:34,334 --> 00:05:37,304
那么我们将 当然了

90
00:05:37,371 --> 00:05:41,575
但意识到我们正在远离x4和y4属性

91
00:05:41,642 --> 00:05:44,845
而采用一些更匹配真实相机的东西

92
00:05:45,078 --> 00:05:49,183
比如 如果你想配置你的透视投影

93
00:05:49,249 --> 00:05:51,785
设置fieldOfView属性

94
00:05:51,852 --> 00:05:54,454
或配置focalLength和sensorHeight

95
00:05:55,088 --> 00:05:57,991
这些属性是连接在一起的

96
00:05:58,058 --> 00:06:00,561
比如说它将会相应地更新fieldOfView

97
00:05:58,058 --> 00:06:00,561
比如说它将会相应地更新fieldOfView

98
00:06:00,627 --> 00:06:01,595
反过来也一样

99
00:06:03,063 --> 00:06:07,334
然后SceneKit会给一个

100
00:06:07,668 --> 00:06:09,136
为了实现景深

101
00:06:09,203 --> 00:06:13,006
将wantsDepthOfField属性设为真

102
00:06:13,073 --> 00:06:16,176
通过设置focusDistance和fStop属性

103
00:06:17,244 --> 00:06:20,480
SceneKit将粗略估计

104
00:06:20,547 --> 00:06:24,918
并模糊场景 通过与这些摄影界的参数

105
00:06:24,985 --> 00:06:27,020
保持一致的方式

106
00:06:28,755 --> 00:06:32,826
所以新景深也会模拟

107
00:06:32,893 --> 00:06:34,194
你通过真实相机获得的散景

108
00:06:35,262 --> 00:06:39,566
散景出现在明亮的对象上 模糊不清

109
00:06:39,633 --> 00:06:44,438
因为它们是由像素生成的 强度很高

110
00:06:44,505 --> 00:06:48,375
如果你通过HDR相机渲染场景

111
00:06:48,509 --> 00:06:51,011
要配置这个

112
00:06:51,078 --> 00:06:52,779
在SCNcamera上设为真即可

113
00:06:54,548 --> 00:06:58,685
然后散景的形状

114
00:06:58,919 --> 00:07:01,889
并且你还可以在

115
00:06:58,919 --> 00:07:01,889
并且你还可以在

116
00:07:02,222 --> 00:07:05,492
这里有一些关于

117
00:07:08,729 --> 00:07:11,999
那么我们在本次发布中

118
00:07:12,065 --> 00:07:15,636
我们去年已经发布了

119
00:07:15,702 --> 00:07:19,907
即可以根据相机运动模糊场景

120
00:07:19,973 --> 00:07:22,776
意思就是如果你的相机

121
00:07:22,843 --> 00:07:25,913
你将会获得运动模糊

122
00:07:25,979 --> 00:07:29,082
而对象动来动去

123
00:07:29,449 --> 00:07:33,987
那么在本次发布中

124
00:07:34,054 --> 00:07:39,293
当你在相机上启动运动模糊时

125
00:07:41,395 --> 00:07:45,199
SCNcamera现在提供的另一种

126
00:07:46,867 --> 00:07:49,369
环境光遮蔽的原理很简单

127
00:07:50,237 --> 00:07:53,273
平面上的一个

128
00:07:53,340 --> 00:07:56,543
点能接收全部环境光

129
00:07:57,144 --> 00:08:01,048
而洞中的点却只能接收一部分环境光

130
00:07:57,144 --> 00:08:01,048
而洞中的点却只能接收一部分环境光

131
00:08:01,114 --> 00:08:04,551
因为有些环境光被表面挡住了

132
00:08:05,953 --> 00:08:08,689
SceneKit支持

133
00:08:08,755 --> 00:08:11,091
意思是这个遮蔽因素

134
00:08:11,158 --> 00:08:14,328
将在屏幕空间中的每一个像素上计算

135
00:08:15,629 --> 00:08:18,765
这是通过分析深度缓存

136
00:08:18,832 --> 00:08:22,503
SceneKit将决定

137
00:08:22,569 --> 00:08:26,106
通过与临近的正常碎片比较其深度实现

138
00:08:27,407 --> 00:08:31,712
那么这是一个

139
00:08:31,778 --> 00:08:35,414
而这里有很强的环境光遮蔽

140
00:08:37,650 --> 00:08:39,820
要启动屏幕空间环境光遮蔽

141
00:08:40,254 --> 00:08:42,856
只需要将screenSpaceAmbient

142
00:08:42,923 --> 00:08:44,825
的值设置为大于零即可

143
00:08:45,325 --> 00:08:48,729
然后你有一些参数 你可以进行调整

144
00:08:48,795 --> 00:08:51,632
根据你想要实现的效果以及场景的尺寸

145
00:08:51,698 --> 00:08:53,267
和拓扑

146
00:08:53,333 --> 00:08:56,136
让我们在演示中实际看一下这些效果

147
00:08:56,203 --> 00:08:58,338
关于这个 让我们欢迎Anatole上台

148
00:09:01,508 --> 00:09:02,342
谢谢Thomas

149
00:09:03,644 --> 00:09:04,778
大家早上好

150
00:09:07,214 --> 00:09:11,518
那么让我们回到第一个演示中

151
00:09:11,585 --> 00:09:13,453
给你们展示新的景深效果

152
00:09:15,222 --> 00:09:17,191
这里我们有…抱歉

153
00:09:19,126 --> 00:09:22,062
在这里在前景中

154
00:09:22,129 --> 00:09:24,665
焦距被设为短距离

155
00:09:24,731 --> 00:09:26,700
因为钥匙离相机很近

156
00:09:27,568 --> 00:09:29,937
效果数量也被设为了一个小值

157
00:09:30,003 --> 00:09:31,772
因为我们想要一个很强烈的模糊

158
00:09:32,272 --> 00:09:34,808
正如你所看到的

159
00:09:34,875 --> 00:09:37,110
由于微粒的照明度

160
00:09:39,246 --> 00:09:42,716
现在通过第二个相机

161
00:09:43,317 --> 00:09:46,153
那么背景中的对象很鲜明

162
00:09:46,220 --> 00:09:48,589
前景中的花很模糊

163
00:09:50,357 --> 00:09:53,360
另一种视角 在这里我可以 比如说

164
00:09:53,427 --> 00:09:56,530
玩一下FStop的值

165
00:09:57,865 --> 00:09:59,299
就像一台真实的相机一样

166
00:10:00,834 --> 00:10:02,469
然后通过第二个滑块

167
00:10:02,536 --> 00:10:05,138
我们定义了要在场景中的哪里聚焦

168
00:10:07,407 --> 00:10:11,111
那么这个新的景深效果非常有用

169
00:10:11,178 --> 00:10:13,614
在视频游戏中创建电影效果

170
00:10:15,115 --> 00:10:19,019
现在让我们打开另一个应用

171
00:10:20,654 --> 00:10:23,090
在这里我们有一个场景

172
00:10:23,390 --> 00:10:26,894
如果我点击射击按钮

173
00:10:29,530 --> 00:10:32,766
这是默认没有任何运动模糊时的样子

174
00:10:33,634 --> 00:10:36,036
现在我重设场景 启动运动模糊

175
00:10:36,103 --> 00:10:37,804
然后用小球扔那座塔

176
00:10:41,175 --> 00:10:43,310
你可以看到运动模糊的效果

177
00:10:43,377 --> 00:10:45,712
是那些小球的运动模糊

178
00:10:46,313 --> 00:10:50,517
你还可以看到当塔爆炸时

179
00:10:51,318 --> 00:10:52,953
但现在让我们近距离地看一下

180
00:10:53,487 --> 00:10:56,857
我可以冻结场景 稍微离近一点儿

181
00:10:57,925 --> 00:11:00,494
我们的大脑把这种模糊阐述为移动

182
00:10:57,925 --> 00:11:00,494
我们的大脑把这种模糊阐述为移动

183
00:11:00,661 --> 00:11:04,631
你甚至可以在静态图像中

184
00:11:05,732 --> 00:11:07,334
我们甚至可以修改视角

185
00:11:07,401 --> 00:11:10,537
我们仍然对每个对象的方向

186
00:11:12,272 --> 00:11:15,809
所以这真的改善了场景中的运动感知

187
00:11:15,876 --> 00:11:18,145
结果看起来更贴近现实了

188
00:11:19,479 --> 00:11:22,516
现在让我们看一下

189
00:11:24,017 --> 00:11:28,155
你可以看到一些小球被天空照亮

190
00:11:29,456 --> 00:11:33,227
通过第一个滑块

191
00:11:33,861 --> 00:11:36,196
你可以看到 添加了一些环境光阴影

192
00:11:36,263 --> 00:11:39,733
并且我可以修改强度

193
00:11:41,435 --> 00:11:45,005
遮蔽的面积取决于表面的曲率

194
00:11:45,706 --> 00:11:50,344
要了解像素是否处于洞中

195
00:11:50,811 --> 00:11:53,146
所以我们有这个半径参数

196
00:11:53,213 --> 00:11:56,517
可以让我们定义

197
00:11:57,484 --> 00:12:01,688
结果是小半径 环境光遮蔽更尖锐

198
00:11:57,484 --> 00:12:01,688
结果是小半径 环境光遮蔽更尖锐

199
00:12:02,089 --> 00:12:04,725
大半径 获得的多面体阴影最多

200
00:12:06,660 --> 00:12:09,396
这是实时计算的 所以这很好用

201
00:12:09,463 --> 00:12:13,400
如果你正在处理动态对象

202
00:12:15,235 --> 00:12:19,006
那添加了深处 抱歉是深度的感知细节

203
00:12:19,072 --> 00:12:21,975
并把全局光照的效果带到了你的场景中

204
00:12:23,310 --> 00:12:24,344
这就是这个演示

205
00:12:24,411 --> 00:12:27,281
让我们返回到幻灯片中

206
00:12:29,917 --> 00:12:34,021
（演示）

207
00:12:34,221 --> 00:12:35,322
谢谢Anatole

208
00:12:35,622 --> 00:12:38,091
那么我们讲了一些新相机效果

209
00:12:38,225 --> 00:12:40,661
现在让我们谈谈相机控制

210
00:12:41,061 --> 00:12:43,096
我之前的确说过 这是个很困难的难题

211
00:12:43,163 --> 00:12:45,032
且我们也看到了与它相关的许多问题

212
00:12:45,098 --> 00:12:47,901
我们认定了两个主要用例

213
00:12:48,502 --> 00:12:52,172
人们可能会想检验一个3D对象

214
00:12:52,239 --> 00:12:55,642
通过旋转3D对象或围绕3D对象旋转

215
00:12:55,742 --> 00:13:01,415
比如正在创建一个

216
00:12:55,742 --> 00:13:01,415
比如正在创建一个

217
00:13:01,481 --> 00:13:06,220
或需要一些更复杂的

218
00:13:06,286 --> 00:13:08,989
比如一个游戏或更高级的应用

219
00:13:09,690 --> 00:13:11,859
让我们先从第一个用例开始看

220
00:13:12,793 --> 00:13:16,663
直到现在 如果你想操纵一个3D对象

221
00:13:16,830 --> 00:13:19,933
你必须实施你自己的事件管理

222
00:13:20,200 --> 00:13:22,703
并移动相机位置和方向

223
00:13:22,769 --> 00:13:24,905
根据手势或鼠标事件

224
00:13:25,806 --> 00:13:30,677
为了方便 我们在SCNView上

225
00:13:31,144 --> 00:13:34,781
但这些只能为你提供

226
00:13:34,848 --> 00:13:36,783
是不可配置的

227
00:13:36,850 --> 00:13:39,620
这其实是用于调试的

228
00:13:41,188 --> 00:13:45,993
在这次新发布中 我们引入了一个新类

229
00:13:46,527 --> 00:13:50,597
SCNCameraController允许你操纵相机

230
00:13:50,664 --> 00:13:54,368
获得你在3D软件中

231
00:13:55,802 --> 00:13:58,739
那么这些行为被内嵌到相机控制器中

232
00:13:58,805 --> 00:14:02,276
并且SCNView有一个

233
00:13:58,805 --> 00:14:02,276
并且SCNView有一个

234
00:14:02,342 --> 00:14:05,979
你可以根据你应用的需要直接配置

235
00:14:06,947 --> 00:14:08,982
现在如果你需要更具体的行为

236
00:14:09,049 --> 00:14:12,186
你仍可以实例化

237
00:14:12,252 --> 00:14:14,288
并且只要你想

238
00:14:15,856 --> 00:14:18,859
SCNCameraController

239
00:14:18,926 --> 00:14:21,795
绝大部分常用相机操作工具

240
00:14:22,229 --> 00:14:27,100
举例来说 轨道转盘允许你

241
00:14:27,167 --> 00:14:31,438
让你的相机绕着3D对象转

242
00:14:31,505 --> 00:14:35,175
意思是地平线总是保持水平

243
00:14:35,242 --> 00:14:37,644
无论你正在实施哪种旋转

244
00:14:39,046 --> 00:14:44,651
轨道轨迹球会让相机通过屏幕

245
00:14:44,718 --> 00:14:48,856
所以这种模式在某些情况下更直观

246
00:14:48,922 --> 00:14:53,527
但它不能防止摇晃

247
00:14:55,262 --> 00:14:57,197
另一个是飞行模式

248
00:14:57,264 --> 00:15:01,335
更适用于成圈的场景

249
00:14:57,264 --> 00:15:01,335
更适用于成圈的场景

250
00:15:02,035 --> 00:15:06,473
在那种情况下

251
00:15:06,540 --> 00:15:09,276
意思就是你旋转相机

252
00:15:09,343 --> 00:15:13,013
在一个位置查看四周以围着对象转

253
00:15:15,415 --> 00:15:18,418
我们再次相信场景相机控制器会提供

254
00:15:18,952 --> 00:15:21,588
绝大部分常用相机操作工具

255
00:15:21,655 --> 00:15:23,991
如果你需要很具体的效果

256
00:15:24,057 --> 00:15:27,728
你仍然可以尝试以编程方式

257
00:15:28,829 --> 00:15:30,697
现在让我们来看看程序的第二个类

258
00:15:31,431 --> 00:15:35,135
显影 我们需要一个更复杂的相机行为

259
00:15:35,736 --> 00:15:39,239
我们通过链接约束

260
00:15:39,306 --> 00:15:41,308
以定义相机行为来解决这个问题

261
00:15:43,310 --> 00:15:47,948
SceneKit已经提供了

262
00:15:48,015 --> 00:15:50,584
我们今年又增加了一些新约束

263
00:15:50,651 --> 00:15:55,322
可以应用到任意节点中

264
00:15:56,356 --> 00:16:01,562
让我们来阐述其中一些约束

265
00:15:56,356 --> 00:16:01,562
让我们来阐述其中一些约束

266
00:16:01,628 --> 00:16:06,700
与另一个指定目标节点

267
00:16:08,101 --> 00:16:11,638
要复制我们的约束

268
00:16:11,705 --> 00:16:15,075
和方向 通过一个可选的偏移

269
00:16:16,610 --> 00:16:20,347
而加速度约束

270
00:16:20,414 --> 00:16:25,085
比最大指定速度和加速度更快

271
00:16:26,119 --> 00:16:29,423
那么这些只是一些例子

272
00:16:30,724 --> 00:16:34,094
那么在这里我们有一个角色

273
00:16:34,161 --> 00:16:37,164
相机目前没有约束 因此他是静态的

274
00:16:38,465 --> 00:16:41,902
如果我给相机添加一个看约束

275
00:16:41,969 --> 00:16:43,303
作为目标节点

276
00:16:43,370 --> 00:16:47,441
那么现在相机会旋转以实现看约束

277
00:16:47,508 --> 00:16:50,377
相机会朝角色的方向看

278
00:16:51,645 --> 00:16:57,784
如果我添加一个重复约束

279
00:16:57,851 --> 00:17:01,788
那就会重复角色的移动 会有一些偏移

280
00:16:57,851 --> 00:17:01,788
那就会重复角色的移动 会有一些偏移

281
00:17:01,855 --> 00:17:04,391
并继续朝角色的方向看

282
00:17:05,291 --> 00:17:08,161
如果我添加一个加速度约束

283
00:17:08,228 --> 00:17:09,997
我现在拥有同样的行为

284
00:17:10,063 --> 00:17:13,599
那最应该感谢加速度约束

285
00:17:13,666 --> 00:17:16,036
在另一个约束之后应用的

286
00:17:17,905 --> 00:17:22,509
并且如果我用距离约束替换重复约束

287
00:17:22,576 --> 00:17:24,678
我现在就有了一个新的相机行为

288
00:17:24,744 --> 00:17:28,248
现在是跟随角色以实现距离约束

289
00:17:29,049 --> 00:17:31,785
它继续朝角色的方向看 当然了

290
00:17:31,852 --> 00:17:35,255
并且总是在移动 而不管角色的移动

291
00:17:35,322 --> 00:17:38,625
这是由于加速度约束

292
00:17:39,793 --> 00:17:42,563
这是如何定义相机行为 很简单

293
00:17:42,629 --> 00:17:46,333
这是在我们的小狐狸2示例中实现的

294
00:17:47,234 --> 00:17:50,170
只是定义了一组不同的约束

295
00:17:50,237 --> 00:17:52,806
根据游戏的不同区域

296
00:17:52,873 --> 00:17:57,344
我们可以为整个游戏定义相机行为

297
00:17:59,813 --> 00:18:02,049
关于相机控制还需要注意一点

298
00:17:59,813 --> 00:18:02,049
关于相机控制还需要注意一点

299
00:18:03,083 --> 00:18:08,555
我们扩展了SCNNode的类别

300
00:18:08,622 --> 00:18:11,892
以在不同的空间转换和获取矢量

301
00:18:12,559 --> 00:18:15,929
但最重要的是 全部节点转换属性

302
00:18:15,996 --> 00:18:20,234
现有位置、旋转、

303
00:18:20,300 --> 00:18:24,605
现在都能直接在SIMD属性中使用

304
00:18:24,671 --> 00:18:26,540
以减少数学运算

305
00:18:27,107 --> 00:18:28,575
那么由于SIMD类型

306
00:18:29,409 --> 00:18:32,346
四元数、矢量和矩阵的运算的

307
00:18:32,412 --> 00:18:35,749
写入变得更简单了

308
00:18:36,416 --> 00:18:39,720
请了解一些SMD类型的限制

309
00:18:39,786 --> 00:18:43,724
和KVC约束 并且它们不能

310
00:18:45,425 --> 00:18:46,760
那么这就是相机控制器

311
00:18:46,827 --> 00:18:49,863
现在让我们把舞台交给Amaury

312
00:18:49,930 --> 00:18:53,534
（细化和细分曲面）

313
00:18:53,600 --> 00:18:54,535
谢谢Thomas

314
00:18:56,436 --> 00:18:59,740
那么我们知道好的图形

315
00:18:59,806 --> 00:19:02,609
可以实现用户胶着和取悦用户

316
00:18:59,806 --> 00:19:02,609
可以实现用户胶着和取悦用户

317
00:19:02,676 --> 00:19:05,212
要做出好的图形有很多方面需要关注

318
00:19:05,612 --> 00:19:08,182
比如 增加真实性

319
00:19:08,248 --> 00:19:10,617
这也是为什么我们这么多年一直引入

320
00:19:10,684 --> 00:19:14,621
新的渲染功能的原因

321
00:19:14,688 --> 00:19:18,091
以及[听不清]更真实的相机光学

322
00:19:19,693 --> 00:19:24,698
但高分辨率资产

323
00:19:25,933 --> 00:19:30,370
在你的应用中

324
00:19:30,437 --> 00:19:33,340
以及非常丰富和精细的表面

325
00:19:34,007 --> 00:19:37,444
现在问题是当你处理高分辨率资产时

326
00:19:37,511 --> 00:19:41,548
它们需要更多的内存

327
00:19:41,615 --> 00:19:43,750
并且它们需要更多的处理时间

328
00:19:44,384 --> 00:19:48,355
那么在这部分

329
00:19:48,422 --> 00:19:52,059
以及你们开发者

330
00:19:52,125 --> 00:19:55,495
可以变成高质量的

331
00:19:56,730 --> 00:20:00,901
那么我想先解释一下什么是细化

332
00:19:56,730 --> 00:20:00,901
那么我想先解释一下什么是细化

333
00:20:00,968 --> 00:20:04,338
然后展示如何在

334
00:20:04,571 --> 00:20:07,207
最后看一点儿不一样的东西

335
00:20:07,274 --> 00:20:08,775
细分曲面

336
00:20:10,511 --> 00:20:11,445
那么细化

337
00:20:12,312 --> 00:20:15,682
细化是去年在Metal中

338
00:20:15,749 --> 00:20:17,551
这个功能背后的理念是

339
00:20:17,618 --> 00:20:20,988
提供低分辨率网格或粗网格GPU

340
00:20:21,054 --> 00:20:25,392
然后让GPU生成更多几何体

341
00:20:25,459 --> 00:20:29,596
拥有更多的至高点

342
00:20:31,298 --> 00:20:34,568
那么细化的确是一个很强大的工具

343
00:20:34,902 --> 00:20:37,538
它们用于

344
00:20:37,604 --> 00:20:42,943
创建、存储和推动低分辨率模型

345
00:20:43,010 --> 00:20:45,812
当渲染这些低分辨率模型时

346
00:20:46,013 --> 00:20:48,315
让我们看一下 这是一个三角形

347
00:20:48,882 --> 00:20:51,185
这是它的一个细化版本

348
00:20:52,786 --> 00:20:57,624
那么SceneKit就要决定

349
00:20:57,925 --> 00:21:01,895
它可以决定可以在第一条边

350
00:20:57,925 --> 00:21:01,895
它可以决定可以在第一条边

351
00:21:01,962 --> 00:21:03,130
创建多少至高点

352
00:21:03,430 --> 00:21:05,966
当然了 它同样也可以决定第三条边

353
00:21:06,700 --> 00:21:10,571
很棒的是SceneKit还会生成更多至高点

354
00:21:10,637 --> 00:21:12,539
在三角形内

355
00:21:14,107 --> 00:21:16,810
那么这些就叫作细化因素

356
00:21:16,877 --> 00:21:19,213
SceneKit是一个高层级API

357
00:21:19,279 --> 00:21:22,316
我们把它变得非常简单易用

358
00:21:23,050 --> 00:21:27,120
我们新添加了

359
00:21:27,187 --> 00:21:30,357
并在SCNGeometry上添加了细化属性

360
00:21:31,058 --> 00:21:34,027
细化公开了一些属性

361
00:21:34,094 --> 00:21:35,596
考虑到了不同的模式

362
00:21:36,597 --> 00:21:39,700
让我们首先来看一下最简单的例子

363
00:21:40,968 --> 00:21:45,038
在这种模式中

364
00:21:45,105 --> 00:21:47,374
和内部细化因素

365
00:21:47,441 --> 00:21:50,777
将被应用于全部粗网格的三角形

366
00:21:51,178 --> 00:21:54,481
那么通过这种模式

367
00:21:54,548 --> 00:21:56,683
并且你将添加同等数量的几何体

368
00:21:56,750 --> 00:21:58,886
在整个粗网格内

369
00:22:00,521 --> 00:22:04,024
现在让我们看一个更复杂的例子

370
00:22:05,225 --> 00:22:09,229
在这里你可以请求SceneKit

371
00:22:09,296 --> 00:22:11,331
从而防止边太长

372
00:22:11,798 --> 00:22:15,802
那么在这里 你在局部空间内

373
00:22:16,904 --> 00:22:22,109
甚至再强大点 你可以请求

374
00:22:22,176 --> 00:22:27,548
细化因素 根据对象内的项目

375
00:22:28,182 --> 00:22:32,553
那么在这种模式中

376
00:22:32,619 --> 00:22:35,656
最大边长 以像素为单位

377
00:22:39,126 --> 00:22:40,661
这是细化

378
00:22:41,128 --> 00:22:44,364
现在如果你看一下原始三角形

379
00:22:44,431 --> 00:22:48,669
及其细化版本 你可能会感到有点失望

380
00:22:48,735 --> 00:22:50,804
这是因为全部新几何数据

381
00:22:50,871 --> 00:22:54,041
实际上是位于原始三角形内

382
00:22:54,541 --> 00:22:56,443
那么对于你高度细化的网格

383
00:22:56,510 --> 00:23:00,514
你想要通过这种额外的网格

384
00:22:56,510 --> 00:23:00,514
你想要通过这种额外的网格

385
00:23:01,048 --> 00:23:04,952
这就将我们引入了

386
00:23:07,221 --> 00:23:10,057
那么首先 我们回顾一下着色器修改器

387
00:23:10,858 --> 00:23:15,229
着色器修改器完全支持新的细化管道

388
00:23:15,329 --> 00:23:19,066
只需要通过几行代码

389
00:23:19,466 --> 00:23:22,736
那么比如说 如果你有一个应用

390
00:23:22,803 --> 00:23:26,807
你想模拟大海和波浪或任何其它想法

391
00:23:26,874 --> 00:23:28,141
是你自己的效果

392
00:23:28,909 --> 00:23:32,212
着色器修改器正是你所需要的工具

393
00:23:32,513 --> 00:23:35,749
当然了 我们还添加了一些

394
00:23:35,816 --> 00:23:37,551
比如使几何体平滑

395
00:23:38,452 --> 00:23:39,853
这是一个新功能

396
00:23:40,287 --> 00:23:44,858
比如如果你指定

397
00:23:44,925 --> 00:23:50,731
SceneKit将考虑每个顶点

398
00:23:50,797 --> 00:23:55,102
及其临近的点在法线上的位置

399
00:23:55,169 --> 00:23:57,237
从而把它们放在一个平滑的表面上

400
00:23:58,038 --> 00:24:00,407
你可能听说过的另一种效果

401
00:23:58,038 --> 00:24:00,407
你可能听说过的另一种效果

402
00:24:00,474 --> 00:24:02,142
位移图和高度图

403
00:24:03,310 --> 00:24:04,444
那么什么是高度图？

404
00:24:05,112 --> 00:24:07,281
高度图是一个灰度图像

405
00:24:07,347 --> 00:24:12,653
存储了表面上

406
00:24:13,420 --> 00:24:17,858
这种技术通常用于创建

407
00:24:17,925 --> 00:24:20,561
让我们看一个例子

408
00:24:21,695 --> 00:24:25,232
这是一个平面 然后我们进行细化

409
00:24:26,433 --> 00:24:29,136
然后通过高度图使其变形

410
00:24:31,338 --> 00:24:35,275
那么这是一个很简单的例子

411
00:24:36,210 --> 00:24:38,245
API也很简单

412
00:24:38,579 --> 00:24:43,116
我们在SCNMaterial上

413
00:24:43,183 --> 00:24:45,118
所以我敢说你们已经知道如何使用它了

414
00:24:45,285 --> 00:24:49,890
你只需要指定它的内容

415
00:24:49,957 --> 00:24:52,326
你就可以获得我刚刚所展示的动画

416
00:24:53,327 --> 00:24:57,030
现在让我们更进一步 看看矢量位移图

417
00:24:58,165 --> 00:25:01,969
矢量位移图是高度图的扩展

418
00:24:58,165 --> 00:25:01,969
矢量位移图是高度图的扩展

419
00:25:02,035 --> 00:25:04,505
它不仅存储海拔

420
00:25:04,571 --> 00:25:08,242
你还可以存储全部三个方位的位移

421
00:25:08,308 --> 00:25:10,143
这就是为什么

422
00:25:10,777 --> 00:25:16,083
比如绿色是法线上的位移

423
00:25:16,149 --> 00:25:17,951
是切线和双切线上的位移

424
00:25:19,253 --> 00:25:22,155
那么你猜到那有什么用吗？

425
00:25:26,527 --> 00:25:28,529
好的 那么这是一个很傻的例子

426
00:25:28,595 --> 00:25:31,865
但在你的应用中 你可以使用位移图

427
00:25:31,932 --> 00:25:35,102
添加细节

428
00:25:35,235 --> 00:25:39,406
那么比如说

429
00:25:39,473 --> 00:25:41,408
你可以给它的皮肤添加细节

430
00:25:41,742 --> 00:25:45,078
或者如果你有一个应用

431
00:25:45,145 --> 00:25:46,747
你可以近距离地接触到

432
00:25:46,813 --> 00:25:49,249
那么正好可以使用矢量位移图

433
00:25:50,217 --> 00:25:55,989
API是一样的 除了只有红色

434
00:25:56,056 --> 00:26:00,861
纹理组件以表明你将包含一种以上的

435
00:25:56,056 --> 00:26:00,861
纹理组件以表明你将包含一种以上的

436
00:26:00,928 --> 00:26:03,130
色彩通道或输入图像

437
00:26:05,299 --> 00:26:08,435
那么这就是细化和基于细化的效果

438
00:26:08,502 --> 00:26:10,838
现在让我们看看细分曲面

439
00:26:13,707 --> 00:26:16,977
那么你可能已经听说过我们的细分曲面

440
00:26:17,044 --> 00:26:18,779
和[听不清]

441
00:26:19,279 --> 00:26:21,515
它是一个标准化算法

442
00:26:21,582 --> 00:26:26,220
从粗网格开始 反复改善它

443
00:26:31,859 --> 00:26:34,862
那么你可以看到我们从粗网格

444
00:26:34,928 --> 00:26:36,697
到一个非常平滑和精制的网格是多么快

445
00:26:37,698 --> 00:26:40,367
现在并不是所有东西都是完美的圆形

446
00:26:40,434 --> 00:26:44,905
所以对于细分曲面

447
00:26:44,972 --> 00:26:49,977
以使边和至高点拥有明显的锐利度

448
00:26:52,312 --> 00:26:54,014
那么细分曲面

449
00:26:54,515 --> 00:27:00,954
它们被广泛用于创建、存储和推动

450
00:26:54,515 --> 00:27:00,954
它们被广泛用于创建、存储和推动

451
00:27:01,021 --> 00:27:04,324
分辨率模型

452
00:27:04,391 --> 00:27:05,726
可能会变成高品质的模型

453
00:27:06,927 --> 00:27:10,197
并且几年前我们已经

454
00:27:10,264 --> 00:27:11,932
在SceneKit中添加了

455
00:27:12,332 --> 00:27:16,103
但我们过去是在CPU上运行细分代码

456
00:27:16,937 --> 00:27:20,274
那么那需要一些时间以及大量的内存

457
00:27:20,340 --> 00:27:23,577
尤其是当你进入较高细分等级时

458
00:27:23,644 --> 00:27:27,848
因为至高点的数量将呈指数增长

459
00:27:29,650 --> 00:27:31,151
那么我们今年有个好消息

460
00:27:32,819 --> 00:27:36,089
你可能听说了Pixar的

461
00:27:36,156 --> 00:27:38,292
这是一个开源的工具实施

462
00:27:38,358 --> 00:27:41,361
用于细分曲面的高效评估

463
00:27:41,662 --> 00:27:43,864
去年的WWDC时

464
00:27:43,931 --> 00:27:47,167
Apple宣布我们将给这个项目

465
00:27:47,234 --> 00:27:49,703
提供基于Metal的实施

466
00:27:49,770 --> 00:27:53,807
以便你可以在GPU上

467
00:27:54,875 --> 00:27:58,078
那么今年你可以利用

468
00:27:58,145 --> 00:27:59,279
非常简单

469
00:28:00,714 --> 00:28:04,418
基于Metal的实施有许多好处

470
00:28:04,818 --> 00:28:07,254
首先我们利用细分

471
00:28:07,387 --> 00:28:10,858
它伴随着我之前讲过的

472
00:28:11,191 --> 00:28:13,060
并且通过细分

473
00:28:13,126 --> 00:28:17,397
我们甚至将会使低等级的细分

474
00:28:18,098 --> 00:28:22,903
现在除了统一细分

475
00:28:23,170 --> 00:28:25,005
我稍后会解释

476
00:28:25,105 --> 00:28:27,908
最后我们还有全部GPU管道

477
00:28:27,975 --> 00:28:31,178
用于细分网格的高效动画

478
00:28:32,646 --> 00:28:34,982
那么让我们看一下这个例子

479
00:28:35,048 --> 00:28:39,753
这是你在演示中看到的那把钥匙

480
00:28:40,087 --> 00:28:41,288
并没有那么精细

481
00:28:42,222 --> 00:28:45,192
这是一个细化版本 细分版

482
00:28:46,026 --> 00:28:49,263
那么通过这个资产

483
00:28:49,329 --> 00:28:50,931
但还有很漂亮的曲线

484
00:28:51,598 --> 00:28:54,601
那么我们是如何实现的呢？通过褶皱

485
00:28:56,236 --> 00:28:58,205
通过细分曲面

486
00:28:58,272 --> 00:29:01,008
设计师们可以实现很棒的设计

487
00:28:58,272 --> 00:29:01,008
设计师们可以实现很棒的设计

488
00:29:01,074 --> 00:29:03,143
他们可以简便地创建

489
00:29:03,210 --> 00:29:07,080
并调整 获得他们想要的效果

490
00:29:09,650 --> 00:29:12,352
现在功能适应性细分

491
00:29:14,621 --> 00:29:18,392
当统一细分在一个有限的表面上实施时

492
00:29:18,458 --> 00:29:22,729
这是通过呈指数增长的多边形数量

493
00:29:23,764 --> 00:29:28,535
功能适应性细分可以

494
00:29:28,602 --> 00:29:30,771
并创建很多补丁

495
00:29:31,271 --> 00:29:34,007
那么然后 通过细化

496
00:29:34,074 --> 00:29:36,276
在这些完美的数学曲线上

497
00:29:36,343 --> 00:29:41,014
因此它会生成非常平滑的表面

498
00:29:42,783 --> 00:29:44,551
现在 API非常简单

499
00:29:45,252 --> 00:29:50,624
你只需要指定细分等级

500
00:29:51,525 --> 00:29:55,395
然后对于功能适应性细分

501
00:29:56,897 --> 00:30:00,167
最后细分曲面的动画

502
00:29:56,897 --> 00:30:00,167
最后细分曲面的动画

503
00:30:00,968 --> 00:30:05,339
今年我们有了全部GPU管道

504
00:30:05,439 --> 00:30:11,111
你可以有一个粗网格

505
00:30:11,178 --> 00:30:14,114
那么只要你想

506
00:30:14,481 --> 00:30:18,619
最后作为最后一步

507
00:30:18,819 --> 00:30:22,122
性能非常好

508
00:30:22,189 --> 00:30:25,559
在低分辨率的网格上

509
00:30:25,626 --> 00:30:29,062
是由GPU通过细化生成的

510
00:30:30,964 --> 00:30:33,567
那么现在 你想试试细分曲面

511
00:30:33,634 --> 00:30:38,205
你只需要记住两点

512
00:30:38,939 --> 00:30:42,142
请指定preserveOriginalTopology选项

513
00:30:42,843 --> 00:30:45,579
如果你以编程方式创建几何体

514
00:30:45,646 --> 00:30:47,915
请记住使用多边形原始类型

515
00:30:48,515 --> 00:30:52,085
这是因为对于细分 处理三角形

516
00:30:52,152 --> 00:30:53,554
与处理四边形并不一样

517
00:30:54,588 --> 00:30:56,490
然后让我们来看一个快速演示

518
00:31:05,566 --> 00:31:08,769
好的 那么这是一个简单的制陶应用

519
00:31:08,836 --> 00:31:10,170
我要制作一件陶器

520
00:31:10,938 --> 00:31:17,177
那么我可以缩放 并且可以拖动旋转

521
00:31:17,945 --> 00:31:18,912
非常简单

522
00:31:19,546 --> 00:31:23,750
现在如果我放大 然后关注对象的轮廓

523
00:31:24,251 --> 00:31:26,553
正如你所看到的 非常平滑

524
00:31:26,620 --> 00:31:31,491
你可以使用法线图

525
00:31:32,793 --> 00:31:37,631
现在这个应用的目的很简单

526
00:31:38,398 --> 00:31:40,634
在网格上进行雕刻

527
00:31:41,768 --> 00:31:45,239
让我们清除它 然后写一些东西

528
00:31:45,806 --> 00:31:49,343
随着我的绘制 请看对象的轮廓

529
00:31:51,111 --> 00:31:53,847
在这里我实际上正在修改几何体

530
00:31:54,281 --> 00:31:58,652
我不只是添加表面细节

531
00:32:06,393 --> 00:32:07,961
好的 那么是如何实现的呢？

532
00:32:08,195 --> 00:32:12,132
嗯 细分曲面、细化和高度图

533
00:32:12,199 --> 00:32:13,267
让我们来看一下

534
00:32:15,802 --> 00:32:19,106
我们所做的是

535
00:32:19,173 --> 00:32:21,708
正如你所看到的

536
00:32:23,010 --> 00:32:26,747
它并没有法线

537
00:32:26,813 --> 00:32:32,419
但它有纹理坐标 所以我们可以

538
00:32:32,486 --> 00:32:33,987
稍后再映射一个高度图

539
00:32:34,855 --> 00:32:36,857
那么现在 让我们细分它

540
00:32:38,091 --> 00:32:41,595
让我们看看所生成的平滑法线

541
00:32:43,163 --> 00:32:44,631
然后让我们看看

542
00:32:45,465 --> 00:32:49,069
线框以及创建了多少个至高点

543
00:32:50,537 --> 00:32:54,474
当我启动细分时创建了多少个至高点

544
00:32:56,043 --> 00:33:00,914
当我抬起手指时

545
00:32:56,043 --> 00:33:00,914
当我抬起手指时

546
00:33:02,115 --> 00:33:04,318
全部至高点都被移动了

547
00:33:06,086 --> 00:33:07,354
现在让我们清除它

548
00:33:07,621 --> 00:33:11,325
只是为了更有意思

549
00:33:12,059 --> 00:33:16,797
现在我会放大 看看当我离对象

550
00:33:17,898 --> 00:33:20,567
SceneKit将提供新的细化因素

551
00:33:20,634 --> 00:33:23,837
它会在过程中创建新的至高点

552
00:33:27,374 --> 00:33:28,609
这就是这个演示

553
00:33:35,082 --> 00:33:37,684
谢谢 那么总的来说

554
00:33:38,819 --> 00:33:41,755
细化和依赖于细化的功能

555
00:33:41,822 --> 00:33:44,558
都能在全部Mac上的

556
00:33:44,625 --> 00:33:49,029
在拥有A9或更高版本芯片的

557
00:33:49,096 --> 00:33:53,767
那么包括iPhone 6S

558
00:33:55,969 --> 00:33:59,706
现在让我们一些完全不同的东西

559
00:33:59,773 --> 00:34:02,075
我们对动画API的改进

560
00:33:59,773 --> 00:34:02,075
我们对动画API的改进

561
00:34:02,142 --> 00:34:07,948
（动画改进）

562
00:34:08,014 --> 00:34:08,849
那么…

563
00:34:10,851 --> 00:34:14,855
今年我们引入了新SCNAnimation协议

564
00:34:15,088 --> 00:34:19,126
以及SCNAnimationPlayer类

565
00:34:19,860 --> 00:34:24,531
使动画变得更简单了

566
00:34:24,598 --> 00:34:28,068
当动画运行时

567
00:34:28,869 --> 00:34:33,172
那么比如说 现在你可以

568
00:34:33,239 --> 00:34:35,909
并且你可以在融合正在发生的动画

569
00:34:36,376 --> 00:34:41,047
当然 我们仍完全支持CA动画API

570
00:34:41,114 --> 00:34:44,318
CA动画遵从我们的新协议

571
00:34:44,851 --> 00:34:51,625
但通过新API 变得更简单了

572
00:34:51,692 --> 00:34:52,960
当动画在运行时

573
00:34:53,025 --> 00:34:57,231
并且这些API在全部平台上都可用

574
00:34:58,498 --> 00:35:00,367
那么让我们看看老的方式

575
00:34:58,498 --> 00:35:00,367
那么让我们看看老的方式

576
00:35:01,134 --> 00:35:04,605
那么假如你有一个角色 会走会跳

577
00:35:05,072 --> 00:35:07,774
你首先要添加行走动画

578
00:35:07,841 --> 00:35:10,377
然后当你想让角色跳跃时

579
00:35:10,444 --> 00:35:13,714
你就需要添加跳跃动画

580
00:35:15,816 --> 00:35:17,484
现在通过新API

581
00:35:17,551 --> 00:35:21,555
你开始可以创建和配置动画播放器

582
00:35:21,622 --> 00:35:25,325
然后当你想让角色跳跃时

583
00:35:25,392 --> 00:35:29,630
而不是直接操纵动画

584
00:35:30,497 --> 00:35:34,268
不同点是你现在可以操纵

585
00:35:34,334 --> 00:35:37,638
所以你可以修改动画的速度

586
00:35:38,505 --> 00:35:40,941
动画混合实际上是今年的新功能

587
00:35:41,942 --> 00:35:46,680
那么让我们来看一个例子

588
00:35:47,314 --> 00:35:51,018
每种运动都有不同的动画文件

589
00:35:52,653 --> 00:35:56,990
通过新的混合API 你可以很简便地

590
00:35:57,057 --> 00:35:59,927
从迈步动画过渡到行走动画

591
00:35:59,993 --> 00:36:04,097
那么你可以引入流动性

592
00:35:59,993 --> 00:36:04,097
那么你可以引入流动性

593
00:36:04,898 --> 00:36:08,135
在你混合动画之后

594
00:36:08,202 --> 00:36:12,840
马克斯可以跑慢点儿

595
00:36:14,441 --> 00:36:19,680
最后让我提一下动画评估代码的改进

596
00:36:20,514 --> 00:36:26,019
那么我们有一个新的实施

597
00:36:26,086 --> 00:36:28,355
开启任意对象的动画变得更快

598
00:36:29,323 --> 00:36:33,594
并且我们对骨骼动画的评估性能更好

599
00:36:33,660 --> 00:36:38,398
那么如果你有许多角色

600
00:36:38,465 --> 00:36:41,468
比如你刚才看到的小狐狸演示

601
00:36:42,269 --> 00:36:45,506
那么通过我们这个新实施

602
00:36:46,874 --> 00:36:49,510
然后让我把舞台交给Sebastien

603
00:36:49,576 --> 00:36:51,812
他会给大家讲开发者工具的更新

604
00:36:51,879 --> 00:36:54,648
（开发者工具）

605
00:36:54,715 --> 00:36:55,716
谢谢Amaury

606
00:36:58,785 --> 00:37:01,488
那么去年我们引入了FPS计量

607
00:36:58,785 --> 00:37:01,488
那么去年我们引入了FPS计量

608
00:37:02,089 --> 00:37:05,092
那是一个了解你应用

609
00:37:05,158 --> 00:37:06,426
对于SceneKit的性能概览的

610
00:37:06,660 --> 00:37:09,696
并且它们进行了分类

611
00:37:09,763 --> 00:37:12,332
CPU和GPU的具体信息

612
00:37:12,399 --> 00:37:14,034
那么你可以了解是否正在渲染

613
00:37:14,101 --> 00:37:15,736
和物理处理或微粒处理

614
00:37:16,336 --> 00:37:18,772
它被整合在Xcode中

615
00:37:18,839 --> 00:37:20,407
它的具体情况

616
00:37:20,908 --> 00:37:22,576
能具体了解

617
00:37:22,643 --> 00:37:27,814
哪些占用了时间很酷 所以你可以

618
00:37:28,282 --> 00:37:30,317
但当你跳过某一帧时会发生什么呢？

619
00:37:30,384 --> 00:37:35,589
你如何知道具体发生了什么？

620
00:37:36,790 --> 00:37:38,926
今年我们引入了新工具

621
00:37:39,226 --> 00:37:41,495
是SceneKit的模板

622
00:37:41,562 --> 00:37:44,398
你可以用于记录你应用的踪迹

623
00:37:44,464 --> 00:37:47,334
并具体了解每一帧到底发生了什么

624
00:37:48,769 --> 00:37:51,371
非常简单易用 你只需要创建一个模板

625
00:37:52,039 --> 00:37:54,474
就跟你创建用于其它追踪的模板一样

626
00:37:54,541 --> 00:37:57,010
那么它将会记录你应用的性能

627
00:37:57,077 --> 00:37:58,645
并且你会得到这个视图

628
00:37:58,946 --> 00:38:02,783
它是全长的 显示了你应用中

629
00:37:58,946 --> 00:38:02,783
它是全长的 显示了你应用中

630
00:38:02,850 --> 00:38:05,786
第一个是帧 它显示了所占用的时间

631
00:38:05,853 --> 00:38:11,592
在应用中渲染某一个帧

632
00:38:12,459 --> 00:38:15,128
第二个提供了渲染时间

633
00:38:15,195 --> 00:38:18,899
是由SceneKit收集全部数据

634
00:38:18,966 --> 00:38:20,434
并将其发送到GPU所占用的时间

635
00:38:21,635 --> 00:38:25,739
第三个提供了更新过程

636
00:38:25,806 --> 00:38:28,909
是用于更新物理处理、微粒处理

637
00:38:28,976 --> 00:38:32,045
以及自定义委托（如果你有的话）

638
00:38:33,146 --> 00:38:35,148
最后一个但也是非常重要的一个

639
00:38:35,215 --> 00:38:38,018
是将纹理上传到GPU

640
00:38:38,085 --> 00:38:39,686
以及编译着色器所占用的时间

641
00:38:40,821 --> 00:38:44,458
让我们看看跳帧时是什么样的

642
00:38:44,525 --> 00:38:46,059
这是一个很简单的例子

643
00:38:46,927 --> 00:38:49,229
你可以看到所有帧的渲染时间都很短

644
00:38:49,296 --> 00:38:53,600
并且在某一点上来说

645
00:38:53,667 --> 00:38:56,570
与正常的四帧占用的时间一样

646
00:38:56,937 --> 00:39:01,175
我们向下深挖

647
00:38:56,937 --> 00:39:01,175
我们向下深挖

648
00:39:01,241 --> 00:39:04,745
我们可以看到编译了一个新着色器

649
00:39:04,811 --> 00:39:10,417
在这种情况下我们就可以了解

650
00:39:11,585 --> 00:39:13,187
在应用刚开启的时候

651
00:39:14,421 --> 00:39:17,391
我们还添加了一种方式 可以结合

652
00:39:18,325 --> 00:39:20,561
SceneKit工具和

653
00:39:20,627 --> 00:39:25,499
那么你可以同时看到这两者的结合

654
00:39:25,566 --> 00:39:28,502
后台发生了什么

655
00:39:28,569 --> 00:39:30,971
以便了解你的应用中发生了什么

656
00:39:32,439 --> 00:39:34,608
今年我们还添加了一个新调试工具

657
00:39:35,375 --> 00:39:38,478
是Xcode中视图调试器的改进

658
00:39:38,545 --> 00:39:41,315
简单易用 你只需要使用

659
00:39:41,381 --> 00:39:42,683
就跟你往常的用法一样

660
00:39:43,350 --> 00:39:48,722
它将自动捕捉视图等级以及场景

661
00:39:49,256 --> 00:39:50,991
那么如果有SceneKit场景

662
00:39:51,225 --> 00:39:55,028
在你应用的SceneKit视图中

663
00:39:55,095 --> 00:39:57,965
如果你在视图等级中选择场景

664
00:39:58,465 --> 00:40:00,000
它将自动把它发送到

665
00:40:00,234 --> 00:40:03,337
SceneKit编辑器

666
00:40:03,403 --> 00:40:06,507
移动相机 看具体…

667
00:40:06,940 --> 00:40:09,276
你的应用中发生了什么

668
00:40:12,045 --> 00:40:14,848
我们今年的新功能还有附加支持

669
00:40:14,915 --> 00:40:19,052
那么我们有一种新方式

670
00:40:19,419 --> 00:40:23,290
你可以看到有一种新方式

671
00:40:24,892 --> 00:40:27,528
我们添加了远景相机和自动绘图相机

672
00:40:27,594 --> 00:40:30,764
因此你可以更简单地检验你的场景

673
00:40:31,198 --> 00:40:34,368
你仍然可以获取全部常规相机

674
00:40:35,936 --> 00:40:40,007
我们还添加了新行为

675
00:40:40,073 --> 00:40:41,375
并使用轨迹球

676
00:40:41,441 --> 00:40:44,745
检验很大的场景变得更简单了

677
00:40:47,214 --> 00:40:50,517
我们还完全修订了着色器修改器编辑器

678
00:40:50,584 --> 00:40:55,189
那么现在你可以在一个屏幕上同时编辑

679
00:40:55,255 --> 00:40:56,690
你的着色器修改器以及你的素材了

680
00:40:56,757 --> 00:40:59,560
你不必来回选择对象

681
00:41:00,394 --> 00:41:02,329
这是一个全新的实施

682
00:41:02,396 --> 00:41:04,932
并且它支持自定义素材属性

683
00:41:04,998 --> 00:41:09,570
那么如果你的素材中

684
00:41:09,636 --> 00:41:13,273
你可以添加颜色、浮动或矢量

685
00:41:13,340 --> 00:41:16,977
以在你的着色器修改器中

686
00:41:17,211 --> 00:41:18,312
非常简单易用

687
00:41:19,746 --> 00:41:23,116
我们今年添加的许多功能都有附加支持

688
00:41:23,417 --> 00:41:27,221
首先是有一个新的位移素材slot

689
00:41:27,287 --> 00:41:29,790
你可以用于细化

690
00:41:30,757 --> 00:41:32,292
当然了 我们有细化

691
00:41:33,160 --> 00:41:35,229
新的约束也有附加支持

692
00:41:35,295 --> 00:41:39,800
那么你可以将它们添加到你的节点中

693
00:41:39,867 --> 00:41:41,702
然后在检验器中编辑它们

694
00:41:42,636 --> 00:41:46,473
我们有级联式阴影的支持

695
00:41:47,374 --> 00:41:51,111
我们还有一个新的程序化天空

696
00:41:51,178 --> 00:41:53,113
或照亮环境 比如说

697
00:41:53,180 --> 00:41:57,017
测试你的PBM素材

698
00:41:57,451 --> 00:42:00,954
并且它是完全可配置的

699
00:41:57,451 --> 00:42:00,954
并且它是完全可配置的

700
00:42:01,021 --> 00:42:01,922
比如说

701
00:42:03,423 --> 00:42:07,594
最后也是最重要的 我们添加了

702
00:42:07,661 --> 00:42:11,298
什么是引用节点？

703
00:42:11,431 --> 00:42:18,272
引用节点其实是指向一个

704
00:42:18,338 --> 00:42:21,008
但可在你的场景中多次使用

705
00:42:21,975 --> 00:42:26,246
直到现在 我们只能对两者

706
00:42:26,313 --> 00:42:28,582
对于全部节点 不只是两个节点

707
00:42:28,849 --> 00:42:32,619
但现在 你可以覆盖某些或全部素材

708
00:42:32,686 --> 00:42:35,656
你正在场景中使用的素材

709
00:42:35,722 --> 00:42:37,624
或全部素材的外观 比如说

710
00:42:38,659 --> 00:42:42,663
接下来我要把舞台交给Thomas

711
00:42:42,996 --> 00:42:45,232
（相关技术）

712
00:42:45,332 --> 00:42:46,266
谢谢

713
00:42:49,436 --> 00:42:54,174
好的 让我们谈谈相关技术

714
00:42:54,408 --> 00:42:56,176
那么你…是的

715
00:42:58,679 --> 00:43:03,550
那么你们已经

716
00:42:58,679 --> 00:43:03,550
那么你们已经

717
00:43:03,617 --> 00:43:05,152
以及国情咨文中针对ARKit的介绍

718
00:43:05,219 --> 00:43:10,390
你可能注意到ARKit

719
00:43:10,557 --> 00:43:15,395
ARSCNView为AR提供了一个

720
00:43:16,029 --> 00:43:20,634
事实上 ARSCNView

721
00:43:20,701 --> 00:43:24,705
意思是通过ARKit

722
00:43:24,805 --> 00:43:26,440
你可以获取场景图

723
00:43:26,507 --> 00:43:31,478
你可以添加后置处理、粒子系统、

724
00:43:31,545 --> 00:43:33,814
只要你想 你基本可以实现一切

725
00:43:34,615 --> 00:43:36,783
通过ARKit和SceneKit

726
00:43:36,850 --> 00:43:41,255
设置场景真的非常简单

727
00:43:41,321 --> 00:43:44,291
我想让你猜一下这个视频的拍摄地

728
00:43:44,358 --> 00:43:47,928
背景中有一条线索

729
00:43:49,062 --> 00:43:54,601
在这里要设施这样的一个场景

730
00:43:55,135 --> 00:43:59,673
就像你通常做的那样 并设置一个

731
00:43:59,873 --> 00:44:05,212
然后从ARSCNView委托中

732
00:43:59,873 --> 00:44:05,212
然后从ARSCNView委托中

733
00:44:05,279 --> 00:44:10,450
到ARKit所检测到的锚点上即可

734
00:44:11,451 --> 00:44:18,425
为了支持ARSCNView

735
00:44:18,559 --> 00:44:24,164
AVCaptureDevice和AVPlayer

736
00:44:24,898 --> 00:44:27,534
那么那意味着非常简单

737
00:44:27,601 --> 00:44:31,438
你就可以直接连接了

738
00:44:31,505 --> 00:44:36,210
或iPad直接在SceneKit的纹理

739
00:44:37,644 --> 00:44:38,512
是的

740
00:44:42,282 --> 00:44:45,919
现在我希望给你提供一些小技巧

741
00:44:45,986 --> 00:44:47,354
和阴影

742
00:44:47,421 --> 00:44:50,591
那么事实是你的对象

743
00:44:50,657 --> 00:44:55,762
如果你的对象在地面上投有阴影的话

744
00:44:57,197 --> 00:45:03,570
那么这个小技巧就是为了实现这种效果

745
00:44:57,197 --> 00:45:03,570
那么这个小技巧就是为了实现这种效果

746
00:45:03,637 --> 00:45:06,773
我们添加了平行光 投射了一些阴影

747
00:45:07,875 --> 00:45:11,011
然后我们添加了一个平面

748
00:45:11,078 --> 00:45:13,914
现在的目标是隐藏平面

749
00:45:13,981 --> 00:45:18,151
但我们不能就那样使平面藏起来

750
00:45:18,218 --> 00:45:20,687
否则阴影就会消失

751
00:45:21,355 --> 00:45:27,261
那么技巧就是配置平面

752
00:45:27,327 --> 00:45:32,599
这可以通过编程实现

753
00:45:32,666 --> 00:45:36,103
如果这样做平面将会消失

754
00:45:36,803 --> 00:45:39,940
但平面仍会写入深度缓冲器

755
00:45:40,240 --> 00:45:44,077
意思就是我不能配置

756
00:45:44,144 --> 00:45:49,316
以及从这前边移动到延迟的阴影

757
00:45:50,284 --> 00:45:54,855
现在阴影又回来了 因为延迟的阴影

758
00:45:54,922 --> 00:45:57,057
是整个屏幕的第二个步骤

759
00:45:57,491 --> 00:46:02,629
它会根据场景的深度缓存

760
00:45:57,491 --> 00:46:02,629
它会根据场景的深度缓存

761
00:46:02,696 --> 00:46:04,598
在图像上制造阴影

762
00:46:05,098 --> 00:46:08,435
那么对于延迟的阴影

763
00:46:08,502 --> 00:46:10,771
仍渲染到深度缓存中

764
00:46:12,105 --> 00:46:14,208
这是在ARKit中关于阴影的小技巧

765
00:46:14,274 --> 00:46:16,643
现在我想谈谈GamePlayKit

766
00:46:17,811 --> 00:46:22,416
GamePlayKit实体和组件现在

767
00:46:22,482 --> 00:46:25,786
典型用例就是当你想实施角色行为时

768
00:46:25,853 --> 00:46:29,256
这是我们在小狐狸2示例中对敌人做的

769
00:46:29,556 --> 00:46:34,094
在我们的示例中有一个GKScene

770
00:46:34,862 --> 00:46:37,965
并且我们实施了两个行为

771
00:46:38,465 --> 00:46:42,936
现在关键点在Xcode整合允许我们

772
00:46:43,003 --> 00:46:47,174
在Xcode中直接给敌人分配行为

773
00:46:47,541 --> 00:46:49,643
我们还可以使用Xcode检验器

774
00:46:49,710 --> 00:46:54,615
直接编辑我们行为的属性

775
00:46:56,617 --> 00:46:58,185
接下来Model I/O

776
00:46:59,286 --> 00:47:02,689
Model I/O改进了

777
00:46:59,286 --> 00:47:02,689
Model I/O改进了

778
00:47:02,756 --> 00:47:06,193
提示一下 USD指的是通用场景描述

779
00:47:06,260 --> 00:47:09,796
它是一个3D文件格式

780
00:47:11,365 --> 00:47:14,368
SceneKit和Model I/O

781
00:47:14,434 --> 00:47:17,938
且特别是对Metal I/O

782
00:47:18,005 --> 00:47:23,343
如果你想了解更多关于USD的信息

783
00:47:23,410 --> 00:47:27,648
也可以参加周五下午

784
00:47:27,714 --> 00:47:29,950
从艺术到引擎 Model I/O

785
00:47:31,685 --> 00:47:33,120
接下来是UIFocus

786
00:47:33,420 --> 00:47:38,192
UIFocus引擎是UIKit的

787
00:47:38,258 --> 00:47:43,463
选择对象并将其聚焦在你的Apple TV上

788
00:47:44,331 --> 00:47:51,338
现在SCN遵从UIFocusItem

789
00:47:51,405 --> 00:47:56,343
在你的场景中放哪个对象

790
00:47:57,110 --> 00:48:00,414
然后聚焦引擎将回调你并告诉你

791
00:47:57,110 --> 00:48:00,414
然后聚焦引擎将回调你并告诉你

792
00:48:00,480 --> 00:48:02,149
现在应该聚焦于哪个对象

793
00:48:02,216 --> 00:48:04,751
在响应Apple Siri Remote上

794
00:48:06,119 --> 00:48:08,455
然后由你决定你要采取哪些行动

795
00:48:08,522 --> 00:48:10,824
以及你想提供哪些视觉反馈

796
00:48:11,225 --> 00:48:12,960
简要地解释一下

797
00:48:13,594 --> 00:48:16,964
假如我把白色象棋配置为可聚焦

798
00:48:17,931 --> 00:48:22,102
SceneKit将自动计算

799
00:48:22,169 --> 00:48:24,137
并将其提供给聚焦引擎

800
00:48:25,005 --> 00:48:31,111
然后聚焦引擎会选择合适的对象

801
00:48:31,178 --> 00:48:33,413
根据遥控上的手势

802
00:48:34,648 --> 00:48:39,486
并且SceneKit会保持

803
00:48:39,553 --> 00:48:42,523
如果你移动对象或移动相机的话

804
00:48:43,423 --> 00:48:45,058
那么你要做的唯一一件事就是

805
00:48:45,125 --> 00:48:48,829
定义哪些对象是可聚焦的 仅此而已

806
00:48:54,468 --> 00:48:56,103
现在让我们来总结一下

807
00:48:56,170 --> 00:48:58,205
我想提一些渲染附件

808
00:48:58,272 --> 00:48:59,973
是我们添加到我们的渲染器中的

809
00:49:00,307 --> 00:49:03,810
第一个是对点云渲染的支持

810
00:49:04,611 --> 00:49:08,015
我们改善了我们的SCN几何体对象

811
00:49:08,081 --> 00:49:11,685
这将允许你配置点云的外观

812
00:49:12,452 --> 00:49:15,822
那么这些属性适用于是点云的几何体

813
00:49:15,889 --> 00:49:19,660
通过一堆点和一个原始类型点

814
00:49:20,160 --> 00:49:23,630
有了这些属性 你可以配置

815
00:49:23,697 --> 00:49:27,568
并且SceneKit将渲染你的点云

816
00:49:27,634 --> 00:49:29,536
给它们添加纹理和光照

817
00:49:29,603 --> 00:49:32,806
根据附属于你几何体的素材

818
00:49:35,909 --> 00:49:41,615
然后我们给我们的素材添加了两个

819
00:49:41,682 --> 00:49:46,887
双面对象或凹面对象半透明的问题

820
00:49:47,387 --> 00:49:49,857
那么如果你看一下左侧的对象

821
00:49:49,923 --> 00:49:54,194
你可以看到一个双面球体

822
00:49:54,261 --> 00:49:58,232
工件 因为多边形不是从后往前渲染的

823
00:49:58,799 --> 00:50:03,070
那么SceneKit将从后往前渲染

824
00:49:58,799 --> 00:50:03,070
那么SceneKit将从后往前渲染

825
00:50:03,136 --> 00:50:07,908
但它并不会处理几何体的单一多边形

826
00:50:08,475 --> 00:50:12,312
那么要解决这个问题

827
00:50:12,379 --> 00:50:17,317
那么第一个 单层

828
00:50:17,384 --> 00:50:20,787
在第二个步骤中只渲染最靠前的面

829
00:50:21,288 --> 00:50:22,990
那么这就修复了工件

830
00:50:23,056 --> 00:50:25,559
但正如你所看到的

831
00:50:25,626 --> 00:50:30,163
这个模式的一个典型用例就是

832
00:50:30,230 --> 00:50:32,599
并避免工件时

833
00:50:32,666 --> 00:50:36,837
由于在淡出时对多边形的覆盖

834
00:50:38,138 --> 00:50:39,806
那么第二个模式是双层

835
00:50:39,873 --> 00:50:42,409
双层也会以两个步骤渲染你的对象

836
00:50:42,476 --> 00:50:44,678
那么第一个步骤是渲染后面的面

837
00:50:44,745 --> 00:50:47,281
第二个步骤是渲染前面的面

838
00:50:47,347 --> 00:50:50,717
它允许我们正确地渲染这个双面球体

839
00:50:50,784 --> 00:50:55,255
还有小狐狸演示中的宝石

840
00:50:55,322 --> 00:50:58,358
Swift Playground Learn to Code课程

841
00:51:00,227 --> 00:51:01,528
最后一个添加

842
00:51:01,595 --> 00:51:04,364
是对级联式阴影图的支持

843
00:51:04,431 --> 00:51:08,202
那么级联式阴影图是阴影图的一个优化

844
00:51:08,268 --> 00:51:12,773
概念是它会把你的阴影图分成多个纹理

845
00:51:12,840 --> 00:51:18,412
或多个级联 以更准确地分配给

846
00:51:18,478 --> 00:51:22,115
更模糊地分配给距相机较远的区域

847
00:51:23,183 --> 00:51:27,087
要配置级联式阴影图 你只需要

848
00:51:27,154 --> 00:51:29,323
你可以配置级联的侧面

849
00:51:29,790 --> 00:51:34,695
然后你有一个参数

850
00:51:35,562 --> 00:51:40,567
你可以调整它以控制级联的分配

851
00:51:40,634 --> 00:51:42,970
根据距离视点的距离

852
00:51:43,704 --> 00:51:47,941
比如这是一个片段

853
00:51:48,375 --> 00:51:50,544
在我们的例子中 我们用了四个级联

854
00:51:50,611 --> 00:51:53,413
呈现为不同的色彩

855
00:51:54,448 --> 00:51:58,519
在这里我正在用拆分因素

856
00:51:58,585 --> 00:52:02,089
那么你可以了解这是如何

857
00:51:58,585 --> 00:52:02,089
那么你可以了解这是如何

858
00:52:02,155 --> 00:52:05,192
取决于距离视点的距离

859
00:52:05,926 --> 00:52:09,196
正如你所看到的

860
00:52:09,263 --> 00:52:12,032
那么它呈现了世界中较小的一个区域

861
00:52:12,099 --> 00:52:14,201
那么我们在这里有较高的精确度

862
00:52:14,601 --> 00:52:18,572
而后面的绿色级联式一片较大的区域

863
00:52:18,639 --> 00:52:21,508
那么我们对于绿色级联有较小的精确度

864
00:52:22,476 --> 00:52:27,548
请注意你可以

865
00:52:27,614 --> 00:52:29,883
在你自己的场景中

866
00:52:32,386 --> 00:52:33,620
好了 总结一下

867
00:52:34,454 --> 00:52:38,659
那么SceneKit的新版本

868
00:52:38,725 --> 00:52:40,594
用于简化相机控制

869
00:52:40,661 --> 00:52:44,131
通过一些新的很棒的效果

870
00:52:44,198 --> 00:52:46,066
和屏幕空间环境光遮蔽

871
00:52:47,401 --> 00:52:50,904
同时针对细化和细分

872
00:52:50,971 --> 00:52:52,439
一些新API

873
00:52:52,506 --> 00:52:56,376
对于动画和动画混合有更好的性能

874
00:52:57,244 --> 00:53:01,648
一些新的很棒的工具

875
00:52:57,244 --> 00:53:01,648
一些新的很棒的工具

876
00:53:01,715 --> 00:53:06,086
当然了 因为有ARKit

877
00:53:08,055 --> 00:53:11,091
要获取更多信息

878
00:53:11,225 --> 00:53:14,061
你可以从那里获取我们的示例代码

879
00:53:15,863 --> 00:53:17,631
一些相关演讲

880
00:53:19,833 --> 00:53:24,538
SceneKit整合了00图形技术

881
00:53:24,605 --> 00:53:27,574
如Metal、SpriteKit

882
00:53:29,343 --> 00:53:33,413
有一个演讲

883
00:53:33,480 --> 00:53:36,149
明天还有一场很棒的演讲

884
00:53:36,216 --> 00:53:40,187
时间是明天早上

885
00:53:40,554 --> 00:53:41,522
这就是全部内容了

886
00:53:41,989 --> 00:53:42,823
谢谢大家
