1
00:00:22,736 --> 00:00:23,106
&gt;&gt;  好的

2
00:00:25,106 --> 00:00:27,386
那么谢谢大家

3
00:00:27,546 --> 00:00:27,986
欢迎大家

4
00:00:28,066 --> 00:00:29,446
我叫 David Hayward

5
00:00:29,446 --> 00:00:30,736
特别开心今天能来

6
00:00:30,736 --> 00:00:32,046
为大家介绍我们为

7
00:00:32,046 --> 00:00:33,826
iOS macOS tvOS 上的

8
00:00:33,826 --> 00:00:35,556
Core Image 框架新添的

9
00:00:35,756 --> 00:00:37,786
出色特性和功能

10
00:00:39,926 --> 00:00:41,936
我们今天的内容很充实

11
00:00:42,036 --> 00:00:43,496
我会带大家简要回顾一下

12
00:00:43,496 --> 00:00:45,546
Core Image

13
00:00:45,546 --> 00:00:46,906
概括一下我们今年

14
00:00:46,906 --> 00:00:47,586
新加入的一些要点

15
00:00:48,376 --> 00:00:49,496
然后我们会用

16
00:00:49,496 --> 00:00:51,266
剩余时间深入了解

17
00:00:51,266 --> 00:00:53,286
所有新 API 和

18
00:00:53,496 --> 00:00:54,096
新特性的具体情况

19
00:00:54,986 --> 00:00:56,196
那么按照这个大纲

20
00:00:56,466 --> 00:00:57,086
让我们来进入正题

21
00:00:58,986 --> 00:01:00,336
先是对 Core Image 的

22
00:00:58,986 --> 00:01:00,336
先是对 Core Image 的

23
00:01:00,336 --> 00:01:00,666
简要回顾

24
00:01:01,546 --> 00:01:02,886
简单说 Core Image 框架

25
00:01:02,886 --> 00:01:03,966
提供一种简单易用的

26
00:01:03,966 --> 00:01:05,926
高性能 API 用来对图像

27
00:01:06,006 --> 00:01:06,986
进行滤镜处理

28
00:01:07,436 --> 00:01:09,026
这些图像可被用来

29
00:01:09,526 --> 00:01:10,906
调整颜色调整几何属性

30
00:01:10,906 --> 00:01:12,916
或者执行复杂的

31
00:01:12,996 --> 00:01:14,516
切割或卷积

32
00:01:16,116 --> 00:01:18,406
Core Image 会使用

33
00:01:18,546 --> 00:01:19,916
几种小技巧来实现

34
00:01:19,956 --> 00:01:21,876
这些操作的最佳效果

35
00:01:21,876 --> 00:01:24,696
因为这些滤镜可以组合

36
00:01:24,696 --> 00:01:25,966
要么是通过简单的叠加

37
00:01:25,966 --> 00:01:27,696
就像上面这个例子

38
00:01:27,696 --> 00:01:28,176
要么是复杂图形

39
00:01:28,716 --> 00:01:32,476
Core Image 为了出色效果

40
00:01:32,556 --> 00:01:34,106
使用的技巧之一

41
00:01:34,106 --> 00:01:36,186
就是支持自动平铺

42
00:01:36,416 --> 00:01:38,646
这让我们可以

43
00:01:38,646 --> 00:01:40,356
如果图像尺寸过大

44
00:01:40,356 --> 00:01:41,136
或者需要大量内存

45
00:01:41,136 --> 00:01:42,406
来渲染图像

46
00:01:42,406 --> 00:01:44,556
我们就可以降低

47
00:01:44,616 --> 00:01:44,976
相应的内存占用

48
00:01:48,846 --> 00:01:50,326
平铺功能的另一个特点

49
00:01:50,356 --> 00:01:51,976
意味着如果我们只需

50
00:01:51,976 --> 00:01:53,336
渲染图像的一部分

51
00:01:53,776 --> 00:01:54,996
这样做的效率会很高

52
00:01:54,996 --> 00:01:56,926
只需要加载我们需要的

53
00:01:56,926 --> 00:01:58,046
图像的相应部分

54
00:01:58,946 --> 00:02:00,216
以上这些出众的性能

55
00:01:58,946 --> 00:02:00,216
以上这些出众的性能

56
00:02:00,216 --> 00:02:01,506
大家都可以免费享受

57
00:02:01,506 --> 00:02:02,336
只需要使用 Core Image

58
00:02:02,896 --> 00:02:03,866
此外如果大家要在 Core Image 内

59
00:02:03,866 --> 00:02:06,286
编写自己的内核

60
00:02:06,286 --> 00:02:08,086
我们的语言扩展也能

61
00:02:08,086 --> 00:02:09,136
让大家以最低的难度

62
00:02:09,136 --> 00:02:10,455
免费实现

63
00:02:10,455 --> 00:02:12,146
这项功能

64
00:02:12,646 --> 00:02:15,976
还有一点也要记住

65
00:02:15,976 --> 00:02:17,136
Core Image 中的

66
00:02:17,136 --> 00:02:19,566
所有滤镜都基于

67
00:02:20,456 --> 00:02:21,546
一个或多个内核

68
00:02:21,546 --> 00:02:22,826
要么是内置内核

69
00:02:22,826 --> 00:02:23,326
要么是自定义内核

70
00:02:23,956 --> 00:02:25,166
Core Image 用来实现

71
00:02:25,166 --> 00:02:27,356
出色性能的另一个技巧

72
00:02:27,356 --> 00:02:29,656
就是将这些内核

73
00:02:29,686 --> 00:02:30,516
全部并置到程序中

74
00:02:30,916 --> 00:02:32,316
这能让 Core Image

75
00:02:32,356 --> 00:02:33,286
减少中间缓存的

76
00:02:33,286 --> 00:02:35,066
个数帮助我们

77
00:02:35,066 --> 00:02:36,526
降低对内存的要求

78
00:02:36,526 --> 00:02:37,966
同时提高图像质量

79
00:02:41,216 --> 00:02:42,426
基于以上介绍

80
00:02:42,426 --> 00:02:43,826
我要为大家简要

81
00:02:43,826 --> 00:02:45,106
讲解一下我们今年

82
00:02:45,106 --> 00:02:46,366
为 Core Image 添加的功能

83
00:02:46,626 --> 00:02:47,566
这些功能可以分为

84
00:02:47,566 --> 00:02:48,216
三大类别

85
00:02:48,626 --> 00:02:49,506
首先当然就是

86
00:02:49,506 --> 00:02:50,096
性能

87
00:02:50,146 --> 00:02:51,136
在任何时候这一点

88
00:02:51,136 --> 00:02:52,116
对于 Core Image 来说

89
00:02:52,116 --> 00:02:53,446
都十分重要我们也在

90
00:02:53,576 --> 00:02:55,756
这方面做了些加强

91
00:02:55,756 --> 00:02:57,086
让大家能够获得

92
00:02:57,086 --> 00:02:57,626
最佳的性能

93
00:02:58,196 --> 00:03:00,926
我要提到的

94
00:02:58,196 --> 00:03:00,926
我要提到的

95
00:03:00,926 --> 00:03:01,766
第二点也是我们

96
00:03:01,766 --> 00:03:04,146
今年花了很多时间

97
00:03:04,146 --> 00:03:06,976
来加强的 Core Image 特性

98
00:03:06,976 --> 00:03:08,026
好让各位开发者大家

99
00:03:08,026 --> 00:03:09,396
更好地获知 Core Image

100
00:03:09,396 --> 00:03:10,636
内部运行情况的信息

101
00:03:11,166 --> 00:03:13,086
我在前面几页中

102
00:03:13,086 --> 00:03:14,336
提到的我们所做的

103
00:03:14,336 --> 00:03:15,896
所有这些优化

104
00:03:15,896 --> 00:03:17,996
大家都可以看到

105
00:03:17,996 --> 00:03:18,306
我们是如何做到的

106
00:03:20,156 --> 00:03:21,676
第三点我们添加了

107
00:03:21,676 --> 00:03:23,186
许多功能这是为了

108
00:03:23,186 --> 00:03:24,686
能让大家的应用程序

109
00:03:24,856 --> 00:03:26,016
以最轻松的方式利用

110
00:03:26,016 --> 00:03:27,116
我们平台上的所有新特性

111
00:03:28,856 --> 00:03:30,386
那么再来更详细地

112
00:03:30,386 --> 00:03:30,616
解释一下这三点

113
00:03:30,616 --> 00:03:32,336
在性能方面

114
00:03:32,336 --> 00:03:33,856
Core Image 如今可让大家

115
00:03:33,966 --> 00:03:35,116
直接使用 Metal 编写 CI 内核

116
00:03:35,116 --> 00:03:38,086
我们还推出了一款新的 API

117
00:03:38,086 --> 00:03:39,696
能让大家更好地

118
00:03:39,696 --> 00:03:40,516
渲染目标 (destination)

119
00:03:40,596 --> 00:03:41,616
我们稍后再来

120
00:03:41,616 --> 00:03:42,886
具体讲解其中的

121
00:03:42,886 --> 00:03:43,566
更多细节

122
00:03:44,596 --> 00:03:46,856
信息方面

123
00:03:46,856 --> 00:03:48,086
我们推出了一款新的 API

124
00:03:48,086 --> 00:03:50,116
可让大家获知 Core Image

125
00:03:50,116 --> 00:03:51,196
处理给定渲染程序

126
00:03:51,196 --> 00:03:51,556
的相关信息

127
00:03:52,106 --> 00:03:53,556
此外我们还新增了

128
00:03:53,556 --> 00:03:54,956
对 Xcode Quick Look 的出色支持

129
00:03:54,956 --> 00:03:55,496
稍后会展示给大家看

130
00:03:56,866 --> 00:03:57,606
接下来是

131
00:03:57,606 --> 00:03:58,676
功能方面我们也

132
00:03:58,676 --> 00:03:59,676
新增了些出色的功能

133
00:03:59,676 --> 00:04:00,766
我们新增了一套

134
00:03:59,676 --> 00:04:00,766
我们新增了一套

135
00:04:00,816 --> 00:04:02,766
滤镜条形码支持

136
00:04:03,066 --> 00:04:05,746
还有对深度编辑的

137
00:04:05,746 --> 00:04:05,966
支持

138
00:04:06,606 --> 00:04:08,576
我想让大家回忆一下

139
00:04:08,576 --> 00:04:10,286
今天在前面的一个讲座里

140
00:04:10,426 --> 00:04:11,496
提到的支持深度的图像编辑

141
00:04:11,496 --> 00:04:12,886
如果有人错过了

142
00:04:12,886 --> 00:04:14,006
请务必回去看一看

143
00:04:14,006 --> 00:04:15,846
里面十分详尽地讲解了

144
00:04:15,846 --> 00:04:16,856
如何使用 Core Image

145
00:04:16,856 --> 00:04:16,976
来编辑深度

146
00:04:20,726 --> 00:04:22,116
现在让我再来

147
00:04:22,116 --> 00:04:23,306
更详尽地讲解一下

148
00:04:23,306 --> 00:04:24,476
我们此次添加的新滤镜

149
00:04:25,236 --> 00:04:27,686
现在我们总共有 196 种

150
00:04:27,686 --> 00:04:30,456
内置滤镜其中包括

151
00:04:30,456 --> 00:04:32,606
一些非常出色的

152
00:04:32,606 --> 00:04:33,196
新滤镜

153
00:04:33,626 --> 00:04:34,816
比如说其中有几种

154
00:04:34,816 --> 00:04:36,586
在你处理深度数据时

155
00:04:36,586 --> 00:04:37,256
会变得非常有用

156
00:04:37,736 --> 00:04:39,036
比如说我们为

157
00:04:39,036 --> 00:04:40,366
深度与视差之间的转换

158
00:04:40,366 --> 00:04:41,356
提供了一些实用滤镜

159
00:04:41,946 --> 00:04:43,366
我们也提供了

160
00:04:43,366 --> 00:04:44,966
形态学处理可让大家

161
00:04:45,306 --> 00:04:46,986
对图像进行腐蚀和膨胀处理

162
00:04:46,986 --> 00:04:48,936
这在操作深度掩码时

163
00:04:48,936 --> 00:04:49,606
非常有用

164
00:04:50,266 --> 00:04:52,116
我们还有一些实用滤镜

165
00:04:52,116 --> 00:04:53,376
可以让大家

166
00:04:53,376 --> 00:04:54,806
基于图像深度使用

167
00:04:54,806 --> 00:04:56,186
两种不同的色彩立方体

168
00:04:56,186 --> 00:04:56,526
来合成图像

169
00:04:58,036 --> 00:04:59,396
我还想让大家回忆一下

170
00:04:59,396 --> 00:05:00,706
我们早先提到的一个

171
00:04:59,396 --> 00:05:00,706
我们早先提到的一个

172
00:05:00,706 --> 00:05:01,876
很厉害的新滤镜

173
00:05:01,876 --> 00:05:03,166
是在图像编辑那场里

174
00:05:03,166 --> 00:05:04,846
叫作 CIDepthBlurEffect

175
00:05:04,846 --> 00:05:06,436
作用是让你能使用

176
00:05:06,436 --> 00:05:08,516
出色的深度模糊效果

177
00:05:08,566 --> 00:05:10,286
就像我们在相机照片

178
00:05:10,286 --> 00:05:11,176
应用中所用的那种

179
00:05:13,016 --> 00:05:14,976
再说一次我还是要

180
00:05:14,976 --> 00:05:16,836
强烈推荐大家去看看

181
00:05:16,836 --> 00:05:18,416
今天早些时候录制的

182
00:05:18,416 --> 00:05:19,696
图像编辑与深度讲座

183
00:05:21,336 --> 00:05:23,226
我们也根据收到的

184
00:05:23,226 --> 00:05:24,736
强烈要求加入了

185
00:05:24,736 --> 00:05:25,286
另外几种新滤镜

186
00:05:25,506 --> 00:05:26,826
有一个滤镜

187
00:05:26,826 --> 00:05:28,026
可让大家用文本

188
00:05:28,026 --> 00:05:29,016
生成图像很适合

189
00:05:29,016 --> 00:05:30,506
在给视频添加水印

190
00:05:30,506 --> 00:05:32,446
或其他文本覆层时

191
00:05:32,446 --> 00:05:32,906
使用

192
00:05:33,546 --> 00:05:34,886
还有一款滤镜

193
00:05:34,886 --> 00:05:36,136
可让大家在 LabDeltaE 空间内

194
00:05:36,136 --> 00:05:37,946
对比两幅图像很适合

195
00:05:38,006 --> 00:05:39,666
用来查看编辑结果

196
00:05:39,666 --> 00:05:41,146
是否符合预期

197
00:05:41,146 --> 00:05:42,486
或者让用户获取

198
00:05:42,486 --> 00:05:43,536
图像修改程度的信息

199
00:05:44,666 --> 00:05:47,576
我们也添加了新的

200
00:05:47,576 --> 00:05:49,216
双立方上采样下采样滤镜

201
00:05:49,646 --> 00:05:51,666
非常适合多种

202
00:05:51,666 --> 00:05:52,196
用途的使用

203
00:05:53,006 --> 00:05:54,126
我们还推出了一种

204
00:05:54,126 --> 00:05:55,306
新的条形码生成方法

205
00:05:55,306 --> 00:05:56,586
我会在稍后

206
00:05:56,586 --> 00:05:57,336
更加详细地讲解

207
00:05:59,416 --> 00:06:00,676
最后滤镜方面

208
00:05:59,416 --> 00:06:00,676
最后滤镜方面

209
00:06:00,676 --> 00:06:01,716
这次有一些滤镜

210
00:06:02,196 --> 00:06:03,376
相比上次发行

211
00:06:03,376 --> 00:06:03,696
做了一些改进

212
00:06:03,696 --> 00:06:04,756
这次有几款

213
00:06:04,876 --> 00:06:06,396
混合模式滤镜

214
00:06:06,836 --> 00:06:07,946
现在的效果更合乎期望

215
00:06:07,946 --> 00:06:10,166
我们还大幅提高了

216
00:06:10,346 --> 00:06:11,876
去马赛克滤镜和

217
00:06:11,876 --> 00:06:12,986
降噪滤镜的质量

218
00:06:12,986 --> 00:06:14,276
这些都隶属于 RAW 图像处理

219
00:06:14,686 --> 00:06:17,056
我们推出新的相机

220
00:06:17,056 --> 00:06:17,926
我们也将

221
00:06:17,926 --> 00:06:18,816
为新款相机提供支持

222
00:06:18,816 --> 00:06:19,976
届时大家将会看到这些改进

223
00:06:24,506 --> 00:06:26,446
新滤镜的情况就是这样

224
00:06:26,516 --> 00:06:28,836
现在我想请 Tony 上台

225
00:06:28,836 --> 00:06:29,976
他将为大家详细讲解

226
00:06:29,976 --> 00:06:32,156
如何直接使用 Metal

227
00:06:32,336 --> 00:06:33,456
来编写内核

228
00:06:33,456 --> 00:06:33,976
这也是个很棒的新特性

229
00:06:39,916 --> 00:06:40,246
&gt;&gt;  好的

230
00:06:40,246 --> 00:06:41,506
谢谢 David

231
00:06:42,036 --> 00:06:42,856
大家下午好

232
00:06:43,006 --> 00:06:44,446
我叫 Tony 真的很开心

233
00:06:44,446 --> 00:06:45,636
能来为大家讲解

234
00:06:45,636 --> 00:06:46,936
我们为 Core Image

235
00:06:46,936 --> 00:06:47,436
添加的新特性

236
00:06:48,036 --> 00:06:49,426
让我们直接进入正题

237
00:06:50,036 --> 00:06:51,176
首先让我们先来

238
00:06:51,176 --> 00:06:52,316
明确一下这个问题的语境

239
00:06:52,456 --> 00:06:54,006
如果这里指的是

240
00:06:54,006 --> 00:06:55,106
我们刚才看到过的

241
00:06:55,106 --> 00:06:55,556
这张简单滤镜的图表

242
00:06:55,556 --> 00:06:57,226
我们现在所讲的

243
00:06:57,226 --> 00:06:58,636
就是这些内核大家可以

244
00:06:58,636 --> 00:07:00,356
在底部这里看到

245
00:06:58,636 --> 00:07:00,356
在底部这里看到

246
00:07:00,356 --> 00:07:01,566
你可以用它来实现自己的

247
00:07:01,566 --> 00:07:03,116
自定义代码代码内容

248
00:07:03,116 --> 00:07:04,536
就是精确描述你想在

249
00:07:04,536 --> 00:07:06,006
GPU 上执行的像素处理方式

250
00:07:06,606 --> 00:07:09,546
在以前这些内核

251
00:07:09,546 --> 00:07:10,566
都是使用 CIKernel 语言

252
00:07:10,566 --> 00:07:12,496
编写这是一种

253
00:07:12,496 --> 00:07:14,946
基于 GLSL 的着色语言

254
00:07:14,946 --> 00:07:16,586
但它也提供一些扩展

255
00:07:16,906 --> 00:07:18,466
能让 Core Image 支持

256
00:07:18,466 --> 00:07:20,206
自动平铺和

257
00:07:20,206 --> 00:07:20,586
分区域渲染

258
00:07:22,046 --> 00:07:23,176
举个例子我们有一个函数

259
00:07:23,176 --> 00:07:24,286
叫作 destCoord

260
00:07:24,286 --> 00:07:25,456
能让你获得

261
00:07:25,526 --> 00:07:26,486
你准备渲染的

262
00:07:26,486 --> 00:07:28,066
目标坐标

263
00:07:28,066 --> 00:07:28,986
无论你是要渲染

264
00:07:28,986 --> 00:07:30,486
输出的一个区域

265
00:07:30,486 --> 00:07:31,566
还是要平铺输出图像

266
00:07:33,026 --> 00:07:34,276
我们还有两个函数

267
00:07:34,276 --> 00:07:34,866
分别叫作

268
00:07:34,866 --> 00:07:37,196
samplerTransform和sample

269
00:07:37,196 --> 00:07:38,346
能让你对输入图像

270
00:07:38,346 --> 00:07:40,036
进行采样无论

271
00:07:40,036 --> 00:07:41,066
输入图像是否经过平铺处理

272
00:07:41,536 --> 00:07:43,436
所以就像 David

273
00:07:43,436 --> 00:07:44,556
之前提过的这能为

274
00:07:44,556 --> 00:07:46,086
平铺操作提供妥善的抽象化

275
00:07:46,086 --> 00:07:46,926
让你在编写你的

276
00:07:46,926 --> 00:07:48,346
内核时不用为此烦心

277
00:07:50,696 --> 00:07:52,056
当这些内核

278
00:07:52,056 --> 00:07:53,006
编写完毕后它们会

279
00:07:53,006 --> 00:07:54,786
接着经过转译

280
00:07:54,786 --> 00:07:55,946
尽可能多地与其他内核

281
00:07:55,946 --> 00:07:57,476
并置在一起然后

282
00:07:57,476 --> 00:07:59,216
在运行时被编译成

283
00:07:59,216 --> 00:08:00,456
Metal 或者 GLSL

284
00:07:59,216 --> 00:08:00,456
Metal 或者 GLSL

285
00:08:01,686 --> 00:08:03,576
对于 Metal 这样的

286
00:08:03,576 --> 00:08:05,786
富语言编译阶段

287
00:08:05,786 --> 00:08:07,146
在运行时可能会

288
00:08:07,146 --> 00:08:07,576
耗费很长的一段时间

289
00:08:07,576 --> 00:08:09,356
事实上在最坏情景下

290
00:08:09,356 --> 00:08:10,446
如果你是要渲染

291
00:08:10,446 --> 00:08:12,086
一幅很小的输入图像...抱歉

292
00:08:12,086 --> 00:08:13,456
渲染一幅很小的图像

293
00:08:13,456 --> 00:08:14,546
或者相对简单的滤镜图表

294
00:08:14,546 --> 00:08:16,236
大部分的时间可能

295
00:08:16,236 --> 00:08:17,656
都会花在编译上

296
00:08:17,656 --> 00:08:18,776
而非实际的渲染上

297
00:08:19,386 --> 00:08:21,646
为了给大家看个例子

298
00:08:21,646 --> 00:08:23,786
这里有个案例

299
00:08:23,786 --> 00:08:25,206
是在任何编译结果被写入

300
00:08:25,206 --> 00:08:26,606
cache 前的第一次渲染时

301
00:08:27,146 --> 00:08:28,116
大家可以看到有大量时间

302
00:08:28,116 --> 00:08:29,376
都花费在编译

303
00:08:29,376 --> 00:08:29,796
而非渲染上

304
00:08:29,946 --> 00:08:31,606
所以如果我们逐句

305
00:08:32,155 --> 00:08:33,706
调试下这些步骤第一步

306
00:08:33,706 --> 00:08:35,126
是翻译这里蓝色显示的

307
00:08:35,126 --> 00:08:35,996
CIKernel

308
00:08:36,535 --> 00:08:37,476
第二个步骤是

309
00:08:37,476 --> 00:08:38,726
并置这些 CIKernel

310
00:08:39,035 --> 00:08:40,796
接下来这一步里

311
00:08:40,796 --> 00:08:42,346
我们要把 CIKernel

312
00:08:42,346 --> 00:08:43,616
编译成中间表示

313
00:08:43,756 --> 00:08:45,046
这个过程是

314
00:08:45,046 --> 00:08:45,416
独立于设备类型的

315
00:08:45,486 --> 00:08:47,026
然后是最后一步

316
00:08:47,026 --> 00:08:50,956
要把中间表示编译成

317
00:08:50,956 --> 00:08:53,386
GPU 代码以便在

318
00:08:53,386 --> 00:08:53,906
GPU 上执行

319
00:08:55,216 --> 00:08:56,646
这里的问题在于

320
00:08:56,646 --> 00:08:59,246
CIKernel 的并置

321
00:08:59,246 --> 00:09:00,276
原本是在运行时

322
00:08:59,246 --> 00:09:00,276
原本是在运行时

323
00:09:00,276 --> 00:09:04,366
动态完成的如果我们

324
00:09:04,366 --> 00:09:06,166
把这个过程放到编译后

325
00:09:06,166 --> 00:09:07,936
再来完成会是什么结果呢

326
00:09:08,876 --> 00:09:10,686
结果就是让我们能够

327
00:09:10,686 --> 00:09:12,076
将成本非常高的

328
00:09:12,076 --> 00:09:14,196
编译过程提到构建时完成

329
00:09:14,196 --> 00:09:15,676
最后只留下那些

330
00:09:15,676 --> 00:09:17,136
需要在运行时

331
00:09:17,486 --> 00:09:18,176
完成的部分

332
00:09:18,806 --> 00:09:20,166
大家可以看到

333
00:09:20,166 --> 00:09:21,666
这样做对 CPU 的

334
00:09:21,666 --> 00:09:23,876
利用要高效很多不用说

335
00:09:23,876 --> 00:09:24,426
耗电量也会减少

336
00:09:24,996 --> 00:09:27,216
所以我要很高兴地告诉大家

337
00:09:27,216 --> 00:09:29,256
Core Image 现在也能这么做了

338
00:09:29,256 --> 00:09:30,536
只要直接使用 Metal

339
00:09:30,536 --> 00:09:31,416
编写 CIKernel 就好

340
00:09:31,916 --> 00:09:34,146
为了实现这一点需要我们

341
00:09:34,146 --> 00:09:35,496
与 Metal 框架的开发团队

342
00:09:35,496 --> 00:09:36,656
和 Metal 编译器的开发团队

343
00:09:36,656 --> 00:09:37,866
展开十分密切的

344
00:09:37,866 --> 00:09:38,026
合作

345
00:09:38,026 --> 00:09:39,386
我们认为这样做

346
00:09:39,386 --> 00:09:40,696
将会打开新的大门

347
00:09:40,696 --> 00:09:41,716
迎来令人兴奋的新机遇

348
00:09:43,326 --> 00:09:44,256
首先我要特别讲几个

349
00:09:44,256 --> 00:09:45,546
大家现在已经感受到的

350
00:09:45,546 --> 00:09:47,176
主要优点

351
00:09:48,276 --> 00:09:51,056
就像之前看到的

352
00:09:51,056 --> 00:09:52,466
CIKernel 现在已支持

353
00:09:52,466 --> 00:09:54,526
在构建时进行离线预编译

354
00:09:54,666 --> 00:09:55,956
有了这项功能

355
00:09:55,956 --> 00:09:57,056
你就能很方便地

356
00:09:57,056 --> 00:09:57,836
进行出错诊断

357
00:09:58,156 --> 00:09:59,266
如果你在编写内核时

358
00:09:59,266 --> 00:10:00,376
拼错了单词或者出了什么错

359
00:09:59,266 --> 00:10:00,376
拼错了单词或者出了什么错

360
00:10:00,376 --> 00:10:01,816
都能直接在 Xcode 中看到

361
00:10:02,236 --> 00:10:03,636
而不必等到运行时

362
00:10:03,636 --> 00:10:05,336
才检测出问题

363
00:10:06,316 --> 00:10:08,236
第二点则是添加了

364
00:10:08,236 --> 00:10:09,596
更多的现代语言支持

365
00:10:09,596 --> 00:10:11,456
因为 Metal 就是一种

366
00:10:11,456 --> 00:10:12,796
近几年才问世的

367
00:10:12,796 --> 00:10:13,766
基于 C++ 的语言

368
00:10:13,836 --> 00:10:17,536
我还想强调一点

369
00:10:17,736 --> 00:10:19,106
用 Metal 编写 CIKernel 时

370
00:10:19,316 --> 00:10:20,976
大家照样能够享受

371
00:10:20,976 --> 00:10:22,496
并置平铺这些优点

372
00:10:22,596 --> 00:10:23,646
这也是多年来

373
00:10:23,646 --> 00:10:24,836
我们为 Core Image 框架

374
00:10:24,836 --> 00:10:25,246
做出的重大突破

375
00:10:25,586 --> 00:10:26,776
所以改用现在的

376
00:10:26,776 --> 00:10:28,356
新方法编写 CIKernel

377
00:10:28,356 --> 00:10:28,606
不会带来任何损失

378
00:10:29,166 --> 00:10:31,346
另外这些用 Metal

379
00:10:31,346 --> 00:10:33,796
写成的新 CIKernel

380
00:10:33,796 --> 00:10:34,756
也可以与旧版的

381
00:10:34,756 --> 00:10:35,386
CIKernel 一起混用

382
00:10:35,686 --> 00:10:37,496
所以在今后的图像中

383
00:10:37,496 --> 00:10:39,656
既可以包含旧版的内核

384
00:10:39,656 --> 00:10:40,616
也可以包含 Metal 写成的内核

385
00:10:40,876 --> 00:10:42,466
这能让这项新特性

386
00:10:42,766 --> 00:10:45,436
与大家现有的应用程序

387
00:10:45,566 --> 00:10:46,766
实现最大兼容

388
00:10:47,336 --> 00:10:50,036
大家可能也希望

389
00:10:50,196 --> 00:10:51,316
这项特性能够得到

390
00:10:51,316 --> 00:10:52,896
各类平台的广泛支持也就是

391
00:10:52,896 --> 00:10:56,066
支持 A8 或更新版本的 iOS

392
00:10:56,066 --> 00:10:59,506
还有 macOS 和 tvOS

393
00:10:59,686 --> 00:11:01,136
现在我们来看一下

394
00:10:59,686 --> 00:11:01,136
现在我们来看一下

395
00:11:01,136 --> 00:11:02,516
到底要如何用 Metal

396
00:11:02,516 --> 00:11:03,136
创建这些 CIKernel

397
00:11:03,656 --> 00:11:05,886
第一步就是用 Metal 着色文件

398
00:11:05,886 --> 00:11:07,466
来编写你的 CIKernel

399
00:11:09,316 --> 00:11:11,366
接着在你完成这个 CIKernel 的

400
00:11:11,366 --> 00:11:12,946
实现后第二步就是

401
00:11:12,976 --> 00:11:14,236
编译和链接 Metal 着色文件

402
00:11:14,236 --> 00:11:16,296
以便生成相应的 Metal 库

403
00:11:16,296 --> 00:11:17,616
可在运行时

404
00:11:17,616 --> 00:11:18,656
进行加载

405
00:11:19,236 --> 00:11:21,696
接着最后一步就是

406
00:11:22,266 --> 00:11:23,996
用 Metal 库内的任何函数

407
00:11:23,996 --> 00:11:25,066
对 CIKernel 进行

408
00:11:25,066 --> 00:11:25,446
初始化

409
00:11:25,446 --> 00:11:28,926
那么我们来具体地

410
00:11:28,926 --> 00:11:29,916
看下第一步

411
00:11:29,916 --> 00:11:32,466
用 Metal 编写 CIKernel

412
00:11:33,216 --> 00:11:34,286
对于这项任务我要向

413
00:11:34,286 --> 00:11:35,266
大家介绍我们新推出的

414
00:11:35,266 --> 00:11:36,586
CIKernal Metal 库

415
00:11:37,086 --> 00:11:38,346
它基本上就是一个

416
00:11:38,346 --> 00:11:40,046
头文件包含我们为

417
00:11:40,046 --> 00:11:41,806
Metal 着色语言添加的

418
00:11:41,806 --> 00:11:42,616
CIKernel 扩展

419
00:11:42,936 --> 00:11:44,876
换句话说我们加入了一些

420
00:11:44,876 --> 00:11:47,536
新的数据类型比如目标 (destination)

421
00:11:47,636 --> 00:11:48,906
采样器 (sampler) 样本 (sample)

422
00:11:49,536 --> 00:11:51,216
目标类型可让你获得

423
00:11:51,216 --> 00:11:52,386
你需要的有关输出的

424
00:11:52,706 --> 00:11:54,506
所有信息

425
00:11:55,046 --> 00:11:56,506
采样器类型可让你获得

426
00:11:56,506 --> 00:11:57,846
有关输入图像的

427
00:11:57,846 --> 00:11:58,556
所有信息

428
00:11:59,136 --> 00:12:00,916
样本类型则用来表示

429
00:11:59,136 --> 00:12:00,916
样本类型则用来表示

430
00:12:00,916 --> 00:12:02,866
输入图像中的某个

431
00:12:02,866 --> 00:12:03,476
单色样本

432
00:12:04,766 --> 00:12:05,856
除了这些数据类型外

433
00:12:05,856 --> 00:12:07,136
我们也添加了一些

434
00:12:07,136 --> 00:12:08,336
实用函数非常方便

435
00:12:08,336 --> 00:12:09,256
图像处理使用

436
00:12:10,666 --> 00:12:11,776
比如说你可以进行

437
00:12:11,776 --> 00:12:13,846
预乘 (premulitply) 去预乘 (unpremultiply)

438
00:12:13,926 --> 00:12:14,986
还可以进行不同

439
00:12:14,986 --> 00:12:16,316
色彩空间之间的

440
00:12:16,466 --> 00:12:17,196
一些色彩转换

441
00:12:17,616 --> 00:12:19,816
所以这些新扩展的

442
00:12:20,196 --> 00:12:21,366
语义与它们用在

443
00:12:21,366 --> 00:12:22,586
CIKernel 语言中的时候

444
00:12:22,586 --> 00:12:23,056
是一样的

445
00:12:23,536 --> 00:12:25,686
只是在涉及目标和

446
00:12:25,876 --> 00:12:27,496
采样器类型时稍微存在

447
00:12:27,496 --> 00:12:29,116
一点语法上的差异

448
00:12:29,836 --> 00:12:30,566
让我来给大家

449
00:12:30,566 --> 00:12:31,346
看个更具体的例子

450
00:12:32,096 --> 00:12:34,426
这里有一小段代码

451
00:12:34,556 --> 00:12:35,786
我们的 CIKernel Metal 库

452
00:12:35,786 --> 00:12:35,976
看起来就是这样

453
00:12:36,596 --> 00:12:38,706
库的名字是 CIKernelMetalLib.h

454
00:12:39,276 --> 00:12:40,686
我们所有的扩展

455
00:12:40,806 --> 00:12:42,316
都在 CoreImage 这个

456
00:12:42,316 --> 00:12:43,906
命名空间中加以声明

457
00:12:43,906 --> 00:12:44,746
以免与 Metal 发生冲突

458
00:12:45,326 --> 00:12:47,386
这里的第一步就是

459
00:12:47,386 --> 00:12:48,796
定义一个目标

460
00:12:48,916 --> 00:12:50,196
它包含一个函数

461
00:12:50,196 --> 00:12:51,456
可让你用来读取

462
00:12:51,456 --> 00:12:52,106
目标的坐标

463
00:12:53,076 --> 00:12:54,126
在以前使用 CIKernel 语言

464
00:12:54,176 --> 00:12:55,676
编写 CIKernel 内核的时候

465
00:12:55,676 --> 00:12:57,776
只能通过一个叫作

466
00:12:57,776 --> 00:12:59,496
destCoord 的全局函数

467
00:12:59,496 --> 00:13:00,276
来完成

468
00:12:59,496 --> 00:13:00,276
来完成

469
00:13:00,606 --> 00:13:01,346
而现在使用 Metal 语言

470
00:13:01,346 --> 00:13:02,926
编写内核的话

471
00:13:02,926 --> 00:13:04,616
只需要将这个数据类型

472
00:13:04,616 --> 00:13:05,646
声明为内核的实参

473
00:13:05,646 --> 00:13:06,506
就能访问这个方法

474
00:13:07,046 --> 00:13:09,396
接下来要定义的

475
00:13:09,396 --> 00:13:10,636
第二种数据类型是 sampler

476
00:13:11,136 --> 00:13:12,226
它所包含的方法就是以前

477
00:13:12,226 --> 00:13:13,866
那些同名的全局函数

478
00:13:13,866 --> 00:13:15,326
但它们现在被定义成了

479
00:13:15,326 --> 00:13:17,326
sampler 类型的

480
00:13:17,326 --> 00:13:18,656
成员函数

481
00:13:19,226 --> 00:13:22,436
为了更好地概括

482
00:13:22,436 --> 00:13:23,986
这些函数这里有个表格

483
00:13:23,986 --> 00:13:25,496
能让大家看到过去在

484
00:13:25,496 --> 00:13:28,166
CIKernel 语言里使用的语法

485
00:13:28,166 --> 00:13:29,796
和如今在 Metal 里

486
00:13:29,796 --> 00:13:30,996
使用的语法

487
00:13:31,596 --> 00:13:32,416
大家还可以看到

488
00:13:32,416 --> 00:13:34,446
在 CIKernel 语言中所有函数

489
00:13:34,446 --> 00:13:35,636
全用全球函数的方式来实现

490
00:13:35,756 --> 00:13:37,176
而现在在 Metal 中它们

491
00:13:37,176 --> 00:13:38,616
全都会被定义为相应

492
00:13:38,616 --> 00:13:39,466
数据类型的成员函数

493
00:13:40,046 --> 00:13:40,886
所以我们认为

494
00:13:40,886 --> 00:13:41,846
这种新语法将能让

495
00:13:41,846 --> 00:13:43,326
大家把代码写得

496
00:13:43,476 --> 00:13:44,816
更简明更易读

497
00:13:46,766 --> 00:13:47,996
出于可移植性的考虑

498
00:13:47,996 --> 00:13:49,546
我们也在头文件中

499
00:13:49,546 --> 00:13:51,336
包含了 sampler 的全局函数

500
00:13:51,336 --> 00:13:52,886
实质上就是把新语法

501
00:13:52,886 --> 00:13:53,506
封装了一下

502
00:13:53,586 --> 00:13:54,746
这样一来就能让大家

503
00:13:54,746 --> 00:13:55,856
只需要修改最少的代码

504
00:13:55,856 --> 00:13:57,016
就能将已有的内核

505
00:13:57,016 --> 00:13:58,326
导入到 Metal 中

506
00:13:58,926 --> 00:14:01,786
现在我们来看几个用 Metal

507
00:13:58,926 --> 00:14:01,786
现在我们来看几个用 Metal

508
00:14:01,786 --> 00:14:03,226
编写的 CIKernel 例子

509
00:14:03,316 --> 00:14:04,896
我们看到的第一个例子

510
00:14:04,966 --> 00:14:06,456
是一个 warp 内核

511
00:14:06,626 --> 00:14:08,456
在编写任何 Metal 着色器时

512
00:14:08,456 --> 00:14:09,156
需要引入的第一个库

513
00:14:09,156 --> 00:14:10,756
就是 metal_stdlib

514
00:14:10,756 --> 00:14:12,776
而在编写 CIKernel 时

515
00:14:12,776 --> 00:14:14,266
还需要引入我们的 Metal

516
00:14:14,266 --> 00:14:15,896
内核库具体方法

517
00:14:15,896 --> 00:14:17,046
就是引入一个综合头文件

518
00:14:17,096 --> 00:14:20,166
CoreImage.h 接下来

519
00:14:20,406 --> 00:14:22,686
第二步是在

520
00:14:22,686 --> 00:14:25,076
Extern “C" 这个部分中

521
00:14:25,076 --> 00:14:29,226
实现你要的所有内核它的作用

522
00:14:29,226 --> 00:14:30,276
是让这些内核可以在运行时

523
00:14:30,276 --> 00:14:31,886
通过名称来访问

524
00:14:32,956 --> 00:14:35,326
这里写的是一个简单的内核

525
00:14:35,326 --> 00:14:36,396
叫作 myWarp

526
00:14:36,616 --> 00:14:37,966
它只需要一个实参

527
00:14:37,966 --> 00:14:39,606
数据类型为 destination

528
00:14:40,086 --> 00:14:41,246
根据这个实参

529
00:14:41,246 --> 00:14:42,436
你便可以获取

530
00:14:42,436 --> 00:14:43,936
有待执行渲染

531
00:14:43,936 --> 00:14:45,206
和实现你想看到的

532
00:14:45,206 --> 00:14:46,346
各种几何变换的

533
00:14:46,346 --> 00:14:46,496
相应坐标

534
00:14:46,756 --> 00:14:47,906
然后返回执行的结果

535
00:14:47,906 --> 00:14:50,036
作为对比

536
00:14:50,166 --> 00:14:51,456
这里也有一个同样的

537
00:14:51,456 --> 00:14:52,586
warp 内核不过是用

538
00:14:52,586 --> 00:14:53,546
CIKernel 语言实现的

539
00:14:54,126 --> 00:14:56,276
大家可以看到这两段代码

540
00:14:56,276 --> 00:14:58,166
几乎完全相同只有一些

541
00:14:58,526 --> 00:14:59,506
细微的语法差异

542
00:14:59,896 --> 00:15:00,886
但它们的语义是

543
00:14:59,896 --> 00:15:00,886
但它们的语义是

544
00:15:00,886 --> 00:15:02,306
完全相同的到最后

545
00:15:02,306 --> 00:15:04,156
也都会被编译成一模一样的

546
00:15:04,746 --> 00:15:04,846
一段 GPU 代码

547
00:15:06,036 --> 00:15:07,586
第二个例子是个

548
00:15:07,586 --> 00:15:08,246
color 内核

549
00:15:08,696 --> 00:15:09,926
它的大部分代码

550
00:15:09,926 --> 00:15:11,376
看上去都差不多

551
00:15:11,376 --> 00:15:12,396
唯一的区别就是换成了

552
00:15:12,396 --> 00:15:14,616
一个叫作 myColor 的内核

553
00:15:14,616 --> 00:15:16,066
它的输入只需要一个

554
00:15:16,066 --> 00:15:16,436
sample 类型的实参

555
00:15:16,546 --> 00:15:18,406
根据这个实参你可以应用

556
00:15:18,406 --> 00:15:19,836
你想要看到的

557
00:15:19,836 --> 00:15:21,286
各种色彩变换最后

558
00:15:21,286 --> 00:15:22,076
同样是返回执行结果

559
00:15:23,616 --> 00:15:25,336
那么这里同样是

560
00:15:25,336 --> 00:15:26,636
用 CIKernel 语言实现的

561
00:15:26,696 --> 00:15:27,686
同一个 color 内核

562
00:15:28,226 --> 00:15:31,146
我想给大家看的

563
00:15:31,146 --> 00:15:32,916
最后一个例子是个通用内核

564
00:15:33,466 --> 00:15:35,026
可以在你的内核既不能用

565
00:15:35,026 --> 00:15:36,286
warp 内核也不能用 color 内核

566
00:15:36,286 --> 00:15:37,246
实现的时候使用

567
00:15:37,936 --> 00:15:39,096
所以这里有这样一个内核

568
00:15:39,096 --> 00:15:39,906
叫作 myKernel

569
00:15:39,906 --> 00:15:41,756
它只需要一个输入参数

570
00:15:42,046 --> 00:15:44,006
数据类型是 sampler

571
00:15:44,006 --> 00:15:44,996
根据这个参数你就可以对

572
00:15:44,996 --> 00:15:46,516
输入图像的任意部位采样

573
00:15:46,516 --> 00:15:48,176
根据你的需要获取

574
00:15:48,176 --> 00:15:48,696
足够数量的样本

575
00:15:49,256 --> 00:15:50,016
同样在这里

576
00:15:50,016 --> 00:15:51,306
执行一些操作

577
00:15:51,306 --> 00:15:51,776
返回执行结果

578
00:15:52,946 --> 00:15:54,256
同样这个是

579
00:15:54,296 --> 00:15:56,686
用以前的 CIKernal 语言

580
00:15:56,686 --> 00:15:57,636
写成的同一个 CIKernal 内核

581
00:15:58,226 --> 00:16:01,776
现在你已经在 Metal 着色文件中

582
00:15:58,226 --> 00:16:01,776
现在你已经在 Metal 着色文件中

583
00:16:01,776 --> 00:16:02,736
完成了 CIKernal 的实现

584
00:16:02,736 --> 00:16:04,306
下一步就是

585
00:16:04,306 --> 00:16:05,556
编译和链接 Metal

586
00:16:05,556 --> 00:16:05,876
着色文件

587
00:16:07,856 --> 00:16:08,726
对于有过 Metal 着色器

588
00:16:08,726 --> 00:16:10,076
编写经验的人来说

589
00:16:10,076 --> 00:16:11,416
这套构建管道看起来

590
00:16:11,416 --> 00:16:13,296
应该十分眼熟

591
00:16:13,726 --> 00:16:14,776
基本上它分为

592
00:16:14,776 --> 00:16:15,206
两个阶段

593
00:16:15,536 --> 00:16:17,646
第一个阶段是

594
00:16:17,646 --> 00:16:20,086
将.metal 编译成.air 文件

595
00:16:20,086 --> 00:16:21,796
第二个阶段是

596
00:16:21,796 --> 00:16:23,446
链接.air 文件然后把它

597
00:16:23,446 --> 00:16:24,486
打包在.metallib 文件里

598
00:16:25,946 --> 00:16:27,506
处理 CIKernel 时只需要

599
00:16:27,506 --> 00:16:29,086
在这里多做一件事

600
00:16:29,086 --> 00:16:30,256
就是设定几个新的选项

601
00:16:31,306 --> 00:16:32,626
第一个需要设定的选项

602
00:16:32,626 --> 00:16:33,926
是针对编译器的

603
00:16:34,116 --> 00:16:35,746
叫作-fcikernel

604
00:16:35,776 --> 00:16:38,346
第二个选项是

605
00:16:38,346 --> 00:16:39,796
针对链接器的

606
00:16:40,366 --> 00:16:40,946
叫作-cikernel

607
00:16:40,946 --> 00:16:42,496
注意这个选项

608
00:16:42,496 --> 00:16:42,876
就是少了个 f

609
00:16:43,736 --> 00:16:44,946
你可以直接在 Xcode 里

610
00:16:44,986 --> 00:16:47,446
完成这一步让我用

611
00:16:47,446 --> 00:16:48,836
一段小视频给大家演示一下

612
00:16:48,836 --> 00:16:50,086
这个步骤是如何

613
00:16:50,086 --> 00:16:50,346
完成的

614
00:16:51,536 --> 00:16:53,876
对于编译器选项

615
00:16:53,876 --> 00:16:54,886
只需要查看 Metal 编译器的

616
00:16:54,886 --> 00:16:56,386
Build Options 然后直接在

617
00:16:56,386 --> 00:16:59,656
Other Metal Compiler Flags 中

618
00:16:59,656 --> 00:17:00,976
写明-fcikernel 即可

619
00:16:59,656 --> 00:17:00,976
写明-fcikernel 即可

620
00:17:01,556 --> 00:17:03,346
由于链接器选项没有

621
00:17:03,346 --> 00:17:05,326
这种界面来进行相关设置

622
00:17:05,326 --> 00:17:06,246
必须使用

623
00:17:06,246 --> 00:17:07,336
Add User-Defined Setting

624
00:17:08,036 --> 00:17:09,726
然后为它设置一个键

625
00:17:09,776 --> 00:17:12,576
命名为 MTLLINKER_FLAGS

626
00:17:12,576 --> 00:17:15,086
然后将对应的值

627
00:17:15,086 --> 00:17:16,955
设定为 -cikernel

628
00:17:17,036 --> 00:17:19,096
你只需要为你的项目

629
00:17:19,096 --> 00:17:20,126
设置一次

630
00:17:20,126 --> 00:17:21,306
之后你在这里处理的

631
00:17:21,306 --> 00:17:22,536
所有的 Metal 着色器都会

632
00:17:22,756 --> 00:17:23,906
自动使用这些选项

633
00:17:23,906 --> 00:17:24,506
进行编译

634
00:17:25,156 --> 00:17:27,226
但如果你更喜欢使用

635
00:17:27,306 --> 00:17:28,256
或者自定义脚本来处理

636
00:17:28,256 --> 00:17:30,196
同样可以调用这两个

637
00:17:30,226 --> 00:17:32,696
编译器和链接器工具

638
00:17:32,796 --> 00:17:32,956
就像这样

639
00:17:36,496 --> 00:17:38,216
那么最后一步大概也是

640
00:17:38,216 --> 00:17:40,246
最简单的一步就是使用

641
00:17:40,326 --> 00:17:42,166
Metal 库中的给定函数

642
00:17:42,166 --> 00:17:43,036
对 CIKernel 进行初始化

643
00:17:43,596 --> 00:17:46,046
为此我们为 CIKernel 类

644
00:17:46,046 --> 00:17:47,876
加入了新的 API

645
00:17:48,006 --> 00:17:50,416
可以让你使用通过函数名

646
00:17:50,416 --> 00:17:51,906
调用的给定函数以及

647
00:17:51,906 --> 00:17:53,876
可在运行时予以

648
00:17:53,876 --> 00:17:55,306
加载的 Metal 库

649
00:17:55,526 --> 00:17:56,536
来初始化 CIKernel

650
00:17:57,046 --> 00:17:58,156
这个 API 还有一个变种

651
00:17:58,156 --> 00:17:59,826
能让你为你的内核

652
00:17:59,826 --> 00:18:01,696
指定一种

653
00:17:59,826 --> 00:18:01,696
指定一种

654
00:18:01,696 --> 00:18:02,146
输出像素格式

655
00:18:02,206 --> 00:18:04,146
如果你的内核只是要

656
00:18:04,176 --> 00:18:05,566
输出一些单一阴影数据

657
00:18:05,566 --> 00:18:07,296
你完全可以为内核

658
00:18:07,296 --> 00:18:08,916
指定一种单一阴影格式

659
00:18:09,646 --> 00:18:13,166
这里有个例子来演示

660
00:18:13,166 --> 00:18:14,356
CIKernel 的初始化

661
00:18:14,806 --> 00:18:15,786
总共只需要

662
00:18:15,786 --> 00:18:16,406
这么三行代码

663
00:18:17,396 --> 00:18:19,356
前两行用来

664
00:18:19,356 --> 00:18:21,706
加载库如果是

665
00:18:21,706 --> 00:18:22,736
在 Xcode 内构建的

666
00:18:22,736 --> 00:18:23,776
会默认调用

667
00:18:23,776 --> 00:18:24,646
default.metallib

668
00:18:24,816 --> 00:18:26,796
而在完成数据加载后

669
00:18:26,796 --> 00:18:28,116
便可以用这个库中的

670
00:18:28,116 --> 00:18:30,566
给定函数名来

671
00:18:30,566 --> 00:18:31,516
初始化 CIKernel 了

672
00:18:33,336 --> 00:18:35,096
同样 warp 和 color 内核

673
00:18:35,096 --> 00:18:36,756
可以用同样的 API

674
00:18:36,756 --> 00:18:38,066
来完成初始化

675
00:18:39,746 --> 00:18:40,816
在完成内核初始化后

676
00:18:41,146 --> 00:18:42,466
你就可以用自己喜欢的方式

677
00:18:42,466 --> 00:18:43,886
应用这个内核生成

678
00:18:43,886 --> 00:18:45,156
你想要的滤镜图像

679
00:18:46,246 --> 00:18:47,136
以上就是使用 Metal

680
00:18:47,136 --> 00:18:49,326
编写 CIKernel 的所有内容

681
00:18:49,326 --> 00:18:50,186
我们认为这会为开发者

682
00:18:50,186 --> 00:18:51,226
新建出很好的工作流

683
00:18:51,226 --> 00:18:53,876
很期待大家能利用这些

684
00:18:54,396 --> 00:18:55,496
新性能做出一些

685
00:18:55,496 --> 00:18:56,376
令人惊艳的

686
00:18:56,376 --> 00:18:57,036
产品来

687
00:18:59,296 --> 00:18:59,906
好的

688
00:19:00,176 --> 00:19:01,346
那么下一个主题

689
00:19:01,346 --> 00:19:03,496
我想讲讲我们用来

690
00:19:03,496 --> 00:19:05,106
渲染目标的一种

691
00:19:05,106 --> 00:19:05,786
新的 API

692
00:19:06,456 --> 00:19:10,016
这款新 API 应用在我们

693
00:19:10,286 --> 00:19:11,676
支持的所有 destination 类型时

694
00:19:11,846 --> 00:19:12,876
都能给出一致统一的

695
00:19:12,876 --> 00:19:13,336
表现

696
00:19:13,856 --> 00:19:15,776
它的名字叫 IOSurfaces

697
00:19:15,776 --> 00:19:17,306
目前是 iOS 上的一款公共 API

698
00:19:18,226 --> 00:19:19,906
我们还支持渲染至

699
00:19:19,906 --> 00:19:21,976
CVPixelBuffer 以及 Metal 和

700
00:19:21,976 --> 00:19:22,926
OpenGL 纹理

701
00:19:23,896 --> 00:19:25,066
甚至是内存中的

702
00:19:25,066 --> 00:19:26,176
某些原始位图数据

703
00:19:26,736 --> 00:19:29,136
这款 API 时首先让你

704
00:19:29,136 --> 00:19:30,256
注意到的一点是

705
00:19:30,676 --> 00:19:32,386
如今它在检测到

706
00:19:32,386 --> 00:19:33,616
渲染失败时会立即返回

707
00:19:33,616 --> 00:19:35,136
并且回复给你

708
00:19:35,136 --> 00:19:36,626
一条出错消息表明

709
00:19:36,626 --> 00:19:37,006
失败原因

710
00:19:37,496 --> 00:19:39,156
所以现在你可以通过程序

711
00:19:39,156 --> 00:19:40,236
检测应用中的此类问题

712
00:19:40,236 --> 00:19:41,916
并在检测到出错时

713
00:19:42,196 --> 00:19:43,386
有所准备地失败

714
00:19:43,906 --> 00:19:47,706
凭借这款 API 你还可以设定

715
00:19:47,766 --> 00:19:49,376
destination 对象的一些

716
00:19:49,376 --> 00:19:51,426
常见属性例如行为是

717
00:19:51,426 --> 00:19:52,776
alpha 模式还是 clamping 模式

718
00:19:52,776 --> 00:19:54,736
甚至可以是你想要用来

719
00:19:54,776 --> 00:19:55,656
渲染输出的

720
00:19:55,656 --> 00:19:56,246
色彩空间

721
00:19:57,266 --> 00:19:58,936
以前在使用旧式的

722
00:19:58,936 --> 00:20:00,756
API 时 alpha 模式和

723
00:19:58,936 --> 00:20:00,756
API 时 alpha 模式和

724
00:20:00,756 --> 00:20:02,126
clamping 模式

725
00:20:02,126 --> 00:20:03,686
都是通过隐晦的方式设定

726
00:20:03,686 --> 00:20:05,076
基于目标所用的格式

727
00:20:05,626 --> 00:20:06,866
而如今你完全可以

728
00:20:06,866 --> 00:20:08,526
明确地使用你想要的

729
00:20:08,526 --> 00:20:09,586
行为进行重写

730
00:20:11,986 --> 00:20:12,956
除了这些常见属性外

731
00:20:12,956 --> 00:20:14,226
我们还添加了几种

732
00:20:14,226 --> 00:20:15,416
新的高级属性

733
00:20:15,466 --> 00:20:16,976
可供你设置目标时使用

734
00:20:17,036 --> 00:20:18,016
例如抖动 (dithering) 和混合 (blending)

735
00:20:18,736 --> 00:20:19,866
举个例子如果你有一个

736
00:20:19,866 --> 00:20:22,126
8位的输出缓冲区

737
00:20:22,126 --> 00:20:23,476
并且打算用来渲染

738
00:20:23,476 --> 00:20:25,176
那你只需要开启抖动

739
00:20:25,336 --> 00:20:26,586
来获得某种感知范围

740
00:20:26,586 --> 00:20:28,426
更广的色彩深度以便减少

741
00:20:28,426 --> 00:20:30,806
可能会在图像

742
00:20:30,806 --> 00:20:31,866
局部区域出现的

743
00:20:31,866 --> 00:20:32,336
一些色带瑕疵

744
00:20:32,866 --> 00:20:36,546
这些属性有一点

745
00:20:36,546 --> 00:20:38,226
很不错就是

746
00:20:38,336 --> 00:20:40,016
能够有效地降低

747
00:20:40,016 --> 00:20:41,766
被迫创建多个

748
00:20:41,766 --> 00:20:42,546
CIContext 的需要

749
00:20:42,546 --> 00:20:44,746
这是因为这些属性中

750
00:20:44,746 --> 00:20:46,546
有的原本是 CIContext 的

751
00:20:46,546 --> 00:20:47,456
附属属性

752
00:20:47,456 --> 00:20:48,566
所以当你需要

753
00:20:48,566 --> 00:20:49,676
配置多个不同的

754
00:20:49,676 --> 00:20:51,356
目标时就必须

755
00:20:51,356 --> 00:20:52,946
为每个目标单独

756
00:20:52,946 --> 00:20:53,486
创建一个 CIContext

757
00:20:54,096 --> 00:20:55,346
如今这些属性全都

758
00:20:55,346 --> 00:20:57,716
很好地剥离了出来

759
00:20:57,716 --> 00:20:58,966
在大部分时候你都可以

760
00:20:58,966 --> 00:21:00,876
只用一个 CIContext 就能

761
00:20:58,966 --> 00:21:00,876
只用一个 CIContext 就能

762
00:21:00,876 --> 00:21:02,336
渲染出多个不同的目标

763
00:21:03,836 --> 00:21:06,096
这款 API 不光提供了

764
00:21:06,166 --> 00:21:07,396
前面提到的所有

765
00:21:07,396 --> 00:21:09,206
这些功能还可以用它

766
00:21:09,206 --> 00:21:11,376
实现一些

767
00:21:11,616 --> 00:21:13,296
特别出色的

768
00:21:13,296 --> 00:21:13,686
性能增强

769
00:21:14,946 --> 00:21:16,866
比如说我们的 CIContext API

770
00:21:16,976 --> 00:21:18,816
在用来渲染到 IOSurface 或者

771
00:21:18,816 --> 00:21:19,726
CVPixelBuffer 时

772
00:21:20,426 --> 00:21:22,486
以前它们会在 GPU

773
00:21:22,486 --> 00:21:24,656
完成所有的渲染工作后

774
00:21:24,736 --> 00:21:25,286
再返回执行结果

775
00:21:26,236 --> 00:21:28,866
但现在使用新的 API

776
00:21:28,866 --> 00:21:30,746
会在 CPU 将 GPU 的这些工作

777
00:21:30,746 --> 00:21:32,016
指令全部发送完毕后

778
00:21:32,016 --> 00:21:33,026
就立即返回结果

779
00:21:33,556 --> 00:21:34,886
再也不用等到

780
00:21:34,886 --> 00:21:36,026
GPU 结束所有工作后了

781
00:21:37,166 --> 00:21:38,666
所以我们认为这种新增的

782
00:21:38,666 --> 00:21:40,406
灵活性能让大家

783
00:21:40,466 --> 00:21:42,136
更加高效地安排

784
00:21:42,136 --> 00:21:42,786
CPU 和 GPU 的所有工作

785
00:21:44,116 --> 00:21:45,646
现在让我来给

786
00:21:46,346 --> 00:21:46,906
大家看个使用实例

787
00:21:47,736 --> 00:21:49,266
这里是一个简单的

788
00:21:49,266 --> 00:21:52,236
渲染子程序目的是

789
00:21:52,236 --> 00:21:53,866
清理出一个目标面

790
00:21:53,866 --> 00:21:55,986
然后在背景图像上层

791
00:21:55,986 --> 00:21:57,206
渲染出前景图像

792
00:21:58,326 --> 00:21:59,856
我们要做的第一件事

793
00:21:59,856 --> 00:22:01,936
就是初始化一个 ioSurface 给定的

794
00:21:59,856 --> 00:22:01,936
就是初始化一个 ioSurface 给定的

795
00:22:01,936 --> 00:22:03,816
CIRenderDestination 对象

796
00:22:04,406 --> 00:22:07,076
然后我们想要的第一个结果

797
00:22:07,496 --> 00:22:09,866
则是获取一个 CIContext

798
00:22:09,866 --> 00:22:11,426
启动渲染任务

799
00:22:11,426 --> 00:22:12,086
清理目标

800
00:22:13,606 --> 00:22:15,466
但在等候这项任务

801
00:22:15,466 --> 00:22:16,786
实际完成前我们就可以

802
00:22:16,786 --> 00:22:18,756
先启动另一项任务

803
00:22:18,756 --> 00:22:19,506
在目标处渲染

804
00:22:19,506 --> 00:22:19,966
背景图像

805
00:22:23,176 --> 00:22:24,806
然后在我们启动

806
00:22:24,806 --> 00:22:26,136
最后一项任务之前我们可以

807
00:22:26,136 --> 00:22:27,776
为目标对象设定一个混合内核

808
00:22:27,776 --> 00:22:29,866
可以从我们提供的 37 个内置的

809
00:22:29,866 --> 00:22:32,086
混合内核中任选一个

810
00:22:32,606 --> 00:22:33,786
在这个例子里我们选了一个

811
00:22:33,786 --> 00:22:34,686
sourceOver 混合内核

812
00:22:35,196 --> 00:22:37,176
但你还可以使用最新的

813
00:22:37,176 --> 00:22:39,066
CIBlendKernel API 创建

814
00:22:39,066 --> 00:22:40,616
一个自定义的混合内核

815
00:22:40,616 --> 00:22:44,376
那么我们要的混合内核

816
00:22:44,526 --> 00:22:47,476
也有了现在让我们来

817
00:22:47,476 --> 00:22:49,056
调用 CIContext 启动最后的

818
00:22:49,056 --> 00:22:50,346
渲染任务在目标处

819
00:22:50,346 --> 00:22:52,086
已有的任何结果

820
00:22:52,406 --> 00:22:53,566
上层叠加渲染

821
00:22:53,566 --> 00:22:54,216
前景图像

822
00:22:54,936 --> 00:22:56,276
只有这个时候你才需要

823
00:22:56,276 --> 00:22:58,456
调用 waitUntilCompleted

824
00:22:58,456 --> 00:23:00,446
用它来获取 CPU 上的

825
00:22:58,456 --> 00:23:00,446
用它来获取 CPU 上的

826
00:23:00,446 --> 00:23:01,066
内容

827
00:23:01,706 --> 00:23:03,506
所以通过这种新设计

828
00:23:03,506 --> 00:23:05,266
能将获取结果的延迟时间

829
00:23:05,266 --> 00:23:06,856
缩到最短还不用

830
00:23:06,856 --> 00:23:08,746
执行任何不必要的

831
00:23:08,746 --> 00:23:09,956
GPU 同步指令

832
00:23:13,456 --> 00:23:14,696
我要给大家看的

833
00:23:14,856 --> 00:23:16,716
第二个用例会特别

834
00:23:17,256 --> 00:23:18,656
演示一下性能方面的

835
00:23:18,656 --> 00:23:21,066
细微优势但这点优势

836
00:23:21,066 --> 00:23:22,046
却能为你的应用程序

837
00:23:22,046 --> 00:23:22,586
带来巨大影响

838
00:23:22,636 --> 00:23:23,966
那就是渲染到

839
00:23:23,966 --> 00:23:24,906
Metal 可绘制纹理

840
00:23:25,156 --> 00:23:27,356
这做起来很简单只要

841
00:23:27,356 --> 00:23:29,746
获取一个 currentDrawable

842
00:23:29,746 --> 00:23:30,536
就行比如说

843
00:23:30,616 --> 00:23:30,966
从 Metal 视图中获取

844
00:23:31,226 --> 00:23:32,776
接下来便可使用

845
00:23:32,776 --> 00:23:34,806
可绘制视图中的纹理

846
00:23:35,196 --> 00:23:36,346
完成一 个CIRenderDestination 的

847
00:23:36,346 --> 00:23:36,786
初始化

848
00:23:36,786 --> 00:23:40,556
这段程序就能达成我们的目的

849
00:23:40,626 --> 00:23:41,876
但如果你是在每帧渲染循环中

850
00:23:41,876 --> 00:23:44,476
执行这样的任务却有可能

851
00:23:44,866 --> 00:23:46,066
遇到性能上的瓶颈

852
00:23:46,066 --> 00:23:47,236
而表面上可能

853
00:23:47,236 --> 00:23:48,026
并不明显

854
00:23:48,376 --> 00:23:51,036
让我用一个时间轴图示

855
00:23:51,686 --> 00:23:52,896
来更加详细地

856
00:23:52,896 --> 00:23:54,436
描述解释一下

857
00:23:54,436 --> 00:23:54,706
这个情况

858
00:23:55,646 --> 00:23:56,786
还请大家耐心听

859
00:23:56,786 --> 00:23:58,316
因为这里面会涉及到

860
00:23:58,316 --> 00:23:58,676
非常多的步骤

861
00:23:59,376 --> 00:24:01,606
我们在这条时间轴上

862
00:23:59,376 --> 00:24:01,606
我们在这条时间轴上

863
00:24:01,606 --> 00:24:03,296
追踪两个对象上面是

864
00:24:03,296 --> 00:24:04,736
CPU 下面是 GPU

865
00:24:05,506 --> 00:24:06,466
严格来说这个过程里

866
00:24:06,466 --> 00:24:07,346
其实还存在一个第三方

867
00:24:07,346 --> 00:24:08,406
也就是显示

868
00:24:08,406 --> 00:24:10,436
但为了简明起见

869
00:24:10,686 --> 00:24:11,696
姑且把它当作是

870
00:24:11,696 --> 00:24:12,096
GPU 的一部分

871
00:24:12,756 --> 00:24:14,746
那么在第一帧里

872
00:24:14,746 --> 00:24:16,496
你的应用会试图从

873
00:24:16,496 --> 00:24:17,046
视图中获取一个可绘制对象

874
00:24:17,576 --> 00:24:19,926
根据这个对象又可以

875
00:24:19,926 --> 00:24:22,386
获取一种纹理然后启动

876
00:24:22,386 --> 00:24:24,736
渲染该纹理的

877
00:24:24,906 --> 00:24:25,386
任务

878
00:24:26,796 --> 00:24:28,566
在 CI 收到调用命令后

879
00:24:28,566 --> 00:24:29,656
我们就要开始对

880
00:24:29,656 --> 00:24:32,336
完成 GPU 任务所用的

881
00:24:32,336 --> 00:24:33,576
CPU 命令进行编码

882
00:24:34,286 --> 00:24:35,616
单以这个例子来说

883
00:24:35,616 --> 00:24:37,576
我们描画的是一个滤镜图表

884
00:24:37,576 --> 00:24:38,866
实际上由多次滤镜处理

885
00:24:38,866 --> 00:24:40,126
组成分别是两次

886
00:24:40,126 --> 00:24:41,866
中间处理和一次

887
00:24:41,866 --> 00:24:43,506
最终处理

888
00:24:44,756 --> 00:24:45,796
当 Core Image 完成所有任务的

889
00:24:45,796 --> 00:24:47,236
编码工作后对 startTask 的

890
00:24:47,236 --> 00:24:48,326
调用便会返回执行结果

891
00:24:48,756 --> 00:24:50,876
从这个时点开始

892
00:24:50,876 --> 00:24:52,446
GPU 会很高兴地将

893
00:24:52,446 --> 00:24:53,816
待执行任务安排在

894
00:24:53,816 --> 00:24:55,966
适当的时间段内

895
00:24:56,176 --> 00:24:58,756
但是如果 GPU 的任务

896
00:24:58,756 --> 00:25:01,026
需要很长的时间才能完成

897
00:24:58,756 --> 00:25:01,026
需要很长的时间才能完成

898
00:25:01,026 --> 00:25:02,946
你的应用可能会在上述任务

899
00:25:02,946 --> 00:25:05,666
完成前就接到调用去渲染

900
00:25:05,666 --> 00:25:06,036
另一帧

901
00:25:06,906 --> 00:25:08,136
此时如果你试图获取

902
00:25:08,136 --> 00:25:10,596
一个可绘制对象相应的

903
00:25:10,596 --> 00:25:12,746
调用命令将会暂停直到它

904
00:25:12,746 --> 00:25:14,166
可以被提供给你的应用时

905
00:25:14,166 --> 00:25:14,816
才会执行

906
00:25:15,066 --> 00:25:18,096
这个时候你才能

907
00:25:18,096 --> 00:25:19,756
从它那里获取纹理

908
00:25:19,756 --> 00:25:21,796
启动另一项任务去开始渲染

909
00:25:22,586 --> 00:25:24,176
后续的所有帧也会

910
00:25:24,176 --> 00:25:24,506
重复同一过程

911
00:25:24,506 --> 00:25:27,096
所大家所见

912
00:25:27,096 --> 00:25:28,496
这个过程对 CPU 和 GPU 的

913
00:25:28,496 --> 00:25:29,996
利用效率并不高

914
00:25:29,996 --> 00:25:31,436
两个处理器都存在着

915
00:25:31,436 --> 00:25:32,206
大量的闲置时间

916
00:25:32,776 --> 00:25:35,286
但如果你仔细看下这部分

917
00:25:35,286 --> 00:25:37,676
我们要渲染的可绘制纹理

918
00:25:37,676 --> 00:25:39,456
实际上在最后一步的

919
00:25:39,456 --> 00:25:41,336
渲染处理之前

920
00:25:41,336 --> 00:25:41,956
是用不到的

921
00:25:43,016 --> 00:25:44,276
那我们来看看

922
00:25:44,276 --> 00:25:45,816
可以如何改进这个情况

923
00:25:48,716 --> 00:25:49,646
使用我们最新的

924
00:25:49,646 --> 00:25:52,346
CIRenderDestination API

925
00:25:52,346 --> 00:25:54,416
在初始化的时候

926
00:25:54,416 --> 00:25:56,936
不必使用纹理本身

927
00:25:56,936 --> 00:25:58,306
而是纹理的所有属性

928
00:25:58,536 --> 00:26:00,716
比如纹理的宽高

929
00:25:58,536 --> 00:26:00,716
比如纹理的宽高

930
00:26:00,716 --> 00:26:02,156
像素格式

931
00:26:02,676 --> 00:26:04,666
然后可以通过回调

932
00:26:04,666 --> 00:26:06,626
提供该纹理而且会

933
00:26:06,626 --> 00:26:08,496
等到最后的最后

934
00:26:08,496 --> 00:26:10,196
确实要用到该纹理的时候

935
00:26:10,196 --> 00:26:11,726
才会真正调用

936
00:26:12,356 --> 00:26:15,216
于是现在你就能立刻

937
00:26:15,216 --> 00:26:17,126
完成目标对象的初始化

938
00:26:17,126 --> 00:26:18,506
可以提前很多时间来

939
00:26:18,506 --> 00:26:20,496
启动任务和执行渲染

940
00:26:20,496 --> 00:26:22,006
这也会有效地推迟

941
00:26:22,136 --> 00:26:23,316
那个可能造成妨碍的

942
00:26:23,316 --> 00:26:24,866
currentDrawable 调用让它在

943
00:26:24,866 --> 00:26:25,506
更靠后的时点发生

944
00:26:25,546 --> 00:26:28,306
我们仔细看一下

945
00:26:28,306 --> 00:26:32,096
这个例子它能把CPU

946
00:26:32,096 --> 00:26:33,706
和 GPU 的任务安排得

947
00:26:33,706 --> 00:26:34,346
更加高效

948
00:26:35,476 --> 00:26:36,806
所以如果你要渲染 Metal

949
00:26:36,806 --> 00:26:38,386
可绘制纹理我们强烈

950
00:26:38,386 --> 00:26:39,696
建议你使用这款

951
00:26:39,696 --> 00:26:39,876
新出的 API

952
00:26:39,876 --> 00:26:41,726
因为它能极大地

953
00:26:41,726 --> 00:26:43,056
提高你的应用的

954
00:26:43,056 --> 00:26:43,586
帧率

955
00:26:44,116 --> 00:26:45,336
事实上我们看到过

956
00:26:45,336 --> 00:26:46,616
一些案例在运用了

957
00:26:46,616 --> 00:26:48,426
这项技巧后帧率真的

958
00:26:48,426 --> 00:26:48,996
提高了一倍

959
00:26:48,996 --> 00:26:49,626
好的

960
00:26:51,856 --> 00:26:55,676
现在我要把讲台

961
00:26:55,676 --> 00:26:57,126
交回给 David 他会为大家

962
00:26:57,126 --> 00:26:58,426
讲解一些特别精彩的内容

963
00:26:58,426 --> 00:26:59,866
让大家一窥 Core Image 框架的

964
00:26:59,866 --> 00:27:00,586
个中奥妙

965
00:26:59,866 --> 00:27:00,586
个中奥妙

966
00:27:00,796 --> 00:27:00,976
谢谢大家

967
00:27:06,456 --> 00:27:07,396
&gt;&gt; 谢谢 Tony

968
00:27:07,396 --> 00:27:08,206
讲得很棒

969
00:27:09,376 --> 00:27:10,146
就像我在介绍的部分中

970
00:27:10,146 --> 00:27:11,876
提到的 Core Image 运用了

971
00:27:11,876 --> 00:27:13,286
很多漂亮的技巧用来

972
00:27:13,286 --> 00:27:14,456
实现最佳的性能表现

973
00:27:14,986 --> 00:27:16,286
我们今年的一大目标

974
00:27:16,286 --> 00:27:17,576
就是让各位开发者大家

975
00:27:17,576 --> 00:27:19,376
更清晰地了解这些技巧

976
00:27:19,376 --> 00:27:20,616
是如何发挥作用的好让大家

977
00:27:20,616 --> 00:27:22,686
更好地理解应该

978
00:27:22,686 --> 00:27:23,716
如何高效地使用

979
00:27:23,716 --> 00:27:24,256
Core Image

980
00:27:25,546 --> 00:27:27,076
在这方面我们采用了

981
00:27:27,076 --> 00:27:27,876
两种有意思的方式

982
00:27:28,216 --> 00:27:29,766
一种是利用我们新出的 API

983
00:27:29,866 --> 00:27:30,776
我们设计了一些新方法

984
00:27:30,776 --> 00:27:32,606
来返回你的

985
00:27:32,646 --> 00:27:33,076
渲染器信息

986
00:27:34,216 --> 00:27:36,046
在你对渲染器发出

987
00:27:36,046 --> 00:27:37,976
任务指令后现在你可以...

988
00:27:37,976 --> 00:27:39,026
在你等到任务完成后

989
00:27:39,026 --> 00:27:40,266
该任务便会返回一个

990
00:27:40,266 --> 00:27:42,476
CIRenderInfo 对象

991
00:27:42,856 --> 00:27:44,346
这个对象又会为你

992
00:27:44,346 --> 00:27:45,276
返回一个附带少量

993
00:27:45,276 --> 00:27:46,866
属性的对象包括

994
00:27:46,866 --> 00:27:48,396
Core Image 执行这个

995
00:27:48,616 --> 00:27:50,056
渲染命令所需用到的

996
00:27:50,186 --> 00:27:50,576
处理次数

997
00:27:50,916 --> 00:27:52,236
以及在设备上

998
00:27:52,236 --> 00:27:54,016
执行内核所耗费的

999
00:27:54,016 --> 00:27:55,706
总时间还有处理到的

1000
00:27:55,706 --> 00:27:57,086
像素总数

1001
00:27:57,426 --> 00:27:58,936
所以你可以从

1002
00:27:58,936 --> 00:28:00,076
我们返回的信息中

1003
00:27:58,936 --> 00:28:00,076
我们返回的信息中

1004
00:28:00,246 --> 00:28:01,536
获得十分丰富的信息

1005
00:28:02,766 --> 00:28:04,766
但也许更厉害的

1006
00:28:05,066 --> 00:28:06,716
还是一些好用的新版本

1007
00:28:06,716 --> 00:28:07,986
我们现在可以让

1008
00:28:07,986 --> 00:28:09,446
Core Image 在 Xcode 中

1009
00:28:09,506 --> 00:28:09,896
提供更出色的 Quick Looks

1010
00:28:11,856 --> 00:28:14,636
特别是我们现在为 CIImage

1011
00:28:14,766 --> 00:28:16,566
提供了很棒的 Quick Look 支持

1012
00:28:16,836 --> 00:28:17,946
除了显示像素外

1013
00:28:17,986 --> 00:28:19,216
我们现在还能显示你在

1014
00:28:19,246 --> 00:28:20,606
生成图像的过程中

1015
00:28:20,606 --> 00:28:21,536
构建的图像图表

1016
00:28:22,686 --> 00:28:23,766
如果你对一个 CIRenderTask

1017
00:28:23,766 --> 00:28:26,416
执行 Quick Look 结果会显示出

1018
00:28:26,416 --> 00:28:28,036
Core Image 对你的图像图表

1019
00:28:28,196 --> 00:28:29,626
进行优化处理后的图表

1020
00:28:30,516 --> 00:28:31,886
此外如果你正在等候

1021
00:28:31,886 --> 00:28:33,486
渲染器信息的返回结果

1022
00:28:33,486 --> 00:28:34,496
此时对该进程执行 Quick Look 的话

1023
00:28:34,776 --> 00:28:35,936
结果将会显示

1024
00:28:35,936 --> 00:28:37,536
Core Image 内部发生的

1025
00:28:37,536 --> 00:28:38,766
所有并置时间点以及

1026
00:28:38,766 --> 00:28:39,686
缓存信息

1027
00:28:40,056 --> 00:28:41,616
为了帮助大家理解

1028
00:28:41,616 --> 00:28:42,426
让我们来用一种非常

1029
00:28:42,426 --> 00:28:43,036
直观的方式为大家说明

1030
00:28:43,466 --> 00:28:44,206
这里有一段代码

1031
00:28:44,266 --> 00:28:45,476
假装我们正在 Xcode 的

1032
00:28:45,476 --> 00:28:46,366
环境中逐步调试这段代码

1033
00:28:47,116 --> 00:28:49,456
这是一个例子

1034
00:28:49,456 --> 00:28:50,116
内容是我们准备构建的

1035
00:28:50,116 --> 00:28:50,706
图像图表

1036
00:28:51,026 --> 00:28:52,106
在这个例子里我们

1037
00:28:52,106 --> 00:28:54,456
在创建一个 CIImage

1038
00:28:54,456 --> 00:28:55,236
所用参数一个是 url

1039
00:28:55,236 --> 00:28:57,346
一个是我们为

1040
00:28:57,346 --> 00:28:57,516
该图像指定的新选项

1041
00:28:57,696 --> 00:29:01,286
kCIApplyImageOrientationProperty

1042
00:28:57,696 --> 00:29:01,286
kCIApplyImageOrientationProperty

1043
00:29:02,256 --> 00:29:03,686
且赋值为真

1044
00:29:03,896 --> 00:29:05,266
这段的作用是

1045
00:29:05,266 --> 00:29:06,596
让图像在你面前

1046
00:29:06,596 --> 00:29:08,656
自动直立起来这能

1047
00:29:08,656 --> 00:29:09,176
带来很多便利

1048
00:29:10,066 --> 00:29:11,056
接下来我们会看到的

1049
00:29:11,056 --> 00:29:12,216
是要为这个图像

1050
00:29:12,216 --> 00:29:13,226
另外增加一个

1051
00:29:13,226 --> 00:29:14,616
仿射变换将图像

1052
00:29:14,616 --> 00:29:16,896
缩小为五分之一

1053
00:29:16,896 --> 00:29:18,606
假设我们现在是在 Xcode 环境下

1054
00:29:18,606 --> 00:29:20,186
将我们的鼠标悬停在图像对象上

1055
00:29:20,576 --> 00:29:22,346
此时如果你点击这个

1056
00:29:22,346 --> 00:29:24,516
小小的眼睛图标它会显示出

1057
00:29:24,516 --> 00:29:25,336
一幅这样的图像

1058
00:29:25,746 --> 00:29:27,046
这幅图像不仅让你看到了

1059
00:29:27,046 --> 00:29:28,116
生成图像的观看效果

1060
00:29:28,116 --> 00:29:29,486
图像清晰直立端正

1061
00:29:29,486 --> 00:29:31,426
还能让你在它下方看到

1062
00:29:31,426 --> 00:29:32,806
这幅图像生成过程的图表

1063
00:29:33,246 --> 00:29:35,346
如果把镜头拉近我们可以

1064
00:29:35,346 --> 00:29:36,086
看到各种有意思的

1065
00:29:36,086 --> 00:29:36,716
信息

1066
00:29:37,266 --> 00:29:39,426
可以看到在图像图表的

1067
00:29:39,426 --> 00:29:41,036
输入端是我们的

1068
00:29:41,036 --> 00:29:41,846
IOSurface

1069
00:29:41,976 --> 00:29:43,536
仔细看一下会得知

1070
00:29:43,536 --> 00:29:44,726
它是一幅 YCC 图像

1071
00:29:44,726 --> 00:29:45,706
这说明它大概出自一个

1072
00:29:45,706 --> 00:29:47,666
JPEG 文件还可以看到

1073
00:29:48,606 --> 00:29:51,366
这个面的尺寸而且

1074
00:29:51,366 --> 00:29:51,876
是不透明的

1075
00:29:52,476 --> 00:29:54,986
然后可以在图表接下来

1076
00:29:54,986 --> 00:29:56,586
往上的第二步中看到

1077
00:29:56,586 --> 00:29:57,846
色彩匹配的操作

1078
00:29:57,846 --> 00:29:59,066
这让我们能够

1079
00:29:59,066 --> 00:29:59,996
自动确定输入图像的

1080
00:30:00,226 --> 00:30:01,416
使用的是哪种

1081
00:30:01,416 --> 00:30:01,756
色彩空间

1082
00:30:02,026 --> 00:30:03,316
然后我们将它插入

1083
00:30:03,316 --> 00:30:05,266
渲染图表及操作

1084
00:30:05,466 --> 00:30:06,816
从 P3 色彩空间显示

1085
00:30:06,816 --> 00:30:08,256
转换到 Core Image 的

1086
00:30:08,256 --> 00:30:08,956
工作空间

1087
00:30:10,986 --> 00:30:12,896
最后可以看到

1088
00:30:12,896 --> 00:30:13,946
三个仿射矩阵

1089
00:30:14,076 --> 00:30:15,366
从下往上数的

1090
00:30:15,366 --> 00:30:16,886
第一个矩阵是用来将

1091
00:30:16,886 --> 00:30:17,856
图像的坐标系

1092
00:30:17,856 --> 00:30:18,976
转换为 Core Image

1093
00:30:18,976 --> 00:30:20,256
所使用的

1094
00:30:20,256 --> 00:30:21,086
笛卡尔坐标系

1095
00:30:21,946 --> 00:30:23,416
接着是一个仿射

1096
00:30:23,416 --> 00:30:24,826
将图像放正

1097
00:30:24,826 --> 00:30:27,116
再接着是将图像

1098
00:30:27,116 --> 00:30:27,706
缩小为五分之一

1099
00:30:28,466 --> 00:30:29,656
所以如今能让大家

1100
00:30:29,656 --> 00:30:30,706
仔细审视图像了解

1101
00:30:30,746 --> 00:30:33,486
它接受过的所有操作了

1102
00:30:33,766 --> 00:30:35,276
现在我们再来做点

1103
00:30:35,276 --> 00:30:35,986
不太一样的事情

1104
00:30:35,986 --> 00:30:37,716
现在我们要请求获得

1105
00:30:37,716 --> 00:30:38,686
一幅图像不过这次是

1106
00:30:38,686 --> 00:30:40,766
一幅视差补偿

1107
00:30:40,766 --> 00:30:41,126
图像

1108
00:30:41,266 --> 00:30:42,466
这也是我们这次推出的

1109
00:30:42,466 --> 00:30:44,396
一个新选项如果你的

1110
00:30:44,396 --> 00:30:46,176
图像包含深度信息

1111
00:30:46,176 --> 00:30:49,156
它便会以单色图像的方式

1112
00:30:49,156 --> 00:30:50,176
返回该信息

1113
00:30:51,816 --> 00:30:53,276
在我们请求完毕后

1114
00:30:53,666 --> 00:30:55,086
我们要对它应用

1115
00:30:55,086 --> 00:30:55,196
一个滤镜

1116
00:30:55,306 --> 00:30:56,266
在这个例子里我们

1117
00:30:56,266 --> 00:30:58,176
要对它应用双三次缩放变换

1118
00:30:58,456 --> 00:30:59,526
来调整它的大小

1119
00:31:01,206 --> 00:31:03,206
在 Xcode 环境下调试时

1120
00:31:03,206 --> 00:31:04,246
如果我们把鼠标悬停在

1121
00:31:04,246 --> 00:31:06,226
这个对象上就能

1122
00:31:06,736 --> 00:31:07,816
得到这样一幅图像

1123
00:31:08,246 --> 00:31:09,266
大家可以明确地看到

1124
00:31:09,266 --> 00:31:11,726
这张视差图像的前景

1125
00:31:11,726 --> 00:31:13,756
是白的在背景方向上

1126
00:31:14,146 --> 00:31:15,146
越深颜色就越暗

1127
00:31:15,456 --> 00:31:17,716
但我们还能看到

1128
00:31:17,716 --> 00:31:19,066
这幅图像生成过程的图表

1129
00:31:19,796 --> 00:31:21,596
像这里可以看到

1130
00:31:21,596 --> 00:31:23,926
输入图像是一个 IOSurface

1131
00:31:23,926 --> 00:31:25,576
格式是亮度半浮点精度

1132
00:31:25,576 --> 00:31:27,976
还可以看到

1133
00:31:27,976 --> 00:31:29,016
图像的尺寸

1134
00:31:29,016 --> 00:31:30,456
要小于原始图像

1135
00:31:31,916 --> 00:31:33,306
在这张图表的最上方

1136
00:31:33,306 --> 00:31:36,456
还能看到我们刚才应用

1137
00:31:36,456 --> 00:31:37,386
的 cubicUpsample 滤镜

1138
00:31:38,816 --> 00:31:40,016
对于图表的显示用色

1139
00:31:40,016 --> 00:31:41,286
其实也是有规则可循的

1140
00:31:41,556 --> 00:31:42,726
首先你会注意到

1141
00:31:42,726 --> 00:31:44,296
该图表所有的输入框

1142
00:31:44,336 --> 00:31:44,666
都是紫色

1143
00:31:45,256 --> 00:31:46,556
任何会影响到图像

1144
00:31:46,556 --> 00:31:48,646
色彩的或者说 CIColorKernel

1145
00:31:49,036 --> 00:31:49,536
都是红色

1146
00:31:49,626 --> 00:31:50,876
任何会影响到图像

1147
00:31:50,876 --> 00:31:52,176
几何属性的或者说

1148
00:31:52,176 --> 00:31:53,676
CIWarpKernel 都是绿色

1149
00:31:54,076 --> 00:31:55,646
其余的内核

1150
00:31:55,646 --> 00:31:56,976
全都是蓝色

1151
00:32:00,846 --> 00:32:02,586
让我们再来做点

1152
00:32:02,586 --> 00:32:03,026
更好玩的事情

1153
00:32:03,026 --> 00:32:04,786
我们打算取用一幅

1154
00:32:04,786 --> 00:32:05,796
原始图像为它应用

1155
00:32:05,796 --> 00:32:07,906
两种不同的色彩立方体

1156
00:32:08,256 --> 00:32:09,716
然后分别取用得到的

1157
00:32:09,716 --> 00:32:10,966
两幅图像再用一个

1158
00:32:10,966 --> 00:32:12,216
CIBlendWithMask 滤镜

1159
00:32:12,276 --> 00:32:13,766
把它们合并成一幅图像

1160
00:32:14,416 --> 00:32:16,476
如果在 Quick Looks 里

1161
00:32:16,476 --> 00:32:18,356
查看这一串操作的结果

1162
00:32:18,356 --> 00:32:19,796
便能看到最后生成的图像

1163
00:32:19,956 --> 00:32:21,206
分别基于前景和背景

1164
00:32:21,206 --> 00:32:22,276
经过两种不同效果的

1165
00:32:22,316 --> 00:32:23,246
滤镜处理

1166
00:32:23,536 --> 00:32:25,986
同时我们还能看到

1167
00:32:25,986 --> 00:32:27,516
整个生成过程对应图表

1168
00:32:27,516 --> 00:32:28,476
的详细信息

1169
00:32:29,286 --> 00:32:30,726
大家可以看到

1170
00:32:30,776 --> 00:32:32,286
在最左侧我们取用

1171
00:32:32,286 --> 00:32:33,656
输入图像对应的

1172
00:32:33,656 --> 00:32:36,346
子图部分拿到了色彩立方体的

1173
00:32:36,346 --> 00:32:40,056
数据一个 32x1024 的图像

1174
00:32:40,486 --> 00:32:41,906
然后把这个色彩立方体

1175
00:32:41,906 --> 00:32:42,186
应用到了图像上

1176
00:32:42,806 --> 00:32:44,986
图表的中间部分

1177
00:32:44,986 --> 00:32:45,786
我们是在对背景

1178
00:32:45,786 --> 00:32:46,666
做一遍相同的事情

1179
00:32:47,416 --> 00:32:49,076
所有这些再加上遮罩图像

1180
00:32:49,076 --> 00:32:50,556
全部用 blendWithMask 内核

1181
00:32:50,556 --> 00:32:51,586
进行合并

1182
00:32:52,186 --> 00:32:55,206
希望这些讲解让大家

1183
00:32:55,206 --> 00:32:57,196
对于应用程序创建 CIImage 的

1184
00:32:57,196 --> 00:32:58,806
过程有了很好的理解

1185
00:32:59,076 --> 00:33:00,406
不过到了渲染这个环节

1186
00:32:59,076 --> 00:33:00,406
不过到了渲染这个环节

1187
00:33:00,406 --> 00:33:00,946
又会发生些什么呢？

1188
00:33:00,946 --> 00:33:01,766
这就是事情变得

1189
00:33:01,766 --> 00:33:02,496
有意思的地方了

1190
00:33:03,296 --> 00:33:04,926
在你告诉一个 CIContext 

1191
00:33:04,926 --> 00:33:06,566
启动一项任务后这个过程

1192
00:33:06,566 --> 00:33:07,916
会返回一个 CIRenderedTask 对象

1193
00:33:08,186 --> 00:33:10,066
这里同样支持 Quick Looks

1194
00:33:10,606 --> 00:33:12,156
让我们来看一下

1195
00:33:12,156 --> 00:33:13,286
显然这个图表的内容

1196
00:33:13,286 --> 00:33:13,676
更加详尽

1197
00:33:14,156 --> 00:33:16,996
同样这里的配色规则

1198
00:33:16,996 --> 00:33:18,596
是一样的我们也能看到

1199
00:33:18,596 --> 00:33:21,726
一些前面出现过的操作

1200
00:33:21,726 --> 00:33:23,126
但是我们之前看到的

1201
00:33:23,126 --> 00:33:24,466
色彩匹配操作

1202
00:33:24,466 --> 00:33:25,426
被转换成了

1203
00:33:25,426 --> 00:33:26,596
执行色彩管理

1204
00:33:26,596 --> 00:33:27,046
所需要的基元

1205
00:33:27,276 --> 00:33:28,416
我们可以看到我们需要

1206
00:33:28,416 --> 00:33:30,506
应用这个 gamma 函数

1207
00:33:30,506 --> 00:33:31,856
和这个色彩矩阵以便

1208
00:33:31,856 --> 00:33:33,566
从 P3 转换到我们的工作空间

1209
00:33:34,726 --> 00:33:35,936
大家还能看到

1210
00:33:35,936 --> 00:33:37,226
虽然原始图像经过

1211
00:33:37,226 --> 00:33:39,136
三次仿射变换

1212
00:33:39,136 --> 00:33:41,086
但 Core Image 已将三次

1213
00:33:41,086 --> 00:33:41,516
全部并置成了一次

1214
00:33:42,046 --> 00:33:45,636
还有一点大家会注意到的

1215
00:33:45,696 --> 00:33:47,376
就是在图表要结束时

1216
00:33:47,376 --> 00:33:48,456
我们已经知道目标的

1217
00:33:48,456 --> 00:33:49,286
色彩空间是什么了

1218
00:33:49,396 --> 00:33:50,986
这些操作已经全部

1219
00:33:50,986 --> 00:33:52,236
应用在图像上

1220
00:33:53,416 --> 00:33:57,236
全都经过了色彩空间

1221
00:33:57,236 --> 00:33:58,366
和坐标系的转换

1222
00:33:58,366 --> 00:33:59,396
用以得出最后的

1223
00:33:59,396 --> 00:33:59,976
目标

1224
00:33:59,976 --> 00:34:01,996
大家还可以看到

1225
00:33:59,976 --> 00:34:01,996
大家还可以看到

1226
00:34:01,996 --> 00:34:03,056
所有这些对象或者说

1227
00:34:03,056 --> 00:34:04,326
渲染图表每一个环节所涉及到的

1228
00:34:04,326 --> 00:34:05,506
所有图像的所有尺寸

1229
00:34:05,506 --> 00:34:09,206
这里也全都有用到

1230
00:34:09,275 --> 00:34:10,606
现在等到你给定的

1231
00:34:10,606 --> 00:34:12,456
任务完成后这里又

1232
00:34:12,456 --> 00:34:13,156
出现了一个新对象

1233
00:34:13,156 --> 00:34:14,746
这个新对象会涉及到

1234
00:34:15,835 --> 00:34:17,596
Core Image 是如何

1235
00:34:17,596 --> 00:34:18,906
实现并置

1236
00:34:18,906 --> 00:34:20,235
以及渲染器性能的

1237
00:34:20,235 --> 00:34:21,735
详细信息

1238
00:34:22,386 --> 00:34:23,286
大家也看到了这里的

1239
00:34:23,286 --> 00:34:25,025
树形图上出现的对象比较少

1240
00:34:25,025 --> 00:34:26,186
就是因为执行了并置

1241
00:34:26,525 --> 00:34:27,525
如果我们来看一下靠近

1242
00:34:27,525 --> 00:34:29,636
下方的地方会发现这有一个

1243
00:34:29,696 --> 00:34:31,676
专门的 program 它就是

1244
00:34:31,676 --> 00:34:33,565
将几个步骤并置到

1245
00:34:33,565 --> 00:34:36,815
一段程序后得到的结果

1246
00:34:36,815 --> 00:34:38,326
我们还能看到它用到的

1247
00:34:38,556 --> 00:34:39,496
参数还有这段程序执行起来

1248
00:34:39,496 --> 00:34:41,126
所耗费的时间

1249
00:34:41,126 --> 00:34:41,815
单位是毫秒

1250
00:34:42,556 --> 00:34:43,835
Core Image 有个很好的功能是

1251
00:34:43,835 --> 00:34:44,795
如果你接着又将

1252
00:34:44,795 --> 00:34:47,085
这幅图像渲染了一遍

1253
00:34:47,085 --> 00:34:48,545
渲染的图像部位也完全相同

1254
00:34:48,545 --> 00:34:50,516
那么 Core Image 能从

1255
00:34:50,516 --> 00:34:51,656
缓存里调取上次的

1256
00:34:51,656 --> 00:34:52,146
处理结果

1257
00:34:52,676 --> 00:34:54,016
发生这种情况的时候你会发现

1258
00:34:54,016 --> 00:34:55,266
这里的所用时间

1259
00:34:55,266 --> 00:34:55,735
都变成了 0

1260
00:34:56,216 --> 00:34:57,816
这也从另一个侧面

1261
00:34:57,816 --> 00:34:59,566
让大家了解到

1262
00:34:59,566 --> 00:35:00,906
在给定的内存限制下

1263
00:34:59,566 --> 00:35:00,906
在给定的内存限制下

1264
00:35:00,906 --> 00:35:02,776
Core Image 是如何高效地

1265
00:35:02,776 --> 00:35:05,416
渲染和缓存结果的

1266
00:35:05,986 --> 00:35:09,136
希望这能帮助大家

1267
00:35:09,136 --> 00:35:10,886
更具体也更清晰地了解

1268
00:35:10,886 --> 00:35:12,226
Core Image 的内部机制

1269
00:35:13,896 --> 00:35:14,846
我今天要讲的

1270
00:35:14,846 --> 00:35:17,006
下一个主题

1271
00:35:17,536 --> 00:35:18,926
是条形码确切说

1272
00:35:18,926 --> 00:35:20,446
就是 CIBarcodeDescriptor 这个 API

1273
00:35:21,696 --> 00:35:23,376
我们的平台现在为条形码

1274
00:35:23,416 --> 00:35:24,886
提供很出色的广泛支持

1275
00:35:25,336 --> 00:35:26,796
不同类型的条形码

1276
00:35:26,796 --> 00:35:29,006
无论是 Aztec Code128

1277
00:35:29,006 --> 00:35:31,036
还是二维码  PDF417

1278
00:35:32,466 --> 00:35:33,816
我们还在多种不同的

1279
00:35:33,816 --> 00:35:35,726
框架内支持条形码

1280
00:35:35,726 --> 00:35:37,406
这些框架都对条形码

1281
00:35:37,406 --> 00:35:38,596
有着不同方式的

1282
00:35:38,596 --> 00:35:39,976
合理运用

1283
00:35:40,596 --> 00:35:43,316
比如说

1284
00:35:43,316 --> 00:35:46,046
AVFoundation 就是一种

1285
00:35:46,046 --> 00:35:47,496
在用摄影机拍摄

1286
00:35:47,576 --> 00:35:49,046
视频时帮你检测

1287
00:35:49,296 --> 00:35:50,406
条形码的框架

1288
00:35:51,506 --> 00:35:53,636
如果你想要从

1289
00:35:53,896 --> 00:35:55,656
静态图像或者

1290
00:35:55,656 --> 00:35:57,756
已摄视频中检测

1291
00:35:57,756 --> 00:35:58,936
条形码这个框架

1292
00:35:59,036 --> 00:36:00,066
会很好用

1293
00:35:59,036 --> 00:36:00,066
会很好用

1294
00:36:00,256 --> 00:36:01,516
最后大家可以使用

1295
00:36:01,516 --> 00:36:04,176
Core Image 将二维码

1296
00:36:04,176 --> 00:36:05,256
渲染成真正的图像文件

1297
00:36:06,596 --> 00:36:08,116
考虑到不同框架对二维码的

1298
00:36:08,116 --> 00:36:09,816
广泛支持我们便想加入

1299
00:36:09,816 --> 00:36:11,216
一种新的数据类型

1300
00:36:11,826 --> 00:36:14,016
能让条形码信息

1301
00:36:14,016 --> 00:36:15,206
在不同框架之间

1302
00:36:15,246 --> 00:36:17,206
无损传递

1303
00:36:19,106 --> 00:36:21,136
于是我们就有了新推出的

1304
00:36:21,136 --> 00:36:23,786
CIBarcodeDescription API

1305
00:36:25,036 --> 00:36:27,546
这个对象只有一个

1306
00:36:27,546 --> 00:36:28,926
重要属性就是

1307
00:36:28,926 --> 00:36:30,096
errorCorrectedPayload

1308
00:36:30,856 --> 00:36:32,756
它所包含的并不只是

1309
00:36:32,756 --> 00:36:34,786
一个条形码的文字信息

1310
00:36:34,786 --> 00:36:36,036
而是它的原始数据

1311
00:36:36,346 --> 00:36:38,366
因而能让你通过

1312
00:36:38,366 --> 00:36:39,896
单纯的文字信息以外的

1313
00:36:40,096 --> 00:36:41,716
方式使用条形码

1314
00:36:41,716 --> 00:36:42,676
从中获取信息

1315
00:36:43,016 --> 00:36:45,046
利用包含原始数据的

1316
00:36:45,796 --> 00:36:47,246
errorCorrectedPayload

1317
00:36:47,246 --> 00:36:48,876
加上对每种条形码

1318
00:36:49,046 --> 00:36:50,416
格式的了解可以让你

1319
00:36:50,896 --> 00:36:53,036
基于二维码做出

1320
00:36:53,036 --> 00:36:53,806
很有意思的功能打造出

1321
00:36:53,806 --> 00:36:55,306
有意思的垂直应用

1322
00:36:56,296 --> 00:36:58,056
此外每种条形码

1323
00:36:58,056 --> 00:36:59,426
也有一些自己独有的

1324
00:36:59,426 --> 00:36:59,936
属性

1325
00:37:00,426 --> 00:37:01,746
就拿 Aztec 条形码

1326
00:37:01,746 --> 00:37:04,266
来说你可以获知

1327
00:37:04,536 --> 00:37:06,446
一个条形码包含了

1328
00:37:06,446 --> 00:37:06,896
多少个层

1329
00:37:07,296 --> 00:37:08,966
再比如说二维码

1330
00:37:09,216 --> 00:37:10,766
就用到了所谓的

1331
00:37:10,766 --> 00:37:11,756
掩码图案

1332
00:37:12,876 --> 00:37:14,926
那么我来给大家举个例子

1333
00:37:14,926 --> 00:37:16,606
看看这个新的数据类型可以

1334
00:37:16,646 --> 00:37:17,776
如何在这三大框架下使用

1335
00:37:18,236 --> 00:37:20,506
首先要说的是

1336
00:37:20,566 --> 00:37:23,426
AVFoundation

1337
00:37:23,666 --> 00:37:24,466
你可以注册一个

1338
00:37:24,466 --> 00:37:26,606
metadataOutputObjectDelegate

1339
00:37:26,916 --> 00:37:29,126
它能看到输入视频中

1340
00:37:29,126 --> 00:37:31,846
出现的条形码

1341
00:37:33,066 --> 00:37:35,446
而你在代码中要做的

1342
00:37:35,446 --> 00:37:36,446
就是设置这个对象

1343
00:37:36,746 --> 00:37:38,696
在该对象检测到条形码时

1344
00:37:38,696 --> 00:37:41,246
你可以在响应部分

1345
00:37:41,426 --> 00:37:44,106
将该对象以

1346
00:37:44,106 --> 00:37:45,816
AVMetadataMachineReadableCodeObject的

1347
00:37:45,816 --> 00:37:47,276
名义调用

1348
00:37:47,906 --> 00:37:49,366
通过这个对象你可以

1349
00:37:49,456 --> 00:37:51,006
获得 descriptor 属性

1350
00:37:51,006 --> 00:37:52,116
这会返回其中的一个

1351
00:37:52,116 --> 00:37:53,976
CIBarcodeDescriptor 对象

1352
00:37:57,156 --> 00:37:58,606
其次如果你想使用

1353
00:37:58,606 --> 00:37:59,776
Vision 框架来检测

1354
00:37:59,846 --> 00:38:00,996
条形码所用的代码

1355
00:37:59,846 --> 00:38:00,996
条形码所用的代码

1356
00:38:00,996 --> 00:38:01,766
也十分简单

1357
00:38:02,256 --> 00:38:03,346
基本上我们会使用

1358
00:38:03,346 --> 00:38:05,216
Vision 创建请求处理器

1359
00:38:05,216 --> 00:38:06,956
也会直接把它用作为请求

1360
00:38:07,626 --> 00:38:09,216
接着我们要将这个请求

1361
00:38:09,216 --> 00:38:10,836
发送给处理器让它

1362
00:38:10,886 --> 00:38:11,436
去检测条形码

1363
00:38:11,996 --> 00:38:13,936
当我们收到返回的

1364
00:38:13,936 --> 00:38:15,776
请求结果后便可以

1365
00:38:15,776 --> 00:38:17,456
从结果中获取

1366
00:38:17,456 --> 00:38:18,216
barcodeDescriptor 对象

1367
00:38:19,006 --> 00:38:19,556
非常简单

1368
00:38:20,666 --> 00:38:23,086
最后也是最简单的就是

1369
00:38:23,086 --> 00:38:24,526
用 Core Image 根据 descriptor

1370
00:38:24,526 --> 00:38:26,336
生成条形码图像

1371
00:38:26,976 --> 00:38:28,056
这种情况实现起来

1372
00:38:28,056 --> 00:38:28,426
特别简单

1373
00:38:28,426 --> 00:38:29,556
我们只要创建一个

1374
00:38:29,556 --> 00:38:31,416
BarcodeGenerator 类型的

1375
00:38:31,476 --> 00:38:32,386
CIFilter 实例

1376
00:38:33,166 --> 00:38:34,966
然后为这个滤镜提供

1377
00:38:34,966 --> 00:38:36,726
descriptor 对象的输入

1378
00:38:36,786 --> 00:38:38,466
供 inputBarcodeDescriptor 使用

1379
00:38:39,136 --> 00:38:40,146
然后要求返回

1380
00:38:40,146 --> 00:38:40,816
输出图像

1381
00:38:42,176 --> 00:38:43,946
这些技巧结合在一起

1382
00:38:43,946 --> 00:38:45,716
就可以让我们利用

1383
00:38:46,096 --> 00:38:47,636
条形码的检测与生成

1384
00:38:47,636 --> 00:38:48,226
做出有意思的东西

1385
00:38:48,626 --> 00:38:50,626
这里有一段我们事先录制的

1386
00:38:50,626 --> 00:38:52,056
演示视频给大家看一个

1387
00:38:52,056 --> 00:38:53,056
我们编写的示例应用

1388
00:38:53,816 --> 00:38:55,856
它的功能就是检查

1389
00:38:56,096 --> 00:38:57,626
视频的每一帧从中

1390
00:38:57,626 --> 00:38:59,306
拉取条形码然后渲染出来

1391
00:38:59,536 --> 00:39:01,076
再覆盖在视频中的

1392
00:38:59,536 --> 00:39:01,076
再覆盖在视频中的

1393
00:39:01,246 --> 00:39:03,976
条形码上有点类似

1394
00:39:03,976 --> 00:39:05,336
某种增强图像

1395
00:39:05,836 --> 00:39:06,696
大家可以看到我们能够

1396
00:39:06,696 --> 00:39:08,606
完美地复制出

1397
00:39:08,606 --> 00:39:10,116
检测到的条形码并在它上方

1398
00:39:10,116 --> 00:39:10,726
重新渲染出来

1399
00:39:11,206 --> 00:39:12,496
如果我们再来快速地

1400
00:39:12,496 --> 00:39:13,986
看一遍还可以发现

1401
00:39:13,986 --> 00:39:15,156
这确实是渲染出来的

1402
00:39:15,156 --> 00:39:17,526
因为它直接覆盖在了

1403
00:39:17,526 --> 00:39:18,016
我的大拇指上

1404
00:39:19,456 --> 00:39:19,746
所以

1405
00:39:26,356 --> 00:39:26,726
好的

1406
00:39:26,726 --> 00:39:28,596
那么在今天这场讲座的

1407
00:39:28,596 --> 00:39:30,416
最后一个部分里我很开心地

1408
00:39:30,416 --> 00:39:32,036
要跟大家讲讲如何将

1409
00:39:32,036 --> 00:39:33,466
Core Image 和 Vision 结合使用

1410
00:39:33,976 --> 00:39:35,416
两者都是非常优秀的框架

1411
00:39:35,596 --> 00:39:36,926
Core Image 能让你

1412
00:39:36,926 --> 00:39:38,196
很轻松地使用框架

1413
00:39:38,256 --> 00:39:39,366
对图像应用图像处理

1414
00:39:39,686 --> 00:39:41,296
Vision 则能让你

1415
00:39:41,486 --> 00:39:42,736
非常方便地找到

1416
00:39:42,736 --> 00:39:43,166
图像的信息。

1417
00:39:43,166 --> 00:39:44,926
而这两者也可以通过

1418
00:39:44,926 --> 00:39:46,616
便利且创新的方式结合使用

1419
00:39:48,346 --> 00:39:50,636
比如说你可以将

1420
00:39:50,636 --> 00:39:52,136
Core Image 用作为

1421
00:39:52,136 --> 00:39:53,866
将图像提交给 Vision 之前的

1422
00:39:53,866 --> 00:39:54,256
预处理手段

1423
00:39:54,746 --> 00:39:56,096
再比如你或许

1424
00:39:56,096 --> 00:39:57,626
想把图像按你的喜好

1425
00:39:57,626 --> 00:39:58,146
进行裁切

1426
00:39:58,146 --> 00:39:59,936
或者将图像的角度

1427
00:39:59,936 --> 00:40:00,466
放端正

1428
00:39:59,936 --> 00:40:00,466
放端正

1429
00:40:00,746 --> 00:40:02,326
或者在提交给 Vision 前

1430
00:40:02,356 --> 00:40:03,166
转换为灰度图像

1431
00:40:04,976 --> 00:40:06,396
同样在你调用 Vision 后

1432
00:40:06,666 --> 00:40:07,936
在你获得图像信息后

1433
00:40:07,936 --> 00:40:09,276
你也能将其作为

1434
00:40:09,276 --> 00:40:10,716
调整图像

1435
00:40:10,716 --> 00:40:12,446
外观的

1436
00:40:12,446 --> 00:40:12,976
指导手段

1437
00:40:13,256 --> 00:40:14,566
比如说如果在图像中

1438
00:40:14,566 --> 00:40:16,156
检测到了某个特性

1439
00:40:16,156 --> 00:40:17,896
你就可以选择不同的

1440
00:40:18,396 --> 00:40:19,636
图像处理方式

1441
00:40:20,986 --> 00:40:22,276
这两者当然完全

1442
00:40:22,276 --> 00:40:23,026
可以结合在一起

1443
00:40:23,906 --> 00:40:25,426
但为了讲得

1444
00:40:25,496 --> 00:40:26,526
更具体些

1445
00:40:26,526 --> 00:40:28,026
我们有个有趣的演示程序

1446
00:40:28,026 --> 00:40:29,756
想跟大家探讨一下

1447
00:40:29,756 --> 00:40:31,526
我们会试着用

1448
00:40:31,526 --> 00:40:34,066
视频的几个帧

1449
00:40:34,066 --> 00:40:34,516
生成一张照片

1450
00:40:34,786 --> 00:40:36,676
并将多余的物体

1451
00:40:36,676 --> 00:40:38,446
从中删除

1452
00:40:38,846 --> 00:40:39,896
这段演示将会

1453
00:40:39,896 --> 00:40:41,506
涉及三种框架

1454
00:40:41,506 --> 00:40:42,346
四个步骤

1455
00:40:42,826 --> 00:40:44,156
第一个步骤会

1456
00:40:44,156 --> 00:40:45,526
使用 AVFoundation

1457
00:40:45,526 --> 00:40:46,556
提取视频的帧

1458
00:40:47,506 --> 00:40:49,216
这一步非常简单

1459
00:40:50,056 --> 00:40:51,376
接着我们要用 Vision

1460
00:40:51,546 --> 00:40:53,206
来确定需要哪些

1461
00:40:53,206 --> 00:40:55,286
单应矩阵来让每一帧

1462
00:40:55,286 --> 00:40:57,026
依据共用参照系

1463
00:40:57,026 --> 00:40:57,546
进行校准

1464
00:40:58,666 --> 00:40:59,806
一些相机抖动也是

1465
00:40:59,806 --> 00:41:00,596
在所难免所以一些

1466
00:40:59,806 --> 00:41:00,596
在所难免所以一些

1467
00:41:00,596 --> 00:41:01,836
校正处理也会大有益处

1468
00:41:02,956 --> 00:41:04,446
于是我们便能得到

1469
00:41:04,446 --> 00:41:06,486
这样一些单应矩阵

1470
00:41:06,486 --> 00:41:07,486
如屏幕所示画面的

1471
00:41:07,696 --> 00:41:09,636
每一帧里都有这些

1472
00:41:09,636 --> 00:41:10,436
位置会稍稍变化的箭头

1473
00:41:11,896 --> 00:41:13,736
第三步是用 Core Image

1474
00:41:13,736 --> 00:41:15,486
让所有这些帧

1475
00:41:15,486 --> 00:41:15,966
参照彼此进行校准

1476
00:41:16,746 --> 00:41:17,936
这一步也非常

1477
00:41:17,936 --> 00:41:18,106
简单

1478
00:41:19,106 --> 00:41:20,796
最后我们要用

1479
00:41:20,796 --> 00:41:22,566
求取中位数的办法

1480
00:41:22,566 --> 00:41:24,496
根据视频中的所有帧

1481
00:41:24,496 --> 00:41:26,926
创建一张照片

1482
00:41:27,046 --> 00:41:29,106
并且生成最佳的图像

1483
00:41:29,886 --> 00:41:31,416
这里的技巧在于

1484
00:41:31,416 --> 00:41:33,166
生成一幅输出图像

1485
00:41:33,166 --> 00:41:34,316
在图像中的每一个输出方位

1486
00:41:34,496 --> 00:41:36,266
我们都要在输入帧中

1487
00:41:36,266 --> 00:41:37,066
查看相应的方位

1488
00:41:37,456 --> 00:41:38,776
然后我们会使用

1489
00:41:38,776 --> 00:41:41,236
每个方位上的中位值

1490
00:41:41,486 --> 00:41:42,856
大家看一下这个例子

1491
00:41:42,856 --> 00:41:44,966
前四幅图像里

1492
00:41:45,736 --> 00:41:47,496
小圆点都出现在

1493
00:41:47,496 --> 00:41:49,206
水泥路上而在第五幅里

1494
00:41:49,206 --> 00:41:52,046
却出现在人腿上

1495
00:41:52,666 --> 00:41:54,016
如果我们对这五个值

1496
00:41:54,126 --> 00:41:55,656
求取中位数便可以

1497
00:41:55,656 --> 00:41:56,726
得到一个看上去像是

1498
00:41:56,876 --> 00:41:57,676
水泥路的值

1499
00:41:58,236 --> 00:41:59,066
如果我们对图像中的

1500
00:41:59,066 --> 00:42:00,436
另一处区域进行同样的操作

1501
00:41:59,066 --> 00:42:00,436
另一处区域进行同样的操作

1502
00:42:00,626 --> 00:42:02,276
得出的结果则是在

1503
00:42:02,276 --> 00:42:02,706
这棵树下

1504
00:42:02,946 --> 00:42:04,876
这五帧中有三帧

1505
00:42:04,876 --> 00:42:05,216
没问题

1506
00:42:05,266 --> 00:42:07,716
另外两帧就差一些

1507
00:42:07,916 --> 00:42:08,926
所以我们要对它们

1508
00:42:08,926 --> 00:42:10,426
求取中位数而在对图像的

1509
00:42:10,426 --> 00:42:12,336
每一个像素都如此处理后

1510
00:42:12,516 --> 00:42:13,296
便能得到一个很好的结果

1511
00:42:13,296 --> 00:42:14,536
所有在视频中

1512
00:42:14,536 --> 00:42:16,176
暂时出现的物体

1513
00:42:16,176 --> 00:42:17,066
全都被神奇地删除了

1514
00:42:17,526 --> 00:42:20,006
现在让我先来多说几句

1515
00:42:20,006 --> 00:42:21,336
这段代码我保证在最后

1516
00:42:21,336 --> 00:42:22,226
会让大家看到这段演示的

1517
00:42:22,986 --> 00:42:24,576
这里的第一步

1518
00:42:24,576 --> 00:42:26,086
我们要用 Vision

1519
00:42:26,086 --> 00:42:27,866
来确定每一帧的

1520
00:42:27,866 --> 00:42:28,356
单应配准

1521
00:42:28,716 --> 00:42:29,906
同样这也很简单

1522
00:42:30,096 --> 00:42:31,066
我们要用 Vision

1523
00:42:31,066 --> 00:42:32,836
创建请求和

1524
00:42:32,836 --> 00:42:35,386
请求处理器用来

1525
00:42:35,386 --> 00:42:36,086
生成这些信息

1526
00:42:36,536 --> 00:42:38,226
我们要告诉 Vision

1527
00:42:38,226 --> 00:42:39,276
执行这条请求

1528
00:42:40,416 --> 00:42:41,826
然后在获得结果后

1529
00:42:41,826 --> 00:42:43,326
我们要返回结果

1530
00:42:43,696 --> 00:42:45,076
并要确保返回的是

1531
00:42:45,126 --> 00:42:47,836
一个 VNImageHomographic 类型的

1532
00:42:48,776 --> 00:42:49,896
AlignmentObservation 对象

1533
00:42:49,896 --> 00:42:50,606
啊好拗口

1534
00:42:51,046 --> 00:42:52,556
于是我们就按要求返回

1535
00:42:52,616 --> 00:42:54,906
这个对象基本上就是

1536
00:42:54,906 --> 00:42:55,616
一个 3x3 的矩阵

1537
00:42:56,136 --> 00:42:59,156
返回结果后我们便可

1538
00:42:59,156 --> 00:43:01,076
接着使用 Core Image

1539
00:42:59,156 --> 00:43:01,076
接着使用 Core Image

1540
00:43:01,076 --> 00:43:02,786
依据这个 3x3 的矩阵

1541
00:43:02,786 --> 00:43:03,276
校准图像

1542
00:43:03,586 --> 00:43:04,576
这部分需要点技巧

1543
00:43:04,576 --> 00:43:05,956
但如果使用 Metal 写成的

1544
00:43:06,216 --> 00:43:07,946
自定义 Warp 内核实现起来

1545
00:43:07,946 --> 00:43:08,576
其实非常简单

1546
00:43:09,866 --> 00:43:11,356
大家可以在这个内核中看到

1547
00:43:11,686 --> 00:43:13,026
我们现在有个参数

1548
00:43:13,026 --> 00:43:14,056
是个 3x3 的浮点数据

1549
00:43:14,056 --> 00:43:15,026
这是今年新增到

1550
00:43:15,026 --> 00:43:15,916
Core Image 中的

1551
00:43:16,656 --> 00:43:17,696
我们要做的就是

1552
00:43:17,696 --> 00:43:18,746
获取 destCoord

1553
00:43:18,966 --> 00:43:20,396
将它转换成单应性的

1554
00:43:20,396 --> 00:43:21,926
destCoord  办法是

1555
00:43:21,926 --> 00:43:22,096
在末端加个 1

1556
00:43:22,846 --> 00:43:24,096
接着我们要用

1557
00:43:24,096 --> 00:43:26,956
这个矢量与矩阵相乘

1558
00:43:26,956 --> 00:43:27,856
这会给出我们想要的

1559
00:43:27,856 --> 00:43:29,696
homogenousSrcCoord

1560
00:43:29,696 --> 00:43:31,246
然后我们要进行一次

1561
00:43:31,246 --> 00:43:33,326
透视分割以便获取

1562
00:43:33,326 --> 00:43:34,356
源坐标供我们

1563
00:43:34,356 --> 00:43:35,076
采样用

1564
00:43:35,986 --> 00:43:37,246
这就是这部分的全部代码

1565
00:43:39,086 --> 00:43:40,566
第三步是要用

1566
00:43:40,566 --> 00:43:41,936
Core Image应用中位数滤镜

1567
00:43:41,976 --> 00:43:43,896
在现在这个例子里

1568
00:43:43,896 --> 00:43:45,196
给大家看的是一段用来

1569
00:43:45,256 --> 00:43:47,406
对5幅图像取中位数的代码

1570
00:43:48,046 --> 00:43:49,446
事实上有时候你要处理的图像

1571
00:43:49,446 --> 00:43:50,516
数量比这多得多我们会在

1572
00:43:50,516 --> 00:43:51,126
演示程序中再涉及这个问题

1573
00:43:51,636 --> 00:43:52,636
不过在现在这个例子里

1574
00:43:52,636 --> 00:43:54,506
我们会用一个排序网络

1575
00:43:55,076 --> 00:43:56,716
来求取五个像素样本的

1576
00:43:56,716 --> 00:43:58,366
中位值

1577
00:43:59,166 --> 00:44:00,336
同样大家留意一下这部分

1578
00:43:59,166 --> 00:44:00,336
同样大家留意一下这部分

1579
00:44:00,336 --> 00:44:02,076
这是一个用 Metal 编写

1580
00:44:02,076 --> 00:44:03,616
此类内核的绝佳示例

1581
00:44:03,616 --> 00:44:05,596
又便捷又简单

1582
00:44:05,596 --> 00:44:07,116
因为如今我们在

1583
00:44:07,116 --> 00:44:08,526
将这些值传递给

1584
00:44:08,526 --> 00:44:11,076
这个 swap 函数时

1585
00:44:11,136 --> 00:44:11,856
可以按引用而非按值传递

1586
00:44:12,566 --> 00:44:15,016
接下来这个有趣的部分

1587
00:44:15,016 --> 00:44:16,956
我要请 Sky

1588
00:44:16,956 --> 00:44:17,416
上台来

1589
00:44:17,416 --> 00:44:18,326
他会为大家讲解这个主题的

1590
00:44:18,326 --> 00:44:19,826
更多细节以及这款滤镜的

1591
00:44:19,826 --> 00:44:19,966
工作原理

1592
00:44:27,466 --> 00:44:27,736
&gt;&gt;  好的

1593
00:44:27,736 --> 00:44:28,256
谢谢 David

1594
00:44:28,806 --> 00:44:30,566
嗨我叫 Sky

1595
00:44:30,566 --> 00:44:31,586
很高兴今天能为

1596
00:44:31,586 --> 00:44:33,356
大家带来这段演示

1597
00:44:33,356 --> 00:44:34,716
就像大家看到的画面上半部

1598
00:44:34,716 --> 00:44:36,276
是我们的输入视频

1599
00:44:36,476 --> 00:44:38,446
我在滑条上来回刷动一下

1600
00:44:38,446 --> 00:44:40,506
我们可以看到

1601
00:44:40,506 --> 00:44:41,686
在这一整段视频中

1602
00:44:41,686 --> 00:44:43,286
没有任何一个时间点

1603
00:44:43,286 --> 00:44:44,906
能让我们为这块地标

1604
00:44:44,906 --> 00:44:46,196
提取出一个清晰的图像

1605
00:44:46,766 --> 00:44:48,146
所以就像这样

1606
00:44:48,146 --> 00:44:49,376
在一开始这里有

1607
00:44:49,376 --> 00:44:50,466
影子把我们挡住了

1608
00:44:50,506 --> 00:44:52,026
接着又有路人

1609
00:44:52,026 --> 00:44:52,376
来来往往

1610
00:44:52,996 --> 00:44:54,186
所以在整段视频中

1611
00:44:54,186 --> 00:44:55,536
完全没有一个时间点

1612
00:44:55,536 --> 00:44:56,446
能让我们获得清晰的影像

1613
00:44:57,206 --> 00:45:00,576
实际上如果我们将镜头

1614
00:44:57,206 --> 00:45:00,576
实际上如果我们将镜头

1615
00:45:00,576 --> 00:45:01,836
拉近到它的一角处

1616
00:45:01,836 --> 00:45:03,056
便会发现整个视频期间

1617
00:45:03,286 --> 00:45:04,876
画面都在不停变化

1618
00:45:05,606 --> 00:45:06,806
所以在我们运行 reduction 内核

1619
00:45:06,806 --> 00:45:08,386
之前需要先对这些帧

1620
00:45:08,386 --> 00:45:09,136
进行校准

1621
00:45:09,246 --> 00:45:10,526
我们的办法就是使用

1622
00:45:10,526 --> 00:45:11,746
Vision  像 David 提到的那样

1623
00:45:12,546 --> 00:45:14,516
现在 Vision可提供两个

1624
00:45:14,546 --> 00:45:17,346
配准 API 滑条这里有

1625
00:45:17,346 --> 00:45:17,976
显示

1626
00:45:18,526 --> 00:45:20,736
其中一行字是单应性 (homographic)

1627
00:45:20,736 --> 00:45:21,666
也是 David 刚才提到过的

1628
00:45:21,666 --> 00:45:22,776
不过 Vision 还提供了一种

1629
00:45:22,776 --> 00:45:24,466
平移校准

1630
00:45:24,466 --> 00:45:25,556
以我们这个例子而言

1631
00:45:25,556 --> 00:45:26,366
效果并不太好

1632
00:45:26,366 --> 00:45:27,666
因为我们的相机移动

1633
00:45:27,666 --> 00:45:29,376
并不是全部发生在一个

1634
00:45:29,376 --> 00:45:30,446
与图像所在平面相平行的

1635
00:45:31,346 --> 00:45:31,736
平面上

1636
00:45:31,986 --> 00:45:33,356
所以我们用来

1637
00:45:33,356 --> 00:45:34,406
稳定画面的办法

1638
00:45:34,406 --> 00:45:35,896
就是将视频的每一帧

1639
00:45:35,896 --> 00:45:37,686
都配准到中间帧上

1640
00:45:38,076 --> 00:45:39,316
如此处理时不难预见

1641
00:45:39,316 --> 00:45:41,306
第一帧和中间帧的

1642
00:45:41,306 --> 00:45:42,566
相机位置变化非常之大

1643
00:45:42,566 --> 00:45:43,716
所以在这种情况下

1644
00:45:43,716 --> 00:45:45,226
单应性配准

1645
00:45:45,226 --> 00:45:46,156
会给我们带来

1646
00:45:46,156 --> 00:45:46,526
更好的处理效果

1647
00:45:46,526 --> 00:45:48,886
所以我们就用它处理

1648
00:45:48,886 --> 00:45:50,486
把这个操作打开后如果再把镜头

1649
00:45:50,486 --> 00:45:52,306
拉近地标的这个角这里

1650
00:45:52,306 --> 00:45:54,586
然后在滑条上刷动

1651
00:45:54,636 --> 00:45:56,396
你会发现这个点在每一帧中

1652
00:45:56,396 --> 00:45:58,806
基本都没有移动过

1653
00:45:59,496 --> 00:46:01,276
如果我们在滑条上反着刷回去

1654
00:45:59,496 --> 00:46:01,276
如果我们在滑条上反着刷回去

1655
00:46:01,276 --> 00:46:02,936
整个视频的画面

1656
00:46:02,936 --> 00:46:04,206
也非常稳定

1657
00:46:05,266 --> 00:46:06,716
这倒是让我们想到

1658
00:46:06,756 --> 00:46:08,376
如果你打算写个

1659
00:46:08,376 --> 00:46:10,856
图像稳定应用

1660
00:46:10,996 --> 00:46:12,136
完全可以用 Core Image

1661
00:46:12,136 --> 00:46:13,216
和 Vision 轻松搞定

1662
00:46:14,326 --> 00:46:15,786
接下来让我跳到

1663
00:46:15,786 --> 00:46:16,566
还原的部分

1664
00:46:17,146 --> 00:46:18,326
这里我要指出的第一点

1665
00:46:18,326 --> 00:46:20,566
就是这里需要我们进行

1666
00:46:20,566 --> 00:46:23,286
中位数还原处理的帧

1667
00:46:23,286 --> 00:46:24,866
共有 148 帧

1668
00:46:25,046 --> 00:46:26,316
这么做比较不切实际

1669
00:46:26,316 --> 00:46:27,416
因为我们在对它们

1670
00:46:27,416 --> 00:46:28,376
进行排序时需要把

1671
00:46:28,376 --> 00:46:29,116
所有帧都保存在内存中

1672
00:46:29,786 --> 00:46:31,306
所以我们这里的做法其实是

1673
00:46:31,306 --> 00:46:33,276
求取中位数的中位数

1674
00:46:33,276 --> 00:46:34,046
作为一个近似值

1675
00:46:34,466 --> 00:46:35,586
我们要做的第一件事

1676
00:46:35,586 --> 00:46:37,376
就是将所有这些帧

1677
00:46:37,516 --> 00:46:39,986
148 帧划分为

1678
00:46:39,986 --> 00:46:40,356
几个组别

1679
00:46:40,896 --> 00:46:41,806
然后对其中的每一个

1680
00:46:41,806 --> 00:46:43,386
组别都计算出一个

1681
00:46:43,386 --> 00:46:43,796
局部的组别中位值

1682
00:46:44,276 --> 00:46:45,626
接着在第二道处理中

1683
00:46:45,626 --> 00:46:46,936
我们再对这些局部中位值

1684
00:46:46,936 --> 00:46:48,306
运行 reduction 内核

1685
00:46:48,306 --> 00:46:50,196
计算出最终的近似结果

1686
00:46:50,696 --> 00:46:51,766
于是我们在最下方这里

1687
00:46:51,766 --> 00:46:53,986
能看到这个控制条

1688
00:46:54,236 --> 00:46:56,526
还有这些按钮为你显示

1689
00:46:56,526 --> 00:46:58,806
这些帧的分组情况

1690
00:46:59,526 --> 00:47:01,476
所以如果我改变一下这里的

1691
00:46:59,526 --> 00:47:01,476
所以如果我改变一下这里的

1692
00:47:01,476 --> 00:47:03,466
组别总数我们可以看到

1693
00:47:03,466 --> 00:47:04,486
这些指示器也会跟着变化

1694
00:47:04,486 --> 00:47:05,876
那么如果我们将组别数

1695
00:47:05,876 --> 00:47:07,136
设为 3 意思就是我们将把

1696
00:47:07,136 --> 00:47:08,306
整段视频的所有帧划分为

1697
00:47:08,306 --> 00:47:08,866
3 个组别

1698
00:47:09,416 --> 00:47:10,606
对于每一个组别

1699
00:47:10,606 --> 00:47:11,606
我也可以更改每组容量

1700
00:47:11,606 --> 00:47:14,236
这个指标的意思是

1701
00:47:14,236 --> 00:47:15,736
我们会将所有帧平均

1702
00:47:15,916 --> 00:47:17,716
分配成一组多少帧

1703
00:47:17,716 --> 00:47:18,426
以供我们计算

1704
00:47:18,426 --> 00:47:18,996
组别中位数之用

1705
00:47:19,826 --> 00:47:21,066
那么依照这些规则

1706
00:47:21,066 --> 00:47:23,376
我们姑且将组别总数定为 5

1707
00:47:23,616 --> 00:47:26,456
每组容量定为7

1708
00:47:26,606 --> 00:47:27,196
先这样吧

1709
00:47:28,166 --> 00:47:29,116
让我们看看这会

1710
00:47:29,116 --> 00:47:29,646
给我们怎样的结果

1711
00:47:30,176 --> 00:47:32,596
等它运行完毕需要

1712
00:47:32,596 --> 00:47:33,876
一些时间因为 Vision

1713
00:47:33,876 --> 00:47:35,206
需要完成所有的配准

1714
00:47:35,206 --> 00:47:37,056
我们还需要扭曲这些图像

1715
00:47:37,546 --> 00:47:39,226
那么就像我们在输出

1716
00:47:39,226 --> 00:47:41,256
这里看到的我们最后的

1717
00:47:41,256 --> 00:47:42,726
还原图像中没有出现任何

1718
00:47:42,726 --> 00:47:45,446
移动的暂时性的物体

1719
00:47:45,446 --> 00:47:47,326
我们得到的地标照片

1720
00:47:47,326 --> 00:47:48,946
非常干净完全符合我们

1721
00:47:48,946 --> 00:47:49,256
想要的结果

1722
00:47:49,726 --> 00:47:51,826
如果我们在输入与

1723
00:47:51,906 --> 00:47:53,816
输出之间来回切换一下

1724
00:47:53,816 --> 00:47:55,346
会发现整个文字细节都

1725
00:47:55,346 --> 00:47:57,146
保留得非常完美

1726
00:47:57,146 --> 00:47:58,656
可以让你看到 Vision

1727
00:47:58,656 --> 00:47:59,546
强大的校准能力

1728
00:48:00,176 --> 00:48:02,236
希望这能给大家一些概念

1729
00:48:02,236 --> 00:48:03,546
知道你们可以在 Core Image

1730
00:48:03,546 --> 00:48:04,806
和 Vision 之间创造出

1731
00:48:04,806 --> 00:48:06,056
多么有意思的

1732
00:48:06,056 --> 00:48:07,146
协同效果

1733
00:48:08,026 --> 00:48:09,666
那么我要请

1734
00:48:09,816 --> 00:48:11,516
David 回到台上

1735
00:48:11,516 --> 00:48:11,976
为大家做个总结

1736
00:48:18,676 --> 00:48:19,046
&gt;&gt;  好的

1737
00:48:19,046 --> 00:48:20,276
非常感谢大家

1738
00:48:20,806 --> 00:48:22,286
让我来概括一下

1739
00:48:22,286 --> 00:48:23,536
我们今天所讲的内容

1740
00:48:23,606 --> 00:48:25,046
还是那句话我们这个新版本的

1741
00:48:25,046 --> 00:48:26,446
主要目标是为了让大家的应用

1742
00:48:26,446 --> 00:48:27,936
实现更好的性能

1743
00:48:28,596 --> 00:48:29,776
在 Core Image 的运行方面

1744
00:48:29,826 --> 00:48:32,196
获取更好的信息

1745
00:48:32,196 --> 00:48:32,986
还有提供出色的新功能

1746
00:48:33,326 --> 00:48:34,626
我们十分期待看到大家

1747
00:48:34,626 --> 00:48:36,226
应用利用这些新功能后

1748
00:48:36,776 --> 00:48:39,196
会在今年实现

1749
00:48:39,426 --> 00:48:40,196
怎样的成长

1750
00:48:40,696 --> 00:48:43,266
希望也能在我们的

1751
00:48:43,516 --> 00:48:45,316
相关讲座上见到各位

1752
00:48:45,616 --> 00:48:46,986
如果大家需要了解

1753
00:48:46,986 --> 00:48:48,036
更多信息请访问

1754
00:48:48,036 --> 00:48:50,346
网站 developer.apple.com

1755
00:48:50,986 --> 00:48:52,246
有一些相关内容的讲座

1756
00:48:52,246 --> 00:48:53,326
绝对值得大家

1757
00:48:53,326 --> 00:48:53,776
一看

1758
00:48:53,776 --> 00:48:54,886
今年早些时候也有一场讲座

1759
00:48:54,886 --> 00:48:57,196
主题是支持深度的图像编辑

1760
00:48:57,276 --> 00:48:59,646
还有几场介绍 Vision 框架的

1761
00:48:59,646 --> 00:49:02,576
几场介绍支持深度的

1762
00:48:59,646 --> 00:49:02,576
几场介绍支持深度的

1763
00:49:02,576 --> 00:49:04,816
数据捕捉的

1764
00:49:05,026 --> 00:49:06,266
感谢大家的参加

1765
00:49:06,266 --> 00:49:07,716
祝大家接下来也玩得开心

1766
00:49:07,716 --> 00:49:07,966
谢谢
