1
00:00:21,126 --> 00:00:21,806
&gt;&gt; Hello everyone.

2
00:00:22,516 --> 00:00:26,546
[ Applause ]

3
00:00:27,046 --> 00:00:28,206
I hope you're have a great time

4
00:00:28,206 --> 00:00:29,006
at WWDC so far.

5
00:00:29,776 --> 00:00:31,216
Allow me to introduce myself.

6
00:00:31,906 --> 00:00:33,646
My name is Brett Keating and I'm

7
00:00:33,646 --> 00:00:34,896
here with my colleague Frank

8
00:00:34,896 --> 00:00:36,386
Doepke and we're here to tell

9
00:00:36,386 --> 00:00:38,256
you about Apple's new Vision

10
00:00:38,256 --> 00:00:39,836
framework, so let's get started.

11
00:00:39,836 --> 00:00:42,506
We're going to begin by showing

12
00:00:42,506 --> 00:00:43,716
you what Vision can do for your

13
00:00:43,716 --> 00:00:44,266
apps.

14
00:00:44,746 --> 00:00:45,686
We're going to go through a few

15
00:00:45,686 --> 00:00:47,126
visual examples of the

16
00:00:47,126 --> 00:00:48,106
algorithms that are going to be

17
00:00:48,106 --> 00:00:49,016
made available in the Vision

18
00:00:49,016 --> 00:00:49,766
framework this year.

19
00:00:50,936 --> 00:00:51,976
At which point I'll hand it off

20
00:00:51,976 --> 00:00:54,636
to Frank to talk about the

21
00:00:54,636 --> 00:00:56,116
concepts behind the Vision

22
00:00:56,116 --> 00:00:57,566
framework, why we designed

23
00:00:57,566 --> 00:00:58,836
things the way we did, what the

24
00:00:58,836 --> 00:01:00,696
mental model behind our API is.

25
00:00:58,836 --> 00:01:00,696
mental model behind our API is.

26
00:01:00,796 --> 00:01:02,516
And then we'll go a little

27
00:01:02,516 --> 00:01:04,906
deeper and go through a code

28
00:01:04,906 --> 00:01:05,446
example.

29
00:01:06,006 --> 00:01:08,796
This code example brings

30
00:01:08,796 --> 00:01:09,716
together a few different

31
00:01:09,716 --> 00:01:11,386
technologies in our SDK,

32
00:01:11,496 --> 00:01:14,566
including Core Image, as well as

33
00:01:14,566 --> 00:01:16,406
the brand-new Core ML framework

34
00:01:16,656 --> 00:01:17,516
that we're offering this year

35
00:01:18,386 --> 00:01:19,926
which enables you to put in your

36
00:01:19,926 --> 00:01:21,226
own custom models and have them

37
00:01:21,276 --> 00:01:23,746
be accelerated using our

38
00:01:24,896 --> 00:01:26,106
hardware.

39
00:01:26,896 --> 00:01:28,716
So, let's begin with what you

40
00:01:28,716 --> 00:01:29,326
can do with Vision.

41
00:01:30,596 --> 00:01:32,986
Let's start off with face

42
00:01:32,986 --> 00:01:33,466
detection.

43
00:01:33,466 --> 00:01:35,676
Now face detection is something

44
00:01:35,676 --> 00:01:37,136
we already have in our SDK, but

45
00:01:37,866 --> 00:01:39,126
we're offering in the Vision

46
00:01:39,126 --> 00:01:40,536
framework new this year a face

47
00:01:40,536 --> 00:01:41,646
detection that's based on deep

48
00:01:41,646 --> 00:01:42,036
learning.

49
00:01:43,246 --> 00:01:44,776
And you may already know that

50
00:01:44,986 --> 00:01:46,006
deep learning has made

51
00:01:46,496 --> 00:01:47,786
groundbreaking changes in the

52
00:01:47,786 --> 00:01:49,916
accuracy in what we can do with

53
00:01:49,986 --> 00:01:51,296
Vision technologies and face

54
00:01:51,296 --> 00:01:53,386
detection is no exception.

55
00:01:54,136 --> 00:01:54,886
We're going to have higher

56
00:01:54,886 --> 00:01:56,086
precision which means fewer

57
00:01:56,086 --> 00:01:57,686
false positives, but we are also

58
00:01:57,686 --> 00:01:58,906
going to have dramatically

59
00:01:59,326 --> 00:02:01,806
higher recall which means we'll

60
00:01:59,326 --> 00:02:01,806
higher recall which means we'll

61
00:02:01,806 --> 00:02:02,796
miss less faces.

62
00:02:03,286 --> 00:02:04,156
So, let's look at some of the

63
00:02:04,156 --> 00:02:05,986
examples of faces that we will

64
00:02:05,986 --> 00:02:07,446
now be able to detect with the

65
00:02:07,446 --> 00:02:08,106
Vision framework.

66
00:02:08,936 --> 00:02:10,515
For one thing, we'll be able to

67
00:02:10,515 --> 00:02:11,756
detect smaller faces.

68
00:02:13,936 --> 00:02:15,536
We'll also be doing a better job

69
00:02:15,536 --> 00:02:17,066
of detecting strong profiles.

70
00:02:19,516 --> 00:02:21,386
We'll also do a better job

71
00:02:21,846 --> 00:02:23,036
detecting more partially

72
00:02:23,036 --> 00:02:25,616
occluded faces and that includes

73
00:02:25,826 --> 00:02:27,276
things like hats and glasses.

74
00:02:27,276 --> 00:02:30,506
Sticking with the faces theme

75
00:02:30,506 --> 00:02:33,496
for a little longer, we now are

76
00:02:33,496 --> 00:02:34,786
offering in the Vision framework

77
00:02:34,786 --> 00:02:37,006
new this year face landmarks,

78
00:02:37,656 --> 00:02:38,596
what are face landmarks?

79
00:02:39,496 --> 00:02:41,026
This is a constellation of

80
00:02:41,026 --> 00:02:42,006
points that we detect on the

81
00:02:42,006 --> 00:02:43,696
facer, things like the corners

82
00:02:43,696 --> 00:02:45,036
of the eyes, the outline of the

83
00:02:45,036 --> 00:02:47,036
mouth, the contour of the chin.

84
00:02:48,316 --> 00:02:50,876
Here's an example, here's

85
00:02:50,876 --> 00:02:53,766
another example, and one more

86
00:02:53,766 --> 00:02:54,266
example.

87
00:02:55,396 --> 00:02:56,946
We're really excited about this

88
00:02:56,946 --> 00:02:57,956
I think there's going to be some

89
00:02:57,956 --> 00:02:59,056
great apps created with this

90
00:02:59,056 --> 00:02:59,596
technology.

91
00:03:01,996 --> 00:03:03,696
Next, also new this year in the

92
00:03:03,696 --> 00:03:04,776
Vision framework is image

93
00:03:04,776 --> 00:03:05,426
registration.

94
00:03:06,026 --> 00:03:07,176
If you don't know what image

95
00:03:07,176 --> 00:03:08,546
registration is it's basically

96
00:03:08,876 --> 00:03:11,126
aligning two images based on the

97
00:03:11,126 --> 00:03:12,226
features that are present in

98
00:03:12,226 --> 00:03:12,876
those images.

99
00:03:13,496 --> 00:03:15,826
You can use this for stitching

100
00:03:15,826 --> 00:03:17,166
together used for panorama kind

101
00:03:17,286 --> 00:03:18,686
of like this example or image

102
00:03:18,686 --> 00:03:19,726
stacking applications.

103
00:03:20,536 --> 00:03:22,406
We have two different kinds, one

104
00:03:22,406 --> 00:03:24,126
that's translation only and one

105
00:03:24,126 --> 00:03:24,756
that gives you for full

106
00:03:24,756 --> 00:03:27,176
homography for greater accuracy.

107
00:03:28,656 --> 00:03:31,136
We're also offering a few

108
00:03:31,136 --> 00:03:32,276
technologies that are already in

109
00:03:32,276 --> 00:03:33,566
our SDK through CIDetector

110
00:03:33,566 --> 00:03:34,406
interface.

111
00:03:34,796 --> 00:03:35,706
We're making them available in

112
00:03:35,706 --> 00:03:36,776
the Vision API as well.

113
00:03:36,896 --> 00:03:38,766
That includes rectangle

114
00:03:38,766 --> 00:03:40,516
detection as you can see, we

115
00:03:40,516 --> 00:03:42,296
detect the sign in the picture.

116
00:03:43,816 --> 00:03:45,566
We're also doing barcode

117
00:03:45,566 --> 00:03:46,776
detection and recognition in the

118
00:03:46,776 --> 00:03:50,726
Vision API and text detection as

119
00:03:52,256 --> 00:03:52,376
well.

120
00:03:53,766 --> 00:03:54,866
Another new technology,

121
00:03:55,116 --> 00:03:55,976
brand-new in the Vision

122
00:03:55,976 --> 00:03:56,986
framework this year is object

123
00:03:56,986 --> 00:03:57,366
tracking.

124
00:03:58,186 --> 00:04:00,576
You can use this to track a face

125
00:03:58,186 --> 00:04:00,576
You can use this to track a face

126
00:04:00,576 --> 00:04:01,726
if you've detected a face.

127
00:04:01,726 --> 00:04:03,246
You can use that face rectangle

128
00:04:03,246 --> 00:04:05,186
as an initial condition to the

129
00:04:05,186 --> 00:04:06,436
tracking and then the Vision

130
00:04:06,436 --> 00:04:07,756
framework will track that square

131
00:04:08,196 --> 00:04:09,056
throughout the rest of your

132
00:04:09,056 --> 00:04:09,446
video.

133
00:04:10,246 --> 00:04:12,486
Will also track rectangles and

134
00:04:12,486 --> 00:04:14,036
you can also define the initial

135
00:04:14,036 --> 00:04:15,036
condition yourself.

136
00:04:15,846 --> 00:04:17,426
So that's what I mean by general

137
00:04:17,426 --> 00:04:19,456
templates, if you decide to for

138
00:04:19,456 --> 00:04:21,305
example, put a square around

139
00:04:21,305 --> 00:04:24,656
this wakeboarder as I have, you

140
00:04:24,656 --> 00:04:27,116
can then go ahead and track

141
00:04:27,116 --> 00:04:27,376
that.

142
00:04:29,336 --> 00:04:30,556
You can see that we handle

143
00:04:30,556 --> 00:04:32,666
pretty large changes in scale,

144
00:04:32,756 --> 00:04:34,396
pretty large deformations fairly

145
00:04:34,396 --> 00:04:35,746
robustly with this technology.

146
00:04:39,096 --> 00:04:40,266
Another really exciting

147
00:04:41,296 --> 00:04:42,956
technology that's new in Apple's

148
00:04:42,956 --> 00:04:45,086
SDK this year Core ML and you

149
00:04:45,086 --> 00:04:46,126
can integrate your Core ML

150
00:04:46,126 --> 00:04:47,576
models directly into Vision.

151
00:04:48,236 --> 00:04:50,916
As I've mentioned, machine

152
00:04:50,916 --> 00:04:52,496
learning does great things for

153
00:04:52,496 --> 00:04:55,336
Computer Vision and you can use

154
00:04:55,336 --> 00:04:57,066
Core ML if you want to create

155
00:04:57,066 --> 00:04:58,166
your own models, do your own

156
00:04:58,166 --> 00:04:58,716
solution.

157
00:04:59,416 --> 00:05:01,246
Perhaps for example, you want to

158
00:04:59,416 --> 00:05:01,246
Perhaps for example, you want to

159
00:05:01,246 --> 00:05:02,476
create a wedding application

160
00:05:02,986 --> 00:05:06,316
where you're able to detect this

161
00:05:06,316 --> 00:05:08,006
part of the wedding is the

162
00:05:08,006 --> 00:05:08,956
reception, this part of the

163
00:05:08,956 --> 00:05:09,816
wedding is where the bride is

164
00:05:09,816 --> 00:05:10,686
walking down the aisle.

165
00:05:11,416 --> 00:05:12,456
If you want to train your own

166
00:05:12,456 --> 00:05:14,706
model and you have the data to

167
00:05:14,706 --> 00:05:17,196
train your own model you can do

168
00:05:17,196 --> 00:05:17,476
that.

169
00:05:18,556 --> 00:05:20,766
Core ML as I mentioned, provides

170
00:05:20,766 --> 00:05:22,116
native acceleration for custom

171
00:05:22,116 --> 00:05:23,206
models so they'll run really

172
00:05:23,206 --> 00:05:25,706
fast and Vision provides the

173
00:05:25,706 --> 00:05:26,876
imaging pipeline to support

174
00:05:26,876 --> 00:05:28,776
these models, so you won't have

175
00:05:28,776 --> 00:05:30,276
to do any rescaling or anything

176
00:05:30,276 --> 00:05:31,156
like that we'll take care of all

177
00:05:31,156 --> 00:05:31,586
that for you.

178
00:05:31,586 --> 00:05:33,106
We know what your model is

179
00:05:33,106 --> 00:05:34,476
expecting and we'll put the

180
00:05:34,476 --> 00:05:35,626
image in the right format.

181
00:05:37,596 --> 00:05:38,826
If you're interested in Core ML

182
00:05:38,826 --> 00:05:40,396
there's some sessions that you

183
00:05:40,396 --> 00:05:42,576
can go to, we've listed the labs

184
00:05:42,576 --> 00:05:43,306
down here for you.

185
00:05:43,866 --> 00:05:45,346
One of them will be tomorrow

186
00:05:45,346 --> 00:05:47,356
morning and then another one on

187
00:05:47,356 --> 00:05:47,986
Friday afternoon.

188
00:05:49,446 --> 00:05:51,386
So that's basically the features

189
00:05:51,386 --> 00:05:52,346
that are in the Vision

190
00:05:52,346 --> 00:05:52,796
framework.

191
00:05:54,236 --> 00:05:56,526
Overall, what Apple's new Vision

192
00:05:56,526 --> 00:05:58,306
framework provides are

193
00:05:58,766 --> 00:06:00,776
high-level on-device solutions

194
00:05:58,766 --> 00:06:00,776
high-level on-device solutions

195
00:06:01,306 --> 00:06:02,586
to Computer Vision problems

196
00:06:02,706 --> 00:06:03,756
through one simple API.

197
00:06:03,756 --> 00:06:06,576
Now let me break this statement

198
00:06:06,576 --> 00:06:08,266
down just a little bit.

199
00:06:09,276 --> 00:06:10,586
What do I mean by high-level

200
00:06:10,586 --> 00:06:11,186
solutions?

201
00:06:11,896 --> 00:06:14,336
Well we don't want you to have

202
00:06:14,336 --> 00:06:15,556
to be a Computer Vision expert

203
00:06:15,556 --> 00:06:16,876
to put the magic of Computer

204
00:06:16,876 --> 00:06:18,066
Vision into your applications.

205
00:06:18,656 --> 00:06:20,706
You don't want to necessarily

206
00:06:20,706 --> 00:06:22,216
have to know which feature

207
00:06:22,216 --> 00:06:23,636
detector you want to use in

208
00:06:23,636 --> 00:06:25,086
combination with what classifier

209
00:06:25,086 --> 00:06:26,966
or set of classifiers, we're

210
00:06:26,966 --> 00:06:28,366
going to handle that for you or

211
00:06:28,366 --> 00:06:29,196
whether or not you want to use

212
00:06:29,196 --> 00:06:30,216
machine learning for example.

213
00:06:30,976 --> 00:06:31,946
If you're a developer you're

214
00:06:32,326 --> 00:06:33,426
probably thinking I just want to

215
00:06:33,426 --> 00:06:34,246
know where the faces are.

216
00:06:35,626 --> 00:06:36,506
And so, we're going to handle

217
00:06:36,506 --> 00:06:37,666
all that complexity for you.

218
00:06:38,926 --> 00:06:42,166
Depending on your use case we'll

219
00:06:42,166 --> 00:06:43,896
be doing either traditional

220
00:06:43,896 --> 00:06:45,206
approach if that's what's needed

221
00:06:45,206 --> 00:06:46,846
for maybe real-time applications

222
00:06:46,846 --> 00:06:49,166
or deep learning algorithms for

223
00:06:49,416 --> 00:06:50,176
higher accuracy.

224
00:06:50,846 --> 00:06:54,186
Now I also mentioned that we're

225
00:06:54,186 --> 00:06:55,666
doing all these algorithms on

226
00:06:55,666 --> 00:06:58,116
the device, let's talk a little

227
00:06:58,116 --> 00:07:00,436
bit about why we'd want to do

228
00:06:58,116 --> 00:07:00,436
bit about why we'd want to do

229
00:07:00,436 --> 00:07:01,916
things on device versus provided

230
00:07:01,916 --> 00:07:02,906
a cloud-based solution.

231
00:07:03,396 --> 00:07:05,766
First of all, it's privacy.

232
00:07:06,866 --> 00:07:08,836
As you know, Apple cares a lot

233
00:07:08,836 --> 00:07:11,006
about privacy, I care a lot

234
00:07:11,006 --> 00:07:12,476
about privacy working at Apple,

235
00:07:12,796 --> 00:07:14,136
sometimes it makes my job a

236
00:07:14,136 --> 00:07:16,446
little harder, but nonetheless

237
00:07:17,026 --> 00:07:18,056
keeping all your data on the

238
00:07:18,056 --> 00:07:20,156
device is the best way to

239
00:07:20,156 --> 00:07:21,736
protect your user's data

240
00:07:21,736 --> 00:07:22,176
privacy.

241
00:07:24,456 --> 00:07:26,276
Furthermore, with certain

242
00:07:26,276 --> 00:07:28,036
cloud-based solutions there's a

243
00:07:28,036 --> 00:07:29,106
cost associated with it.

244
00:07:29,306 --> 00:07:31,616
If you're a developer maybe

245
00:07:31,616 --> 00:07:32,796
you're paying usage fees to use

246
00:07:32,796 --> 00:07:33,976
a cloud-based solution.

247
00:07:35,316 --> 00:07:37,146
Your users will have to transfer

248
00:07:37,146 --> 00:07:38,066
the data to that cloud.

249
00:07:39,516 --> 00:07:41,306
All these costs they can add up

250
00:07:41,306 --> 00:07:42,296
for both the developers and the

251
00:07:42,296 --> 00:07:42,726
users.

252
00:07:42,956 --> 00:07:44,506
So, when everything's on the

253
00:07:44,506 --> 00:07:45,586
device it's free.

254
00:07:45,816 --> 00:07:50,566
And you can support real-time

255
00:07:50,566 --> 00:07:51,966
use cases like the tracking

256
00:07:51,966 --> 00:07:52,756
example I showed you.

257
00:07:53,566 --> 00:07:54,616
Imagine trying to track

258
00:07:54,616 --> 00:07:55,536
something through a video by

259
00:07:55,536 --> 00:07:56,416
sending every frame to the

260
00:07:56,416 --> 00:07:57,926
cloud, I don't think that's

261
00:07:57,926 --> 00:07:58,556
going to work too well.

262
00:07:59,226 --> 00:08:01,456
So, no latency, fast execution

263
00:07:59,226 --> 00:08:01,456
So, no latency, fast execution

264
00:08:01,926 --> 00:08:02,946
that's what we're offering with

265
00:08:03,226 --> 00:08:03,896
the Vision framework.

266
00:08:04,786 --> 00:08:07,696
So, I hope you enjoyed that

267
00:08:08,076 --> 00:08:09,186
introduction, now we're going to

268
00:08:09,186 --> 00:08:12,226
go a little deeper and talk

269
00:08:12,226 --> 00:08:13,446
about the Vision concepts.

270
00:08:13,446 --> 00:08:13,996
For this part of the

271
00:08:13,996 --> 00:08:15,356
presentation I'm going to hand

272
00:08:15,356 --> 00:08:15,976
it off to Frank.

273
00:08:16,516 --> 00:08:19,566
[ Applause ]

274
00:08:20,066 --> 00:08:20,556
&gt;&gt; Thank you Brett.

275
00:08:22,956 --> 00:08:24,406
Hi, good afternoon, my name is

276
00:08:24,406 --> 00:08:25,466
Frank Doepke and I'm going to

277
00:08:25,466 --> 00:08:26,996
talk about more of the technical

278
00:08:26,996 --> 00:08:28,876
details what is part of our

279
00:08:28,876 --> 00:08:29,496
Vision framework.

280
00:08:29,796 --> 00:08:33,916
So, what do we want to do, when

281
00:08:33,916 --> 00:08:35,726
we want to analyze an image we

282
00:08:35,916 --> 00:08:37,836
have three major tasks that we

283
00:08:37,836 --> 00:08:39,816
actually want to perform.

284
00:08:40,275 --> 00:08:41,416
So, we [inaudible] finding out

285
00:08:41,416 --> 00:08:42,576
what is in the image and what do

286
00:08:42,576 --> 00:08:43,456
I want to know about it.

287
00:08:44,316 --> 00:08:45,356
There's the machinery,

288
00:08:46,076 --> 00:08:47,166
somebody's got to do the work

289
00:08:47,676 --> 00:08:48,956
and we get some results out of

290
00:08:48,956 --> 00:08:50,316
it, at least we hope that's

291
00:08:50,316 --> 00:08:51,206
what's going to happen.

292
00:08:52,106 --> 00:08:54,036
So, in terminology for Vision

293
00:08:54,036 --> 00:08:56,046
that means the asks these are

294
00:08:56,046 --> 00:08:56,836
requests.

295
00:08:57,476 --> 00:08:59,166
And I just did a few examples

296
00:08:59,166 --> 00:09:01,016
here like the barcode detection

297
00:08:59,166 --> 00:09:01,016
here like the barcode detection

298
00:09:01,016 --> 00:09:03,936
or face detection and we feed

299
00:09:03,936 --> 00:09:07,016
them into our request handler.

300
00:09:07,926 --> 00:09:08,996
That's the one in this case to

301
00:09:08,996 --> 00:09:10,106
be an image request and

302
00:09:10,176 --> 00:09:11,136
[inaudible] hold on to the image

303
00:09:11,446 --> 00:09:12,576
and it's going to do all the

304
00:09:12,576 --> 00:09:13,416
work for us.

305
00:09:14,066 --> 00:09:16,486
And as a result, we get back

306
00:09:16,526 --> 00:09:18,086
what we call observations, what

307
00:09:18,086 --> 00:09:19,446
did we observe in this image.

308
00:09:20,046 --> 00:09:21,666
And these observations depend on

309
00:09:21,666 --> 00:09:22,726
what you asked us to do.

310
00:09:23,006 --> 00:09:24,516
So, we have classification

311
00:09:24,516 --> 00:09:26,956
observation or detected objects.

312
00:09:27,786 --> 00:09:28,986
Now when you want to track

313
00:09:28,986 --> 00:09:30,076
something in the sequence like

314
00:09:30,076 --> 00:09:32,656
the wakeboarder it's basically

315
00:09:32,656 --> 00:09:33,466
the same concept.

316
00:09:33,566 --> 00:09:34,796
We have some asks, we have the

317
00:09:34,796 --> 00:09:36,376
machinery, and we get some

318
00:09:36,376 --> 00:09:39,096
results out of it in the end.

319
00:09:39,096 --> 00:09:40,826
Again, the asks are requests.

320
00:09:41,426 --> 00:09:42,936
Now since this changes with

321
00:09:42,936 --> 00:09:44,686
every frame the image actually

322
00:09:44,686 --> 00:09:45,926
travels with the request.

323
00:09:47,736 --> 00:09:48,936
Our machinery is again

324
00:09:48,936 --> 00:09:49,826
[inaudible] request handler it's

325
00:09:49,826 --> 00:09:52,506
the sequence request handler and

326
00:09:52,506 --> 00:09:54,046
we get results which are

327
00:09:54,046 --> 00:09:55,906
observations that go with our

328
00:09:55,976 --> 00:09:56,546
requests.

329
00:09:58,086 --> 00:10:00,866
So, let me talk a little bit

330
00:09:58,086 --> 00:10:00,866
So, let me talk a little bit

331
00:10:00,866 --> 00:10:02,066
more about these two image

332
00:10:02,066 --> 00:10:02,966
request handlers that I

333
00:10:02,966 --> 00:10:03,806
mentioned so far.

334
00:10:04,476 --> 00:10:05,606
So, we have the image request

335
00:10:05,606 --> 00:10:07,666
handler that is mostly if you

336
00:10:07,666 --> 00:10:09,026
want to do something interactive

337
00:10:09,026 --> 00:10:09,736
with the image.

338
00:10:10,166 --> 00:10:11,386
You want to do multiple Vision

339
00:10:11,386 --> 00:10:13,466
tasks on an image, sometimes you

340
00:10:13,466 --> 00:10:15,116
actually do one and then based

341
00:10:15,116 --> 00:10:16,566
on the results you then kick off

342
00:10:16,566 --> 00:10:17,926
the next one and that's what you

343
00:10:17,926 --> 00:10:19,016
want to use the image request

344
00:10:19,016 --> 00:10:19,486
handler for.

345
00:10:19,966 --> 00:10:21,296
It'll hold on to the image that

346
00:10:21,296 --> 00:10:22,446
it's set up with for its

347
00:10:22,446 --> 00:10:25,366
lifecycle and that allows us

348
00:10:25,396 --> 00:10:26,856
under the cover to do

349
00:10:26,856 --> 00:10:28,856
performance optimizations by

350
00:10:28,856 --> 00:10:30,996
holding on to intermediates to

351
00:10:31,146 --> 00:10:32,866
make these requests perform

352
00:10:32,866 --> 00:10:33,276
faster.

353
00:10:34,016 --> 00:10:36,466
On the flipside, if I want to

354
00:10:36,466 --> 00:10:37,726
track something we use the

355
00:10:37,726 --> 00:10:38,816
sequence request handler.

356
00:10:39,276 --> 00:10:40,516
The sequence request handler

357
00:10:40,516 --> 00:10:42,086
allows us to keep tracking

358
00:10:42,186 --> 00:10:42,996
[inaudible] in the sequence

359
00:10:42,996 --> 00:10:43,666
request handler.

360
00:10:44,316 --> 00:10:46,136
And it will not hold on to all

361
00:10:46,136 --> 00:10:47,466
the images that gets fed into it

362
00:10:47,466 --> 00:10:48,626
over its lifecycle so they get

363
00:10:48,626 --> 00:10:49,326
released earlier.

364
00:10:50,056 --> 00:10:51,536
But that means on the flipside,

365
00:10:51,776 --> 00:10:53,486
you cannot do the same

366
00:10:53,486 --> 00:10:54,866
optimizations if you want to do

367
00:10:54,866 --> 00:10:56,146
multiple requests on the same

368
00:10:56,146 --> 00:10:56,486
image.

369
00:10:57,716 --> 00:10:59,836
So how does this look in the

370
00:10:59,836 --> 00:11:01,596
code, we are developers that's

371
00:10:59,836 --> 00:11:01,596
code, we are developers that's

372
00:11:01,596 --> 00:11:02,526
what we want to see.

373
00:11:04,116 --> 00:11:05,606
So, we start as a blank slate

374
00:11:05,606 --> 00:11:07,316
that's always good and then we

375
00:11:07,316 --> 00:11:08,446
create a request.

376
00:11:08,886 --> 00:11:10,466
In this case, it's a face

377
00:11:10,466 --> 00:11:12,746
detection request.

378
00:11:13,346 --> 00:11:14,496
Now we create the request

379
00:11:14,496 --> 00:11:16,546
handler, what I'm choosing here

380
00:11:16,546 --> 00:11:17,816
is a request handler based on

381
00:11:17,816 --> 00:11:19,216
the files so I have a file on

382
00:11:19,216 --> 00:11:22,556
disk that I want to use.

383
00:11:22,556 --> 00:11:24,026
Now I ask myRequestHandler to

384
00:11:24,026 --> 00:11:25,646
perform my request and this in

385
00:11:25,646 --> 00:11:27,566
this case [inaudible] it's just

386
00:11:27,566 --> 00:11:29,716
one request I have my array, but

387
00:11:29,716 --> 00:11:32,746
it could be many and I get my

388
00:11:32,906 --> 00:11:33,836
observations back.

389
00:11:34,996 --> 00:11:36,606
And this can be many faces that

390
00:11:36,606 --> 00:11:37,266
I detected.

391
00:11:37,836 --> 00:11:39,216
Now the one thing I would like

392
00:11:39,216 --> 00:11:42,746
to highlight here is the results

393
00:11:43,006 --> 00:11:45,036
come back as part of the request

394
00:11:45,156 --> 00:11:46,076
that we actually set up

395
00:11:46,076 --> 00:11:46,526
initially.

396
00:11:46,526 --> 00:11:49,916
How does it look when we want to

397
00:11:51,076 --> 00:11:52,506
track something?

398
00:11:52,616 --> 00:11:53,946
We create a sequence request

399
00:11:54,966 --> 00:11:55,776
handler [inaudible] of course

400
00:11:55,776 --> 00:11:57,026
not set up as an image because

401
00:11:57,216 --> 00:11:58,236
we have to [inaudible] all the

402
00:11:58,236 --> 00:11:59,656
frames of the sequence.

403
00:12:01,476 --> 00:12:02,326
So, I started with an

404
00:12:02,326 --> 00:12:03,906
observation that I got from the

405
00:12:03,906 --> 00:12:05,906
previous detection or I mark

406
00:12:05,956 --> 00:12:07,596
something up and I create my

407
00:12:07,596 --> 00:12:09,276
tracking request.

408
00:12:09,826 --> 00:12:12,026
And I simply have to run the

409
00:12:12,026 --> 00:12:12,596
request.

410
00:12:13,246 --> 00:12:15,036
And I feed in in this case as a

411
00:12:15,036 --> 00:12:17,026
pixel buffer the frame that is

412
00:12:17,026 --> 00:12:17,996
currently being dragged.

413
00:12:19,406 --> 00:12:21,176
And out of it again I get some

414
00:12:21,176 --> 00:12:21,616
results.

415
00:12:22,246 --> 00:12:25,246
So, now that we have talked

416
00:12:25,246 --> 00:12:26,816
about how this API is kind of

417
00:12:26,816 --> 00:12:28,426
structured I would like to guide

418
00:12:28,426 --> 00:12:30,066
you through some best practices

419
00:12:30,066 --> 00:12:31,616
so that you get, you know, the

420
00:12:31,616 --> 00:12:33,006
best experience out of Vision.

421
00:12:33,666 --> 00:12:37,456
So, when we want to put together

422
00:12:37,456 --> 00:12:38,936
a Computer Vision task you have

423
00:12:38,936 --> 00:12:39,886
to think about a few things.

424
00:12:41,476 --> 00:12:43,216
Number one, what is the right

425
00:12:43,216 --> 00:12:44,586
image type that I want to use.

426
00:12:45,826 --> 00:12:47,876
Number two, what am I going to

427
00:12:47,876 --> 00:12:48,746
do with the image.

428
00:12:50,396 --> 00:12:52,196
And number three, what

429
00:12:52,226 --> 00:12:53,496
performance do I need or want.

430
00:12:53,496 --> 00:12:54,346
Of course, you always want

431
00:12:54,346 --> 00:12:55,346
fastest, but there are some

432
00:12:55,346 --> 00:12:56,356
tradeoffs that you have to think

433
00:12:56,356 --> 00:12:56,636
about.

434
00:12:57,026 --> 00:12:59,136
So, let's talk about the image

435
00:13:00,526 --> 00:13:00,636
type.

436
00:13:00,846 --> 00:13:02,346
Vision supports a number of

437
00:13:02,346 --> 00:13:04,196
image types and they range from

438
00:13:04,196 --> 00:13:06,836
CVPixelBuffer, CGIImage or even

439
00:13:06,836 --> 00:13:09,276
as we saw in the previous

440
00:13:09,276 --> 00:13:11,446
example just from data that I

441
00:13:11,446 --> 00:13:12,606
use in NSURL.

442
00:13:13,216 --> 00:13:15,776
And we go over all these types

443
00:13:15,886 --> 00:13:17,076
in the following slides so that

444
00:13:17,076 --> 00:13:18,396
you know what to choose when.

445
00:13:20,556 --> 00:13:22,756
Which to choose depends a lot of

446
00:13:22,756 --> 00:13:23,916
like what you want to do.

447
00:13:23,916 --> 00:13:25,836
If you run from a camera stream

448
00:13:25,836 --> 00:13:27,596
or if you run from files on disk

449
00:13:28,346 --> 00:13:29,996
you have to look at that

450
00:13:30,096 --> 00:13:31,396
[inaudible] kind of which type

451
00:13:31,396 --> 00:13:32,856
of image you want to use.

452
00:13:33,246 --> 00:13:34,536
Now two important things to

453
00:13:34,536 --> 00:13:37,576
remember is we already have an

454
00:13:37,666 --> 00:13:39,206
imaging pipeline in the Vision

455
00:13:39,206 --> 00:13:41,076
framework you don't need to

456
00:13:41,076 --> 00:13:42,006
scale the images.

457
00:13:42,406 --> 00:13:43,616
So, unless you already have a

458
00:13:43,616 --> 00:13:44,926
very small representation that

459
00:13:44,926 --> 00:13:45,806
you absolutely want to use,

460
00:13:45,856 --> 00:13:47,136
please don't pre-scale because

461
00:13:47,246 --> 00:13:50,476
we'll just do the work twice.

462
00:13:50,666 --> 00:13:52,356
And mind the orientation.

463
00:13:52,526 --> 00:13:54,086
Computer Vision algorithms are

464
00:13:54,086 --> 00:13:57,056
mostly not, you know, sensitive

465
00:13:57,056 --> 00:13:59,226
to orientation or sorry, they

466
00:13:59,356 --> 00:14:01,176
are sensitive to orientation so

467
00:13:59,356 --> 00:14:01,176
are sensitive to orientation so

468
00:14:01,236 --> 00:14:02,576
you have to pass that in.

469
00:14:03,166 --> 00:14:04,586
And that is an important part

470
00:14:04,586 --> 00:14:05,676
because if you pass in a

471
00:14:05,816 --> 00:14:07,206
portrait image that's actually

472
00:14:07,206 --> 00:14:08,166
lying on its side we will not

473
00:14:08,166 --> 00:14:09,616
find the faces and that's one of

474
00:14:09,616 --> 00:14:10,996
the common mistakes that usually

475
00:14:10,996 --> 00:14:11,386
happens.

476
00:14:12,906 --> 00:14:14,396
So, I promised to go over the

477
00:14:14,396 --> 00:14:14,846
types.

478
00:14:15,796 --> 00:14:16,696
When you want to do something

479
00:14:16,696 --> 00:14:17,866
streaming we want to use the

480
00:14:17,866 --> 00:14:18,746
CVPixelBuffer.

481
00:14:19,906 --> 00:14:21,956
When you create a VideoDataOut

482
00:14:21,956 --> 00:14:23,206
[inaudible] capture you will get

483
00:14:23,286 --> 00:14:24,776
CMSampleBuffers and through

484
00:14:24,916 --> 00:14:25,806
those we get your

485
00:14:25,866 --> 00:14:26,686
CVPixelBuffers.

486
00:14:27,856 --> 00:14:29,456
It's also a pretty good format

487
00:14:29,456 --> 00:14:30,886
if you already have something

488
00:14:30,886 --> 00:14:32,806
where you keep your image data

489
00:14:32,806 --> 00:14:34,376
raw in memory like it's LGB

490
00:14:34,376 --> 00:14:35,936
pixels and wrap them into a

491
00:14:35,936 --> 00:14:37,276
CVPixelBuffer this is a great

492
00:14:37,276 --> 00:14:38,496
format to pass into Vision.

493
00:14:40,666 --> 00:14:41,976
When you get files from disk

494
00:14:42,146 --> 00:14:44,046
please use the URL or if it

495
00:14:44,046 --> 00:14:44,996
comes from the web use the

496
00:14:44,996 --> 00:14:46,926
NSData path.

497
00:14:47,126 --> 00:14:48,886
The great thing about that is it

498
00:14:48,886 --> 00:14:50,796
really allows us to reduce the

499
00:14:50,796 --> 00:14:51,936
memory for print in your

500
00:14:51,936 --> 00:14:52,616
application.

501
00:14:53,086 --> 00:14:54,566
Vision will only read what it

502
00:14:54,566 --> 00:14:56,236
needs to perform the task.

503
00:14:57,156 --> 00:14:58,256
If you think about you want to

504
00:14:58,256 --> 00:14:59,226
do face detection on a

505
00:14:59,226 --> 00:15:02,376
64-megapixel panorama Vision

506
00:14:59,226 --> 00:15:02,376
64-megapixel panorama Vision

507
00:15:02,376 --> 00:15:03,526
will actually reduce your memory

508
00:15:03,526 --> 00:15:04,936
for it, but not reading the full

509
00:15:04,936 --> 00:15:06,436
file actually into the memory

510
00:15:06,436 --> 00:15:07,466
and that is an important thing

511
00:15:07,466 --> 00:15:08,136
to keep in mind.

512
00:15:10,396 --> 00:15:12,006
We will read in this case the

513
00:15:12,006 --> 00:15:13,336
EXIF Orientation out of the

514
00:15:13,336 --> 00:15:15,336
file, but you can override it if

515
00:15:15,336 --> 00:15:17,266
you have to for those formats

516
00:15:17,266 --> 00:15:18,706
that don't support it.

517
00:15:20,666 --> 00:15:22,126
If you're already using Core

518
00:15:22,166 --> 00:15:24,076
Image in your application by all

519
00:15:24,076 --> 00:15:25,286
means process the CI image.

520
00:15:25,286 --> 00:15:27,366
This is also important when you

521
00:15:27,366 --> 00:15:28,096
want to actually do some

522
00:15:28,096 --> 00:15:28,806
preprocessing.

523
00:15:28,806 --> 00:15:29,786
If you have some domain

524
00:15:29,786 --> 00:15:30,946
knowledge of what you want to do

525
00:15:30,946 --> 00:15:33,286
in your Computer Vision task you

526
00:15:33,286 --> 00:15:34,506
can do some preprocessing and

527
00:15:34,506 --> 00:15:35,766
try and enhance the image and,

528
00:15:35,806 --> 00:15:37,186
therefore, enhance the Vision

529
00:15:37,186 --> 00:15:37,716
results.

530
00:15:39,346 --> 00:15:40,316
If you want to learn a bit more

531
00:15:40,316 --> 00:15:42,706
about Core Image, there's a

532
00:15:42,706 --> 00:15:45,006
session on Thursday at 1:50 and

533
00:15:45,396 --> 00:15:46,146
they will also show the

534
00:15:46,146 --> 00:15:47,836
integration with our Vision

535
00:15:47,836 --> 00:15:48,286
framework.

536
00:15:48,756 --> 00:15:52,276
Last but not least, if you have

537
00:15:52,276 --> 00:15:54,246
all the images in your UI you

538
00:15:54,426 --> 00:15:56,346
can use the CG image [inaudible]

539
00:15:56,716 --> 00:15:59,116
out of the NS image or the UI

540
00:15:59,226 --> 00:16:01,196
images let's say it comes from

541
00:15:59,226 --> 00:16:01,196
images let's say it comes from

542
00:16:01,196 --> 00:16:02,906
the UI image picker and pass

543
00:16:02,976 --> 00:16:03,686
those into Vision.

544
00:16:03,806 --> 00:16:07,006
Now what am I going to do with

545
00:16:07,096 --> 00:16:08,496
the image and that's where we

546
00:16:08,496 --> 00:16:10,236
have to decide if I want to do

547
00:16:10,236 --> 00:16:11,346
something interactive with the

548
00:16:11,426 --> 00:16:13,206
image in that case I use my

549
00:16:13,206 --> 00:16:14,336
ImageRequestHandler.

550
00:16:14,606 --> 00:16:16,226
It will hold on to the image for

551
00:16:16,226 --> 00:16:17,926
the time and I can do multiple

552
00:16:17,926 --> 00:16:19,656
passes on that image and get the

553
00:16:19,656 --> 00:16:20,866
best results out of that.

554
00:16:22,126 --> 00:16:23,426
Now the CVPixelBuffer

555
00:16:23,426 --> 00:16:24,926
technically will allow you that

556
00:16:24,926 --> 00:16:26,826
you could change the pixels

557
00:16:27,226 --> 00:16:28,216
[inaudible], but we see them as

558
00:16:28,216 --> 00:16:29,756
immutable so don't do that

559
00:16:29,756 --> 00:16:30,776
because we'll get some strange

560
00:16:30,776 --> 00:16:31,246
results.

561
00:16:31,546 --> 00:16:35,406
Next, if you want to track

562
00:16:35,606 --> 00:16:36,816
something we use the

563
00:16:36,816 --> 00:16:38,156
SequenceRequestHandler.

564
00:16:39,636 --> 00:16:40,506
It allows us to keep the

565
00:16:40,506 --> 00:16:42,946
tracking state and lifecycle of

566
00:16:42,946 --> 00:16:44,676
my image is not tied to those

567
00:16:44,736 --> 00:16:46,256
requests handler anymore, but

568
00:16:46,296 --> 00:16:47,576
just how long it needs it for

569
00:16:47,576 --> 00:16:47,976
the tracking.

570
00:16:52,176 --> 00:16:53,976
Performance, so these Vision

571
00:16:53,976 --> 00:16:55,796
tasks are computationally

572
00:16:55,796 --> 00:16:57,726
intensive very often and they do

573
00:16:57,726 --> 00:16:59,056
take time, so you have to think

574
00:16:59,056 --> 00:17:01,486
about that you want to actually

575
00:16:59,056 --> 00:17:01,486
about that you want to actually

576
00:17:01,486 --> 00:17:03,376
run your task on a different

577
00:17:03,856 --> 00:17:05,465
queue not your main queue.

578
00:17:06,616 --> 00:17:08,296
And think about if you want to

579
00:17:08,296 --> 00:17:09,376
do it in the background, which

580
00:17:09,376 --> 00:17:11,086
is a bit slower or if you need

581
00:17:11,086 --> 00:17:12,356
it very quickly use a more

582
00:17:12,356 --> 00:17:13,915
interactive quality of service

583
00:17:14,366 --> 00:17:15,516
to get the performance.

584
00:17:16,596 --> 00:17:19,276
A good practice is to use the

585
00:17:19,276 --> 00:17:22,026
completion handler to get the

586
00:17:22,056 --> 00:17:23,606
results back, this is part of

587
00:17:23,606 --> 00:17:24,026
our API.

588
00:17:24,026 --> 00:17:26,165
But keep in mind that this

589
00:17:26,215 --> 00:17:27,866
completion handler gets called

590
00:17:27,915 --> 00:17:29,236
on that queue in which you

591
00:17:29,236 --> 00:17:30,686
actually set it off.

592
00:17:30,686 --> 00:17:32,576
So, if you need to update your

593
00:17:32,576 --> 00:17:33,936
UI you have to dispatch that

594
00:17:33,936 --> 00:17:34,746
back to the main queue.

595
00:17:35,426 --> 00:17:38,796
So as Brett already highlighted,

596
00:17:38,796 --> 00:17:40,036
we have a new face detection and

597
00:17:40,036 --> 00:17:41,206
you might say oh God, yet

598
00:17:41,206 --> 00:17:41,706
another one.

599
00:17:43,946 --> 00:17:45,156
But we have good reasons for

600
00:17:45,156 --> 00:17:45,446
this.

601
00:17:45,706 --> 00:17:47,546
Vision uses deep learning and

602
00:17:47,546 --> 00:17:48,976
this gives us really a lot

603
00:17:49,186 --> 00:17:50,516
better precision and recall,

604
00:17:50,926 --> 00:17:52,366
therefore, much better results.

605
00:17:52,916 --> 00:17:55,826
The downside of it, on older

606
00:17:55,826 --> 00:17:56,976
hardware it will run a bit

607
00:17:56,976 --> 00:17:57,356
slower.

608
00:17:57,436 --> 00:17:58,946
So, let's look a little bit at

609
00:17:58,946 --> 00:18:01,006
our overall landscape of face

610
00:17:58,946 --> 00:18:01,006
our overall landscape of face

611
00:18:01,006 --> 00:18:01,926
detectors that we have

612
00:18:01,926 --> 00:18:02,476
available.

613
00:18:03,236 --> 00:18:04,876
So, we have Vision which really

614
00:18:04,876 --> 00:18:06,346
gives us the best results and

615
00:18:06,346 --> 00:18:08,736
it's pretty fast and also pretty

616
00:18:08,736 --> 00:18:09,966
good in its power use as it is

617
00:18:09,966 --> 00:18:10,926
optimized for that.

618
00:18:11,246 --> 00:18:12,766
And we have it available on all

619
00:18:12,766 --> 00:18:14,376
platforms except the watchOS.

620
00:18:15,446 --> 00:18:16,886
And this is the same in terms of

621
00:18:16,886 --> 00:18:18,566
availability for Core Image and

622
00:18:18,566 --> 00:18:19,686
it's a bit faster, but the

623
00:18:19,686 --> 00:18:21,106
results are not quite as good.

624
00:18:21,736 --> 00:18:24,266
In the AV capture session which

625
00:18:24,266 --> 00:18:25,536
is only happening during the

626
00:18:25,536 --> 00:18:27,016
capture side we can actually use

627
00:18:27,016 --> 00:18:28,436
hardware so it's really fast in

628
00:18:28,436 --> 00:18:30,176
performance, but the results

629
00:18:30,176 --> 00:18:31,666
again are not as good as we get

630
00:18:31,666 --> 00:18:31,976
out of Vision.

631
00:18:32,466 --> 00:18:34,006
So, you have to choose depending

632
00:18:34,006 --> 00:18:35,286
on your application what you

633
00:18:35,286 --> 00:18:36,996
want to do choose the right

634
00:18:36,996 --> 00:18:38,146
technology for the face

635
00:18:38,146 --> 00:18:38,566
detection.

636
00:18:40,406 --> 00:18:41,446
Now I did mention that our

637
00:18:41,446 --> 00:18:43,056
quality is better, so let me try

638
00:18:43,056 --> 00:18:44,096
to prove that a little bit.

639
00:18:44,576 --> 00:18:46,796
So, I have here an image and I

640
00:18:46,796 --> 00:18:47,896
ran the face detection through

641
00:18:47,896 --> 00:18:48,506
Core Image.

642
00:18:48,976 --> 00:18:50,956
And we find two faces and we see

643
00:18:50,956 --> 00:18:53,056
roughly where the eyes and where

644
00:18:53,656 --> 00:18:55,126
the mouth are.

645
00:18:55,396 --> 00:18:56,986
Now in Vision we find all four

646
00:18:56,986 --> 00:18:58,496
faces even the occluded ones and

647
00:18:58,496 --> 00:18:59,986
we get a whole lot more details

648
00:19:00,036 --> 00:19:03,196
with the visual landmarks.

649
00:19:04,356 --> 00:19:05,486
Speaking of Core Image, I would

650
00:19:05,486 --> 00:19:06,426
like to highlight a little bit

651
00:19:06,426 --> 00:19:07,306
what's happening with the

652
00:19:07,386 --> 00:19:08,046
CIDetectors.

653
00:19:08,076 --> 00:19:11,456
So, whoever uses it already can

654
00:19:11,456 --> 00:19:12,536
keep on using them they are

655
00:19:12,536 --> 00:19:15,596
still in Core Image, but all new

656
00:19:15,596 --> 00:19:17,136
parts and all the improvements

657
00:19:17,136 --> 00:19:18,296
in terms of algorithms for

658
00:19:18,296 --> 00:19:20,216
computer moving forward will be

659
00:19:20,216 --> 00:19:22,046
in Vision that's the new home

660
00:19:22,046 --> 00:19:22,946
for Computer Vision.

661
00:19:23,546 --> 00:19:28,126
So, an awful lot of sides, how

662
00:19:28,126 --> 00:19:28,656
about a demo.

663
00:19:29,606 --> 00:19:30,826
So, what I'm going to show you

664
00:19:30,826 --> 00:19:33,756
is an application that runs an

665
00:19:33,756 --> 00:19:35,726
AV capture session on the device

666
00:19:35,996 --> 00:19:37,256
if the demo Gods are with us.

667
00:19:37,896 --> 00:19:39,936
And we will do a very simple

668
00:19:39,936 --> 00:19:41,296
rectangle detection request.

669
00:19:42,376 --> 00:19:43,916
So, what do I have to do to set

670
00:19:43,916 --> 00:19:44,296
this up?

671
00:19:46,156 --> 00:19:48,386
What you see here is I create my

672
00:19:48,386 --> 00:19:52,136
request, that's my simple

673
00:19:52,136 --> 00:19:54,516
rectangle detection request in

674
00:19:55,886 --> 00:19:56,816
this case.

675
00:19:56,996 --> 00:19:58,376
I'm actually in the wrong sample

676
00:19:58,376 --> 00:19:59,416
that's why I'm getting confused

677
00:19:59,416 --> 00:19:59,826
here, my apologies.

678
00:20:00,356 --> 00:20:02,516
Here we go.

679
00:20:02,546 --> 00:20:03,826
Okay we have our rectangle

680
00:20:03,826 --> 00:20:05,956
detection request and I'm

681
00:20:05,956 --> 00:20:07,406
setting some parameters just as

682
00:20:07,406 --> 00:20:08,856
an example here, I only want

683
00:20:08,856 --> 00:20:10,626
them this minimum size in our

684
00:20:10,626 --> 00:20:11,946
coordinates are normalized so I

685
00:20:11,946 --> 00:20:13,796
only want a 10% minimize size of

686
00:20:13,796 --> 00:20:16,666
the image and I just want 20

687
00:20:16,666 --> 00:20:17,206
rectangles.

688
00:20:17,436 --> 00:20:19,036
I could get more, but I want 20,

689
00:20:19,036 --> 00:20:20,156
I just picked a number.

690
00:20:21,386 --> 00:20:23,086
I set up my area of the request

691
00:20:23,116 --> 00:20:25,986
that I want to perform and the

692
00:20:26,236 --> 00:20:28,506
right here this is our

693
00:20:28,676 --> 00:20:30,616
completion handler and all that

694
00:20:30,616 --> 00:20:32,326
I'm going to do is I'm going to

695
00:20:32,326 --> 00:20:34,406
draw my rectangles, but as you

696
00:20:34,406 --> 00:20:35,816
notice I'm just patching it to

697
00:20:35,816 --> 00:20:37,826
the main queue to update our UI.

698
00:20:39,176 --> 00:20:40,216
Where do our images come from?

699
00:20:40,216 --> 00:20:41,736
So, we look at the capture

700
00:20:41,736 --> 00:20:45,526
output here and as I promised,

701
00:20:45,666 --> 00:20:47,006
in the capture output we get our

702
00:20:47,006 --> 00:20:48,566
pixelBuffer from the

703
00:20:48,566 --> 00:20:49,606
CMSampleBuffer.

704
00:20:50,376 --> 00:20:54,276
Right here I'm getting the

705
00:20:54,276 --> 00:20:55,166
cameraIntrinsics.

706
00:20:55,166 --> 00:20:56,496
Now this is something that is

707
00:20:56,596 --> 00:20:57,606
important in some of these

708
00:20:57,656 --> 00:20:58,816
Computer Vision paths where we

709
00:20:58,816 --> 00:21:00,126
actually know what the camera is

710
00:20:58,816 --> 00:21:00,126
actually know what the camera is

711
00:21:00,126 --> 00:21:00,866
kind of looking at.

712
00:21:02,406 --> 00:21:04,206
As I mentioned, we don't forget

713
00:21:04,206 --> 00:21:06,446
the acts of orientation and I

714
00:21:06,446 --> 00:21:07,876
create an image request handler

715
00:21:08,026 --> 00:21:09,696
and perform our tasks.

716
00:21:09,696 --> 00:21:10,636
So, how does this look when we

717
00:21:10,636 --> 00:21:11,886
actually run it?

718
00:21:12,156 --> 00:21:13,006
All right, so what we're going

719
00:21:13,006 --> 00:21:14,296
to see here is that now we

720
00:21:14,586 --> 00:21:16,516
tracked this rectangle and

721
00:21:16,516 --> 00:21:17,906
that's as simple as it is, we

722
00:21:17,906 --> 00:21:19,386
can find other rectangles.

723
00:21:20,896 --> 00:21:22,036
If the cable is long enough we

724
00:21:22,036 --> 00:21:23,076
can actually look oh, there we

725
00:21:23,076 --> 00:21:24,406
find a computer with various

726
00:21:24,406 --> 00:21:24,906
rectangles.

727
00:21:25,516 --> 00:21:27,976
Now I chose the yellow kind of

728
00:21:27,976 --> 00:21:29,666
on purpose because it's the same

729
00:21:29,666 --> 00:21:31,456
color as you saw in the demo

730
00:21:31,726 --> 00:21:33,246
during the keynote for the new

731
00:21:33,246 --> 00:21:34,516
document camera on notes.

732
00:21:34,576 --> 00:21:36,536
And I borrowed their color

733
00:21:36,536 --> 00:21:37,706
because they borrowed our code

734
00:21:37,706 --> 00:21:38,686
to do actually the rectangle

735
00:21:38,686 --> 00:21:38,976
detection.

736
00:21:39,516 --> 00:21:44,636
[ Applause ]

737
00:21:45,136 --> 00:21:45,876
Thank you.

738
00:21:46,016 --> 00:21:48,000
[ Applause ]

739
00:21:51,046 --> 00:21:52,516
Now that was simple, let's do a

740
00:21:52,516 --> 00:21:52,916
bit more.

741
00:21:56,396 --> 00:21:58,746
So, how about we throw some

742
00:21:58,746 --> 00:22:00,096
machine learning at this as well

743
00:21:58,746 --> 00:22:00,096
machine learning at this as well

744
00:22:00,096 --> 00:22:01,286
just for the fun of it.

745
00:22:01,956 --> 00:22:03,776
So, what I have to do is I have

746
00:22:03,776 --> 00:22:06,136
a little model that I just

747
00:22:06,196 --> 00:22:07,566
dragged into my project here.

748
00:22:14,156 --> 00:22:16,456
And that is a classifier that

749
00:22:16,456 --> 00:22:17,576
will tell us a bit something

750
00:22:17,576 --> 00:22:18,276
about the image.

751
00:22:19,456 --> 00:22:21,726
And we see when we look at this

752
00:22:21,726 --> 00:22:25,536
part here that we need to feed

753
00:22:25,536 --> 00:22:27,116
it an image of a very strange

754
00:22:27,116 --> 00:22:30,556
size and get out of it some

755
00:22:30,556 --> 00:22:31,416
classification.

756
00:22:32,496 --> 00:22:33,596
Now you don't need to worry

757
00:22:33,596 --> 00:22:35,886
about that size because Vision

758
00:22:35,886 --> 00:22:37,006
will do the work for you.

759
00:22:37,006 --> 00:22:43,026
So, what do I need to do?

760
00:22:43,626 --> 00:22:46,076
I first need to create a Vision

761
00:22:46,076 --> 00:22:48,226
model and my request with that.

762
00:22:48,286 --> 00:22:50,326
And that is the part that we

763
00:22:50,326 --> 00:22:52,736
have here, so I'm simply loading

764
00:22:52,736 --> 00:22:56,166
the inception model and I create

765
00:22:56,166 --> 00:22:57,456
my classification request.

766
00:22:58,726 --> 00:22:59,476
Now it tells me there's

767
00:22:59,476 --> 00:23:00,696
something missing and I will get

768
00:22:59,476 --> 00:23:00,696
something missing and I will get

769
00:23:00,696 --> 00:23:01,706
to that in just a moment.

770
00:23:01,996 --> 00:23:03,256
The last thing I want to

771
00:23:03,256 --> 00:23:05,006
highlight here is it says that

772
00:23:05,366 --> 00:23:06,956
it was okay square image, but

773
00:23:06,956 --> 00:23:09,446
our cameras don't see squares so

774
00:23:09,446 --> 00:23:10,786
I need to tell it actually how

775
00:23:10,786 --> 00:23:12,586
to handle just, you know, the

776
00:23:12,586 --> 00:23:14,136
aspect ratio that I want to use.

777
00:23:14,136 --> 00:23:15,636
And I say okay I want to just

778
00:23:15,636 --> 00:23:15,976
send a crop.

779
00:23:20,276 --> 00:23:22,636
So, I need a completion handler

780
00:23:22,636 --> 00:23:26,246
for my task and I have that

781
00:23:26,246 --> 00:23:28,336
already pre canned here as well.

782
00:23:30,496 --> 00:23:31,806
So, in this completion handler I

783
00:23:31,806 --> 00:23:33,296
simply look at my observation

784
00:23:33,296 --> 00:23:34,656
and I will get so this

785
00:23:34,696 --> 00:23:36,216
classifier can see a thousand

786
00:23:36,216 --> 00:23:37,876
different things and I don't

787
00:23:37,876 --> 00:23:39,206
want to show all of them I only

788
00:23:39,376 --> 00:23:40,816
show the ones that I care about.

789
00:23:40,816 --> 00:23:42,576
So, what I'm doing is a little

790
00:23:42,576 --> 00:23:43,516
bit of filtering, I only take

791
00:23:43,516 --> 00:23:46,216
the top four and I only look at

792
00:23:46,216 --> 00:23:47,706
the ones that have a confidence

793
00:23:47,706 --> 00:23:49,676
of at least 30%, it just works

794
00:23:49,676 --> 00:23:50,946
well for my demo here, but you

795
00:23:50,946 --> 00:23:52,126
know you will figure out what

796
00:23:52,126 --> 00:23:53,356
kind of works well for your

797
00:23:53,356 --> 00:23:53,696
model.

798
00:23:54,036 --> 00:23:57,286
And all I have to do next is add

799
00:23:58,016 --> 00:24:01,136
my classification request into

800
00:23:58,016 --> 00:24:01,136
my classification request into

801
00:24:01,136 --> 00:24:02,516
my area of request and now I

802
00:24:02,516 --> 00:24:05,346
will actually run two requests.

803
00:24:06,026 --> 00:24:07,416
So, I have this already loaded

804
00:24:07,416 --> 00:24:09,886
on my device, let's see how this

805
00:24:09,886 --> 00:24:11,196
actually looks.

806
00:24:12,156 --> 00:24:13,526
Of course, you will see it when

807
00:24:13,526 --> 00:24:14,826
I switch to the correct machine,

808
00:24:15,386 --> 00:24:15,686
there we go.

809
00:24:22,046 --> 00:24:25,056
Okay, so we have a coffee mug

810
00:24:25,456 --> 00:24:27,016
which is empty, somebody better

811
00:24:27,016 --> 00:24:27,966
fill that for me.

812
00:24:27,966 --> 00:24:33,066
We have a ballpoint pen, we have

813
00:24:33,066 --> 00:24:37,616
a padlock and look an iPod.

814
00:24:38,396 --> 00:24:44,076
Who has stolen those empty cards

815
00:24:44,076 --> 00:24:45,436
away and didn't realize it was

816
00:24:45,436 --> 00:24:45,976
an iPod?

817
00:24:46,516 --> 00:24:49,500
[ Applause ]

818
00:24:53,056 --> 00:24:54,676
All right, let's go back to the

819
00:24:54,676 --> 00:24:58,096
slides before we get to the next

820
00:24:58,096 --> 00:24:59,406
show-and-tell.

821
00:25:00,456 --> 00:25:01,846
For my next demo, I want to do

822
00:25:01,846 --> 00:25:02,976
something a little bit more

823
00:25:02,976 --> 00:25:06,516
elaborate and with that I chose

824
00:25:06,516 --> 00:25:07,246
something that's called

825
00:25:07,246 --> 00:25:08,006
MNISTVision.

826
00:25:09,486 --> 00:25:10,876
People in the machine learning

827
00:25:10,876 --> 00:25:12,296
community have already looked at

828
00:25:12,296 --> 00:25:13,376
that a little bit more.

829
00:25:13,566 --> 00:25:15,766
MNIST is a dataset where a bunch

830
00:25:15,766 --> 00:25:17,076
of government employees and high

831
00:25:17,076 --> 00:25:18,536
school students wrote numbers

832
00:25:18,596 --> 00:25:21,086
down and this was marked up and

833
00:25:21,146 --> 00:25:22,106
people were trained in our

834
00:25:22,106 --> 00:25:23,166
classifier on that.

835
00:25:23,796 --> 00:25:25,156
Note this is basically like

836
00:25:25,156 --> 00:25:26,326
white numbers on black

837
00:25:26,396 --> 00:25:28,336
background, so I guess they've

838
00:25:28,336 --> 00:25:30,626
written it with chalk on an old

839
00:25:30,666 --> 00:25:31,136
blackboard.

840
00:25:32,516 --> 00:25:34,346
So, in this sample code I'm

841
00:25:34,346 --> 00:25:35,846
going to show you I want to show

842
00:25:35,846 --> 00:25:37,356
a few concepts that are kind of

843
00:25:37,356 --> 00:25:38,646
important like making something

844
00:25:38,646 --> 00:25:40,606
a bit more elaborate with

845
00:25:41,276 --> 00:25:41,456
Vision.

846
00:25:41,606 --> 00:25:43,646
First, we'll spin off model

847
00:25:43,646 --> 00:25:45,006
requests based on top of each

848
00:25:45,006 --> 00:25:47,516
other then we use Core Image in

849
00:25:47,516 --> 00:25:49,566
between to do some image process

850
00:25:49,566 --> 00:25:51,666
and last but not least, we use

851
00:25:51,666 --> 00:25:53,246
Core ML again for the machine

852
00:25:53,246 --> 00:25:53,716
learning part.

853
00:25:56,666 --> 00:25:57,686
So, how is this going to work?

854
00:25:58,926 --> 00:26:00,596
We have here an image on which

855
00:25:58,926 --> 00:26:00,596
We have here an image on which

856
00:26:00,596 --> 00:26:01,506
we find a sticky note.

857
00:26:02,106 --> 00:26:04,846
Well we find it by using the

858
00:26:04,846 --> 00:26:06,796
rectangle detector, there's our

859
00:26:06,796 --> 00:26:07,326
sticky note.

860
00:26:07,896 --> 00:26:09,226
Now that is prospectively

861
00:26:09,226 --> 00:26:10,866
distorted and it's clearly not

862
00:26:10,926 --> 00:26:12,306
white text on black background.

863
00:26:13,456 --> 00:26:14,846
So, we use Core Image in the

864
00:26:14,846 --> 00:26:16,686
next step and we'll actually do

865
00:26:16,686 --> 00:26:18,046
the perspective correction of it

866
00:26:18,686 --> 00:26:20,666
and invert the color and enhance

867
00:26:20,666 --> 00:26:22,086
also the contrast so that we get

868
00:26:22,086 --> 00:26:23,356
rid this black-and-white image.

869
00:26:24,896 --> 00:26:26,076
And last but not least, I need

870
00:26:26,076 --> 00:26:28,826
to run my MNIST classifier on it

871
00:26:29,016 --> 00:26:30,476
and it should tell me that this

872
00:26:30,476 --> 00:26:32,256
is the number four and this has

873
00:26:32,256 --> 00:26:35,096
80% confidence that this is the

874
00:26:35,096 --> 00:26:35,636
number four.

875
00:26:35,636 --> 00:26:38,666
Again, let's see how this looks

876
00:26:38,666 --> 00:26:39,066
in the app.

877
00:26:41,496 --> 00:26:43,426
So again, I start off as a

878
00:26:43,426 --> 00:26:45,236
rectangle detector request, it's

879
00:26:45,236 --> 00:26:46,316
my favorite I know.

880
00:26:47,886 --> 00:26:48,946
But it's more interesting what

881
00:26:48,946 --> 00:26:50,246
I'm going to do in the

882
00:26:50,246 --> 00:26:51,206
completion handler.

883
00:26:52,426 --> 00:26:53,746
So, I do some validation just to

884
00:26:53,746 --> 00:26:54,876
make sure that the rectangles

885
00:26:54,876 --> 00:26:55,746
I'm getting out of it are

886
00:26:55,746 --> 00:26:56,456
actually okay.

887
00:26:56,456 --> 00:26:58,656
But the interesting part happens

888
00:26:58,736 --> 00:26:58,926
here.

889
00:26:59,596 --> 00:27:01,256
I get the coordinates of the

890
00:26:59,596 --> 00:27:01,256
I get the coordinates of the

891
00:27:01,256 --> 00:27:04,126
corners and feed them into CI to

892
00:27:04,126 --> 00:27:05,786
use the CIPerspectiveCorrection.

893
00:27:06,476 --> 00:27:07,636
That allows me to take this

894
00:27:07,636 --> 00:27:09,226
prospectively distorted image

895
00:27:09,226 --> 00:27:10,916
and actually bring it upright as

896
00:27:10,916 --> 00:27:11,966
if I would have the camera

897
00:27:11,966 --> 00:27:12,506
straight on.

898
00:27:14,076 --> 00:27:15,936
I use the CIColorControls to

899
00:27:16,186 --> 00:27:17,456
really bring out the contrast of

900
00:27:17,506 --> 00:27:19,066
the image to make it kind of

901
00:27:19,066 --> 00:27:19,546
binarized.

902
00:27:20,896 --> 00:27:22,246
And as I said, I have to color

903
00:27:22,246 --> 00:27:23,306
invert it.

904
00:27:24,976 --> 00:27:26,776
Now the resulting image of that

905
00:27:26,776 --> 00:27:28,116
I feed into a new request in

906
00:27:28,116 --> 00:27:28,936
there because we have a new

907
00:27:28,936 --> 00:27:31,146
image on which I'll run the

908
00:27:31,146 --> 00:27:32,086
classification.

909
00:27:32,296 --> 00:27:34,066
So, how does the classification

910
00:27:34,066 --> 00:27:34,416
look like?

911
00:27:35,906 --> 00:27:37,446
The classification for that I

912
00:27:37,446 --> 00:27:39,446
use my endless model which I

913
00:27:39,446 --> 00:27:41,776
actually have ready and this is

914
00:27:41,776 --> 00:27:43,046
a small model that I've really

915
00:27:43,046 --> 00:27:44,866
trained actually on this laptop

916
00:27:44,866 --> 00:27:45,996
very easily give us a few lines

917
00:27:45,996 --> 00:27:47,576
of code script and then thanks

918
00:27:47,576 --> 00:27:49,386
to Core ML I can just drag that

919
00:27:49,386 --> 00:27:50,706
in and use this very easily.

920
00:27:51,106 --> 00:27:52,316
So, I have my model here.

921
00:27:53,766 --> 00:27:55,046
Now again, this one part I would

922
00:27:55,046 --> 00:27:57,636
like to highlight this, so that

923
00:27:57,636 --> 00:27:59,436
takes in this case a very small

924
00:27:59,436 --> 00:28:00,166
grayscale image.

925
00:27:59,436 --> 00:28:00,166
grayscale image.

926
00:28:00,166 --> 00:28:02,636
So, an image 28 by 28 pixels it

927
00:28:02,636 --> 00:28:03,636
should be able to read these

928
00:28:03,636 --> 00:28:03,976
numbers.

929
00:28:12,056 --> 00:28:12,526
So that's where my

930
00:28:12,526 --> 00:28:14,716
classification is coming from

931
00:28:15,326 --> 00:28:16,906
and now I need to feed in the

932
00:28:16,906 --> 00:28:17,216
image.

933
00:28:17,216 --> 00:28:19,056
So, this sample code has been

934
00:28:19,056 --> 00:28:20,046
made available also for the

935
00:28:20,046 --> 00:28:21,506
session to make it easy also to

936
00:28:21,506 --> 00:28:22,716
run a simulator not running it

937
00:28:22,716 --> 00:28:24,266
live off of the camera I'm just

938
00:28:24,266 --> 00:28:25,196
going to use actually the

939
00:28:25,196 --> 00:28:29,046
UIImagePicker and feed it into

940
00:28:29,086 --> 00:28:32,306
my VMImageRequestHandler and let

941
00:28:32,306 --> 00:28:33,526
it just perform the rectangle

942
00:28:33,526 --> 00:28:33,986
request.

943
00:28:33,986 --> 00:28:37,136
Now notice I buried the request

944
00:28:37,136 --> 00:28:38,906
for the classification into the

945
00:28:38,906 --> 00:28:40,396
completion handler of my

946
00:28:40,396 --> 00:28:42,146
rectangle detection and that

947
00:28:42,146 --> 00:28:43,496
allows us to basically cascade

948
00:28:43,496 --> 00:28:44,966
multiple requests on top of each

949
00:28:44,966 --> 00:28:45,146
other.

950
00:28:46,096 --> 00:28:47,546
So, let's try the demo for this.

951
00:28:50,896 --> 00:28:55,016
Okay, so I have my app here and

952
00:28:55,196 --> 00:28:56,656
well [inaudible] giveaway.

953
00:28:59,076 --> 00:29:00,696
Okay, so what I see here is

954
00:28:59,076 --> 00:29:00,696
Okay, so what I see here is

955
00:29:00,696 --> 00:29:01,976
again I have my image on the

956
00:29:01,976 --> 00:29:03,436
top, this was actually the photo

957
00:29:03,436 --> 00:29:04,346
that I took earlier.

958
00:29:04,926 --> 00:29:07,476
We see its correctly classifying

959
00:29:07,476 --> 00:29:10,366
as a number one, it was a really

960
00:29:10,366 --> 00:29:11,556
high confidence in this case.

961
00:29:11,556 --> 00:29:12,646
And what you see on the bottom

962
00:29:12,646 --> 00:29:14,816
is just basically just to

963
00:29:14,816 --> 00:29:16,126
visualize that I took this

964
00:29:16,126 --> 00:29:17,296
intermediate image that we

965
00:29:17,296 --> 00:29:19,676
created in CI and show this as

966
00:29:19,676 --> 00:29:19,946
well.

967
00:29:19,946 --> 00:29:21,706
Let's choose another number.

968
00:29:23,066 --> 00:29:24,316
Yes, this is the number three.

969
00:29:26,466 --> 00:29:27,756
Can we guess what this number

970
00:29:27,846 --> 00:29:28,826
is, it's the number four?

971
00:29:29,626 --> 00:29:30,706
It works correctly.

972
00:29:32,576 --> 00:29:33,806
All right, thank you.

973
00:29:34,516 --> 00:29:37,556
[ Applause ]

974
00:29:38,056 --> 00:29:39,176
Let me go back to our slides.

975
00:29:41,486 --> 00:29:42,936
So that is our Vision framework.

976
00:29:43,986 --> 00:29:45,316
Let's capitalize a little bit on

977
00:29:45,316 --> 00:29:46,466
what we really have seen here.

978
00:29:47,486 --> 00:29:49,426
So, Vision is a high-level

979
00:29:49,426 --> 00:29:50,696
framework for Computer Vision

980
00:29:50,756 --> 00:29:51,816
and it should really make it

981
00:29:51,816 --> 00:29:53,756
easy for you to use this in your

982
00:29:53,756 --> 00:29:55,356
applications even if you're not

983
00:29:55,356 --> 00:29:56,576
a Computer Vision expert.

984
00:29:57,276 --> 00:29:58,756
We have various detectors and

985
00:29:58,756 --> 00:30:00,166
there's a whole variety of that

986
00:29:58,756 --> 00:30:00,166
there's a whole variety of that

987
00:30:00,166 --> 00:30:01,946
and they all run through one

988
00:30:01,946 --> 00:30:03,296
consistent interface which would

989
00:30:03,336 --> 00:30:04,896
make it very easy to learn that

990
00:30:04,896 --> 00:30:05,446
set of APIs.

991
00:30:06,826 --> 00:30:08,596
And last but not least, the

992
00:30:08,596 --> 00:30:09,886
integration with Core ML.

993
00:30:10,376 --> 00:30:11,736
By bringing your own custom

994
00:30:11,736 --> 00:30:13,696
models you can do a lot in your

995
00:30:13,696 --> 00:30:15,586
application, you can find

996
00:30:15,586 --> 00:30:17,426
hotdogs and see if they are

997
00:30:17,426 --> 00:30:18,076
really hotdogs.

998
00:30:19,416 --> 00:30:20,336
I had to make that joke.

999
00:30:23,576 --> 00:30:24,606
So, if you want to learn more

1000
00:30:24,606 --> 00:30:26,816
about our session, please go to

1001
00:30:26,816 --> 00:30:28,626
our website and I would

1002
00:30:28,626 --> 00:30:29,746
definitely highlight there are

1003
00:30:29,796 --> 00:30:31,576
some related sessions that you

1004
00:30:31,576 --> 00:30:33,266
should have watched perhaps in

1005
00:30:33,266 --> 00:30:33,706
the past.

1006
00:30:33,706 --> 00:30:34,786
I'll read you the Core ML one,

1007
00:30:34,786 --> 00:30:35,876
but you can find it on our

1008
00:30:35,876 --> 00:30:36,106
website.

1009
00:30:36,106 --> 00:30:39,616
Please come for our get-together

1010
00:30:39,616 --> 00:30:42,146
that we have at 6:30 today, chat

1011
00:30:42,146 --> 00:30:43,416
about what we can do.

1012
00:30:43,896 --> 00:30:45,536
And for the little bit more

1013
00:30:45,536 --> 00:30:46,776
advanced part of Core ML there's

1014
00:30:46,826 --> 00:30:48,886
a session on Thursday, as well

1015
00:30:48,886 --> 00:30:50,256
as we have a session with Core

1016
00:30:50,256 --> 00:30:51,486
Image where they will also do

1017
00:30:51,486 --> 00:30:53,556
some very fancy stuff with Core

1018
00:30:53,556 --> 00:30:54,246
Image and Vision.

1019
00:30:55,826 --> 00:30:57,126
And with that I'd like to thank

1020
00:30:57,126 --> 00:30:58,646
you for coming today and enjoy

1021
00:30:58,646 --> 00:30:59,276
the rest of WWDC.

1022
00:30:59,276 --> 00:30:59,456
Thank you.

1023
00:31:00,516 --> 00:31:06,770
[ Applause ]
