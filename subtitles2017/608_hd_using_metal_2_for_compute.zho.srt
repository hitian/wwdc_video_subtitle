1
00:00:28,596 --> 00:00:29,576
&gt;&gt;大家下午好

2
00:00:30,076 --> 00:00:32,006
欢迎参加“Metal 2 

3
00:00:32,006 --> 00:00:32,946
的计算功能”会议

4
00:00:33,886 --> 00:00:35,296
我叫 Anna Tikhonova

5
00:00:35,296 --> 00:00:36,686
是 GPU 软件团队的

6
00:00:36,686 --> 00:00:37,976
工程师 现在就开始吧

7
00:00:42,156 --> 00:00:44,046
Metal 2 回波系统的功能

8
00:00:44,046 --> 00:00:45,836
比 Metal API 和语言要

9
00:00:45,836 --> 00:00:46,356
多得多

10
00:00:46,796 --> 00:00:48,946
我们还拥有 GPU 工具

11
00:00:48,946 --> 00:00:50,336
以及 MetalKit 和

12
00:00:50,336 --> 00:00:51,586
Metal Performance Shader 框架

13
00:00:53,006 --> 00:00:54,146
你可能会认为 Metal 是

14
00:00:54,496 --> 00:00:56,376
开发高端游戏和图像

15
00:00:56,376 --> 00:00:57,566
的优秀技术

16
00:00:58,396 --> 00:00:59,616
但它同时也用于

17
00:00:59,616 --> 00:01:00,506
计算处理

18
00:00:59,616 --> 00:01:00,506
计算处理

19
00:01:01,626 --> 00:01:02,806
事实上 Metal 在计算方面

20
00:01:02,806 --> 00:01:04,616
非常强大和灵活

21
00:01:04,616 --> 00:01:06,526
以至于 Metal 

22
00:01:06,526 --> 00:01:08,196
Performance Shader 框架

23
00:01:08,196 --> 00:01:09,326
完全建立在

24
00:01:09,406 --> 00:01:09,756
计算之上

25
00:01:11,026 --> 00:01:12,486
在本次会议中 我们将介绍

26
00:01:12,486 --> 00:01:14,076
Metal Performance Shader 框架

27
00:01:14,076 --> 00:01:15,176
的新功能

28
00:01:17,956 --> 00:01:19,596
我们在 2015 年推出了

29
00:01:19,596 --> 00:01:21,026
Metal Performers Shader 框架

30
00:01:21,026 --> 00:01:22,756
简称 MPS

31
00:01:23,486 --> 00:01:24,546
之前的会议视频

32
00:01:24,546 --> 00:01:25,916
可以在我们的开发者

33
00:01:25,916 --> 00:01:28,906
网站上找到

34
00:01:29,266 --> 00:01:30,686
MPS 利用 GPU 的

35
00:01:30,686 --> 00:01:33,446
计算功能为 GPU 提供

36
00:01:33,446 --> 00:01:33,816
加速图元

37
00:01:34,286 --> 00:01:35,886
用于图像处理

38
00:01:35,926 --> 00:01:37,416
线性代数和机器学习

39
00:01:39,146 --> 00:01:40,416
这个框架针对 iOS 

40
00:01:40,416 --> 00:01:42,336
进行了优化 我们很高兴地宣布

41
00:01:42,336 --> 00:01:44,096
今年 MPS 也将在

42
00:01:44,096 --> 00:01:44,836
Mac 上应用

43
00:01:45,516 --> 00:01:49,786
[掌声] 

44
00:01:50,286 --> 00:01:50,716
谢谢

45
00:01:51,926 --> 00:01:53,366
整个功能集都

46
00:01:53,366 --> 00:01:55,616
可以在 iOS 和 macOS 系统中使用

47
00:01:55,616 --> 00:01:58,476
所以我们先来快速地

48
00:01:58,476 --> 00:02:00,336
看一下图像处理支持的

49
00:01:58,476 --> 00:02:00,336
看一下图像处理支持的

50
00:02:00,336 --> 00:02:00,686
新进展

51
00:02:02,046 --> 00:02:03,866
这里列出了

52
00:02:03,866 --> 00:02:05,576
在 iOS 10 中可以使用的

53
00:02:05,696 --> 00:02:07,486
所有图像处理图元

54
00:02:08,106 --> 00:02:09,675
有 Convolution Gaussian Blur

55
00:02:09,675 --> 00:02:11,586
Lanczos Resampling

56
00:02:11,586 --> 00:02:12,196
就举几个例子

57
00:02:13,126 --> 00:02:14,726
这些现在都可以在 macOS 系统中

58
00:02:14,726 --> 00:02:14,996
使用了

59
00:02:16,146 --> 00:02:17,656
今年我们为大家带来

60
00:02:17,656 --> 00:02:18,926
四种新的图像处理

61
00:02:18,926 --> 00:02:19,336
图元

62
00:02:20,466 --> 00:02:21,816
Image Keypoint

63
00:02:22,206 --> 00:02:24,316
图元可以用于 通常用于

64
00:02:24,316 --> 00:02:26,256
计算机视觉算法 例如

65
00:02:26,256 --> 00:02:28,596
稳像和

66
00:02:28,596 --> 00:02:29,926
双线性缩放

67
00:02:29,926 --> 00:02:31,726
图像统计

68
00:02:31,726 --> 00:02:33,246
元素级算术运算符

69
00:02:33,326 --> 00:02:34,826
通常用于图像

70
00:02:34,826 --> 00:02:35,156
预处理

71
00:02:35,466 --> 00:02:36,386
例如在机器

72
00:02:36,386 --> 00:02:36,656
学习中

73
00:02:37,556 --> 00:02:38,926
算术递增滤色镜也

74
00:02:38,926 --> 00:02:40,446
支持广播操作

75
00:02:41,256 --> 00:02:42,716
例如 允许

76
00:02:42,716 --> 00:02:44,766
添加 2D 图像或 1D 图像

77
00:02:46,176 --> 00:02:48,406
这就是我们对图像处理

78
00:02:48,406 --> 00:02:49,606
新进展的快速介绍

79
00:02:49,986 --> 00:02:51,286
现在我们来谈谈新的

80
00:02:51,286 --> 00:02:52,386
线性代数运算

81
00:02:54,286 --> 00:02:55,686
没有矩阵乘法 

82
00:02:55,686 --> 00:02:57,436
矩阵向量

83
00:02:57,436 --> 00:02:59,736
乘法 三角

84
00:03:00,076 --> 00:03:01,866
矩阵因式分解和

85
00:03:01,866 --> 00:03:02,306
线性求解器的支持

86
00:03:05,356 --> 00:03:06,376
为了支持线性代数

87
00:03:06,376 --> 00:03:09,256
运算 我们现在有了很多

88
00:03:09,256 --> 00:03:10,356
新的数据表示

89
00:03:11,066 --> 00:03:13,076
首先是 MPSVector 对象

90
00:03:13,076 --> 00:03:15,186
它可以将 Metal 

91
00:03:15,186 --> 00:03:16,496
缓冲区中的数据解释为

92
00:03:16,496 --> 00:03:17,416
一维数组

93
00:03:19,106 --> 00:03:21,506
然后是 MPSMatrix 对象

94
00:03:22,076 --> 00:03:23,276
它可以将 Metal 缓冲区中的

95
00:03:23,276 --> 00:03:24,886
数据解释为矩形

96
00:03:24,886 --> 00:03:25,156
数组

97
00:03:25,886 --> 00:03:27,656
而 MPS 矩阵以行序为

98
00:03:27,656 --> 00:03:28,176
主序

99
00:03:28,956 --> 00:03:30,166
你可以将

100
00:03:30,166 --> 00:03:32,956
MPSVector 和 MPSMatrice 都看作是

101
00:03:33,456 --> 00:03:34,736
用户数据缓冲区周围的

102
00:03:34,736 --> 00:03:35,096
封装

103
00:03:37,436 --> 00:03:39,296
而且我们也支持 MPSMatrix 的

104
00:03:39,296 --> 00:03:40,926
临时变化

105
00:03:42,296 --> 00:03:45,196
MPS 图像 临时图像

106
00:03:45,196 --> 00:03:47,056
和 MPS 临时矩阵从

107
00:03:47,056 --> 00:03:48,666
与命令缓冲区相关联的

108
00:03:48,906 --> 00:03:49,956
Metal 堆中分配

109
00:03:49,956 --> 00:03:50,216
出来

110
00:03:50,766 --> 00:03:51,856
之所以称为临时的

111
00:03:52,226 --> 00:03:54,066
是因为它们的寿命

112
00:03:54,216 --> 00:03:55,996
受限于命令缓冲区的

113
00:03:55,996 --> 00:03:56,516
使用寿命

114
00:03:57,546 --> 00:03:58,866
我们建议

115
00:03:58,896 --> 00:04:00,176
在大多数中间存储器中

116
00:03:58,896 --> 00:04:00,176
在大多数中间存储器中

117
00:04:00,636 --> 00:04:02,526
使用临时映像和

118
00:04:03,006 --> 00:04:03,206
矩阵

119
00:04:04,316 --> 00:04:07,416
MPSVector 和 MPSMatrix 都

120
00:04:07,576 --> 00:04:09,116
支持多种输入类型

121
00:04:09,646 --> 00:04:11,596
我们支持单精度

122
00:04:11,596 --> 00:04:14,236
半精度输入类型以及

123
00:04:14,236 --> 00:04:15,266
浮点输入类型

124
00:04:15,756 --> 00:04:17,696
还有 16 位和 8 位带符号

125
00:04:17,986 --> 00:04:19,125
整数输入类型

126
00:04:21,016 --> 00:04:22,136
现在我们来看看怎样

127
00:04:22,136 --> 00:04:24,446
创建大小为 N 的

128
00:04:24,536 --> 00:04:24,886
MPS 向量

129
00:04:24,886 --> 00:04:26,856
如果你还没有

130
00:04:26,856 --> 00:04:28,346
Metal 缓冲区 那就需要先

131
00:04:28,346 --> 00:04:28,606
创建一个

132
00:04:29,666 --> 00:04:30,666
然后再为你的向量

133
00:04:30,666 --> 00:04:31,686
创建一个描述符

134
00:04:32,526 --> 00:04:34,546
请注意 你需要指定

135
00:04:34,726 --> 00:04:36,086
向量的长度

136
00:04:36,666 --> 00:04:38,146
因为向量可以

137
00:04:38,146 --> 00:04:39,946
由原来 Metal 缓冲区的

138
00:04:39,946 --> 00:04:40,926
一部分形成

139
00:04:41,716 --> 00:04:43,236
并且可以在使用该向量

140
00:04:43,236 --> 00:04:44,556
的内核中设置其他相关的

141
00:04:44,556 --> 00:04:45,016
偏移量

142
00:04:45,996 --> 00:04:47,406
最后使用

143
00:04:47,466 --> 00:04:49,586
描述符从缓冲区

144
00:04:49,586 --> 00:04:50,906
创建一个向量

145
00:04:52,966 --> 00:04:53,976
现在我们来看看

146
00:04:53,976 --> 00:04:56,256
如何创建一个 M 行

147
00:04:56,326 --> 00:04:57,906
N 列的 MPS 矩阵

148
00:04:59,516 --> 00:05:00,906
这和创建 MPS 向量

149
00:04:59,516 --> 00:05:00,906
这和创建 MPS 向量

150
00:05:00,906 --> 00:05:02,916
的方式非常类似 

151
00:05:02,916 --> 00:05:04,006
但有几点

152
00:05:04,006 --> 00:05:04,726
需要注意

153
00:05:06,176 --> 00:05:08,256
我们提供了一个方便的 API

154
00:05:08,256 --> 00:05:09,606
你可以用它来查找

155
00:05:09,606 --> 00:05:11,966
每个行值的推荐字节数

156
00:05:12,556 --> 00:05:13,756
用于调整 Metal 缓冲区的大小

157
00:05:14,666 --> 00:05:15,716
如果你选择使用 API

158
00:05:15,796 --> 00:05:17,246
那么这就是

159
00:05:17,246 --> 00:05:18,816
使用这个推荐值创建 Metal 缓冲区

160
00:05:18,816 --> 00:05:19,596
的方法

161
00:05:20,596 --> 00:05:22,106
并且这个 API 是完全

162
00:05:22,106 --> 00:05:24,416
可以选择性使用的 但我们推荐使用

163
00:05:24,416 --> 00:05:25,136
因为它的性能更好

164
00:05:25,986 --> 00:05:27,156
其余的就简单了

165
00:05:28,256 --> 00:05:29,356
你先为矩阵创建一个

166
00:05:29,356 --> 00:05:30,886
描述符 然后创建一个

167
00:05:30,886 --> 00:05:32,346
带有描述符的矩阵

168
00:05:34,936 --> 00:05:36,506
既然刚刚我们讲过了

169
00:05:36,506 --> 00:05:37,806
数据表示 那么现在

170
00:05:37,806 --> 00:05:39,046
我们来看一下图元

171
00:05:39,896 --> 00:05:41,176
对于矩阵-矩阵和

172
00:05:41,176 --> 00:05:43,136
矩阵-向量的乘法 我们的

173
00:05:43,136 --> 00:05:44,586
API 以

174
00:05:44,586 --> 00:05:46,036
标准的 BLAS GEMM 和 GEMV

175
00:05:46,036 --> 00:05:46,766
界面为模型

176
00:05:47,646 --> 00:05:48,846
对于三角矩阵

177
00:05:48,846 --> 00:05:50,196
矢量化和线性

178
00:05:50,196 --> 00:05:52,216
求解器 我们的 API 以

179
00:05:52,216 --> 00:05:53,246
标准的 LAPACK 

180
00:05:53,246 --> 00:05:54,916
分解和求解

181
00:05:54,916 --> 00:05:55,486
界面为模型

182
00:05:55,846 --> 00:05:57,036
所以如果你熟悉这些

183
00:05:57,036 --> 00:05:59,106
界面 那对我们的 API

184
00:05:59,106 --> 00:06:00,526
你也不会陌生

185
00:06:02,576 --> 00:06:04,216
现在我们来看一个

186
00:06:04,216 --> 00:06:05,546
非常简单的代码示例

187
00:06:05,836 --> 00:06:07,536
我们要做矩阵的

188
00:06:07,536 --> 00:06:08,996
乘法和计算

189
00:06:08,996 --> 00:06:10,426
C = A 乘以 B

190
00:06:10,426 --> 00:06:12,716
所以首先我们需要创建

191
00:06:12,716 --> 00:06:14,476
矩阵 A B 和 C

192
00:06:14,706 --> 00:06:15,646
但我知道大家已经知道怎么

193
00:06:15,646 --> 00:06:16,786
操作了 因为在前一张幻灯片里我已经

194
00:06:16,836 --> 00:06:18,306
讲过 所以我们继续往下看

195
00:06:19,336 --> 00:06:21,116
现在我们要在 GPU 上

196
00:06:21,116 --> 00:06:22,596
运行矩阵的乘法

197
00:06:23,886 --> 00:06:25,386
首先像往常一样进行 Metal 

198
00:06:25,466 --> 00:06:27,446
设置来获取设备

199
00:06:27,446 --> 00:06:29,076
命令队列和命令

200
00:06:29,076 --> 00:06:29,356
缓冲区

201
00:06:29,356 --> 00:06:31,766
然后我们需要创建

202
00:06:31,846 --> 00:06:33,186
矩阵乘法内核

203
00:06:33,766 --> 00:06:35,196
注意 你这里需要

204
00:06:35,196 --> 00:06:36,296
指定结果的大小

205
00:06:36,826 --> 00:06:38,216
因为这个内核可以

206
00:06:38,216 --> 00:06:39,896
在矩阵的子区域上

207
00:06:39,896 --> 00:06:40,436
运行

208
00:06:41,066 --> 00:06:45,576
然后将这个内核编码

209
00:06:45,656 --> 00:06:47,056
到 GPU 上 并让它开始

210
00:06:47,056 --> 00:06:47,476
工作

211
00:06:47,476 --> 00:06:51,036
我们已经在

212
00:06:51,036 --> 00:06:52,346
开发者网站上提供了

213
00:06:52,586 --> 00:06:53,906
矩阵乘法的示例代码

214
00:06:53,906 --> 00:06:56,096
以及三角矩阵

215
00:06:56,096 --> 00:06:57,896
向量化的代码

216
00:06:58,206 --> 00:06:59,556
求解线性方程组的示例代码

217
00:06:59,556 --> 00:07:00,986
很快也要发布

218
00:06:59,556 --> 00:07:00,986
很快也要发布

219
00:07:03,026 --> 00:07:05,526
这就是我们关于

220
00:07:05,756 --> 00:07:07,026
线性代数运算的内容

221
00:07:07,386 --> 00:07:08,996
现在我们来看下一个

222
00:07:08,996 --> 00:07:10,756
主题 也就是

223
00:07:10,756 --> 00:07:12,156
在 GPU 上加速机器

224
00:07:12,156 --> 00:07:12,636
学习图元

225
00:07:14,116 --> 00:07:16,246
在今年的 WWDC

226
00:07:16,246 --> 00:07:17,906
大会上有很多关于

227
00:07:17,906 --> 00:07:19,156
机器学习的会议

228
00:07:19,456 --> 00:07:20,346
而我们就是机器学习

229
00:07:20,346 --> 00:07:21,416
团体的一部分

230
00:07:22,306 --> 00:07:23,586
这一页展示了

231
00:07:23,586 --> 00:07:24,206
整体的架构

232
00:07:25,086 --> 00:07:26,606
作为一名应用程序开发人员

233
00:07:26,816 --> 00:07:27,876
你可以通过使用

234
00:07:27,876 --> 00:07:28,816
高级域

235
00:07:28,816 --> 00:07:30,956
特定框架

236
00:07:30,996 --> 00:07:32,856
比如分区框架

237
00:07:32,856 --> 00:07:34,456
和依赖于 Core ML 框架的

238
00:07:34,456 --> 00:07:35,566
自然语言处理框架

239
00:07:35,616 --> 00:07:37,496
为应用程序添加

240
00:07:37,496 --> 00:07:38,366
机器学习功能

241
00:07:39,216 --> 00:07:40,376
Core ML 框架由

242
00:07:40,446 --> 00:07:42,316
CPU 上的

243
00:07:42,316 --> 00:07:44,076
加速框架 BNNS 

244
00:07:44,076 --> 00:07:44,606
原语 

245
00:07:45,066 --> 00:07:46,176
以及 GPU 上的

246
00:07:47,066 --> 00:07:49,046
机器学习和

247
00:07:49,046 --> 00:07:51,946
MPS 框架驱动构成

248
00:07:51,946 --> 00:07:52,706
但是如果你正在编写一个

249
00:07:52,706 --> 00:07:54,556
使用 Metal 的应用程序

250
00:07:54,906 --> 00:07:56,046
那么你可以直接使用

251
00:07:56,046 --> 00:07:58,176
MPS框架 我稍后

252
00:07:58,176 --> 00:07:59,386
将在这个会议中向你展示如何操作

253
00:08:01,666 --> 00:08:02,676
让我们从正在讲的

254
00:08:02,736 --> 00:08:03,486
这个部分开始

255
00:08:04,246 --> 00:08:05,116
什么是深度学习

256
00:08:05,366 --> 00:08:06,236
什么是机器学习

257
00:08:07,686 --> 00:08:08,766
想象一下这是你

258
00:08:08,766 --> 00:08:11,436
当你看到一个图像

259
00:08:11,436 --> 00:08:13,076
你立刻就能知道上面描绘的

260
00:08:13,076 --> 00:08:13,316
是什么

261
00:08:13,416 --> 00:08:13,956
这是一只熊猫

262
00:08:14,936 --> 00:08:16,686
现在想一想你的

263
00:08:16,686 --> 00:08:18,006
iPhone 上所有的图像

264
00:08:18,596 --> 00:08:20,206
或者你家庭相册中的

265
00:08:20,206 --> 00:08:20,996
所有照片

266
00:08:21,606 --> 00:08:22,646
或者互联网上的

267
00:08:22,646 --> 00:08:22,966
所有图像

268
00:08:23,816 --> 00:08:27,096
没有人可以

269
00:08:27,096 --> 00:08:28,816
将这么多的图像分类

270
00:08:29,086 --> 00:08:30,506
但深度学习算法就是

271
00:08:30,506 --> 00:08:32,056
专门为此而

272
00:08:32,056 --> 00:08:32,196
设计的

273
00:08:33,186 --> 00:08:34,416
它们可以用于筛选

274
00:08:34,416 --> 00:08:35,576
大量数据

275
00:08:36,015 --> 00:08:37,866
并回答诸如

276
00:08:37,996 --> 00:08:41,676
图像的内容是什么 等一系列问题

277
00:08:42,236 --> 00:08:43,306
深度学习算法有

278
00:08:43,405 --> 00:08:43,905
两个阶段

279
00:08:44,206 --> 00:08:45,156
训练和推理

280
00:08:45,426 --> 00:08:46,426
让我们先来讲一下

281
00:08:46,426 --> 00:08:46,736
训练

282
00:08:47,946 --> 00:08:49,246
让我们用一个

283
00:08:49,246 --> 00:08:49,676
例子

284
00:08:49,676 --> 00:08:51,326
我们训练一个系统来进行

285
00:08:51,326 --> 00:08:51,716
图像分类

286
00:08:52,586 --> 00:08:53,536
这个系统训练可以

287
00:08:53,536 --> 00:08:56,696
进行图像分类 例如

288
00:08:56,696 --> 00:08:58,066
你想让系统识别

289
00:08:58,126 --> 00:08:58,536
动物

290
00:08:58,966 --> 00:09:00,516
要让它识别猫

291
00:09:00,516 --> 00:09:02,126
那么你就需要为这个系统输入

292
00:08:58,966 --> 00:09:00,516
要让它识别猫

293
00:09:00,516 --> 00:09:02,126
那么你就需要为这个系统输入

294
00:09:02,556 --> 00:09:04,196
大量的包含

295
00:09:04,196 --> 00:09:06,126
猫 兔子和

296
00:09:06,126 --> 00:09:07,336
所有其他你希望

297
00:09:07,336 --> 00:09:08,406
系统能识别动物的

298
00:09:08,406 --> 00:09:08,866
标签的图像

299
00:09:10,546 --> 00:09:12,316
而这个训练步骤是

300
00:09:12,316 --> 00:09:13,916
一次性的

301
00:09:13,916 --> 00:09:16,476
它消耗计算能力且劳动

302
00:09:16,566 --> 00:09:16,786
强度大

303
00:09:17,896 --> 00:09:19,076
它通常是离线完成的

304
00:09:19,696 --> 00:09:20,896
但是训练阶段的结果

305
00:09:20,896 --> 00:09:22,336
是下一阶段

306
00:09:23,306 --> 00:09:24,656
也就是推理阶段

307
00:09:24,656 --> 00:09:25,856
所需要的训练参数

308
00:09:26,906 --> 00:09:28,096
这时候可以将一个从未见过的

309
00:09:28,186 --> 00:09:30,156
新图像呈现在

310
00:09:30,156 --> 00:09:31,736
你的系统中

311
00:09:31,736 --> 00:09:33,186
并对其进行分类

312
00:09:33,186 --> 00:09:33,396
这是一个帽子

313
00:09:35,126 --> 00:09:37,016
我们为第二阶段

314
00:09:37,016 --> 00:09:38,306
也就是推理阶段提供视图

315
00:09:38,306 --> 00:09:38,526
加速

316
00:09:39,096 --> 00:09:40,966
具体来说 去年我们

317
00:09:40,966 --> 00:09:42,936
讨论了在 GPU 上

318
00:09:43,056 --> 00:09:44,296
构建卷积神经网络的

319
00:09:44,296 --> 00:09:45,716
构建块 用于

320
00:09:45,716 --> 00:09:46,146
推理

321
00:09:48,466 --> 00:09:50,176
所以在继续介绍

322
00:09:50,176 --> 00:09:51,966
今年推出的

323
00:09:51,966 --> 00:09:52,826
机器学习的新功能

324
00:09:52,856 --> 00:09:53,936
之前 我们将

325
00:09:53,936 --> 00:09:55,136
回顾一下

326
00:09:55,136 --> 00:09:56,886
去年演讲中介绍的

327
00:09:56,886 --> 00:09:58,146
一些核心信息

328
00:09:58,736 --> 00:10:00,416
比如 什么是卷积

329
00:09:58,736 --> 00:10:00,416
比如 什么是卷积

330
00:10:00,416 --> 00:10:00,966
神经网络

331
00:10:02,396 --> 00:10:04,326
在这之后 我们才会

332
00:10:04,326 --> 00:10:06,056
谈到今年为

333
00:10:06,106 --> 00:10:06,836
卷积神经网络添加的

334
00:10:06,836 --> 00:10:07,906
新原语

335
00:10:07,966 --> 00:10:09,426
然后我们将

336
00:10:09,426 --> 00:10:11,146
介绍一种新的 易用的

337
00:10:11,516 --> 00:10:12,636
神经网络图像 API

338
00:10:13,166 --> 00:10:14,746
而我们最后一个话题是

339
00:10:14,746 --> 00:10:15,726
循环神经网络

340
00:10:18,606 --> 00:10:20,976
让我们按照刚才的概述开始讲

341
00:10:21,106 --> 00:10:22,066
那么 什么是卷积神经

342
00:10:22,066 --> 00:10:22,366
网络

343
00:10:24,446 --> 00:10:25,576
卷积神经网络

344
00:10:25,576 --> 00:10:27,426
受生物学启发而设计出来

345
00:10:27,426 --> 00:10:28,836
用于近似

346
00:10:28,836 --> 00:10:29,246
视觉皮质

347
00:10:29,796 --> 00:10:31,406
所以让我们想一下

348
00:10:31,406 --> 00:10:33,076
大脑是如何处理视觉输入的

349
00:10:34,256 --> 00:10:35,636
在视觉皮质中

350
00:10:35,736 --> 00:10:37,056
接收信息的第一层

351
00:10:37,056 --> 00:10:39,396
神经元对

352
00:10:39,396 --> 00:10:40,786
特定的边缘和色块很

353
00:10:40,886 --> 00:10:41,196
敏感

354
00:10:42,366 --> 00:10:43,466
而大脑区域进一步的

355
00:10:43,466 --> 00:10:45,966
视觉传递会对 

356
00:10:45,966 --> 00:10:47,596
更复杂的结构做出反应

357
00:10:47,596 --> 00:10:49,366
比如朋友的面孔或者

358
00:10:49,366 --> 00:10:50,166
动物 比如猫

359
00:10:50,996 --> 00:10:53,646
所以类似的 卷积神经网络

360
00:10:53,646 --> 00:10:55,836
是多层次结构

361
00:10:55,836 --> 00:10:58,176
其中高级特征

362
00:10:58,296 --> 00:10:59,836
源于低级

363
00:10:59,836 --> 00:11:00,246
特征

364
00:10:59,836 --> 00:11:00,246
特征

365
00:11:01,156 --> 00:11:02,516
因此你的网络中的前几个

366
00:11:02,516 --> 00:11:04,566
层次会对低级特征

367
00:11:04,566 --> 00:11:06,766
比如边缘和色块做出

368
00:11:06,826 --> 00:11:07,196
响应

369
00:11:07,886 --> 00:11:10,646
而随后的层次

370
00:11:10,766 --> 00:11:12,516
对逐渐复杂的特征

371
00:11:12,616 --> 00:11:14,886
比如面孔 做出响应

372
00:11:16,106 --> 00:11:17,406
我一直在说特征

373
00:11:17,846 --> 00:11:19,556
你可以将特征视为

374
00:11:19,556 --> 00:11:21,176
一个过滤器 可以过滤输入的

375
00:11:21,176 --> 00:11:22,706
数据 就是那个特征

376
00:11:25,316 --> 00:11:26,906
这里列出了我们在

377
00:11:26,976 --> 00:11:28,076
iOS 10 中提供的

378
00:11:28,076 --> 00:11:29,356
所有卷积神经网络原语

379
00:11:29,756 --> 00:11:31,806
在这个概述中我将

380
00:11:31,806 --> 00:11:33,686
只讲核心

381
00:11:34,176 --> 00:11:35,146
卷积层

382
00:11:35,216 --> 00:11:36,426
CNN 的核心

383
00:11:36,546 --> 00:11:36,756
构建块

384
00:11:36,756 --> 00:11:39,046
这些原语的其余部分

385
00:11:39,106 --> 00:11:40,906
在我们的演讲文档中

386
00:11:40,906 --> 00:11:42,266
有很详细的

387
00:11:42,266 --> 00:11:43,076
介绍

388
00:11:43,196 --> 00:11:44,566
Pooling Fully-Connected 和

389
00:11:44,616 --> 00:11:45,156
SoftMax.

390
00:11:45,746 --> 00:11:46,856
你可以找到和这些相关的

391
00:11:46,856 --> 00:11:47,056
信息

392
00:11:48,626 --> 00:11:50,386
所以让我们来谈谈

393
00:11:50,386 --> 00:11:51,186
核心构建块

394
00:11:52,596 --> 00:11:54,216
这个核心卷积层的功能

395
00:11:54,216 --> 00:11:56,196
是识别输入

396
00:11:56,196 --> 00:11:57,766
数据中的特征

397
00:11:57,766 --> 00:11:58,906
它之所以被称为

398
00:11:58,906 --> 00:12:01,076
卷积层是因为

399
00:11:58,906 --> 00:12:01,076
卷积层是因为

400
00:12:01,126 --> 00:12:02,576
它对输入进行

401
00:12:02,576 --> 00:12:02,846
卷积操作

402
00:12:03,916 --> 00:12:05,246
我们回想一下常规的

403
00:12:05,246 --> 00:12:06,076
卷积如何进行

404
00:12:06,906 --> 00:12:08,146
你有输入

405
00:12:08,186 --> 00:12:09,366
输出和过滤器

406
00:12:10,366 --> 00:12:12,386
使用输入数据来

407
00:12:12,386 --> 00:12:14,506
调用过滤器 你需要将

408
00:12:14,756 --> 00:12:16,626
过滤器中的

409
00:12:16,626 --> 00:12:18,446
每个值与输入数据中的值相乘

410
00:12:18,446 --> 00:12:19,686
并将该信息组合

411
00:12:19,686 --> 00:12:21,106
从而计算出单个输出值

412
00:12:22,046 --> 00:12:23,536
对于其余的输出像素

413
00:12:23,636 --> 00:12:25,166
你也进行同样的操作

414
00:12:27,596 --> 00:12:29,856
而现在卷积层则是

415
00:12:29,856 --> 00:12:31,606
常规卷积的

416
00:12:31,606 --> 00:12:32,226
一般化

417
00:12:32,396 --> 00:12:34,666
它允许你拥有多个

418
00:12:34,666 --> 00:12:35,136
过滤器

419
00:12:35,526 --> 00:12:37,536
所以你可以拥有和输出通道

420
00:12:37,536 --> 00:12:38,916
一样多的过滤器

421
00:12:38,916 --> 00:12:39,816
这种情况下是 16 个

422
00:12:41,666 --> 00:12:43,046
这些过滤器将

423
00:12:43,046 --> 00:12:44,656
过滤具有特定 

424
00:12:44,656 --> 00:12:46,006
特征的输入数据

425
00:12:47,726 --> 00:12:49,016
现在想象一下你正在

426
00:12:49,016 --> 00:12:50,266
使用 RGB 数据

427
00:12:50,356 --> 00:12:52,186
那么你的输入实际上

428
00:12:52,186 --> 00:12:53,266
有三个通道

429
00:12:54,156 --> 00:12:56,276
鉴于 CNN 的工作原理

430
00:12:56,476 --> 00:12:58,816
这意味着你需要三组过滤器

431
00:12:58,886 --> 00:13:00,156
每组 16 个

432
00:12:58,886 --> 00:13:00,156
每组 16 个

433
00:13:00,866 --> 00:13:02,576
每个输入通道一组

434
00:13:03,856 --> 00:13:05,916
然后将这些滤波器

435
00:13:05,916 --> 00:13:07,296
分别应用于

436
00:13:08,486 --> 00:13:09,036
输入数据

437
00:13:09,036 --> 00:13:10,816
然后最后一步将

438
00:13:10,816 --> 00:13:12,386
所有这些信息合并

439
00:13:12,386 --> 00:13:13,796
计算出单个输出像素

440
00:13:15,516 --> 00:13:17,156
这就是我们对

441
00:13:17,156 --> 00:13:18,006
卷积层的概述

442
00:13:18,536 --> 00:13:19,526
现在我们来谈谈

443
00:13:19,576 --> 00:13:20,846
为卷积神经网络

444
00:13:20,846 --> 00:13:22,026
添加的新原语

445
00:13:22,116 --> 00:13:25,176
如你所见 我们添加了

446
00:13:25,176 --> 00:13:25,686
不少原语

447
00:13:27,736 --> 00:13:29,096
但我接下来只讲一下

448
00:13:29,096 --> 00:13:31,476
黄色的部分

449
00:13:31,476 --> 00:13:33,206
其他的比如 L2Norm 

450
00:13:33,256 --> 00:13:34,686
Pooling Resampling

451
00:13:34,686 --> 00:13:36,086
和 Up-sampling 这些都将

452
00:13:36,086 --> 00:13:37,396
在我们的文档中介绍

453
00:13:39,286 --> 00:13:40,986
那让我们来看看对核心

454
00:13:40,986 --> 00:13:42,786
卷积层进行的更新

455
00:13:43,916 --> 00:13:45,146
我们过去只支持

456
00:13:45,186 --> 00:13:46,716
单精度浮点权重

457
00:13:46,716 --> 00:13:47,026
类型

458
00:13:47,466 --> 00:13:49,076
现在为了帮你减少

459
00:13:49,076 --> 00:13:51,126
内存占用并

460
00:13:51,126 --> 00:13:51,966
提高网络

461
00:13:51,966 --> 00:13:52,326
性能

462
00:13:52,876 --> 00:13:54,546
我们还支持半精度

463
00:13:54,546 --> 00:13:56,466
浮点 8 位整数

464
00:13:56,806 --> 00:13:58,076
和二进制权重类型

465
00:13:59,496 --> 00:14:01,006
我们过去只支持标准

466
00:13:59,496 --> 00:14:01,006
我们过去只支持标准

467
00:14:01,006 --> 00:14:02,676
卷积 现在

468
00:14:02,736 --> 00:14:03,926
我们也支持二进制和 

469
00:14:03,926 --> 00:14:04,646
XNOR 卷积

470
00:14:04,986 --> 00:14:06,096
扩张卷积

471
00:14:06,096 --> 00:14:08,406
子像素卷积和

472
00:14:08,406 --> 00:14:09,366
卷积转置

473
00:14:09,366 --> 00:14:09,996
操作

474
00:14:11,056 --> 00:14:12,156
其中许多是

475
00:14:12,156 --> 00:14:13,716
正交的 所以如果你愿意的话

476
00:14:14,006 --> 00:14:15,946
甚至可以进行 

477
00:14:15,946 --> 00:14:16,276
扩大子像素卷积

478
00:14:17,706 --> 00:14:18,486
让我们一个一个地

479
00:14:18,486 --> 00:14:19,046
看一下

480
00:14:20,806 --> 00:14:22,216
二进制和 XNOR 卷积

481
00:14:22,256 --> 00:14:24,276
与常规卷积执行

482
00:14:24,306 --> 00:14:26,336
相同的精确操作 但它们具有

483
00:14:26,336 --> 00:14:28,016
更好的性能 而且能够

484
00:14:28,476 --> 00:14:29,566
节省极大的空间

485
00:14:30,016 --> 00:14:31,726
所以在常规卷积中

486
00:14:31,726 --> 00:14:33,546
你可能有浮点输入

487
00:14:33,846 --> 00:14:35,166
和浮点权重

488
00:14:36,036 --> 00:14:37,446
而二进制卷积能够

489
00:14:37,516 --> 00:14:39,236
允许你

490
00:14:39,236 --> 00:14:41,266
使用二进制权重的全尺寸

491
00:14:41,266 --> 00:14:41,486
输入

492
00:14:42,416 --> 00:14:44,776
而对于 XNOR 卷积

493
00:14:44,776 --> 00:14:46,706
首先

494
00:14:47,226 --> 00:14:48,626
你的输入会被转换为

495
00:14:48,626 --> 00:14:50,826
二进制的 从而使输入

496
00:14:51,176 --> 00:14:52,396
和权重都是二进制的

497
00:14:53,476 --> 00:14:55,286
在常规卷积中

498
00:14:55,286 --> 00:14:57,066
输入必须与权重

499
00:14:57,106 --> 00:14:57,446
相乘

500
00:14:57,886 --> 00:14:59,876
而对于 XNOR 卷积

501
00:14:59,876 --> 00:15:01,806
分离变成了一个简单的 XNOR 

502
00:14:59,876 --> 00:15:01,806
分离变成了一个简单的 XNOR 

503
00:15:01,806 --> 00:15:02,336
操作

504
00:15:04,746 --> 00:15:06,066
现在我们来谈谈扩张

505
00:15:06,066 --> 00:15:06,656
卷积

506
00:15:07,626 --> 00:15:08,996
我们已经知道常规

507
00:15:08,996 --> 00:15:09,786
卷积如何工作

508
00:15:10,486 --> 00:15:12,396
你需要用过滤器对

509
00:15:12,396 --> 00:15:13,656
输入数据进行计算

510
00:15:13,656 --> 00:15:14,706
来得到单个输出值

511
00:15:17,526 --> 00:15:18,786
但如果你正在研究一种

512
00:15:18,786 --> 00:15:21,736
需要将更广泛的

513
00:15:21,736 --> 00:15:24,846
输入数据进行

514
00:15:25,216 --> 00:15:26,166
全局集成的算法

515
00:15:26,816 --> 00:15:28,466
那么你就不能用 3 乘 3 的内核

516
00:15:28,536 --> 00:15:30,496
而应该用一个 5 乘 5 的内核

517
00:15:31,736 --> 00:15:32,476
来进一步研究

518
00:15:33,026 --> 00:15:33,666
但是这样的话就要进行

519
00:15:33,666 --> 00:15:34,756
更加大量的计算

520
00:15:35,256 --> 00:15:37,266
另外一种方法是使用

521
00:15:37,266 --> 00:15:39,046
扩展卷积这样

522
00:15:39,046 --> 00:15:43,206
你就可以使用

523
00:15:43,206 --> 00:15:45,256
扩展因子在卷积

524
00:15:45,256 --> 00:15:46,836
内核里引入间隔

525
00:15:46,836 --> 00:15:48,836
从而可以

526
00:15:48,836 --> 00:15:50,576
只使用 3 乘 3 的内核

527
00:15:50,576 --> 00:15:52,676
就能够进行进一步的

528
00:15:52,676 --> 00:15:53,016
研究

529
00:15:54,996 --> 00:15:55,876
现在我们来谈谈

530
00:15:55,946 --> 00:15:57,266
亚光圈卷积和

531
00:15:57,266 --> 00:15:58,846
卷积转置原语

532
00:15:59,766 --> 00:16:01,266
常用于图像

533
00:16:01,266 --> 00:16:01,836
放大

534
00:16:03,066 --> 00:16:04,126
让我们想一下图象放大

535
00:16:04,176 --> 00:16:05,366
通常是如何进行的

536
00:16:05,456 --> 00:16:07,456
现在你有输入数据

537
00:16:07,516 --> 00:16:09,196
并想用因子 2 

538
00:16:09,196 --> 00:16:09,956
将其放大

539
00:16:12,336 --> 00:16:13,376
所以你将有一些

540
00:16:13,376 --> 00:16:14,566
缺失的像素需要计算

541
00:16:15,216 --> 00:16:16,536
并且通常扩大是

542
00:16:16,536 --> 00:16:18,156
用恒定过滤器进行的

543
00:16:18,156 --> 00:16:18,606
固定操作

544
00:16:18,766 --> 00:16:20,336
例如 盒式

545
00:16:20,336 --> 00:16:22,336
过滤器如何帮助你进行图像

546
00:16:22,386 --> 00:16:22,756
扩大

547
00:16:23,416 --> 00:16:25,146
盒式过滤器获取

548
00:16:25,316 --> 00:16:28,006
已知像素 并将

549
00:16:28,006 --> 00:16:29,326
已知的数据复制到缺失的

550
00:16:29,326 --> 00:16:30,786
位置从而获得

551
00:16:30,786 --> 00:16:31,216
扩大的结果

552
00:16:33,326 --> 00:16:35,196
对于子像素卷积

553
00:16:35,196 --> 00:16:36,646
你的过滤器不是常数

554
00:16:36,976 --> 00:16:38,226
过滤器会从数据中

555
00:16:38,226 --> 00:16:38,626
学习

556
00:16:38,766 --> 00:16:40,286
它们是经过训练的参数

557
00:16:40,716 --> 00:16:41,786
你可以从训练阶段

558
00:16:41,786 --> 00:16:42,906
获得这些参数 系统接受

559
00:16:42,986 --> 00:16:45,106
训练从而完成这个任务 

560
00:16:45,106 --> 00:16:45,946
完成图像扩大

561
00:16:47,086 --> 00:16:49,176
所以对于 2 倍放大有 4 个

562
00:16:49,236 --> 00:16:49,686
过滤器

563
00:16:49,806 --> 00:16:51,656
对于 4 倍放大有 16 个

564
00:16:51,656 --> 00:16:52,656
过滤器等等

565
00:16:53,566 --> 00:16:55,446
所以对于 2 倍放大

566
00:16:55,446 --> 00:16:57,456
我们需要用 4 个过滤器

567
00:16:57,456 --> 00:16:58,166
并把它应用在输入数据上

568
00:16:58,166 --> 00:17:00,216
然后对刚才的操作输出

569
00:16:58,166 --> 00:17:00,216
然后对刚才的操作输出

570
00:17:00,216 --> 00:17:02,076
进行重新调整 从而获得

571
00:17:02,076 --> 00:17:03,476
最终的全分辨率

572
00:17:03,476 --> 00:17:03,856
图像

573
00:17:04,925 --> 00:17:06,445
现在让我们来谈谈

574
00:17:06,445 --> 00:17:08,076
如何使用卷积转置原语

575
00:17:08,156 --> 00:17:09,536
来放大图像

576
00:17:10,435 --> 00:17:12,026
我们有输入

577
00:17:12,026 --> 00:17:13,466
但还需要计算

578
00:17:13,465 --> 00:17:14,146
缺失的数据

579
00:17:14,945 --> 00:17:16,665
所以这个原语计算

580
00:17:17,156 --> 00:17:18,616
缺失数据的方法是

581
00:17:18,616 --> 00:17:19,586
它使用一种

582
00:17:19,586 --> 00:17:21,296
卷积传递给

583
00:17:21,296 --> 00:17:23,165
有间隙的中间结果

584
00:17:23,166 --> 00:17:24,596
然后计算每个输出像素

585
00:17:25,185 --> 00:17:27,316
这就是如何得到

586
00:17:27,356 --> 00:17:28,256
放大的结果

587
00:17:31,136 --> 00:17:32,216
现在我们将向你展示

588
00:17:32,216 --> 00:17:33,556
如何使用这些新的

589
00:17:33,556 --> 00:17:35,046
卷积原语在

590
00:17:35,046 --> 00:17:36,626
真实世界的网络中如何操作

591
00:17:37,096 --> 00:17:38,606
我们选用了这个着色

592
00:17:38,606 --> 00:17:41,486
网络 它可以输入黑白

593
00:17:41,486 --> 00:17:42,886
图像 然后输出

594
00:17:42,886 --> 00:17:44,356
彩色图像

595
00:17:44,356 --> 00:17:47,156
而这个特定的网络能够

596
00:17:47,236 --> 00:17:48,426
使用扩张卷积原语

597
00:17:48,426 --> 00:17:50,396
更快地整合更广泛

598
00:17:50,396 --> 00:17:52,296
全局环境

599
00:17:52,926 --> 00:17:54,756
并且它使用卷积

600
00:17:54,756 --> 00:17:56,726
转置原语来提高

601
00:17:56,726 --> 00:17:57,776
网络的结果

602
00:18:00,166 --> 00:18:01,276
现在我们来看看这个

603
00:18:01,666 --> 00:18:03,966
着色网络怎样运行

604
00:18:10,226 --> 00:18:11,466
在这个演示中 我们

605
00:18:11,466 --> 00:18:12,886
收集了一些黑白

606
00:18:12,886 --> 00:18:14,046
图像 比如这个

607
00:18:14,046 --> 00:18:14,406
狮子

608
00:18:15,046 --> 00:18:16,416
一旦我点击这个

609
00:18:16,416 --> 00:18:17,796
图像 着色网络

610
00:18:17,796 --> 00:18:20,046
将在这个设备上

611
00:18:20,046 --> 00:18:21,126
运行 然后我们将看到一个

612
00:18:21,126 --> 00:18:21,946
彩色的图像

613
00:18:23,906 --> 00:18:25,456
让我们再试试另外一个例子

614
00:18:25,456 --> 00:18:27,046
这是一座美丽的雪山

615
00:18:27,046 --> 00:18:27,616
图像

616
00:18:28,836 --> 00:18:30,036
我们看到现在它是彩色的了

617
00:18:31,586 --> 00:18:33,756
还有这个美丽可爱的图像

618
00:18:33,756 --> 00:18:35,016
一位爸爸和女儿在弹

619
00:18:35,016 --> 00:18:35,366
吉他

620
00:18:35,366 --> 00:18:37,386
你可以看到现在图像

621
00:18:37,386 --> 00:18:38,026
是彩色的了

622
00:18:39,516 --> 00:18:40,896
还有这个图像我真的很喜欢

623
00:18:40,896 --> 00:18:42,306
一只棕熊在森林里

624
00:18:42,356 --> 00:18:42,696
散步

625
00:18:42,696 --> 00:18:43,756
所以我觉得这个网络

626
00:18:43,786 --> 00:18:45,146
效果非常不错

627
00:18:46,886 --> 00:18:48,726
好了 这就是现场

628
00:18:48,726 --> 00:18:48,916
演示

629
00:18:49,516 --> 00:18:54,686
[掌声]

630
00:18:55,186 --> 00:18:55,796
谢谢

631
00:18:57,766 --> 00:18:59,216
所以我们添加了所有这些新的

632
00:18:59,216 --> 00:19:01,456
卷积 CNN 原语 但

633
00:18:59,216 --> 00:19:01,456
卷积 CNN 原语 但

634
00:19:01,456 --> 00:19:02,056
这并不是全部

635
00:19:02,976 --> 00:19:04,666
我们还返回并改进了

636
00:19:04,666 --> 00:19:06,046
iOS 10 中可用的

637
00:19:06,206 --> 00:19:07,936
一些核心 CNN 内核

638
00:19:07,936 --> 00:19:09,646
的性能

639
00:19:10,406 --> 00:19:11,776
这个图像会显示

640
00:19:11,806 --> 00:19:13,846
Inception-v3 网络的

641
00:19:13,846 --> 00:19:15,386
性能 这是一种常用的

642
00:19:15,386 --> 00:19:16,936
图像识别

643
00:19:17,056 --> 00:19:17,546
网络

644
00:19:18,756 --> 00:19:20,396
它显示了这个网络

645
00:19:20,396 --> 00:19:22,196
在 iOS 11 中的性能

646
00:19:22,196 --> 00:19:23,786
正如你所看到的 我们

647
00:19:23,786 --> 00:19:25,866
在不同的 iOS 硬件上

648
00:19:25,866 --> 00:19:27,546
为你带来了至少 20％

649
00:19:27,756 --> 00:19:28,696
的性能提升

650
00:19:30,406 --> 00:19:33,786
现在我们来谈谈新的

651
00:19:33,786 --> 00:19:37,096
神经网络图像 API

652
00:19:37,716 --> 00:19:40,036
神经网络通常

653
00:19:40,036 --> 00:19:41,416
使用图像抽象化来

654
00:19:41,416 --> 00:19:42,476
描述 就像这个

655
00:19:42,476 --> 00:19:43,506
Inception-v3 网络的

656
00:19:43,506 --> 00:19:44,616
可视化一样

657
00:19:44,616 --> 00:19:46,696
我们现在可以使用

658
00:19:46,696 --> 00:19:48,706
新的图像 API 来做到

659
00:19:48,706 --> 00:19:48,966
这一点

660
00:19:50,446 --> 00:19:51,556
所以让我们将这些初始模块中的一个

661
00:19:51,556 --> 00:19:53,186
放大一下

662
00:19:54,676 --> 00:19:56,496
你有过滤节点可以

663
00:19:56,496 --> 00:19:58,176
描述对数据

664
00:19:58,176 --> 00:19:59,216
执行的操作

665
00:19:59,526 --> 00:20:01,146
比如卷积

666
00:19:59,526 --> 00:20:01,146
比如卷积

667
00:20:01,146 --> 00:20:01,566
池化等

668
00:20:02,556 --> 00:20:04,316
同时你有图像节点

669
00:20:04,316 --> 00:20:05,736
可以描述数据如何在

670
00:20:05,786 --> 00:20:06,546
这些不同操作之间

671
00:20:06,546 --> 00:20:07,096
流动

672
00:20:07,826 --> 00:20:11,306
那么我们为什么要添加这个新的图像

673
00:20:11,306 --> 00:20:11,556
API 呢

674
00:20:11,926 --> 00:20:13,156
因为它很好使用

675
00:20:13,686 --> 00:20:14,656
你可以获得整个

676
00:20:14,656 --> 00:20:16,116
网络的紧凑

677
00:20:16,116 --> 00:20:18,326
表示 并将其保存到

678
00:20:18,326 --> 00:20:20,356
磁盘里 还可以将其还原

679
00:20:20,466 --> 00:20:21,546
它可以在平台间运行

680
00:20:23,166 --> 00:20:24,426
你只需要将图形

681
00:20:24,426 --> 00:20:26,366
进行一次初始化 然后就可以

682
00:20:26,366 --> 00:20:27,716
重新用在多个输入

683
00:20:27,716 --> 00:20:28,106
图像里了

684
00:20:29,516 --> 00:20:31,476
仅仅通过一次调用

685
00:20:31,476 --> 00:20:34,056
你就可以在 GPU 上对整个图形

686
00:20:34,056 --> 00:20:34,346
进行操作

687
00:20:36,276 --> 00:20:37,536
没有中间的图像

688
00:20:37,536 --> 00:20:39,196
需要管理 你只需要

689
00:20:39,196 --> 00:20:40,756
做好输入和

690
00:20:40,756 --> 00:20:41,036
输出

691
00:20:42,146 --> 00:20:45,016
在内部我们使用 Metal 堆

692
00:20:45,016 --> 00:20:46,796
来确保所有

693
00:20:46,796 --> 00:20:47,916
中间图像的

694
00:20:47,916 --> 00:20:49,506
内存占用

695
00:20:49,506 --> 00:20:50,126
尽可能小

696
00:20:50,606 --> 00:20:51,296
例如 对于

697
00:20:51,296 --> 00:20:53,376
Inception-v3 网络来说 

698
00:20:53,826 --> 00:20:56,856
这意味着能节省 5 倍的内存空间

699
00:20:56,856 --> 00:20:58,496
和 10 倍的检查器分配

700
00:20:58,556 --> 00:20:59,256
我觉得这是相当令人惊叹的

701
00:21:00,836 --> 00:21:02,926
正如我所说 图像为你

702
00:21:02,926 --> 00:21:03,956
做了所有的基础工作

703
00:21:04,316 --> 00:21:05,646
它会创建

704
00:21:05,846 --> 00:21:06,846
中间图像

705
00:21:06,996 --> 00:21:08,706
并管理图像的大小

706
00:21:09,296 --> 00:21:11,086
它甚至会管理

707
00:21:11,086 --> 00:21:11,366
输出的大小

708
00:21:11,786 --> 00:21:12,766
它负责处理

709
00:21:12,766 --> 00:21:13,406
填充策略

710
00:21:13,796 --> 00:21:15,016
它也会进行审查

711
00:21:15,426 --> 00:21:17,516
简而言之 它能让你

712
00:21:17,566 --> 00:21:19,406
少写很多代码

713
00:21:19,486 --> 00:21:20,746
也就能避免产生很多

714
00:21:20,746 --> 00:21:20,956
错误

715
00:21:21,956 --> 00:21:24,066
当我说较少的代码时 

716
00:21:24,596 --> 00:21:25,376
我是说少了非常多的代码

717
00:21:26,206 --> 00:21:27,906
所以去年我们发布了

718
00:21:27,996 --> 00:21:30,726
使用 Inception-v3 网络

719
00:21:30,726 --> 00:21:32,036
进行图像识别的 Metal 

720
00:21:32,036 --> 00:21:33,286
识别样本

721
00:21:34,326 --> 00:21:36,026
我们把这个样本

722
00:21:36,026 --> 00:21:37,576
转换了一下 从而能够使用

723
00:21:37,806 --> 00:21:40,036
新的图像 API 然后发现我们

724
00:21:40,036 --> 00:21:41,956
可以少编写四倍的代码

725
00:21:42,356 --> 00:21:43,956
少写的代码行数与为了

726
00:21:43,956 --> 00:21:45,846
执行相同的网络

727
00:21:46,226 --> 00:21:47,916
需要在开源传感器

728
00:21:47,916 --> 00:21:48,886
流程框架中编写的

729
00:21:48,886 --> 00:21:50,436
Python 代码行数

730
00:21:50,436 --> 00:21:50,846
一样多

731
00:21:51,476 --> 00:21:52,956
我们只是想提一下 

732
00:21:52,956 --> 00:21:54,046
我们将发布这个升级的

733
00:21:54,086 --> 00:21:57,196
示例代码 升级的示例作为

734
00:21:57,196 --> 00:21:58,346
示例代码

735
00:21:59,026 --> 00:22:01,796
拥有关于你的整个网络的

736
00:21:59,026 --> 00:22:01,796
拥有关于你的整个网络的

737
00:22:01,796 --> 00:22:03,276
所有信息 使我们能够

738
00:22:03,276 --> 00:22:06,116
在不同的视图中

739
00:22:06,116 --> 00:22:07,956
提供最佳

740
00:22:08,106 --> 00:22:08,866
性能

741
00:22:09,336 --> 00:22:10,946
让你可以轻松地在

742
00:22:10,946 --> 00:22:12,766
CPU 和 GPU 之间进行

743
00:22:12,766 --> 00:22:13,206
并行处理

744
00:22:13,976 --> 00:22:15,876
当图像正在执行  

745
00:22:16,326 --> 00:22:18,076
当 GPU 执行一个

746
00:22:18,076 --> 00:22:19,986
输入图像的图形时

747
00:22:19,986 --> 00:22:21,686
CPU 已经准备好执行

748
00:22:21,686 --> 00:22:22,776
不同的输入

749
00:22:22,776 --> 00:22:23,716
图像图形了

750
00:22:25,176 --> 00:22:26,606
我们还可以将图形节点

751
00:22:26,676 --> 00:22:28,446
融合在一起 比如卷积和

752
00:22:28,856 --> 00:22:29,966
神经元节点

753
00:22:31,856 --> 00:22:33,746
我们可以同时操作

754
00:22:33,746 --> 00:22:34,386
这些图形节点

755
00:22:34,386 --> 00:22:36,256
所以如果我们再看一下

756
00:22:36,256 --> 00:22:38,056
这个初始模块的话 

757
00:22:38,056 --> 00:22:39,886
你就可以看到很多行

758
00:22:39,886 --> 00:22:41,386
节点可以

759
00:22:41,456 --> 00:22:43,036
完全彼此独立的

760
00:22:43,036 --> 00:22:43,236
操作

761
00:22:44,176 --> 00:22:45,486
当然 这些独立执行的

762
00:22:45,486 --> 00:22:47,326
输出需要通过

763
00:22:47,926 --> 00:22:49,216
相关节点进行

764
00:22:49,216 --> 00:22:50,216
连接

765
00:22:51,206 --> 00:22:52,656
而且这个图像也足够智能

766
00:22:52,656 --> 00:22:54,276
可以将这些进行优化处理

767
00:22:54,886 --> 00:22:57,706
现在我们来看看如何使用

768
00:22:57,706 --> 00:22:59,586
新的图形 API

769
00:23:00,296 --> 00:23:02,176
所以这是使用

770
00:23:02,176 --> 00:23:04,126
图形 API 创建

771
00:23:04,126 --> 00:23:04,646
卷积节点的代码

772
00:23:05,826 --> 00:23:07,256
它需要一个图像作为源 

773
00:23:08,226 --> 00:23:09,486
而且它也有权重

774
00:23:09,486 --> 00:23:10,926
所以让我们谈一下

775
00:23:10,926 --> 00:23:11,176
权重

776
00:23:13,056 --> 00:23:14,256
神经网络规模

777
00:23:14,256 --> 00:23:15,396
变得越来越大

778
00:23:16,136 --> 00:23:17,736
如果你的网络中有

779
00:23:17,736 --> 00:23:19,346
很多卷积节点 

780
00:23:19,346 --> 00:23:21,436
那就意味着

781
00:23:21,496 --> 00:23:22,466
你的整个网络的

782
00:23:22,466 --> 00:23:23,616
总体权重可能

783
00:23:23,616 --> 00:23:24,246
相当大

784
00:23:25,216 --> 00:23:27,016
为了解决这个问题

785
00:23:27,016 --> 00:23:30,126
我们添加了一个

786
00:23:30,186 --> 00:23:31,296
可以执行的卷积数据源协议

787
00:23:31,656 --> 00:23:33,186
它能够及时

788
00:23:33,606 --> 00:23:35,036
加载和清除

789
00:23:35,076 --> 00:23:35,276
权重数据

790
00:23:36,296 --> 00:23:40,046
所以我们的想法是

791
00:23:40,046 --> 00:23:41,546
你的整个网络的

792
00:23:41,546 --> 00:23:43,196
权重就不用同时

793
00:23:43,196 --> 00:23:44,086
全部加载到内存中

794
00:23:44,626 --> 00:23:45,956
它们也不必

795
00:23:45,956 --> 00:23:46,886
提前加载

796
00:23:48,396 --> 00:23:49,656
为了帮助将内存空间

797
00:23:49,656 --> 00:23:51,556
占用降到最小 当我们初始化

798
00:23:51,556 --> 00:23:53,136
图形并处理

799
00:23:53,136 --> 00:23:54,516
一个特定的卷积层时

800
00:23:55,096 --> 00:23:56,126
我们将为这个卷积层

801
00:23:56,126 --> 00:23:57,726
加载权重 然后

802
00:23:57,856 --> 00:23:59,486
将它们清除之后

803
00:23:59,486 --> 00:24:00,726
再进入下一个卷积层

804
00:23:59,486 --> 00:24:00,726
再进入下一个卷积层

805
00:24:02,226 --> 00:24:03,586
你要做的就是使用

806
00:24:03,586 --> 00:24:05,146
这个初始化方法

807
00:24:05,146 --> 00:24:06,916
它知道数据的

808
00:24:06,916 --> 00:24:08,376
位置 但实际上并不会

809
00:24:08,376 --> 00:24:09,086
加载数据

810
00:24:10,096 --> 00:24:11,256
然后当图像调用

811
00:24:11,256 --> 00:24:13,266
加载功能的时候 

812
00:24:13,266 --> 00:24:14,846
会提醒你需要

813
00:24:14,846 --> 00:24:15,236
加载权重

814
00:24:15,366 --> 00:24:16,546
然后当图像调用

815
00:24:16,546 --> 00:24:18,166
清除函数功能时

816
00:24:18,166 --> 00:24:19,316
你可以释放权重

817
00:24:21,586 --> 00:24:22,526
现在我们来构建一个图像

818
00:24:23,446 --> 00:24:24,926
这里我们正在使用

819
00:24:24,926 --> 00:24:26,116
这个 makeGraph 函数

820
00:24:26,596 --> 00:24:28,366
而在左边 你可以看到

821
00:24:28,366 --> 00:24:29,636
构建网络所需的

822
00:24:29,636 --> 00:24:30,826
所有节点

823
00:24:31,256 --> 00:24:32,926
然后我们创建节点

824
00:24:33,226 --> 00:24:34,446
创建卷积

825
00:24:34,446 --> 00:24:34,836
节点

826
00:24:35,016 --> 00:24:35,616
池化节点

827
00:24:35,616 --> 00:24:37,456
和剩下的节点

828
00:24:37,756 --> 00:24:38,606
现在节点有了

829
00:24:38,606 --> 00:24:40,226
那我们如何将节点

830
00:24:40,226 --> 00:24:40,446
连接成图像呢

831
00:24:41,646 --> 00:24:43,186
我们只需把一个节点的

832
00:24:43,186 --> 00:24:44,986
结果图像作为

833
00:24:45,066 --> 00:24:46,516
源图像传递给下一个节点 

834
00:24:46,516 --> 00:24:48,106
就形成了图像

835
00:24:49,736 --> 00:24:51,236
现在让我们在 GPU 上运行这个图表

836
00:24:51,906 --> 00:24:54,066
首先像往常一样进行 Metal 

837
00:24:54,066 --> 00:24:54,456
设置

838
00:24:54,886 --> 00:24:56,016
我们初始化这个图像

839
00:24:56,676 --> 00:24:58,166
要管理好输入数据

840
00:24:58,866 --> 00:25:01,066
然后将图像编码到

841
00:24:58,866 --> 00:25:01,066
然后将图像编码到

842
00:25:01,066 --> 00:25:01,506
GPU 上

843
00:25:02,276 --> 00:25:04,026
输出图像中的数据

844
00:25:04,556 --> 00:25:06,546
将会在命令缓冲区

845
00:25:06,546 --> 00:25:08,466
完成时 将数据填充到

846
00:25:08,466 --> 00:25:09,576
输出图像中

847
00:25:10,086 --> 00:25:11,526
然后我们可以选择

848
00:25:11,526 --> 00:25:12,996
等待 GPU 完成

849
00:25:13,406 --> 00:25:14,686
但我们并不推荐

850
00:25:14,686 --> 00:25:14,956
这样做

851
00:25:15,886 --> 00:25:17,506
因为如果这样做的话 

852
00:25:17,506 --> 00:25:19,246
CPU 就会等 GPU 完成之后 

853
00:25:19,836 --> 00:25:21,486
才能开始对下一轮

854
00:25:21,486 --> 00:25:22,846
图像进行编码

855
00:25:23,486 --> 00:25:25,256
而这样会将气泡引入你的

856
00:25:25,256 --> 00:25:26,266
传输途径 并对

857
00:25:26,526 --> 00:25:28,036
性能产生不利影响

858
00:25:29,816 --> 00:25:30,686
所以我们推荐

859
00:25:30,686 --> 00:25:32,606
使用新的

860
00:25:32,606 --> 00:25:34,596
异步执行的 API

861
00:25:35,426 --> 00:25:37,896
使用这个 API 能让你的 Metal 

862
00:25:37,966 --> 00:25:39,436
设置甚至变得更小

863
00:25:39,626 --> 00:25:41,076
这样你只需要准备好

864
00:25:41,076 --> 00:25:41,736
Metal 设备

865
00:25:42,136 --> 00:25:43,096
然后需要

866
00:25:43,096 --> 00:25:44,016
初始化图像

867
00:25:44,056 --> 00:25:46,426
准备好输入数据 然后

868
00:25:46,426 --> 00:25:47,856
执行异步调用

869
00:25:49,586 --> 00:25:52,376
它会立即返回 

870
00:25:52,376 --> 00:25:54,216
然后当这个代码

871
00:25:55,196 --> 00:25:56,236
闭包执行时 输出图像

872
00:25:56,236 --> 00:25:57,086
就已经准备好了

873
00:25:57,796 --> 00:25:59,056
但在此期间 你不需要

874
00:25:59,056 --> 00:26:00,136
等待 GPU 完成

875
00:25:59,056 --> 00:26:00,136
等待 GPU 完成

876
00:26:00,306 --> 00:26:02,056
就可以继续进行

877
00:26:02,056 --> 00:26:03,676
编码和新的 GPU 任务。

878
00:26:04,396 --> 00:26:07,236
这样 CPU 和 GPU 就

879
00:26:07,236 --> 00:26:08,846
可以同时工作

880
00:26:09,406 --> 00:26:10,316
并且你的传输途经中

881
00:26:10,316 --> 00:26:12,756
没有气泡 两者都

882
00:26:12,756 --> 00:26:14,376
被充分地利用了起来

883
00:26:16,756 --> 00:26:18,996
好了 现在我来做一次

884
00:26:18,996 --> 00:26:21,106
现场演示 演示

885
00:26:21,146 --> 00:26:22,846
同步和异步 API 

886
00:26:22,966 --> 00:26:24,526
之间的

887
00:26:24,526 --> 00:26:24,786
性能差异

888
00:26:24,786 --> 00:26:27,576
这个演示将使用

889
00:26:27,576 --> 00:26:29,576
Inception-v3 网络

890
00:26:29,576 --> 00:26:30,116
进行图像识别

891
00:26:30,516 --> 00:26:30,806
好的

892
00:26:31,136 --> 00:26:32,726
我将从同步

893
00:26:32,726 --> 00:26:34,416
API 开始 在这里我们正在

894
00:26:34,416 --> 00:26:35,706
检测一个水瓶

895
00:26:35,706 --> 00:26:38,276
平均每个

896
00:26:38,276 --> 00:26:41,756
图像大约有 50 

897
00:26:41,756 --> 00:26:42,596
毫秒

898
00:26:42,826 --> 00:26:44,066
现在我将切换到

899
00:26:44,066 --> 00:26:44,956
异步 API

900
00:26:44,956 --> 00:26:47,586
现在平均每个图像的

901
00:26:47,586 --> 00:26:49,546
时间约为 36 

902
00:26:49,546 --> 00:26:49,936
毫秒

903
00:26:49,936 --> 00:26:51,656
所以性能

904
00:26:51,686 --> 00:26:52,666
有了很大提升

905
00:26:54,776 --> 00:26:55,066
好的

906
00:26:55,196 --> 00:26:56,436
这就是现场演示

907
00:26:58,516 --> 00:27:04,016
[掌声]

908
00:26:58,516 --> 00:27:04,016
[掌声]

909
00:27:04,516 --> 00:27:04,876
谢谢你们

910
00:27:06,566 --> 00:27:07,656
好的 既然我们已经谈过了

911
00:27:07,656 --> 00:27:08,626
新的神经网络图像

912
00:27:08,626 --> 00:27:10,926
API 并且向你展示了

913
00:27:10,956 --> 00:27:12,716
它使用起来多么简单

914
00:27:12,716 --> 00:27:14,016
性能多么强大 

915
00:27:14,016 --> 00:27:16,086
现在让我们来换个话题 

916
00:27:16,086 --> 00:27:17,166
谈谈循环神经

917
00:27:17,166 --> 00:27:17,566
网络

918
00:27:19,416 --> 00:27:20,386
什么是循环神经

919
00:27:20,386 --> 00:27:20,786
网络呢

920
00:27:23,406 --> 00:27:25,456
CNN 的一个缺点是

921
00:27:25,456 --> 00:27:27,276
无法记住过去

922
00:27:27,306 --> 00:27:28,326
发生的

923
00:27:28,326 --> 00:27:28,466
事情

924
00:27:29,456 --> 00:27:31,226
它们可以将一个图像

925
00:27:31,896 --> 00:27:33,926
作为输入 并生成单个输出

926
00:27:34,446 --> 00:27:36,316
例如图像中所描绘

927
00:27:36,356 --> 00:27:37,396
内容的一组

928
00:27:37,396 --> 00:27:37,836
可能性

929
00:27:39,056 --> 00:27:41,016
但 RNN 是有

930
00:27:41,016 --> 00:27:41,446
记忆的

931
00:27:42,346 --> 00:27:43,466
而且它们擅长按顺序

932
00:27:43,546 --> 00:27:44,066
进行操作

933
00:27:44,536 --> 00:27:48,256
所以它们可以通过一个输入

934
00:27:48,256 --> 00:27:49,576
比如图像中所

935
00:27:49,636 --> 00:27:51,016
描绘内容的一组

936
00:27:51,616 --> 00:27:52,966
可能性 然后产生一个

937
00:27:53,036 --> 00:27:53,366
输出序列

938
00:27:53,366 --> 00:27:56,196
一组有逻辑顺序的单词

939
00:27:56,196 --> 00:27:57,586
成为这个图像的标题

940
00:27:59,416 --> 00:28:01,716
它们还可以通过一个

941
00:27:59,416 --> 00:28:01,716
它们还可以通过一个

942
00:28:01,806 --> 00:28:03,506
序列输入 比如英语句子 

943
00:28:03,506 --> 00:28:06,626
产生多个序列

944
00:28:06,626 --> 00:28:08,506
输出 比如同一个句子翻译成

945
00:28:08,666 --> 00:28:09,946
不同的语言 

946
00:28:09,946 --> 00:28:12,376
比如俄语

947
00:28:12,466 --> 00:28:13,056
或芬兰语

948
00:28:13,366 --> 00:28:16,356
而且我们还支持许多

949
00:28:16,356 --> 00:28:17,756
不同的 RNN 变体

950
00:28:18,586 --> 00:28:20,146
单门限 RNN 

951
00:28:20,146 --> 00:28:22,156
长短期记忆 RNN 或者说 LSTM 

952
00:28:22,596 --> 00:28:24,586
以及 LSTM 的多种变体

953
00:28:24,866 --> 00:28:26,336
GRU 和 MGU

954
00:28:27,766 --> 00:28:29,336
那么让我们来谈谈最简单的

955
00:28:29,366 --> 00:28:31,326
RNN 类型 单门限

956
00:28:31,326 --> 00:28:31,526
RNN

957
00:28:33,666 --> 00:28:34,966
单门限 RNN 具有

958
00:28:34,966 --> 00:28:37,006
循环单元 这使得

959
00:28:37,066 --> 00:28:38,676
RNN 之前的输出

960
00:28:38,996 --> 00:28:40,346
能够影响同一个

961
00:28:40,406 --> 00:28:41,846
RNN 的后续

962
00:28:41,846 --> 00:28:42,406
迭代输出

963
00:28:43,606 --> 00:28:45,496
但是单门限 RNN 的功能

964
00:28:45,546 --> 00:28:47,466
还不够强大 不能将

965
00:28:47,466 --> 00:28:48,746
重要信息对多次

966
00:28:48,746 --> 00:28:49,286
迭代输出构成影响

967
00:28:50,136 --> 00:28:51,676
因为单门限 RNN 的

968
00:28:51,786 --> 00:28:53,976
当前输出也是

969
00:28:53,976 --> 00:28:54,996
它的当前状态

970
00:28:54,996 --> 00:28:55,976
没有别的东西

971
00:28:57,146 --> 00:28:59,426
解决这个问题的方法是

972
00:28:59,476 --> 00:29:01,596
长短期记忆 RNN 或简称 LSTM

973
00:28:59,476 --> 00:29:01,596
长短期记忆 RNN 或简称 LSTM

974
00:29:02,376 --> 00:29:03,906
它由单门限 RNN 构成 

975
00:29:03,906 --> 00:29:06,246
并具有内部存储

976
00:29:06,246 --> 00:29:06,506
单元

977
00:29:07,436 --> 00:29:08,856
一个特定的

978
00:29:08,956 --> 00:29:10,596
门限组合可以控制

979
00:29:10,596 --> 00:29:13,106
信息在 LSTM 内如何流动

980
00:29:13,436 --> 00:29:15,016
并有选择的让信息

981
00:29:15,136 --> 00:29:16,266
存入存储单元

982
00:29:16,846 --> 00:29:19,656
让我们更详细地

983
00:29:19,656 --> 00:29:21,316
看一下 LSTM 的

984
00:29:21,316 --> 00:29:21,776
架构

985
00:29:22,206 --> 00:29:25,246
正如我所说 LSTM 中

986
00:29:25,356 --> 00:29:27,846
最重要的实体是存储

987
00:29:27,886 --> 00:29:30,406
单元 它在 LSTM 的每个循环期内

988
00:29:30,476 --> 00:29:31,536
都会进行更新

989
00:29:31,536 --> 00:29:33,426
所以你可以想到 

990
00:29:33,846 --> 00:29:35,246
LSTM 的每一次迭代

991
00:29:35,306 --> 00:29:37,456
都是这种新旧

992
00:29:37,456 --> 00:29:38,016
内存之间的转换

993
00:29:38,676 --> 00:29:40,786
现在让我们谈谈

994
00:29:40,816 --> 00:29:41,036
门限

995
00:29:41,566 --> 00:29:43,376
首先是遗忘门限 

996
00:29:44,216 --> 00:29:45,876
它决定旧的内存中

997
00:29:45,876 --> 00:29:47,206
哪些能够保留

998
00:29:47,206 --> 00:29:47,566
哪些不能保留

999
00:29:48,966 --> 00:29:50,456
然后是输入和

1000
00:29:50,456 --> 00:29:51,836
单元门限

1001
00:29:51,836 --> 00:29:53,996
它们的相互组合决定了

1002
00:29:54,066 --> 00:29:55,786
当前输入的什么信息

1003
00:29:55,786 --> 00:29:56,936
将影响新的内存

1004
00:29:56,936 --> 00:29:59,136
然后这三个门限

1005
00:29:59,136 --> 00:30:00,866
组合在一起来

1006
00:29:59,136 --> 00:30:00,866
组合在一起来

1007
00:30:01,226 --> 00:30:04,596
更新存储单元

1008
00:30:05,696 --> 00:30:07,576
最后是输出门限

1009
00:30:07,626 --> 00:30:09,656
它决定了

1010
00:30:09,656 --> 00:30:11,976
以前的输入

1011
00:30:12,476 --> 00:30:14,076
输出 当前的

1012
00:30:14,076 --> 00:30:16,126
输入和新的内存中

1013
00:30:16,126 --> 00:30:17,936
哪些信息将会影响 LSTM 的输出

1014
00:30:19,196 --> 00:30:20,626
所以现在你知道 LSTM 

1015
00:30:20,626 --> 00:30:22,206
是由什么组成的了 让我们来看看

1016
00:30:22,206 --> 00:30:24,006
你如何使用我们的框架

1017
00:30:24,006 --> 00:30:24,576
来创建一个 LSTM

1018
00:30:25,616 --> 00:30:27,536
首先创建一个 LSTM 的

1019
00:30:27,756 --> 00:30:28,576
描述符

1020
00:30:29,146 --> 00:30:31,306
然后你需要将门限

1021
00:30:31,526 --> 00:30:31,876
初始化

1022
00:30:32,436 --> 00:30:33,676
那么门限由什么控制呢 

1023
00:30:33,676 --> 00:30:35,146
什么能够控制门限

1024
00:30:35,306 --> 00:30:36,156
控制门限

1025
00:30:36,156 --> 00:30:37,756
如何操作的是经过

1026
00:30:37,756 --> 00:30:38,386
训练的参数

1027
00:30:39,146 --> 00:30:40,156
这些参数来自

1028
00:30:40,156 --> 00:30:41,726
为使系统执行一项特定任务

1029
00:30:41,726 --> 00:30:43,526
而对其进行训练的步骤

1030
00:30:45,566 --> 00:30:47,496
而且你可以看到 

1031
00:30:47,496 --> 00:30:48,586
这里有很多门限

1032
00:30:48,646 --> 00:30:49,856
供你进行初始化

1033
00:30:49,856 --> 00:30:52,356
但为了简要说明

1034
00:30:52,356 --> 00:30:52,726
我们只展示两个初始化

1035
00:30:53,206 --> 00:30:54,336
正如你所看到的 我们也

1036
00:30:54,336 --> 00:30:56,046
在使用一个数据源供应程序 

1037
00:30:56,046 --> 00:30:57,446
和之前给你看过的一样

1038
00:30:57,556 --> 00:30:58,606
它用来初始化权重

1039
00:30:59,656 --> 00:31:01,536
下一步是创建

1040
00:30:59,656 --> 00:31:01,536
下一步是创建

1041
00:31:01,536 --> 00:31:03,606
我们的 LSTM 层 现在我们

1042
00:31:03,606 --> 00:31:04,876
把它放在 GPU 上运行

1043
00:31:06,586 --> 00:31:08,646
我们需要创建数组 

1044
00:31:08,646 --> 00:31:10,976
保存 LSTM 

1045
00:31:10,976 --> 00:31:13,236
执行序列的

1046
00:31:13,236 --> 00:31:14,266
输入和输出

1047
00:31:14,886 --> 00:31:16,076
然后将序列编码到

1048
00:31:16,076 --> 00:31:16,716
GPU 上

1049
00:31:17,416 --> 00:31:19,446
在这里 我们向你展示

1050
00:31:19,666 --> 00:31:21,546
一种基于矩阵的 RNN 但我们

1051
00:31:21,546 --> 00:31:22,646
想提一下 我们

1052
00:31:22,686 --> 00:31:25,726
也支持通过卷积在

1053
00:31:25,726 --> 00:31:27,636
MPS 图像上操作的 RNN

1054
00:31:30,176 --> 00:31:31,216
现在我们来看一个

1055
00:31:31,216 --> 00:31:32,016
实际的例子

1056
00:31:32,596 --> 00:31:34,366
我们将使用图片字幕

1057
00:31:34,366 --> 00:31:35,706
作为使用 LSTM 的例子

1058
00:31:36,726 --> 00:31:38,566
你应该记得 我跟你讲过 

1059
00:31:38,896 --> 00:31:40,646
深度学习算法

1060
00:31:40,646 --> 00:31:42,076
有两个阶段

1061
00:31:42,346 --> 00:31:43,316
训练阶段和

1062
00:31:43,316 --> 00:31:44,026
推理阶段

1063
00:31:44,816 --> 00:31:46,816
所以要想训练一个系统

1064
00:31:46,816 --> 00:31:49,196
为图像添加说明文字

1065
00:31:49,196 --> 00:31:51,056
你需要给它输入大量的带有

1066
00:31:51,056 --> 00:31:52,356
人为添加说明文字的图像

1067
00:31:53,836 --> 00:31:56,606
那么这个系统有什么呢

1068
00:31:56,656 --> 00:31:57,686
它是由什么构成的

1069
00:31:58,536 --> 00:32:02,016
这个系统有一个 CNN 和一个

1070
00:31:58,536 --> 00:32:02,016
这个系统有一个 CNN 和一个

1071
00:32:02,016 --> 00:32:03,906
RNN 一起工作来生成

1072
00:32:03,906 --> 00:32:04,346
说明文字

1073
00:32:04,746 --> 00:32:07,316
CNN 用于确定

1074
00:32:07,316 --> 00:32:09,316
图像中描述的内容

1075
00:32:09,316 --> 00:32:10,886
然后经 RNN 生成

1076
00:32:10,956 --> 00:32:11,806
实际的说明文字

1077
00:32:13,256 --> 00:32:15,076
而该过程的输出

1078
00:32:15,156 --> 00:32:17,006
是经过训练的参数

1079
00:32:17,006 --> 00:32:19,036
它们是下一步也就是

1080
00:32:20,186 --> 00:32:20,886
推理阶段需要的

1081
00:32:21,676 --> 00:32:25,606
因此 在推理阶段

1082
00:32:25,656 --> 00:32:27,766
经过训练的参数控制

1083
00:32:27,766 --> 00:32:29,826
CNN 层

1084
00:32:29,826 --> 00:32:31,866
和 RNN 

1085
00:32:31,866 --> 00:32:32,146
门限的运行

1086
00:32:33,206 --> 00:32:37,276
然后每个图像

1087
00:32:37,336 --> 00:32:39,166
都由 CNN 和 RNN 进行处理

1088
00:32:39,446 --> 00:32:41,326
从而生成说明文字

1089
00:32:42,216 --> 00:32:43,246
我们已经知道有一个很好的

1090
00:32:43,246 --> 00:32:44,636
网络可以确定

1091
00:32:44,706 --> 00:32:45,816
图像中描绘的内容

1092
00:32:46,086 --> 00:32:47,506
就是 Inception-v3 网络

1093
00:32:47,876 --> 00:32:48,626
所以我们将使用它

1094
00:32:49,186 --> 00:32:50,456
而且我们刚刚谈到了 LSTM

1095
00:32:50,456 --> 00:32:52,236
所以让我们用它来生成

1096
00:32:52,446 --> 00:32:53,036
说明文字

1097
00:32:53,996 --> 00:32:56,456
说明文字生成阶段

1098
00:32:57,266 --> 00:32:58,176
说明文字生成过程

1099
00:32:58,176 --> 00:32:59,726
也分为两个阶段

1100
00:33:00,006 --> 00:33:02,206
首先我们有 LSTM 

1101
00:33:02,486 --> 00:33:03,646
初始化阶段

1102
00:33:04,846 --> 00:33:06,126
然后我们运行 Inception-v3 

1103
00:33:06,126 --> 00:33:08,616
网络 实际上我们运行了所有的

1104
00:33:08,616 --> 00:33:10,496
层 除了最后一个

1105
00:33:10,496 --> 00:33:11,986
SoftMax 层

1106
00:33:12,236 --> 00:33:13,386
而输出是一个

1107
00:33:13,386 --> 00:33:15,016
特征向量 它含有

1108
00:33:15,016 --> 00:33:16,196
关于图像描绘

1109
00:33:16,196 --> 00:33:17,226
内容的信息

1110
00:33:17,906 --> 00:33:19,016
然后我们将该

1111
00:33:19,016 --> 00:33:20,566
特征向量转换为

1112
00:33:20,566 --> 00:33:23,246
LSTM 所需的

1113
00:33:23,246 --> 00:33:24,286
紧凑表示

1114
00:33:24,286 --> 00:33:26,596
然后通过 LSTM 运行

1115
00:33:26,946 --> 00:33:27,746
将其初始化

1116
00:33:28,736 --> 00:33:30,466
然后一旦我们有了

1117
00:33:30,466 --> 00:33:32,436
初始化的 LSTM 那就

1118
00:33:32,436 --> 00:33:33,586
准备好可以进入下一个阶段了

1119
00:33:34,606 --> 00:33:36,066
即实际说明文字

1120
00:33:36,066 --> 00:33:36,376
生成阶段

1121
00:33:38,116 --> 00:33:39,676
我们通过向 LSTM 传递

1122
00:33:39,676 --> 00:33:41,366
一个特殊的句子开始令牌 ID 

1123
00:33:41,436 --> 00:33:44,026
来启动这个过程

1124
00:33:44,236 --> 00:33:45,046
并且该操作的输出

1125
00:33:45,046 --> 00:33:46,756
是一个单词序列

1126
00:33:46,756 --> 00:33:50,006
你知道的 就是

1127
00:33:50,006 --> 00:33:51,276
和图像中所描绘的

1128
00:33:51,276 --> 00:33:52,666
内容相关的单词

1129
00:33:53,526 --> 00:33:55,806
然后我们将这些单词传递给

1130
00:33:55,806 --> 00:33:57,226
一个 SoftMax 层 该层可以计算

1131
00:33:57,226 --> 00:33:58,796
这些单词的概率

1132
00:33:59,326 --> 00:34:01,176
我们选择三个概率最高的

1133
00:33:59,326 --> 00:34:01,176
我们选择三个概率最高的

1134
00:34:01,326 --> 00:34:03,276
这三个概率最高的单词也是

1135
00:34:03,276 --> 00:34:05,816
我们对于特定图像的

1136
00:34:05,816 --> 00:34:07,546
说明文字中的单字部分

1137
00:34:08,126 --> 00:34:09,726
所以我们将这些单词拿出来

1138
00:34:09,806 --> 00:34:11,856
并传递给下一个状态的

1139
00:34:11,946 --> 00:34:15,045
LSTM 它的功能是

1140
00:34:15,096 --> 00:34:16,886
为图像算出三组

1141
00:34:16,916 --> 00:34:19,216
最好的双字组合

1142
00:34:19,216 --> 00:34:19,386
说明文字

1143
00:34:19,466 --> 00:34:21,416
我们执行 N 次迭代 

1144
00:34:21,886 --> 00:34:23,076
直到达到停止的

1145
00:34:23,076 --> 00:34:25,596
条件 也就是当

1146
00:34:25,626 --> 00:34:27,116
达到我们想要的说明文字

1147
00:34:27,116 --> 00:34:28,966
字数上限的时候 

1148
00:34:28,966 --> 00:34:30,856
或者当

1149
00:34:30,856 --> 00:34:32,136
新生成的说明文字

1150
00:34:32,136 --> 00:34:33,906
概率下降到 0 的时候

1151
00:34:34,985 --> 00:34:35,996
我知道这仍然

1152
00:34:35,996 --> 00:34:36,505
很抽象

1153
00:34:36,846 --> 00:34:39,005
所以让我们来看看

1154
00:34:39,386 --> 00:34:42,266
LSTM 的输出 也就是

1155
00:34:42,326 --> 00:34:44,556
LSTM 为了一个特定图像

1156
00:34:44,556 --> 00:34:45,545
进行多次迭代之后的实际输出

1157
00:34:46,216 --> 00:34:49,786
在这个图像中 你看到

1158
00:34:49,786 --> 00:34:51,636
有冲浪者驾驭在一个波浪上

1159
00:34:51,636 --> 00:34:53,146
我们想计算出匹配这张图像的

1160
00:34:53,146 --> 00:34:54,666
三句最好的说明文字

1161
00:34:55,696 --> 00:34:57,286
在 LSTM 的第一次迭代中

1162
00:34:57,366 --> 00:34:59,936
生成了三个最好的

1163
00:34:59,936 --> 00:35:00,306
单词

1164
00:34:59,936 --> 00:35:00,306
单词

1165
00:35:02,336 --> 00:35:04,446
所以 这是匹配

1166
00:35:04,446 --> 00:35:05,686
这张图像的最好的

1167
00:35:05,686 --> 00:35:05,996
文字说明

1168
00:35:06,506 --> 00:35:07,596
“man”“a”和“the”

1169
00:35:08,316 --> 00:35:10,596
“a”一词的概率

1170
00:35:10,596 --> 00:35:11,186
最高

1171
00:35:11,936 --> 00:35:13,546
然后我们把这三个字

1172
00:35:13,546 --> 00:35:15,196
传递给下一个

1173
00:35:15,196 --> 00:35:16,436
LSTM 的迭代

1174
00:35:17,166 --> 00:35:19,356
在这个迭代中 

1175
00:35:19,356 --> 00:35:21,416
对于这三个起始单词中的

1176
00:35:22,436 --> 00:35:24,416
每一个 LSTM 都生成了三个新词 

1177
00:35:24,416 --> 00:35:26,026
它们有和这些

1178
00:35:26,026 --> 00:35:28,496
起始单词组合的

1179
00:35:28,496 --> 00:35:29,606
最高概率

1180
00:35:30,666 --> 00:35:31,966
对吧 所以我们有三个

1181
00:35:31,966 --> 00:35:33,556
新词可以和“man”组合

1182
00:35:33,946 --> 00:35:35,256
三个新词和“a”

1183
00:35:35,256 --> 00:35:37,766
组合 还有三个新词

1184
00:35:37,826 --> 00:35:38,976
和“the”组合

1185
00:35:40,686 --> 00:35:42,296
现在你可以看到 

1186
00:35:42,296 --> 00:35:44,486
每一个双字组合说明

1187
00:35:44,486 --> 00:35:45,486
也都有概率

1188
00:35:46,026 --> 00:35:47,866
而且由于“a” 

1189
00:35:47,936 --> 00:35:49,286
在第一次迭代中具有

1190
00:35:49,286 --> 00:35:53,366
如此高的概率 所以

1191
00:35:53,366 --> 00:35:54,646
在第二次迭代中

1192
00:35:54,646 --> 00:35:56,426
以“a”开头的双字组合

1193
00:35:56,476 --> 00:35:58,156
最后也具有最高的

1194
00:35:58,156 --> 00:35:58,796
概率

1195
00:35:58,896 --> 00:36:00,916
这是为什么 因为双字

1196
00:35:58,896 --> 00:36:00,916
这是为什么 因为双字

1197
00:36:00,916 --> 00:36:02,506
说明的概率

1198
00:36:02,536 --> 00:36:04,516
只是其中两个单词

1199
00:36:04,516 --> 00:36:05,706
概率的

1200
00:36:05,706 --> 00:36:06,006
乘积

1201
00:36:07,116 --> 00:36:08,886
这就是我们如何获得这三个的最好

1202
00:36:08,886 --> 00:36:09,396
方法

1203
00:36:09,696 --> 00:36:11,226
然后我们留下它们并

1204
00:36:11,226 --> 00:36:12,836
继续下一个迭代

1205
00:36:13,186 --> 00:36:14,406
而在下一次迭代中

1206
00:36:14,406 --> 00:36:15,936
我们只需为已有说明文字

1207
00:36:15,936 --> 00:36:17,536
再添加一个单词

1208
00:36:17,846 --> 00:36:18,806
这样就有了三字说明

1209
00:36:19,206 --> 00:36:19,996
然后我们计算这些

1210
00:36:19,996 --> 00:36:21,836
说明文字的概率

1211
00:36:21,836 --> 00:36:22,886
并挑选三个概率最高的

1212
00:36:23,936 --> 00:36:25,106
我们继续进行下一次

1213
00:36:25,106 --> 00:36:27,026
迭代 只需再添加

1214
00:36:27,026 --> 00:36:28,746
一个词到

1215
00:36:28,746 --> 00:36:29,186
文字说明中

1216
00:36:29,186 --> 00:36:30,566
然后我们有了四字文字说明

1217
00:36:30,976 --> 00:36:31,876
然后我们计算

1218
00:36:31,926 --> 00:36:33,186
所有这些文字说明的

1219
00:36:33,236 --> 00:36:34,546
概率 并挑选概率

1220
00:36:34,606 --> 00:36:34,816
最高的三个

1221
00:36:36,176 --> 00:36:37,306
等等 我觉得你已经

1222
00:36:37,306 --> 00:36:37,646
了解这个方法了

1223
00:36:37,866 --> 00:36:38,936
那就让我们跳到最后吧

1224
00:36:39,296 --> 00:36:41,416
所以最后 我们得到了三个

1225
00:36:41,416 --> 00:36:43,506
最好的文字说明来匹配

1226
00:36:43,506 --> 00:36:43,936
这个特定的图象

1227
00:36:43,936 --> 00:36:45,906
而其中最好的是一个男人

1228
00:36:45,906 --> 00:36:47,426
踏着冲浪板冲浪

1229
00:36:47,656 --> 00:36:48,616
我觉得意思已经非常接近了

1230
00:36:50,966 --> 00:36:52,346
所以现在我们来

1231
00:36:52,346 --> 00:36:52,726
演示一下

1232
00:36:53,508 --> 00:36:55,508
[掌声] 

1233
00:36:58,476 --> 00:37:00,116
所以现在我们来做一个

1234
00:36:58,476 --> 00:37:00,116
所以现在我们来做一个

1235
00:37:00,606 --> 00:37:02,206
这个字幕网络的演示

1236
00:37:03,346 --> 00:37:04,856
我们在这里收集了

1237
00:37:04,856 --> 00:37:07,156
一些图像 一旦我点击

1238
00:37:07,156 --> 00:37:09,036
一张图像 CNN 

1239
00:37:09,136 --> 00:37:10,826
就会运行并确定

1240
00:37:10,826 --> 00:37:12,526
图像中描绘的内容

1241
00:37:12,526 --> 00:37:14,046
然后 RNN 将运行

1242
00:37:14,046 --> 00:37:15,226
并生成实际的说明文字

1243
00:37:15,356 --> 00:37:16,036
所以让我们试试吧

1244
00:37:17,826 --> 00:37:19,446
&gt;&gt;一个男人踏着

1245
00:37:19,446 --> 00:37:19,766
冲浪板冲浪

1246
00:37:19,766 --> 00:37:22,356
&gt;&gt;这个我们已经知道了

1247
00:37:23,526 --> 00:37:24,566
现在让我们试试另一张

1248
00:37:24,996 --> 00:37:26,536
&gt;&gt;一辆旧卡车停放在

1249
00:37:26,536 --> 00:37:27,106
野外

1250
00:37:27,626 --> 00:37:28,936
&gt;&gt;所以网络实际上知道

1251
00:37:28,976 --> 00:37:30,356
这是一辆旧卡车 

1252
00:37:30,356 --> 00:37:31,786
它是停放着的 不动的

1253
00:37:31,966 --> 00:37:33,336
我觉得这非常

1254
00:37:33,556 --> 00:37:34,156
令人惊叹

1255
00:37:34,786 --> 00:37:35,656
再试一次

1256
00:37:37,026 --> 00:37:38,496
&gt;&gt;一只黑白花纹的狗

1257
00:37:38,496 --> 00:37:39,086
躺在草地上

1258
00:37:39,796 --> 00:37:40,896
&gt;&gt;所以网络知道

1259
00:37:40,896 --> 00:37:42,176
这是一只黑白色的狗 

1260
00:37:42,176 --> 00:37:43,636
它躺在草地上 

1261
00:37:44,326 --> 00:37:45,106
并没有跑

1262
00:37:45,236 --> 00:37:46,356
没有走路

1263
00:37:46,726 --> 00:37:47,876
也没有坐着 

1264
00:37:48,336 --> 00:37:50,266
而是躺在草地上

1265
00:37:50,766 --> 00:37:52,796
太酷了

1266
00:37:53,516 --> 00:37:57,786
[掌声] 

1267
00:37:58,286 --> 00:37:58,726
谢谢

1268
00:37:59,306 --> 00:38:01,166
借着这个说明 我们来

1269
00:37:59,306 --> 00:38:01,166
借着这个说明 我们来

1270
00:38:01,236 --> 00:38:01,586
总结一下

1271
00:38:02,066 --> 00:38:03,536
所以在本次会议中 

1272
00:38:03,536 --> 00:38:05,246
我们讨论了今年在

1273
00:38:05,276 --> 00:38:07,006
MPS 框架中

1274
00:38:07,336 --> 00:38:08,206
添加的所有新原语。

1275
00:38:08,586 --> 00:38:10,236
我们扩大了对

1276
00:38:10,236 --> 00:38:12,386
图像处理原语和

1277
00:38:12,786 --> 00:38:13,736
卷积神经网络的

1278
00:38:13,736 --> 00:38:14,136
支持

1279
00:38:15,006 --> 00:38:16,596
我们还增加了对

1280
00:38:16,596 --> 00:38:18,886
线性代数和循环

1281
00:38:18,886 --> 00:38:22,226
神经网络的支持

1282
00:38:23,096 --> 00:38:24,666
该框架针对针对

1283
00:38:24,666 --> 00:38:26,146
iOS 进行了优化 正如我所说的那样

1284
00:38:26,596 --> 00:38:29,226
现在这些原语也都在

1285
00:38:29,226 --> 00:38:30,016
Mac 上可用

1286
00:38:31,116 --> 00:38:32,416
我们还讨论了新的

1287
00:38:32,416 --> 00:38:34,676
神经网络图像 API 

1288
00:38:34,676 --> 00:38:36,406
并向你展示了如何

1289
00:38:36,406 --> 00:38:38,336
在 GPU 上构建和运行

1290
00:38:38,336 --> 00:38:39,666
你的网络

1291
00:38:40,426 --> 00:38:42,186
而且 这使我们有可能

1292
00:38:42,186 --> 00:38:43,586
在不同的 GPU 上

1293
00:38:43,666 --> 00:38:45,346
为你的网络提供

1294
00:38:45,346 --> 00:38:46,336
最佳性能

1295
00:38:46,336 --> 00:38:49,776
我们希望大家能够

1296
00:38:49,776 --> 00:38:51,976
使用所有这些新功能 

1297
00:38:51,976 --> 00:38:53,526
来创建非常好的应用程序

1298
00:38:53,526 --> 00:38:55,836
并告诉我们

1299
00:38:56,116 --> 00:38:57,296
所以 请查看 Metal 2 相关的

1300
00:38:57,296 --> 00:38:58,856
会议和有关

1301
00:38:58,856 --> 00:39:01,186
核心 ML

1302
00:38:58,856 --> 00:39:01,186
核心 ML

1303
00:39:01,676 --> 00:39:03,006
Accelerate 和 Vision 

1304
00:39:03,006 --> 00:39:03,486
框架的会议

1305
00:39:04,716 --> 00:39:06,036
有关此会议的更多信息

1306
00:39:06,096 --> 00:39:07,636
以及示例代码的链接 

1307
00:39:07,706 --> 00:39:09,936
请登陆我们的

1308
00:39:09,986 --> 00:39:11,426
开发者网站查看这个链接

1309
00:39:11,426 --> 00:39:14,276
非常感谢大家的

1310
00:39:14,276 --> 00:39:15,636
出席 祝大家在

1311
00:39:15,636 --> 00:39:15,846
WWDC 大会期间有更多收获

1312
00:39:16,516 --> 00:39:20,500
[掌声] 
