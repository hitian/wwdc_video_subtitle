1
00:00:06,516 --> 00:00:16,500
[ 人群讲话声 ]

2
00:00:23,516 --> 00:00:27,046
[ 掌声 ]

3
00:00:27,546 --> 00:00:30,546
&gt;&gt; 哇哦 非常激动能够来到	

4
00:00:30,546 --> 00:00:30,676
这里

5
00:00:31,606 --> 00:00:32,786
我叫 Gaurav

6
00:00:32,786 --> 00:00:35,046
今天我们将会

7
00:00:35,776 --> 00:00:37,466
探讨一下机器学习

8
00:00:37,466 --> 00:00:38,686
机器学习是一项非常

9
00:00:38,686 --> 00:00:39,866
强大的技术

10
00:00:40,516 --> 00:00:42,066
再结合我们设备的性能

11
00:00:42,066 --> 00:00:44,656
你们能够创造出许多

12
00:00:44,656 --> 00:00:46,556
令人惊叹的体验

13
00:00:47,896 --> 00:00:49,946
比如说 你可以

14
00:00:49,946 --> 00:00:51,746
进行实时图像识别

15
00:00:52,346 --> 00:00:53,846
和内容创建

16
00:00:54,926 --> 00:00:56,366
在接下来的40分钟里 我们

17
00:00:56,366 --> 00:00:57,576
将会向大家讲述

18
00:00:57,576 --> 00:01:00,126
那些体验以及 Apple 如何

19
00:00:57,576 --> 00:01:00,126
那些体验以及 Apple 如何

20
00:01:00,126 --> 00:01:01,866
方便快捷地

21
00:01:02,076 --> 00:01:03,846
将机器学习融入

22
00:01:03,846 --> 00:01:04,965
你们的 App 中

23
00:01:06,156 --> 00:01:07,916
具体来说 我们将

24
00:01:07,916 --> 00:01:10,366
专注于讨论 Core ML 和我们的机器

25
00:01:10,366 --> 00:01:11,066
学习框架

26
00:01:14,946 --> 00:01:17,026
在 Apple 中 我们正在广泛地使用

27
00:01:17,026 --> 00:01:18,786
机器学习

28
00:01:19,796 --> 00:01:22,586
在我们的照片 App 中 我们使用它来做

29
00:01:22,586 --> 00:01:24,096
人物识别 

30
00:01:24,096 --> 00:01:24,886
场景识别

31
00:01:28,796 --> 00:01:31,106
在我们的键盘 App 中 我们使用它

32
00:01:31,106 --> 00:01:32,496
来做输入预测

33
00:01:33,006 --> 00:01:34,146
和智能回复

34
00:01:35,236 --> 00:01:37,006
我们甚至在 Apple Watch 中使用它

35
00:01:37,006 --> 00:01:38,366
来做智能回复

36
00:01:38,366 --> 00:01:39,736
和手写输入识别

37
00:01:40,926 --> 00:01:43,466
我很确信你们也同样希望

38
00:01:43,466 --> 00:01:45,966
创造出类似的体验

39
00:01:45,966 --> 00:01:47,306
在你们自己的 App 中

40
00:01:48,206 --> 00:01:51,346
比如说 你们中的一些人可能

41
00:01:51,346 --> 00:01:52,646
想要做实时图像

42
00:01:52,646 --> 00:01:53,446
识别

43
00:01:53,996 --> 00:01:56,856
这样的话 你们可以告诉用户

44
00:01:56,856 --> 00:01:59,046
为他们提供

45
00:01:59,046 --> 00:02:00,636
他们所看到的 与场景更加相关的信息

46
00:01:59,046 --> 00:02:00,636
他们所看到的 与场景更加相关的信息

47
00:02:00,636 --> 00:02:02,246
比如说

48
00:02:02,246 --> 00:02:03,536
他们是不是

49
00:02:03,536 --> 00:02:03,956
在吃热狗

50
00:02:04,516 --> 00:02:07,816
[ 笑声 ]

51
00:02:08,316 --> 00:02:11,656
我们希望你们能够启用

52
00:02:11,656 --> 00:02:13,956
这些非常棒的功能

53
00:02:13,956 --> 00:02:14,236
在你们的 App 里

54
00:02:15,076 --> 00:02:17,176
因此 我们推出

55
00:02:17,266 --> 00:02:18,996
机器学习框架 

56
00:02:18,996 --> 00:02:20,476
让你们能够启用所有这些

57
00:02:20,476 --> 00:02:21,116
酷炫的东西

58
00:02:21,536 --> 00:02:22,586
你们该鼓掌了

59
00:02:23,516 --> 00:02:27,916
[ 掌声 ]

60
00:02:28,416 --> 00:02:30,276
但是在我们鼓掌之前 我们应该

61
00:02:30,276 --> 00:02:31,686
首先了解我们需要

62
00:02:31,686 --> 00:02:32,816
机器学习

63
00:02:32,816 --> 00:02:33,096
的原因是什么

64
00:02:33,616 --> 00:02:38,826
以及你们什么时候会用到

65
00:02:38,886 --> 00:02:39,036
机器学习

66
00:02:39,036 --> 00:02:42,486
假设我是一名花匠

67
00:02:42,986 --> 00:02:44,926
我想展示的全都是

68
00:02:44,926 --> 00:02:46,416
玫瑰的图片

69
00:02:46,416 --> 00:02:47,886
在用户照片图库当中

70
00:02:48,596 --> 00:02:50,386
这看起来是一件挺简单的事

71
00:02:50,386 --> 00:02:51,876
那么我要来编程

72
00:02:53,196 --> 00:02:56,006
可能我会从

73
00:02:56,006 --> 00:02:56,756
颜色入手

74
00:02:57,346 --> 00:02:59,406
如果照片里的主色调

75
00:02:59,406 --> 00:03:00,766
是红色 那这可能是一朵

76
00:02:59,406 --> 00:03:00,766
是红色 那这可能是一朵

77
00:03:00,766 --> 00:03:01,026
玫瑰

78
00:03:02,576 --> 00:03:03,966
问题在于 事实上

79
00:03:03,966 --> 00:03:05,386
有许多玫瑰是白色的

80
00:03:05,386 --> 00:03:07,876
或者是

81
00:03:09,076 --> 00:03:09,216
黄色的

82
00:03:09,456 --> 00:03:11,916
所以事实上我要更深入一些

83
00:03:11,916 --> 00:03:13,996
描述外形

84
00:03:13,996 --> 00:03:17,716
很快我就意识到

85
00:03:17,716 --> 00:03:20,016
这是非常困难的

86
00:03:20,356 --> 00:03:23,866
就算去写一个如此简单的程序

87
00:03:25,656 --> 00:03:27,016
通过编程的方式

88
00:03:27,016 --> 00:03:28,276
因此 我们需要机器学习

89
00:03:28,276 --> 00:03:29,216
来帮助我们

90
00:03:30,546 --> 00:03:32,116
与其去以编程的形式来描述

91
00:03:32,116 --> 00:03:33,336
玫瑰是什么样的

92
00:03:33,376 --> 00:03:34,966
我们会

93
00:03:34,966 --> 00:03:37,816
通过我们的经验来描述一朵玫瑰

94
00:03:38,176 --> 00:03:39,026
我们会去了解

95
00:03:39,026 --> 00:03:40,466
玫瑰所代表的东西

96
00:03:40,726 --> 00:03:41,386
通过以观察经验为主的方式

97
00:03:42,036 --> 00:03:43,896
事实上机器学习

98
00:03:43,896 --> 00:03:44,416
有两步

99
00:03:45,146 --> 00:03:46,406
第一步 训练

100
00:03:48,116 --> 00:03:50,096
那么在这一情况下你们要做什么

101
00:03:50,096 --> 00:03:51,376
你们要在离线情况下收集

102
00:03:51,376 --> 00:03:53,056
玫瑰 百合 向日葵的图片

103
00:03:53,666 --> 00:03:56,086
并标记它们

104
00:03:56,086 --> 00:03:59,036
然后你们要在一个

105
00:03:59,096 --> 00:04:01,156
学习算法中运行它们

106
00:03:59,096 --> 00:04:01,156
学习算法中运行它们

107
00:04:01,156 --> 00:04:05,506
之后你们会得到一个我们称之为

108
00:04:05,546 --> 00:04:06,036
模型的东西

109
00:04:07,416 --> 00:04:10,396
这个模型

110
00:04:10,396 --> 00:04:12,616
代表着一朵玫瑰

111
00:04:13,286 --> 00:04:14,896
是什么样子的

112
00:04:15,116 --> 00:04:17,055
几乎所有这些事情

113
00:04:17,156 --> 00:04:17,656
都是在离线状态下完成的

114
00:04:18,446 --> 00:04:21,196
有一个巨大的 [未听清]

115
00:04:21,196 --> 00:04:23,426
在互联网上 围绕着训练这个步骤

116
00:04:23,906 --> 00:04:25,346
训练这一步骤算是一个复杂的问题

117
00:04:27,236 --> 00:04:28,846
那么一旦你们有了这个模型

118
00:04:28,846 --> 00:04:30,026
你们就要使用这个模型

119
00:04:30,026 --> 00:04:33,976
那么你们要怎样做

120
00:04:33,976 --> 00:04:36,236
拍一张玫瑰花的照片

121
00:04:36,286 --> 00:04:38,056
将这个模型嵌入你们的 App

122
00:04:38,136 --> 00:04:41,706
将照片在模型中运行

123
00:04:42,376 --> 00:04:44,546
你们就会得到标签	

124
00:04:44,546 --> 00:04:44,996
以及可信度

125
00:04:45,806 --> 00:04:48,436
这一步被称为推断

126
00:04:49,726 --> 00:04:52,036
训练这一步是非常复杂的

127
00:04:52,336 --> 00:04:53,886
但在今天 推断也在变得

128
00:04:53,886 --> 00:04:55,636
非常非常具有挑战性

129
00:04:58,686 --> 00:05:00,526
比如说 如果你们想

130
00:04:58,686 --> 00:05:00,526
比如说 如果你们想

131
00:05:00,526 --> 00:05:02,516
以编程的方式描述出一个全新的

132
00:05:02,516 --> 00:05:05,336
Deep Neural Network （深度神经网络） 在你们的代码中

133
00:05:05,336 --> 00:05:06,336
那你们将要写出

134
00:05:06,336 --> 00:05:07,726
上千行的代码

135
00:05:07,726 --> 00:05:08,686
仅仅为了描述出这个网络

136
00:05:09,336 --> 00:05:12,146
这会是 [未听清] 很单调乏味的

137
00:05:12,146 --> 00:05:15,866
很有可能你们会面临你们

138
00:05:15,866 --> 00:05:17,946
最大的挑战 就是当你们想证明

139
00:05:17,946 --> 00:05:21,436
这样一个程序的正确性的时候

140
00:05:21,436 --> 00:05:23,826
一旦你们确定

141
00:05:23,826 --> 00:05:26,636
这程序完全正确 你们还需要

142
00:05:26,636 --> 00:05:28,656
确认这一程序

143
00:05:28,656 --> 00:05:30,176
尽可能有着最好的性能表现

144
00:05:31,996 --> 00:05:33,886
最后 你还必须得确认

145
00:05:33,886 --> 00:05:35,496
高能效

146
00:05:35,496 --> 00:05:36,686
也包括在内

147
00:05:37,216 --> 00:05:40,116
这些工作是

148
00:05:40,116 --> 00:05:43,216
非常非常具有挑战性的

149
00:05:43,596 --> 00:05:44,246
同时也可以让你完全深陷其中

150
00:05:44,816 --> 00:05:48,046
在 Apple 中 我们使用设备端的

151
00:05:48,046 --> 00:05:49,306
机器学习

152
00:05:49,306 --> 00:05:49,996
已经有很多年了

153
00:05:50,536 --> 00:05:53,536
并且我们已经完成了

154
00:05:53,536 --> 00:05:54,046
这些挑战

155
00:05:54,126 --> 00:05:55,386
我们已经面对过这些挑战

156
00:05:56,016 --> 00:05:56,716
并且成功完成了它们

157
00:05:57,286 --> 00:05:58,466
我们真的不希望

158
00:05:58,466 --> 00:05:59,096
由你们来面对这些难题

159
00:05:59,096 --> 00:06:00,066
我们会替你们搞定

160
00:05:59,096 --> 00:06:00,066
我们会替你们搞定

161
00:06:00,306 --> 00:06:01,746
我们希望你们只用专注于

162
00:06:01,746 --> 00:06:02,596
体验即可

163
00:06:02,596 --> 00:06:03,166
我们会直接给你们编译器

164
00:06:03,166 --> 00:06:04,476
尽可能是

165
00:06:04,476 --> 00:06:05,776
最好的编译器

166
00:06:06,536 --> 00:06:09,136
因此 我们为你们推出

167
00:06:09,536 --> 00:06:11,216
机器学习框架

168
00:06:11,216 --> 00:06:13,706
这样我们就可以来解决

169
00:06:13,706 --> 00:06:15,516
所有的技术难题 由你们

170
00:06:15,586 --> 00:06:17,016
来负责所有体验方面的问题

171
00:06:17,296 --> 00:06:17,656
在你们的 App 里

172
00:06:18,786 --> 00:06:21,426
这样做的话 我们要

173
00:06:21,426 --> 00:06:22,686
遵从一种分层的形式

174
00:06:23,376 --> 00:06:26,966
最上层的是你们的 App

175
00:06:29,256 --> 00:06:31,016
我们推出全新的

176
00:06:31,016 --> 00:06:32,746
Domain Specific Framework （特定领域框架）

177
00:06:32,746 --> 00:06:33,686
具体来说是 

178
00:06:34,876 --> 00:06:36,496
Vision Framework （视觉框架）

179
00:06:36,496 --> 00:06:38,846
使得你们能够做所有

180
00:06:38,846 --> 00:06:40,266
与计算机视觉

181
00:06:40,266 --> 00:06:40,716
相关的工作

182
00:06:41,506 --> 00:06:42,976
计算机视觉在 Vision Framework （视觉框架）中

183
00:06:42,976 --> 00:06:44,626
最棒的部分

184
00:06:44,626 --> 00:06:46,406
就是你不需要是一名

185
00:06:46,406 --> 00:06:49,616
视觉构造专家

186
00:06:49,616 --> 00:06:50,406
就可以使用 Vision Framework （视觉框架）

187
00:06:50,906 --> 00:06:53,816
我们也在不断强化我们的

188
00:06:53,816 --> 00:06:56,966
NLP API （自然语言处理接口） 来容纳更多的语言

189
00:06:57,466 --> 00:06:58,606
和更多的功能

190
00:06:59,196 --> 00:07:02,486
我们推出一个全新的

191
00:06:59,196 --> 00:07:02,486
我们推出一个全新的

192
00:07:02,486 --> 00:07:04,106
框架 它叫做 Core ML

193
00:07:05,076 --> 00:07:06,676
这一框架

194
00:07:06,756 --> 00:07:08,366
对机器学习算法有着全面的支持

195
00:07:08,366 --> 00:07:10,286
更有深度的学习机制

196
00:07:10,586 --> 00:07:11,656
以及标准

197
00:07:12,276 --> 00:07:16,266
那么最终 所有这些

198
00:07:16,266 --> 00:07:18,496
框架都是建立在

199
00:07:18,496 --> 00:07:20,596
Accelerate and Metal Performance

200
00:07:20,596 --> 00:07:20,826
Shaders 上的

201
00:07:21,396 --> 00:07:28,086
我们可以通过 Vision Framework （视觉框架）

202
00:07:28,306 --> 00:07:29,506
让大家先睹为快

203
00:07:31,206 --> 00:07:33,526
Vision 是我们的一站式商店

204
00:07:33,526 --> 00:07:34,656
在其中可以做所有与

205
00:07:34,656 --> 00:07:36,006
计算机视觉和图像有关的事 

206
00:07:37,056 --> 00:07:38,966
你们可以用它来做像

207
00:07:39,026 --> 00:07:43,316
物体追踪或者

208
00:07:43,316 --> 00:07:44,506
基于深度学习的

209
00:07:44,506 --> 00:07:45,006
面部识别

210
00:07:45,006 --> 00:07:47,266
Vision Framework （视觉框架）

211
00:07:47,266 --> 00:07:47,736
能做的还有很多

212
00:07:47,736 --> 00:07:50,306
我们会更加细化地讨论 Vision 

213
00:07:50,576 --> 00:07:52,066
在明天下午的时候

214
00:07:52,626 --> 00:07:59,566
NLP 这是我们另一个一站式商店

215
00:07:59,566 --> 00:08:00,836
用来进行文字处理

216
00:07:59,566 --> 00:08:00,836
用来进行文字处理

217
00:08:01,366 --> 00:08:04,686
你们可以使用它来做

218
00:08:04,686 --> 00:08:05,916
诸如语言鉴别之类的事

219
00:08:07,126 --> 00:08:09,416
那么我们也会推出 

220
00:08:09,416 --> 00:08:10,886
Named Entity Recognition API （命名实体识别接口）

221
00:08:11,956 --> 00:08:14,986
这些 API 可以告诉你

222
00:08:14,986 --> 00:08:17,116
在你的文字中这是否是一个

223
00:08:17,116 --> 00:08:18,916
地名 人名 

224
00:08:18,916 --> 00:08:19,626
或是组织机构名

225
00:08:20,146 --> 00:08:21,246
我们相信这对于许多 App 开发者而言

226
00:08:21,246 --> 00:08:22,856
是非常强大的功能

227
00:08:23,256 --> 00:08:24,276
所以请各位去更多的了解它

228
00:08:24,656 --> 00:08:26,086
在明天早上的

229
00:08:26,156 --> 00:08:27,946
有关 NLP 的研讨会中

230
00:08:29,876 --> 00:08:33,606
Core ML 直到现在

231
00:08:33,606 --> 00:08:35,476
我们一直在讨论

232
00:08:35,566 --> 00:08:35,936
Domain Specific Framework（特定领域框架）

233
00:08:36,395 --> 00:08:37,916
Core ML 是我们的 

234
00:08:37,916 --> 00:08:39,806
机器学习框架

235
00:08:39,806 --> 00:08:40,525
并且它是对领域不敏感的

236
00:08:41,756 --> 00:08:44,316
它支持许多种

237
00:08:44,316 --> 00:08:47,136
输入形式 例如图像 文字 

238
00:08:48,256 --> 00:08:50,636
字典 原始数据

239
00:08:51,566 --> 00:08:53,156
所以你可以做例如

240
00:08:53,196 --> 00:08:53,566
标记音乐之类的事

241
00:08:55,876 --> 00:08:57,346
Core ML 还有一个有趣的地方

242
00:08:57,346 --> 00:08:59,006
就是

243
00:08:59,006 --> 00:09:01,116
他有处理混合

244
00:08:59,006 --> 00:09:01,116
他有处理混合

245
00:09:01,116 --> 00:09:02,136
输入输出类型的能力

246
00:09:02,446 --> 00:09:04,396
你可以拍一张照片

247
00:09:04,396 --> 00:09:06,286
然后得到一段文字

248
00:09:09,116 --> 00:09:10,916
这些框架最棒的部分

249
00:09:11,026 --> 00:09:13,386
在于它们可以一起

250
00:09:13,386 --> 00:09:13,776
工作

251
00:09:15,086 --> 00:09:17,316
你可以写一段文字 然后使它

252
00:09:17,316 --> 00:09:18,866
通过你的 NLP 之后你得到一个输出值

253
00:09:18,866 --> 00:09:20,476
接着你运行使它通过

254
00:09:20,476 --> 00:09:22,356
Core ML 来做出如

255
00:09:22,436 --> 00:09:23,376
情感分析之类的事

256
00:09:23,376 --> 00:09:25,336
我们将会在关于 Core ML 的研讨会上

257
00:09:25,336 --> 00:09:27,666
更细化地探讨这些

258
00:09:27,746 --> 00:09:29,706
如何进行操作

259
00:09:30,166 --> 00:09:32,876
上述研讨会将会在周四时举行

260
00:09:33,026 --> 00:09:34,556
所有这些框架

261
00:09:34,556 --> 00:09:36,546
都是由 Accelerate and MPS 	

262
00:09:36,856 --> 00:09:37,106
所驱动的

263
00:09:38,316 --> 00:09:39,276
这些就是我们的引擎

264
00:09:40,746 --> 00:09:42,946
无论何时当你们需要某些

265
00:09:43,566 --> 00:09:45,246
与数学相关的功能的时候

266
00:09:45,246 --> 00:09:46,566
你们可以使用 Accelerate and MPS

267
00:09:46,566 --> 00:09:47,876
所以它不一定必须

268
00:09:48,056 --> 00:09:49,436
与机器学习

269
00:09:49,436 --> 00:09:49,706
相关联

270
00:09:50,116 --> 00:09:53,576
你们也可以

271
00:09:53,956 --> 00:09:57,766
在创造定制化的 ML 模型时

272
00:09:57,766 --> 00:10:00,876
使用 Accelerate and MPS

273
00:09:57,766 --> 00:10:00,876
使用 Accelerate and MPS

274
00:10:00,876 --> 00:10:02,156
所以当你们在使用

275
00:10:02,156 --> 00:10:03,746
机器学习模型时 

276
00:10:03,746 --> 00:10:05,776
你会想要用到 Accelerate and MPS 

277
00:10:08,076 --> 00:10:10,836
所有这些 API

278
00:10:10,836 --> 00:10:11,196
都是在用户设备上运行的

279
00:10:11,266 --> 00:10:12,486
并且它们都有非常

280
00:10:12,486 --> 00:10:13,036
优秀的性能表现

281
00:10:13,146 --> 00:10:14,656
我们十分努力地钻研

282
00:10:14,656 --> 00:10:15,846
以确保你们能够得到最好的	

283
00:10:15,846 --> 00:10:16,856
性能表现

284
00:10:18,346 --> 00:10:19,576
因为它们是在用户设备上进行学习的

285
00:10:19,576 --> 00:10:21,786
所以具有以下优势

286
00:10:22,366 --> 00:10:24,456
首先 用户个人隐私

287
00:10:24,626 --> 00:10:27,676
用户非常乐意知道

288
00:10:27,676 --> 00:10:28,716
你并没有

289
00:10:28,716 --> 00:10:30,896
发送他们的个人短信 文字

290
00:10:30,896 --> 00:10:34,456
和图像到服务器上

291
00:10:34,456 --> 00:10:35,866
你们的用户不需要花费额外的

292
00:10:35,866 --> 00:10:38,956
数据流量 来接收这些

293
00:10:38,956 --> 00:10:40,556
不 来发送这些

294
00:10:40,556 --> 00:10:42,686
到服务器端以获得	

295
00:10:44,176 --> 00:10:44,566
预测功能

296
00:10:44,566 --> 00:10:46,496
你们同样不用支付

297
00:10:46,706 --> 00:10:48,136
一大笔钱

298
00:10:48,136 --> 00:10:49,516
给服务器公司 就为了

299
00:10:49,516 --> 00:10:50,586
建立服务器来获得

300
00:10:50,586 --> 00:10:51,176
预测的功能

301
00:10:51,726 --> 00:10:53,136
我们设备的

302
00:10:53,136 --> 00:10:53,486
性能非常非常的强大

303
00:10:53,486 --> 00:10:54,696
你们可以在设备上做许多事  

304
00:10:55,306 --> 00:11:00,206
最后 你的 App 会保持

305
00:10:55,306 --> 00:11:00,206
最后 你的 App 会保持

306
00:11:00,206 --> 00:11:00,646
可使用的状态

307
00:11:01,866 --> 00:11:03,856
让我们假设你们的用户去了

308
00:11:03,936 --> 00:11:06,896
约塞米蒂国家公园里的荒野

309
00:11:06,896 --> 00:11:08,246
到了一个没有

310
00:11:08,246 --> 00:11:08,966
网络的地方

311
00:11:10,076 --> 00:11:11,186
他们还是能够使用你们的 App

312
00:11:11,186 --> 00:11:13,186
这是非常强大的

313
00:11:14,476 --> 00:11:17,366
然而 也许你们能做的最棒的事之一

314
00:11:17,436 --> 00:11:19,686
就是

315
00:11:19,686 --> 00:11:20,396
实时机器学习

316
00:11:21,706 --> 00:11:23,396
我们的设备性能非常强大

317
00:11:23,396 --> 00:11:25,136
它们可以运行 Modern Deep Neural Network（现代深度神经网络）

318
00:11:25,136 --> 00:11:28,356
例如 ResNet 15

319
00:11:28,356 --> 00:11:29,656
[未听清 ]

320
00:11:29,656 --> 00:11:32,966
你们可以使用我们的设备来做

321
00:11:32,966 --> 00:11:34,426
实时图像识别

322
00:11:34,816 --> 00:11:37,176
在这些场景下 你不会有

323
00:11:37,226 --> 00:11:39,306
任何延迟就能够获得

324
00:11:40,076 --> 00:11:42,146
实际应用

325
00:11:43,516 --> 00:11:51,296
[ 掌声 ]

326
00:11:51,796 --> 00:11:53,336
所以对于任何具有潜在敏感性的事物

327
00:11:53,396 --> 00:11:54,716
你可能会使用

328
00:11:54,896 --> 00:11:56,326
实时图像识别

329
00:11:56,326 --> 00:12:01,276
那么我在这里简要重述一下

330
00:11:56,326 --> 00:12:01,276
那么我在这里简要重述一下

331
00:12:01,276 --> 00:12:02,556
我们将会推出一系列的机器学习

332
00:12:02,556 --> 00:12:03,286
框架

333
00:12:03,816 --> 00:12:05,606
如果你的 App 是以视觉显示为主的

334
00:12:05,786 --> 00:12:07,066
请务必使用

335
00:12:07,066 --> 00:12:07,516
Vision Framework （视觉框架）

336
00:12:08,166 --> 00:12:10,326
如果你的 App 是基于文字的

337
00:12:10,386 --> 00:12:11,486
请使用 NLP

338
00:12:12,226 --> 00:12:14,426
那么如果你觉得 NLP 和 Vision Framework（视觉框架）

339
00:12:14,426 --> 00:12:16,286
都没有提供

340
00:12:16,776 --> 00:12:18,896
你所需要的 API

341
00:12:18,896 --> 00:12:19,956
就直接去到 Core ML 层面

342
00:12:20,266 --> 00:12:21,996
Core ML 可对

343
00:12:22,666 --> 00:12:24,366
标准机器学习

344
00:12:24,366 --> 00:12:26,076
和深度学习算法

345
00:12:27,046 --> 00:12:27,586
提供全面支持

346
00:12:27,586 --> 00:12:28,816
假设你

347
00:12:28,956 --> 00:12:30,736
[未听清] 你的 API 机器

348
00:12:30,736 --> 00:12:31,906
学习算法 那么你

349
00:12:31,906 --> 00:12:34,346
应该去使用 Accelerate and MPS.

350
00:12:34,996 --> 00:12:36,806
在接下来的几天里 我们将会深入地探讨

351
00:12:36,806 --> 00:12:39,116
这些框架

352
00:12:39,116 --> 00:12:41,366
所以你们

353
00:12:41,896 --> 00:12:43,796
[未听清] 但是今天

354
00:12:43,796 --> 00:12:44,956
让我们只关注于 Core ML.

355
00:12:44,956 --> 00:12:46,806
接下来 我将邀请

356
00:12:46,866 --> 00:12:50,586
我的朋友和同事 Micheal 上场

357
00:12:51,696 --> 00:12:53,356
&gt;&gt; 谢了 Gaurav 

358
00:12:53,486 --> 00:12:54,186
大家好

359
00:12:54,186 --> 00:12:56,056
我非常激动能够在这里介绍

360
00:12:56,056 --> 00:12:58,066
Core ML 以及它在帮助你们

361
00:12:58,066 --> 00:13:00,066
创造一款优秀的 App 时所扮演的角色

362
00:12:58,066 --> 00:13:00,066
创造一款优秀的 App 时所扮演的角色

363
00:13:00,996 --> 00:13:02,246
我们的讨论将从

364
00:13:02,246 --> 00:13:04,146
高级别 Core ML 的主要目的概览

365
00:13:04,146 --> 00:13:04,976
开始

366
00:13:06,056 --> 00:13:07,106
之后我们会讨论一些

367
00:13:07,106 --> 00:13:08,286
关于模型的事项以及它们

368
00:13:08,286 --> 00:13:08,976
是如果被表现出来的

369
00:13:09,016 --> 00:13:11,666
随后我们会带大家了解一下

370
00:13:11,666 --> 00:13:13,196
使用 Core ML 的

371
00:13:13,196 --> 00:13:16,766
典型的开发过程

372
00:13:17,006 --> 00:13:18,766
Core ML 框架

373
00:13:18,766 --> 00:13:20,956
适用于 macOS iOS

374
00:13:22,186 --> 00:13:23,716
watchOS 和 tvOS

375
00:13:25,046 --> 00:13:26,676
但 Core ML 不仅仅是

376
00:13:26,676 --> 00:13:28,946
一个框架和一大堆的 API 

377
00:13:29,436 --> 00:13:30,946
它实际上是一套开发工具

378
00:13:30,946 --> 00:13:33,016
被设计用于

379
00:13:33,016 --> 00:13:35,046
尽可能地简化

380
00:13:35,046 --> 00:13:36,506
机器学习模型的创造

381
00:13:36,506 --> 00:13:38,826
并将其融入你们的 App

382
00:13:39,556 --> 00:13:41,366
这会让你们专注于

383
00:13:41,366 --> 00:13:42,826
你们希望实现的用户体验

384
00:13:42,826 --> 00:13:44,216
而不是

385
00:13:44,216 --> 00:13:45,546
代码编译的细节方面

386
00:13:47,876 --> 00:13:51,446
Core ML 使用非常简单

387
00:13:51,446 --> 00:13:52,476
它会提供给你所需要的性能表现

388
00:13:52,476 --> 00:13:55,166
同时兼容

389
00:13:55,166 --> 00:13:56,316
多种

390
00:13:56,316 --> 00:14:00,066
机器学习工具

391
00:13:56,316 --> 00:14:00,066
机器学习工具

392
00:14:00,266 --> 00:14:02,516
它的简约之处来自于

393
00:14:02,516 --> 00:14:04,196
它统一标准的推断 API 

394
00:14:04,196 --> 00:14:05,226
涵盖了所有类型的模型

395
00:14:06,276 --> 00:14:08,066
与 Xcode 相融合让你们能够

396
00:14:08,066 --> 00:14:09,166
与机器学习模型互动

397
00:14:09,166 --> 00:14:10,626
通过

398
00:14:10,626 --> 00:14:12,046
你们早就非常熟练的

399
00:14:12,166 --> 00:14:13,556
软件开发应用

400
00:14:15,626 --> 00:14:18,616
Apple 已经把

401
00:14:18,746 --> 00:14:20,066
它使用的推断引擎销售给了

402
00:14:20,066 --> 00:14:21,526
上百万顾客

403
00:14:21,526 --> 00:14:23,136
的 App 和系统服务中

404
00:14:23,136 --> 00:14:24,766
现在你们也可以使用它了

405
00:14:24,766 --> 00:14:25,286
通过 Core ML

406
00:14:25,946 --> 00:14:27,316
如之前所说 它们

407
00:14:27,316 --> 00:14:28,466
是建立在 Metal and

408
00:14:28,466 --> 00:14:29,836
Accelerate 的上层 

409
00:14:29,836 --> 00:14:31,076
以求最大化得提升你的 App

410
00:14:31,076 --> 00:14:32,396
所依附的硬件的性能

411
00:14:35,096 --> 00:14:36,986
Core ML 也同样被设计工作于

412
00:14:36,986 --> 00:14:39,266
这快速更迭的

413
00:14:39,266 --> 00:14:40,126
机器学习生态系统中

414
00:14:40,746 --> 00:14:43,086
它定义了一个全新的公共格式

415
00:14:43,086 --> 00:14:45,196
以描述模型

416
00:14:45,196 --> 00:14:46,856
同时还有一套工具

417
00:14:46,856 --> 00:14:48,056
使你能够将

418
00:14:48,056 --> 00:14:50,316
Popular Training Libraries （普通训练库）的输出值转换

419
00:14:50,316 --> 00:14:51,506
为这一格式

420
00:14:53,156 --> 00:14:55,056
简言之 这就是 Core ML

421
00:14:55,476 --> 00:14:56,656
能够让

422
00:14:56,656 --> 00:14:58,836
你的 App 中融入学习模型的过程

423
00:14:59,056 --> 00:15:00,566
变得极其简单

424
00:14:59,056 --> 00:15:00,566
变得极其简单

425
00:15:00,756 --> 00:15:02,416
让我们再多讨论一下

426
00:15:02,416 --> 00:15:03,316
这些模型

427
00:15:03,816 --> 00:15:07,726
因为 Core ML 

428
00:15:07,726 --> 00:15:08,256
一个模型就基本上是一项功能

429
00:15:08,976 --> 00:15:10,836
那么这项功能的逻辑

430
00:15:10,966 --> 00:15:12,386
恰好是从数据中学习而来

431
00:15:12,696 --> 00:15:13,666
但就像其他任何功能一样

432
00:15:13,666 --> 00:15:15,086
它接受一系列输入值

433
00:15:15,086 --> 00:15:16,756
然后产出一系列

434
00:15:16,756 --> 00:15:17,356
输出值

435
00:15:17,956 --> 00:15:19,046
在这个情况下 如幻灯片所示

436
00:15:19,046 --> 00:15:20,756
我们有一个单一的图像输入

437
00:15:20,756 --> 00:15:22,766
和一个输出值

438
00:15:22,766 --> 00:15:24,006
可能会告诉你什么种类的花

439
00:15:24,116 --> 00:15:26,196
包含在其中

440
00:15:26,456 --> 00:15:28,966
在许多使用场景中

441
00:15:28,966 --> 00:15:30,066
你也许想应用

442
00:15:30,066 --> 00:15:31,976
在核心中有关键功能的

443
00:15:32,206 --> 00:15:33,806
机器学习模型

444
00:15:34,996 --> 00:15:36,876
一项常见的功能就是

445
00:15:36,876 --> 00:15:37,766
做出一种

446
00:15:37,766 --> 00:15:38,636
分类

447
00:15:39,576 --> 00:15:41,636
它接受一系列的输入值

448
00:15:41,636 --> 00:15:42,946
并给它们指定

449
00:15:42,946 --> 00:15:43,316
一些分类标签

450
00:15:43,846 --> 00:15:46,466
比如说

451
00:15:46,466 --> 00:15:47,066
拿情感分析举例

452
00:15:47,706 --> 00:15:49,206
你输入一句英文语句

453
00:15:49,206 --> 00:15:51,196
并输出

454
00:15:51,196 --> 00:15:52,566
这句话是积极的还是消极的

455
00:15:52,566 --> 00:15:55,506
然后这里

456
00:15:56,836 --> 00:15:57,026
由一个 emoji 代表

457
00:15:57,116 --> 00:15:58,736
那么为了编写

458
00:15:59,106 --> 00:16:01,606
这种类型的功能 Core ML

459
00:15:59,106 --> 00:16:01,606
这种类型的功能 Core ML

460
00:16:01,606 --> 00:16:02,836
支持种类繁多的

461
00:16:02,836 --> 00:16:03,366
模型

462
00:16:03,906 --> 00:16:08,866
它对于神经网络有广泛的支持

463
00:16:08,866 --> 00:16:10,886
包括前惯性

464
00:16:10,886 --> 00:16:11,946
和周期性神经网络两种

465
00:16:11,946 --> 00:16:13,246
以及超过三十种不同的层级

466
00:16:13,246 --> 00:16:13,706
类型

467
00:16:14,956 --> 00:16:17,076
它同样支持 Tree Ensembles （树集）

468
00:16:17,076 --> 00:16:18,546
支持向量机

469
00:16:18,546 --> 00:16:19,886
和广义线性模型

470
00:16:21,176 --> 00:16:22,516
每一个类型的模型

471
00:16:22,516 --> 00:16:23,996
事实上都是

472
00:16:23,996 --> 00:16:24,536
模型的大集合

473
00:16:24,766 --> 00:16:26,046
我们可以利用这场研讨会

474
00:16:26,046 --> 00:16:27,696
以及整场大会所剩余的时间

475
00:16:27,696 --> 00:16:28,956
来讨论

476
00:16:28,956 --> 00:16:31,696
它们其中的一个

477
00:16:31,696 --> 00:16:32,826
但是请不要被吓到了

478
00:16:33,106 --> 00:16:34,536
你不需要成为一个

479
00:16:34,536 --> 00:16:36,036
机器学习专家才能使用

480
00:16:36,036 --> 00:16:36,796
这些模型

481
00:16:37,296 --> 00:16:39,446
你只要继续专注于

482
00:16:39,446 --> 00:16:41,246
这些你尽力想实现的使用场景

483
00:16:41,246 --> 00:16:42,936
让 Core ML 去处理那些

484
00:16:42,936 --> 00:16:43,966
低级的细节即可

485
00:16:44,546 --> 00:16:45,896
Core ML 代表一个模型

486
00:16:45,896 --> 00:16:46,776
在一个文件中

487
00:16:47,316 --> 00:16:48,946
也就是说 分享一个模型就像

488
00:16:48,946 --> 00:16:50,196
分享一个文件

489
00:16:50,806 --> 00:16:52,686
这个文件有着高级信息

490
00:16:52,686 --> 00:16:53,976
是作为开发者的你

491
00:16:53,976 --> 00:16:54,886
需要编程完成的

492
00:16:54,886 --> 00:16:55,656
这就是功能

493
00:16:55,656 --> 00:16:57,276
描述 它的输入 类型 

494
00:16:57,276 --> 00:16:59,566
输出 以及那些

495
00:16:59,566 --> 00:17:00,846
Core ML 为了执行功能

496
00:16:59,566 --> 00:17:00,846
Core ML 为了执行功能

497
00:17:00,846 --> 00:17:02,106
所需要的细节部分

498
00:17:02,446 --> 00:17:03,656
对于神经网络而言 这应该就是

499
00:17:03,656 --> 00:17:04,685
神经网络的结构

500
00:17:04,685 --> 00:17:06,486
加上它的

501
00:17:06,486 --> 00:17:06,915
训练参数

502
00:17:07,006 --> 00:17:08,616
我们鼓励大家去

503
00:17:08,616 --> 00:17:10,036
我们周四的研讨会来了解更多

504
00:17:10,036 --> 00:17:11,665
关于这个格式

505
00:17:11,665 --> 00:17:15,695
和一系列它可以编码的模型

506
00:17:15,695 --> 00:17:16,856
但是可能现在

507
00:17:16,856 --> 00:17:17,715
你们会想

508
00:17:17,715 --> 00:17:20,066
我到哪里才能弄到这些

509
00:17:20,066 --> 00:17:20,616
模型

510
00:17:21,116 --> 00:17:24,175
模型是哪里来的

511
00:17:24,175 --> 00:17:25,965
那么 建议大家从这里开始

512
00:17:25,965 --> 00:17:27,326
查看我们的机器学习

513
00:17:27,326 --> 00:17:28,156
登场介绍页面

514
00:17:28,156 --> 00:17:29,386
在 developer.apple.com.

515
00:17:30,816 --> 00:17:32,286
接着你们会找到一些

516
00:17:32,286 --> 00:17:34,276
执行特定任务

517
00:17:34,766 --> 00:17:36,966
立即可用的模型

518
00:17:36,966 --> 00:17:37,916
已经是 Core ML 格式的了

519
00:17:38,976 --> 00:17:40,186
我们会扩充这一套模型	

520
00:17:40,186 --> 00:17:40,746
随着时间的推移

521
00:17:40,746 --> 00:17:42,586
同时我们鼓励大家不断探索

522
00:17:42,826 --> 00:17:43,556
尝试一下

523
00:17:43,556 --> 00:17:44,586
这是一个很棒的途径

524
00:17:44,586 --> 00:17:45,656
去总体了解一下机器学习

525
00:17:45,656 --> 00:17:47,406
和 Core ML 以及

526
00:17:47,406 --> 00:17:49,126
它们可以怎样被应用到你的 App 中

527
00:17:51,076 --> 00:17:52,586
但是我们可能没有

528
00:17:52,586 --> 00:17:53,366
所有你们需要的模型

529
00:17:53,516 --> 00:17:54,886
为了让你们能够应用

530
00:17:54,886 --> 00:17:55,586
你们可能需要基于现有的模型做一些

531
00:17:55,586 --> 00:17:56,956
定制 

532
00:17:56,956 --> 00:17:58,376
或者从头开始

533
00:17:58,376 --> 00:17:59,086
制作一个全新的模型

534
00:18:00,016 --> 00:18:01,856
因此我们鼓励你 

535
00:18:01,856 --> 00:18:03,986
和你的同事们利用好

536
00:18:03,986 --> 00:18:05,256
机器学习社区

537
00:18:05,776 --> 00:18:07,526
这是一个非常活跃

538
00:18:07,526 --> 00:18:08,016
的社区

539
00:18:09,396 --> 00:18:11,026
那里有无数的库和现成的

540
00:18:11,026 --> 00:18:12,486
模型可供你们

541
00:18:12,486 --> 00:18:13,326
使用

542
00:18:14,096 --> 00:18:15,686
另外 每周都会有非常棒的

543
00:18:15,686 --> 00:18:17,426
线上教程和全新的课程

544
00:18:17,426 --> 00:18:18,806
上线

545
00:18:19,966 --> 00:18:20,586
你们可以做到的

546
00:18:20,796 --> 00:18:22,106
那里有非常棒的资源

547
00:18:22,106 --> 00:18:22,606
可供学习

548
00:18:22,606 --> 00:18:24,036
我有信心

549
00:18:24,036 --> 00:18:24,906
你们都可以成功起步的

550
00:18:24,906 --> 00:18:26,776
这是个美好的时代

551
00:18:28,316 --> 00:18:30,066
但你们会发现

552
00:18:30,066 --> 00:18:32,096
大部分的库都是专注于

553
00:18:32,096 --> 00:18:33,266
训练的 

554
00:18:33,986 --> 00:18:35,266
因为 这是非常重要的一步

555
00:18:35,266 --> 00:18:36,986
他们会花大量的

556
00:18:36,986 --> 00:18:38,146
时间确保你们可以

557
00:18:38,146 --> 00:18:39,046
训练出一个很棒的模型

558
00:18:39,046 --> 00:18:40,866
我们希望你们做的是

559
00:18:40,926 --> 00:18:42,776
让 Core ML 代替你们

560
00:18:42,776 --> 00:18:44,686
去获得那些机器学习模型

561
00:18:44,686 --> 00:18:45,916
并切实部署到

562
00:18:45,916 --> 00:18:46,986
你们的 App 上

563
00:18:47,736 --> 00:18:49,416
所以我们推出 Core ML 工具

564
00:18:49,416 --> 00:18:51,206
来做这些

565
00:18:51,206 --> 00:18:52,166
Python package 

566
00:18:52,696 --> 00:18:54,546
这是一个 Python package 

567
00:18:54,546 --> 00:18:55,686
它完全集中于

568
00:18:55,686 --> 00:18:57,826
接受这些来自于机器学习库的

569
00:18:57,826 --> 00:18:59,536
输出值

570
00:18:59,536 --> 00:19:01,126
并将它们转化为

571
00:18:59,536 --> 00:19:01,126
并将它们转化为

572
00:19:01,126 --> 00:19:01,576
Core ML 格式

573
00:19:02,646 --> 00:19:04,096
随后我们会不断扩充这些工具

574
00:19:04,096 --> 00:19:06,606
但同时

575
00:19:06,606 --> 00:19:07,976
它们也是开源的

576
00:19:08,516 --> 00:19:15,046
[ 掌声 ]

577
00:19:15,546 --> 00:19:16,706
所以这意味着 就算你没有

578
00:19:16,706 --> 00:19:17,626
找到你需要的转换器

579
00:19:17,626 --> 00:19:19,466
我们非常相信

580
00:19:19,466 --> 00:19:20,606
你也已经可以自己写出一个了

581
00:19:21,136 --> 00:19:22,576
所有这些原始数据

582
00:19:22,576 --> 00:19:23,606
都可以随时为你所用

583
00:19:24,086 --> 00:19:25,316
我再次鼓励大家

584
00:19:25,316 --> 00:19:27,306
来参加我们周四的研讨会

585
00:19:27,306 --> 00:19:28,836
了解更多关于 Python package 的信息

586
00:19:28,836 --> 00:19:30,116
以及你可以怎样简单地转换

587
00:19:30,116 --> 00:19:30,516
模型

588
00:19:30,516 --> 00:19:34,946
好的 现在我们有了这个模型

589
00:19:35,396 --> 00:19:36,626
让我们来讨论一下如果

590
00:19:36,626 --> 00:19:37,156
在我们的 App 中使用它

591
00:19:37,156 --> 00:19:40,256
那么你需要从

592
00:19:40,256 --> 00:19:41,626
以 Core ML 为格式的

593
00:19:41,626 --> 00:19:42,616
机器学习模型入手

594
00:19:43,986 --> 00:19:45,666
你只需要将它加入到

595
00:19:45,666 --> 00:19:46,656
你的 Xcode 的项目里

596
00:19:47,416 --> 00:19:49,036
然后 Xcode 就会自动

597
00:19:49,176 --> 00:19:50,636
将这个模型识别为

598
00:19:50,636 --> 00:19:51,626
机器学习模型

599
00:19:51,626 --> 00:19:53,366
然后它会为你生成一个

600
00:19:53,366 --> 00:19:53,566
交互界面

601
00:19:54,116 --> 00:19:55,036
它会给你一个

602
00:19:55,036 --> 00:19:56,326
这个模型的编程界面

603
00:19:56,326 --> 00:19:58,746
使用的数据类型和

604
00:19:58,746 --> 00:19:59,646
结构都是

605
00:19:59,646 --> 00:20:00,906
你们编程时很熟悉的

606
00:19:59,646 --> 00:20:00,906
你们编程时很熟悉的

607
00:20:01,386 --> 00:20:03,536
你们将会使用

608
00:20:03,686 --> 00:20:05,346
这一交互界面并将它编译进

609
00:20:05,346 --> 00:20:06,446
你们的 App

610
00:20:07,376 --> 00:20:09,086
但除此之外 模型本身

611
00:20:09,086 --> 00:20:10,866
也会被编译

612
00:20:10,936 --> 00:20:12,496
并归入到你们的 App 中

613
00:20:12,856 --> 00:20:14,636
也就是说 我们使用的这一格式

614
00:20:14,636 --> 00:20:15,636
是已被优化过的

615
00:20:15,636 --> 00:20:17,856
变得更加开放及兼容

616
00:20:17,856 --> 00:20:19,176
并且使它成为

617
00:20:19,176 --> 00:20:20,886
为了在设备上运行

618
00:20:20,886 --> 00:20:21,456
而优化的格式

619
00:20:22,996 --> 00:20:24,556
为了给你们展示这一操作

620
00:20:24,656 --> 00:20:25,866
我要邀请我的朋友

621
00:20:25,866 --> 00:20:27,156
兼同事 Lizi 到台上来

622
00:20:28,516 --> 00:20:34,406
[ 掌声 ]

623
00:20:34,906 --> 00:20:36,436
我是 Core ML 团队

624
00:20:36,436 --> 00:20:36,946
的工程师

625
00:20:37,926 --> 00:20:40,316
今天 让我们来看一下

626
00:20:40,316 --> 00:20:42,216
你们该如何使用 Core ML 将

627
00:20:42,216 --> 00:20:43,576
机器学习融入你们的

628
00:20:43,576 --> 00:20:44,106
App

629
00:20:45,156 --> 00:20:46,976
首先设定一个背景

630
00:20:47,796 --> 00:20:49,016
就像我喜爱机器

631
00:20:49,016 --> 00:20:51,076
学习一样 我同样喜欢园艺

632
00:20:51,076 --> 00:20:53,096
如果你是像我一样的人

633
00:20:53,546 --> 00:20:54,796
每当你见到

634
00:20:54,796 --> 00:20:56,436
新品种的花时

635
00:20:56,436 --> 00:20:58,336
相信你会非常激动并会马上

636
00:20:58,336 --> 00:20:59,276
就想认出它的种类

637
00:21:00,366 --> 00:21:01,706
所以我们希望打造一款 App

638
00:21:02,296 --> 00:21:03,866
可以获取

639
00:21:03,866 --> 00:21:05,476
不同种类的花的图像

640
00:21:05,516 --> 00:21:07,426
并把它们按类型分类

641
00:21:08,346 --> 00:21:09,886
但首先 要做到这一点

642
00:21:10,466 --> 00:21:11,296
我们需要一个模型

643
00:21:12,866 --> 00:21:14,166
所以我们进一步

644
00:21:14,166 --> 00:21:15,766
收集了许多

645
00:21:15,896 --> 00:21:17,116
不同类型的花的图片

646
00:21:17,486 --> 00:21:18,686
并给每一个都做了标记

647
00:21:20,286 --> 00:21:21,656
之后我训练了一个神经网络分类器

648
00:21:21,756 --> 00:21:23,686
通过使用一个开源的

649
00:21:23,756 --> 00:21:25,296
机器学习工具

650
00:21:25,296 --> 00:21:27,326
将其转换成了我们的 Core ML

651
00:21:27,416 --> 00:21:27,666
格式

652
00:21:29,256 --> 00:21:31,896
有了这个训练出的模型

653
00:21:31,896 --> 00:21:33,086
和这个花朵分类器的 App Shell （程序外壳）

654
00:21:33,086 --> 00:21:35,006
我们来看一下

655
00:21:35,006 --> 00:21:36,906
如果将这两者

656
00:21:36,906 --> 00:21:37,276
合二为一

657
00:21:38,946 --> 00:21:40,746
在 Xcode 里 你可以看到

658
00:21:40,746 --> 00:21:42,736
我正在运行花朵分类器

659
00:21:42,736 --> 00:21:44,616
这个 App 

660
00:21:44,616 --> 00:21:45,626
就在我设备屏幕的边上

661
00:21:46,686 --> 00:21:48,606
我可以做的就是

662
00:21:48,606 --> 00:21:50,346
进入到照片图库中

663
00:21:50,346 --> 00:21:52,626
选择一张图片 但现在

664
00:21:52,736 --> 00:21:53,906
它还不能为输出结果

665
00:21:53,906 --> 00:21:54,906
做任何预测

666
00:21:55,396 --> 00:21:57,246
它只显示出这一行而已

667
00:21:58,796 --> 00:22:00,086
那么如果我去看

668
00:21:58,796 --> 00:22:00,086
那么如果我去看

669
00:22:00,086 --> 00:22:02,606
视频控制器 我们能看到的是

670
00:22:02,606 --> 00:22:04,836
它有这样一个 Caption Method （说明方式）

671
00:22:05,046 --> 00:22:06,226
目前只会返回

672
00:22:06,256 --> 00:22:06,856
空白行

673
00:22:07,426 --> 00:22:10,746
它实际上并没有做什么

674
00:22:10,836 --> 00:22:12,636
在这里面 我有

675
00:22:12,636 --> 00:22:14,176
花朵分类器 

676
00:22:14,236 --> 00:22:14,506
是以 ML 模型为格式的

677
00:22:15,186 --> 00:22:16,656
我需要做的就是选中它

678
00:22:17,306 --> 00:22:18,696
并将它拖拽到

679
00:22:18,696 --> 00:22:19,066
项目中

680
00:22:19,786 --> 00:22:22,936
我们可以看到 我一把它加入进去

681
00:22:23,066 --> 00:22:24,796
Xcode 就自动

682
00:22:24,796 --> 00:22:26,546
识别了这个文件格式

683
00:22:27,406 --> 00:22:28,716
显示出了模型的名字

684
00:22:28,716 --> 00:22:30,816
以及它的类型

685
00:22:30,816 --> 00:22:31,346
在这下面

686
00:22:31,926 --> 00:22:33,666
我们可以看到文件大小是

687
00:22:33,666 --> 00:22:35,226
41 兆字节 以及其它

688
00:22:35,226 --> 00:22:36,616
信息例如作者

689
00:22:36,866 --> 00:22:38,296
许可或者描述

690
00:22:38,296 --> 00:22:39,226
都一起显示出来

691
00:22:40,446 --> 00:22:41,876
在底部 我们可以看到

692
00:22:41,916 --> 00:22:43,266
这个模型所承接的

693
00:22:43,266 --> 00:22:45,736
输入和输出 首先就是

694
00:22:46,126 --> 00:22:48,136
花朵图像 它的类型是图像 

695
00:22:48,476 --> 00:22:49,966
被划分为红色 绿色 蓝色

696
00:22:50,086 --> 00:22:51,096
以及宽度和高度

697
00:22:52,406 --> 00:22:53,816
我们同样可以看到

698
00:22:53,816 --> 00:22:55,506
它将花朵类型输出为一行

699
00:22:56,166 --> 00:22:57,756
所以如果给它

700
00:22:57,756 --> 00:22:59,576
一张玫瑰的图片 我会想要花朵类型

701
00:22:59,646 --> 00:23:00,526
显示玫瑰

702
00:22:59,646 --> 00:23:00,526
显示玫瑰

703
00:23:01,896 --> 00:23:03,466
这里同样存在一个词典

704
00:23:03,466 --> 00:23:05,016
包含许多不同类型花朵

705
00:23:05,016 --> 00:23:05,736
的可能性

706
00:23:06,306 --> 00:23:08,796
我要做的第一件事

707
00:23:10,206 --> 00:23:11,236
就是我要确保

708
00:23:11,436 --> 00:23:12,966
我把它加入到了我的 App

709
00:23:13,586 --> 00:23:15,876
之后你们会看到

710
00:23:16,396 --> 00:23:18,406
这中间的窗口会显示

711
00:23:18,406 --> 00:23:20,086
Swift Generated Source （生成源） 

712
00:23:20,366 --> 00:23:21,896
已经加入到了 App 中

713
00:23:22,896 --> 00:23:23,966
这意味着我们可以

714
00:23:23,966 --> 00:23:25,866
真正地使用这生成的代码

715
00:23:26,176 --> 00:23:27,536
来加载这一模型

716
00:23:27,536 --> 00:23:28,046
并靠它来做出预测

717
00:23:28,846 --> 00:23:30,576
为了给你们展示 我们看一下

718
00:23:30,576 --> 00:23:31,206
视频控制器

719
00:23:31,816 --> 00:23:36,156
我要做的第一件事是

720
00:23:36,156 --> 00:23:37,526
定义这些花朵模型

721
00:23:38,766 --> 00:23:40,216
为了将它实例化 我需要

722
00:23:40,216 --> 00:23:42,086
做的就是使用

723
00:23:42,206 --> 00:23:45,656
模型类本身的名字

724
00:23:45,806 --> 00:23:47,346
我们会看到它被高亮的颜色标出

725
00:23:47,506 --> 00:23:48,456
因为它已经存在于

726
00:23:48,456 --> 00:23:48,866
这个项目中

727
00:23:49,906 --> 00:23:51,516
在下一个 Caption Method （说明方式） 中

728
00:23:51,766 --> 00:23:52,866
我们来定义一个预测

729
00:23:53,446 --> 00:23:56,886
我们会使用

730
00:23:56,936 --> 00:24:00,206
这个花朵模型并查看它

731
00:23:56,936 --> 00:24:00,206
这个花朵模型并查看它

732
00:24:01,076 --> 00:24:02,546
我们会看到使用自动完成

733
00:24:02,696 --> 00:24:03,896
这个预测方式是

734
00:24:03,896 --> 00:24:05,156
可用的 并且它将

735
00:24:05,156 --> 00:24:07,056
CVPixelBuffer 作为输入值

736
00:24:07,906 --> 00:24:09,666
我们要使用它并将

737
00:24:09,666 --> 00:24:12,786
图像直接传输给它

738
00:24:13,286 --> 00:24:14,726
现在 我们可以取代

739
00:24:14,866 --> 00:24:16,776
这一预先设定的行 我们可以使用

740
00:24:16,776 --> 00:24:18,716
预测物 同时取代之前的

741
00:24:19,236 --> 00:24:20,966
并返回出花朵类型

742
00:24:21,676 --> 00:24:24,166
现在如果我保存 我们就可以创建

743
00:24:24,166 --> 00:24:25,266
并运行这个 App

744
00:24:26,026 --> 00:24:27,586
我在做这件事的时候

745
00:24:27,586 --> 00:24:29,916
这个模型本身

746
00:24:29,916 --> 00:24:31,306
正在被编译

747
00:24:31,306 --> 00:24:32,566
并归入到 App 中

748
00:24:33,706 --> 00:24:34,936
那么我们回到设备上看

749
00:24:35,476 --> 00:24:37,196
打开我的照片图库

750
00:24:37,506 --> 00:24:39,136
选择一朵

751
00:24:39,136 --> 00:24:39,366
在第二排的玫瑰图片

752
00:24:40,216 --> 00:24:41,536
我们可以看到

753
00:24:41,536 --> 00:24:42,696
它能够显示出 玫瑰

754
00:24:43,516 --> 00:24:49,356
[ 掌声 ]

755
00:24:49,856 --> 00:24:51,106
我们再选一张 

756
00:24:51,106 --> 00:24:52,356
比如第三排的向日葵

757
00:24:53,406 --> 00:24:54,746
它同样能够显示出来

758
00:24:55,736 --> 00:24:56,846
或者识别起来

759
00:24:56,846 --> 00:24:58,216
更加困难的 比如下面的

760
00:24:58,216 --> 00:24:59,646
西番莲

761
00:24:59,646 --> 00:25:00,196
它还是可以识别出来

762
00:24:59,646 --> 00:25:00,196
它还是可以识别出来

763
00:25:01,296 --> 00:25:04,346
那么简要重述一下 我们可以

764
00:25:04,576 --> 00:25:06,876
将一个训练好的机器学习模型

765
00:25:07,146 --> 00:25:09,236
拖拽到 Xcode 中  并将它十分简单地添加到

766
00:25:09,236 --> 00:25:10,906
App 中 只需要三行

767
00:25:10,946 --> 00:25:11,346
代码

768
00:25:12,006 --> 00:25:13,696
现在我们有一个完整的神经

769
00:25:13,696 --> 00:25:15,186
网络分类器

770
00:25:15,186 --> 00:25:15,616
在设备上运行

771
00:25:16,576 --> 00:25:19,096
但我还有一些其他的模型

772
00:25:19,096 --> 00:25:20,576
可能也想要尝试一下

773
00:25:21,006 --> 00:25:21,896
那么让我们再做一次

774
00:25:22,376 --> 00:25:25,016
你们可能注意到了

775
00:25:25,016 --> 00:25:26,506
这也有一个叫 FlowerSqueeze 的模型

776
00:25:27,356 --> 00:25:28,996
那么首先我要做的

777
00:25:28,996 --> 00:25:31,346
就是再一次地拖拽它

778
00:25:32,066 --> 00:25:35,476
然后我也要将它加入到

779
00:25:35,596 --> 00:25:37,246
花朵分类器中  

780
00:25:37,386 --> 00:25:39,416
这个叫 Hello Flowers （你好花朵）的目标项目中

781
00:25:39,566 --> 00:25:40,686
然后在后台

782
00:25:40,816 --> 00:25:41,786
开始生成 Swift 源

783
00:25:42,566 --> 00:25:43,956
我们会看到 如果我们再放大一些

784
00:25:44,036 --> 00:25:46,016
这个模型的名字

785
00:25:46,056 --> 00:25:46,456
是不同的

786
00:25:46,606 --> 00:25:48,606
它叫做 FlowerSqueeze 但是在

787
00:25:48,606 --> 00:25:50,186
底部 输入和

788
00:25:50,186 --> 00:25:51,706
输出是完全一样的

789
00:25:53,086 --> 00:25:54,626
这意味着如果

790
00:25:54,626 --> 00:25:55,886
我回到视频控制器中

791
00:25:57,786 --> 00:25:59,016
取代了花朵 干脆

792
00:25:59,476 --> 00:26:00,906
我们直接删除花朵分类器

793
00:25:59,476 --> 00:26:00,906
我们直接删除花朵分类器

794
00:26:01,076 --> 00:26:02,006
我们不再需要

795
00:26:02,006 --> 00:26:02,336
那个模型了

796
00:26:02,926 --> 00:26:05,656
在视频控制器中

797
00:26:06,216 --> 00:26:07,436
不再将这个实例化

798
00:26:07,436 --> 00:26:10,146
我们来使用 FlowerSqueeze

799
00:26:10,786 --> 00:26:13,336
这个模型非常干净整洁的地方在于

800
00:26:13,386 --> 00:26:15,276
它的大小

801
00:26:16,136 --> 00:26:19,106
我们返回 它的大小

802
00:26:19,106 --> 00:26:21,146
只有 5.4 兆字节 

803
00:26:21,146 --> 00:26:21,806
这是一个非常大的不同之处

804
00:26:22,266 --> 00:26:27,086
回到设备上 我们进入到

805
00:26:27,086 --> 00:26:28,756
照片图库中并选择

806
00:26:28,756 --> 00:26:29,906
另一个 比如这朵雾中之爱

807
00:26:29,906 --> 00:26:32,256
可以看到这个 App

808
00:26:32,256 --> 00:26:34,966
同样可以

809
00:26:35,556 --> 00:26:35,676
将它分类

810
00:26:35,886 --> 00:26:38,856
试一下另一朵西番莲或者

811
00:26:38,856 --> 00:26:40,376
一张更难识别的

812
00:26:40,376 --> 00:26:42,696
边上这朵玫瑰的照片

813
00:26:42,696 --> 00:26:43,966
它仍然能够正确地预测出来

814
00:26:44,586 --> 00:26:48,716
再扼要重述一下 我们刚看到

815
00:26:48,856 --> 00:26:50,126
我们可以在设备上运行这个

816
00:26:50,126 --> 00:26:51,676
神经网络分类器

817
00:26:51,896 --> 00:26:54,086
通过使用 Core ML 这一切

818
00:26:54,176 --> 00:26:55,886
都只用了仅仅几行代码而已

819
00:26:56,516 --> 00:27:04,086
[ 掌声 ]

820
00:26:56,516 --> 00:27:04,086
[ 掌声 ]

821
00:27:04,586 --> 00:27:06,396
现在我们来回顾一下

822
00:27:06,396 --> 00:27:08,616
我们刚才都看到了什么

823
00:27:08,856 --> 00:27:11,556
我们看到在 Xcode 中  一旦

824
00:27:11,746 --> 00:27:13,586
你将一个训练过的机器学习模型拖拽进

825
00:27:13,586 --> 00:27:15,106
你的 App 中

826
00:27:15,376 --> 00:27:16,446
你会得到这个

827
00:27:16,446 --> 00:27:17,956
生成的界面 在下方提供给你

828
00:27:17,956 --> 00:27:19,616
例如模型名称

829
00:27:19,616 --> 00:27:21,836
和类型的信息

830
00:27:21,836 --> 00:27:23,316
以及其他信息

831
00:27:23,316 --> 00:27:25,806
例如模型大小

832
00:27:25,806 --> 00:27:27,526
或者任何其他

833
00:27:27,526 --> 00:27:27,676
作者加入进去的信息

834
00:27:28,276 --> 00:27:29,996
在底部

835
00:27:30,086 --> 00:27:31,816
你们可以看到 例如这一模型的

836
00:27:31,816 --> 00:27:33,096
输入和输出的信息

837
00:27:33,096 --> 00:27:34,946
这是非常有帮助的

838
00:27:34,946 --> 00:27:35,946
当你想要

839
00:27:35,946 --> 00:27:36,106
使用它的时候

840
00:27:36,106 --> 00:27:38,276
一旦你将它加入到你的

841
00:27:38,276 --> 00:27:40,166
App 中  你就会得到生成的代码

842
00:27:40,166 --> 00:27:42,106
你可以用来加载并使用

843
00:27:42,106 --> 00:27:45,366
这一模型来做出预测

844
00:27:45,436 --> 00:27:47,076
我们也在 App 中看到

845
00:27:47,076 --> 00:27:48,706
使用它

846
00:27:48,706 --> 00:27:49,106
是多么的简单

847
00:27:49,956 --> 00:27:51,826
再说一次 即便模型是

848
00:27:51,826 --> 00:27:53,746
一个神经网络分类器 

849
00:27:53,746 --> 00:27:55,266
我们将它实例化所需要做的

850
00:27:55,266 --> 00:27:56,626
就是访问

851
00:27:56,626 --> 00:27:57,066
文件的名称

852
00:27:57,736 --> 00:27:58,856
这意味着模型类型

853
00:27:58,856 --> 00:28:00,686
是完全抽象的

854
00:27:58,856 --> 00:28:00,686
是完全抽象的

855
00:28:00,686 --> 00:28:01,856
不论它是一个向量机

856
00:28:01,856 --> 00:28:03,536
一个一般线性模型

857
00:28:03,536 --> 00:28:05,686
或者一个神经网络

858
00:28:05,916 --> 00:28:07,906
你都可以以同样的方式加载它

859
00:28:07,906 --> 00:28:09,206
我们还注意到 

860
00:28:09,206 --> 00:28:11,036
预测方式使用到了一个

861
00:28:11,136 --> 00:28:12,106
CVPixelBuffer

862
00:28:12,776 --> 00:28:14,346
它是一个强类型 所以你很清楚

863
00:28:14,346 --> 00:28:15,406
你要在

864
00:28:15,536 --> 00:28:17,496
编辑的时候就检查输入错误

865
00:28:17,646 --> 00:28:18,616
而不是在运行的时候

866
00:28:20,026 --> 00:28:22,766
现在让我们来更深入的看一下

867
00:28:23,126 --> 00:28:24,486
由 Xcode 创建的

868
00:28:24,536 --> 00:28:27,416
Generated Source （生成源）

869
00:28:27,476 --> 00:28:29,706
在这里 我们看到它定义了三个

870
00:28:29,706 --> 00:28:31,696
层级 第一级是输入

871
00:28:31,696 --> 00:28:33,966
将花朵图片

872
00:28:33,966 --> 00:28:35,456
定义为一个 CVPixelBuffer

873
00:28:36,456 --> 00:28:38,306
之后我们看到输出值

874
00:28:38,306 --> 00:28:40,836
和两种相同的类型被列在

875
00:28:40,836 --> 00:28:41,976
生成的交互界面中

876
00:28:43,176 --> 00:28:44,936
接下来 在模型层级中

877
00:28:44,936 --> 00:28:46,586
我们能看到

878
00:28:46,586 --> 00:28:48,116
我们用来创造模型的

879
00:28:48,116 --> 00:28:50,346
便利构造器

880
00:28:50,346 --> 00:28:53,336
以及预测方式

881
00:28:53,536 --> 00:28:55,486
同时在 Generated Source （生成源）内

882
00:28:55,486 --> 00:28:57,326
你可以接入

883
00:28:57,386 --> 00:28:58,376
底层模型

884
00:28:58,986 --> 00:29:00,676
那么在更高级的使用场景中

885
00:28:58,986 --> 00:29:00,676
那么在更高级的使用场景中

886
00:29:01,006 --> 00:29:02,656
你可以使用它

887
00:29:02,656 --> 00:29:04,096
也可以以编程的形式

888
00:29:04,096 --> 00:29:04,226
与它互动

889
00:29:05,556 --> 00:29:06,816
我们来看一下

890
00:29:06,886 --> 00:29:08,966
机器学习模型层级的内部 我们可以看到

891
00:29:08,966 --> 00:29:10,186
有一个模型描述

892
00:29:10,896 --> 00:29:12,626
使你可以访问

893
00:29:12,626 --> 00:29:14,946
任何你在 Xcode

894
00:29:15,136 --> 00:29:16,066
元数据中看到的东西

895
00:29:16,636 --> 00:29:18,196
还有一个额外的

896
00:29:18,196 --> 00:29:19,726
预测方式 它接受

897
00:29:19,816 --> 00:29:21,726
符合协议的输入

898
00:29:21,726 --> 00:29:23,206
并返回符合协议的输出

899
00:29:23,206 --> 00:29:24,606
这给你

900
00:29:24,676 --> 00:29:26,456
提供输入的方式

901
00:29:26,456 --> 00:29:26,956
以更多的弹性空间

902
00:29:27,836 --> 00:29:29,366
我们看过了

903
00:29:29,366 --> 00:29:31,016
这一开发流程的上半部分

904
00:29:31,446 --> 00:29:32,946
并看到了

905
00:29:32,946 --> 00:29:34,826
当你将一个训练过的模型拖拽进 Xcode 会发生什么

906
00:29:35,486 --> 00:29:36,766
它可以生成 Swift 源

907
00:29:36,856 --> 00:29:38,806
你可以在你的 App 里使用

908
00:29:39,486 --> 00:29:41,436
在你的 App 里

909
00:29:41,526 --> 00:29:42,006
使用这一模型

910
00:29:44,096 --> 00:29:46,156
如我们所见 这一模型本身

911
00:29:46,156 --> 00:29:47,926
同样也被编译并归入

912
00:29:47,926 --> 00:29:49,066
到你的 App 中

913
00:29:51,816 --> 00:29:53,506
在这一步做一个更详细的说明

914
00:29:53,506 --> 00:29:55,986
我们要做什么 首先

915
00:29:55,986 --> 00:29:58,646
我们从模型的 JSON 形式中得到它

916
00:29:58,836 --> 00:29:59,756
这是优化过的

917
00:29:59,846 --> 00:30:01,056
为了更加便携和易于转化

918
00:29:59,846 --> 00:30:01,056
为了更加便携和易于转化

919
00:30:01,056 --> 00:30:02,886
并编译它

920
00:30:03,166 --> 00:30:04,606
使它能在设备上快速加载

921
00:30:04,606 --> 00:30:06,826
当你启动它的时候

922
00:30:08,036 --> 00:30:09,886
我们还需要确认模型

923
00:30:09,886 --> 00:30:11,376
与底层推断引擎

924
00:30:11,376 --> 00:30:12,716
相连接

925
00:30:12,716 --> 00:30:14,276
最终在你的设备上做出评估

926
00:30:14,276 --> 00:30:15,916
并给你一个优化的预测结果

927
00:30:16,026 --> 00:30:17,426
当你需要的时候

928
00:30:17,426 --> 00:30:20,576
我们在演示中看到的最后一样东西

929
00:30:20,576 --> 00:30:22,806
就是我们换掉了模型

930
00:30:23,646 --> 00:30:25,586
大多数时候都是为了缩减体积

931
00:30:26,426 --> 00:30:28,196
但是还有其他的原因

932
00:30:28,196 --> 00:30:29,226
为什么你可能会需要

933
00:30:29,226 --> 00:30:29,936
使用别的模型

934
00:30:30,346 --> 00:30:32,406
比如说 为了精确性或者仅仅是

935
00:30:32,406 --> 00:30:34,266
为了测试出不同的类型

936
00:30:34,266 --> 00:30:35,096
看它们表现如何

937
00:30:35,696 --> 00:30:40,636
总的来说 今天我们了解了

938
00:30:40,636 --> 00:30:41,966
我们可用的一些

939
00:30:41,966 --> 00:30:43,206
机器学习模型框架

940
00:30:43,206 --> 00:30:43,746
的概览

941
00:30:44,686 --> 00:30:46,736
我们还推出了 Core ML

942
00:30:46,736 --> 00:30:48,166
一个全新的框架

943
00:30:48,276 --> 00:30:48,746
用于设备端的推断

944
00:30:49,956 --> 00:30:51,176
我们也实际向你们展示了

945
00:30:51,176 --> 00:30:52,456
开发流程

946
00:30:54,536 --> 00:30:55,946
需要更多信息的话

947
00:30:55,946 --> 00:30:56,786
请到

948
00:30:56,786 --> 00:30:58,376
developer.apple.com 查看

949
00:30:58,376 --> 00:30:59,816
我们的研讨会序号是 703

950
00:31:00,696 --> 00:31:02,096
同时 周四可以参加一些

951
00:31:02,096 --> 00:31:03,976
的相关研讨会进行深入了解 例如 Vision

952
00:31:03,976 --> 00:31:06,536
和 NLP 以及 Core ML 

953
00:31:06,596 --> 00:31:08,076
如果你们想了解

954
00:31:08,076 --> 00:31:09,606
更多 Core ML 的使用场景

955
00:31:09,606 --> 00:31:11,366
或者如何

956
00:31:11,366 --> 00:31:12,946
将模型转换为 Core ML

957
00:31:13,006 --> 00:31:13,266
格式

958
00:31:14,276 --> 00:31:15,666
感谢各位 

959
00:31:15,666 --> 00:31:16,206
并请期待大会接下来的日程
