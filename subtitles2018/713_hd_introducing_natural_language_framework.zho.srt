1
00:00:17,784 --> 0:00:21,288
（Natural Language

2
00:00:26,093 --> 0:00:27,461
大家下午好

3
00:00:27,761 --> 0:00:30,364
欢迎参加关于自然语言处理的演讲

4
00:00:30,964 --> 0:00:33,033
今天我很高兴见到

5
00:00:33,267 --> 0:00:36,937
我很激动地向大家介绍一些

6
00:00:37,004 --> 0:00:39,606
又新又酷炫的功能

7
00:00:40,607 --> 0:00:43,076
我是Vivek 我将与同事

8
00:00:43,277 --> 0:00:44,711
一起进行这次演讲

9
00:00:45,012 --> 0:00:45,979
让我们开始吧

10
00:00:47,648 --> 0:00:50,551
去年我们重点关注你的app

11
00:00:50,751 --> 0:00:53,921
并告诉你如何利用NLP的力量

12
00:00:54,788 --> 0:00:57,291
来让你的app变得更聪明 更智能

13
00:00:58,225 --> 0:01:00,127
我们曾通过向你演示

14
00:00:58,225 --> 0:01:00,127
我们曾通过向你演示

15
00:01:00,194 --> 0:01:03,764
NSLinguisticTagger中

16
00:01:05,065 --> 0:01:08,869
正如大多数人熟悉或曾使用过的那样

17
00:01:09,603 --> 0:01:14,141
NSLinguisticTagger是一个基础类

18
00:01:14,641 --> 0:01:18,412
从语言识别到语言组织

19
00:01:18,745 --> 0:01:19,580
等等

20
00:01:20,347 --> 0:01:22,683
我们在NSLinguisticTagger中

21
00:01:22,749 --> 0:01:26,386
通过在幕后无缝地融合

22
00:01:26,987 --> 0:01:30,591
这样 你作为一名开发人员

23
00:01:30,657 --> 0:01:32,125
并专注于完成你的任务

24
00:01:33,160 --> 0:01:34,194
这很棒

25
00:01:34,528 --> 0:01:36,063
今年NLP新特性是什么呢？

26
00:01:37,364 --> 0:01:41,168
我们很高兴地宣布

27
00:01:41,235 --> 0:01:42,503
我们称它为

28
00:01:43,203 --> 0:01:48,041
Natural Language将成为

29
00:01:48,108 --> 0:01:50,544
实现NLP所有功能的一站式商店

30
00:01:51,545 --> 0:01:53,881
Natural Language

31
00:01:53,947 --> 0:01:55,449
让我们谈谈其中的每一个

32
00:01:57,117 --> 0:02:00,387
首先 它有一个

33
00:01:57,117 --> 0:02:00,387
首先 它有一个

34
00:02:01,255 --> 0:02:04,358
因此它支持NSLinguisticTagger过去以及

35
00:02:04,424 --> 0:02:08,529
现在仍在使用的所有功能

36
00:02:09,496 --> 0:02:10,464
但还不仅如此

37
00:02:11,064 --> 0:02:13,734
我们现在支持自定义的NLP模型

38
00:02:14,067 --> 0:02:18,172
这些是你可以使用

39
00:02:18,238 --> 0:02:21,041
并使用Core ML API或

40
00:02:22,676 --> 0:02:24,444
我们在Natural Language中

41
00:02:24,511 --> 0:02:27,581
所有机器学习NLP

42
00:02:27,814 --> 0:02:31,118
它针对Apple硬件和模型大小

43
00:02:32,352 --> 0:02:35,956
最后 这一切都是完全私有的

44
00:02:36,156 --> 0:02:39,760
使用Natural Language框架的

45
00:02:40,093 --> 0:02:42,496
都在设备上完成以保护用户的隐私

46
00:02:42,963 --> 0:02:45,832
这正是我们在Apple中为了实现

47
00:02:46,200 --> 0:02:49,469
在设备上进行NLP而使用的技术

48
00:02:50,537 --> 0:02:53,774
我来谈谈Natural Language的

49
00:02:54,007 --> 0:02:55,809
我们从Swift API开始

50
00:02:58,312 --> 0:03:01,648
正如我所提到的

51
00:02:58,312 --> 0:03:01,648
正如我所提到的

52
00:03:01,715 --> 0:03:03,217
所有NSLinguisticTagger的基本构建块

53
00:03:03,517 --> 0:03:07,020
但使用更好 更易于使用的API

54
00:03:08,055 --> 0:03:11,124
为了演示其中的一部分API

55
00:03:11,191 --> 0:03:13,560
我将用一个假想app来说明它们

56
00:03:15,229 --> 0:03:18,398
我们假设你写的第一个app

57
00:03:19,666 --> 0:03:22,402
作为该app的一部分

58
00:03:22,469 --> 0:03:23,971
或点对点消息功能

59
00:03:25,439 --> 0:03:27,574
你在此app中创建的附加功能

60
00:03:27,641 --> 0:03:30,944
是显示正确的贴纸

61
00:03:31,545 --> 0:03:35,482
根据消息的内容 在这个例子中是

62
00:03:35,549 --> 0:03:38,051
“现在太晚了 我很累了

63
00:03:38,352 --> 0:03:40,053
你的app会显示合适的贴纸

64
00:03:40,120 --> 0:03:42,556
你解析了这段文字 然后显示贴纸

65
00:03:42,823 --> 0:03:44,992
用户可以附加并发送它作为回应

66
00:03:45,425 --> 0:03:47,561
这一切都很棒

67
00:03:47,628 --> 0:03:48,929
你得到的好评如潮

68
00:03:49,897 --> 0:03:52,833
但是你也会收到反馈

69
00:03:53,734 --> 0:03:56,336
现在有越来越多的双语用户

70
00:03:56,403 --> 0:03:58,772
他们倾向于用几种不同的语言沟通

71
00:03:59,106 --> 0:04:01,241
当你的app收到中文信息时

72
00:03:59,106 --> 0:04:01,241
当你的app收到中文信息时

73
00:04:01,542 --> 0:04:03,043
它根本不知道如何处理它

74
00:04:04,077 --> 0:04:06,747
我们如何使用Natural Language

75
00:04:08,348 --> 0:04:11,652
我们可以通过对两个不同API的

76
00:04:12,219 --> 0:04:13,887
首先是语言识别

77
00:04:15,088 --> 0:04:16,456
使用新的Natural Language框架

78
00:04:16,523 --> 0:04:18,725
首先你要导入NaturalLanguage

79
00:04:19,793 --> 0:04:23,197
你创建一个

80
00:04:24,431 --> 0:04:26,433
你附上你想要处理的字符串

81
00:04:27,201 --> 0:04:29,636
你只需调用

82
00:04:30,404 --> 0:04:33,373
现在这将根据字符串的语言

83
00:04:34,074 --> 0:04:35,742
返回最可能的语言类别

84
00:04:36,777 --> 0:04:39,479
这里的输出是简体中文

85
00:04:40,480 --> 0:04:43,150
现在在Natural Language中

86
00:04:43,483 --> 0:04:45,219
有些情况下你想知道

87
00:04:45,285 --> 0:04:47,988
特定字符串的较优猜测

88
00:04:48,622 --> 0:04:50,958
所以你想知道最可能的语言是哪些

89
00:04:51,024 --> 0:04:52,759
及其相关概率

90
00:04:53,160 --> 0:04:56,230
你可以设想

91
00:04:56,296 --> 0:04:59,366
这些app中包含多语言信息

92
00:04:59,433 --> 0:05:01,435
为这些可能的语言留有余地

93
00:04:59,433 --> 0:05:01,435
为这些可能的语言留有余地

94
00:05:02,269 --> 0:05:05,839
你可以用一个叫做languageHypotheses的

95
00:05:06,139 --> 0:05:08,775
你可以指定返回语言的最大数量

96
00:05:08,842 --> 0:05:11,778
其将返回的是最可能语言的对象

97
00:05:11,845 --> 0:05:13,447
以及各自的概率

98
00:05:14,581 --> 0:05:16,683
为了对这个中文文本进行分词

99
00:05:16,984 --> 0:05:19,253
你可以看到它的用法非常类似

100
00:05:20,053 --> 0:05:21,688
你再次导入

101
00:05:22,356 --> 0:05:24,458
创建一个

102
00:05:25,158 --> 0:05:28,428
在这个实例中

103
00:05:28,495 --> 0:05:30,664
因为你要将字符串切分为单词

104
00:05:32,799 --> 0:05:33,901
你传入了字符串

105
00:05:34,535 --> 0:05:38,105
然后只需在对象的字符串上

106
00:05:39,039 --> 0:05:41,175
在这里你得到一个tokens数组

107
00:05:41,975 --> 0:05:45,345
现在有了这个tokens数组

108
00:05:45,412 --> 0:05:46,580
这里是“晚安”

109
00:05:47,381 --> 0:05:50,250
瞧 你的app现在支持多语言了

110
00:05:50,984 --> 0:05:54,421
因此 你的app现在可以通过

111
00:05:54,488 --> 0:05:57,858
简单的调用语言识别和分词API

112
00:05:59,059 --> 0:06:01,261
让我们看看另一种

113
00:05:59,059 --> 0:06:01,261
让我们看看另一种

114
00:06:01,328 --> 0:06:05,065
语言识别和分词都很好

115
00:06:05,132 --> 0:06:07,501
自动语音标记 命名实体识别等功能

116
00:06:08,035 --> 0:06:11,238
我来演示一下

117
00:06:11,305 --> 0:06:12,806
使用命名实体识别API

118
00:06:14,341 --> 0:06:17,110
这里有一个app

119
00:06:17,644 --> 0:06:20,514
在你的app中

120
00:06:20,581 --> 0:06:23,383
很多关于皇室婚礼的事情

121
00:06:23,450 --> 0:06:25,085
他们想了解有关皇室婚礼的一切

122
00:06:25,752 --> 0:06:27,955
他们已经在你的app中

123
00:06:28,488 --> 0:06:31,592
然后他们进入搜索栏

124
00:06:32,326 --> 0:06:35,662
然而却看到与他们一直在寻找的

125
00:06:35,729 --> 0:06:37,231
完全不相关的东西

126
00:06:37,297 --> 0:06:39,199
比如哈利波特等等

127
00:06:39,566 --> 0:06:44,705
你想看到的是

128
00:06:45,372 --> 0:06:47,674
现在你可以在app中

129
00:06:47,741 --> 0:06:50,310
通过使用命名实体识别API

130
00:06:51,378 --> 0:06:54,348
正如我所提到的

131
00:06:54,414 --> 0:06:57,684
你们中那些习惯使用

132
00:06:57,751 --> 0:07:00,487
应该觉得这看起来感觉很熟悉

133
00:06:57,751 --> 0:07:00,487
应该觉得这看起来感觉很熟悉

134
00:07:00,554 --> 0:07:01,788
记忆和使用

135
00:07:02,656 --> 0:07:03,957
你导入

136
00:07:04,892 --> 0:07:07,127
你现在创建一个

137
00:07:07,694 --> 0:07:10,030
并指定scheme类型

138
00:07:10,898 --> 0:07:12,199
若你想添加词性标注功能

139
00:07:12,266 --> 0:07:14,868
你需要指定该scheme类型

140
00:07:16,036 --> 0:07:18,539
你再次指定要处理的字符串

141
00:07:19,439 --> 0:07:21,141
在这个例子中

142
00:07:21,208 --> 0:07:24,611
你将语言设置为英语

143
00:07:25,379 --> 0:07:26,747
如果你不熟悉

144
00:07:26,813 --> 0:07:28,982
或者你不确定语言是什么

145
00:07:29,149 --> 0:07:32,252
Natural Language

146
00:07:32,319 --> 0:07:34,922
在底层自动识别该语言种类

147
00:07:36,190 --> 0:07:40,561
最后 你在刚创建的对象上

148
00:07:40,794 --> 0:07:44,131
将unit参数设为word

149
00:07:44,998 --> 0:07:48,669
你得到的输出是这里的人名

150
00:07:48,735 --> 0:07:51,538
哈里王子和梅格汉马克尔

151
00:07:51,805 --> 0:07:54,241
现在 如果用户返回到搜索栏

152
00:07:54,741 --> 0:07:57,811
基于用户浏览的内容信息

153
00:07:57,878 --> 0:08:00,914
你可以显著提高app中的搜索体验

154
00:07:57,878 --> 0:08:00,914
你可以显著提高app中的搜索体验

155
00:08:03,817 --> 0:08:06,920
若想了解更多

156
00:08:06,987 --> 0:08:09,990
你可以参考开发者文档

157
00:08:10,390 --> 0:08:15,696
我想强调的是我们虽然仍支持

158
00:08:16,029 --> 0:08:18,498
但NLP的未来是

159
00:08:18,565 --> 0:08:22,903
因此我们建议并鼓励你

160
00:08:22,970 --> 0:08:26,240
以便可以在此框架中获得

161
00:08:27,341 --> 0:08:30,777
现在让我们思考另一种情况

162
00:08:30,944 --> 0:08:32,913
你有一个app的想法

163
00:08:33,614 --> 0:08:35,948
或者你需要在你的app中添加一个

164
00:08:36,316 --> 0:08:38,085
Natural Language

165
00:08:39,586 --> 0:08:40,419
你该怎么办？

166
00:08:41,455 --> 0:08:45,025
你当然可以创造这些东西 这很棒

167
00:08:45,292 --> 0:08:48,228
但如果我们给你提供工具

168
00:08:50,931 --> 0:08:56,003
为了讨论自定义NLP模型

169
00:08:56,270 --> 0:08:59,873
并使用这些在Natural Language中

170
00:08:59,940 --> 0:09:02,809
我将把这个话题交给

171
00:08:59,940 --> 0:09:02,809
我将把这个话题交给

172
00:09:09,750 --> 0:09:10,584
感谢Vivek

173
00:09:11,118 --> 0:09:15,656
我对新的Natural Language框架

174
00:09:15,722 --> 0:09:19,526
但我最感兴趣的部分是

175
00:09:19,593 --> 0:09:21,361
对构建和使用定制化模型的支持

176
00:09:21,595 --> 0:09:22,663
为什么呢？

177
00:09:23,397 --> 0:09:26,733
我想让你考虑一下你的app

178
00:09:27,167 --> 0:09:30,871
这可能是你已编写的app

179
00:09:31,405 --> 0:09:35,008
并考虑如果它们能够

180
00:09:35,075 --> 0:09:39,646
更好理解他们所处理的文本

181
00:09:40,380 --> 0:09:44,852
然后想一想你自己是如何分析文本的

182
00:09:44,985 --> 0:09:48,088
也许你看到一些样板文本

183
00:09:48,488 --> 0:09:49,990
你从中学习一些信息

184
00:09:50,691 --> 0:09:55,262
然后明白发生了什么

185
00:09:55,329 --> 0:09:58,432
并且马上可以理解

186
00:09:59,333 --> 0:10:00,767
那么 如果是这样的话

187
00:09:59,333 --> 0:10:00,767
那么 如果是这样的话

188
00:10:00,934 --> 0:10:04,605
你就有一定可能

189
00:10:05,572 --> 0:10:07,274
通过设计一个机器学习模型

190
00:10:07,774 --> 0:10:13,347
给它一些例子以便训练和学习

191
00:10:13,780 --> 0:10:17,150
来在你的app中自动为你

192
00:10:17,684 --> 0:10:19,219
能够进行这类分析的模型

193
00:10:19,920 --> 0:10:25,559
当前NLP有很多种类的

194
00:10:25,626 --> 0:10:27,194
并且有许多不同的方式来训练它

195
00:10:27,261 --> 0:10:30,030
你们中许多人可能已经

196
00:10:30,330 --> 0:10:34,468
但我们这里的任务是寻找一种

197
00:10:34,535 --> 0:10:37,671
让这种训练变得极其简单

198
00:10:38,372 --> 0:10:40,340
并能够与Natural Language框架和API

199
00:10:40,641 --> 0:10:43,210
整合得非常好的方法

200
00:10:43,510 --> 0:10:48,081
考虑到这一点

201
00:10:48,282 --> 0:10:52,119
我们认为这些模型能够

202
00:10:52,486 --> 0:10:54,955
且能与NLTagger中的范式

203
00:10:55,022 --> 0:10:58,492
即将标签app于文本片段

204
00:10:58,759 --> 0:11:02,429
我们支持的第一个模型是文本分类器

205
00:10:58,759 --> 0:11:02,429
我们支持的第一个模型是文本分类器

206
00:11:02,796 --> 0:11:03,630
这个…

207
00:11:03,697 --> 0:11:08,235
文本分类器读取一块文本

208
00:11:08,302 --> 0:11:11,405
或整个文档 并为其打上一个标签

209
00:11:11,738 --> 0:11:15,976
我们现有的API中的例子

210
00:11:16,043 --> 0:11:17,377
脚本识别

211
00:11:18,245 --> 0:11:21,215
我们支持的第二种模型是单词标记器

212
00:11:21,648 --> 0:11:26,653
一个单词标记器将一个句子

213
00:11:26,920 --> 0:11:31,225
然后根据上下文

214
00:11:31,458 --> 0:11:35,696
现有API中的例子

215
00:11:35,762 --> 0:11:37,264
和命名实体识别

216
00:11:37,598 --> 0:11:43,337
但这些都是这类模型的通用示例

217
00:11:44,004 --> 0:11:45,906
如果你在app中

218
00:11:45,973 --> 0:11:48,876
你可以用他们做更多的事情

219
00:11:48,942 --> 0:11:49,810
让我给你

220
00:11:49,877 --> 0:11:51,478
一些假设的例子

221
00:11:51,912 --> 0:11:56,283
对于文本分类

222
00:11:56,350 --> 0:11:58,118
你想自动知道

223
00:11:58,352 --> 0:12:01,288
给定的评论是正面评论

224
00:11:58,352 --> 0:12:01,288
给定的评论是正面评论

225
00:12:01,588 --> 0:12:03,857
还是负面评论或介于两者之间的地方

226
00:12:04,291 --> 0:12:06,960
这是你可以通过

227
00:12:07,027 --> 0:12:08,595
这属于情感分类

228
00:12:10,464 --> 0:12:13,567
或者假设你有文章或文章摘要

229
00:12:13,634 --> 0:12:17,137
甚至只是文章标题

230
00:12:17,504 --> 0:12:20,274
而你想根据你最喜欢的主题分类方案

231
00:12:20,674 --> 0:12:22,376
自动确定它们属于哪个主题

232
00:12:22,709 --> 0:12:25,045
这也是你可以训练

233
00:12:25,779 --> 0:12:28,115
一个文本分类器为你做的事情

234
00:12:30,050 --> 0:12:34,388
或者再进一步

235
00:12:34,655 --> 0:12:37,124
当你收到客户的请求时

236
00:12:37,191 --> 0:12:40,561
你想知道的第一件事可能是

237
00:12:40,727 --> 0:12:44,331
是酒店还是餐馆或是航班

238
00:12:45,065 --> 0:12:49,236
这是你可以训练一个文本分类器

239
00:12:50,904 --> 0:12:52,506
继续说单词标记

240
00:12:53,040 --> 0:12:57,711
我们提供了能为许多语言

241
00:12:57,778 --> 0:13:01,815
做词性标注的单词标记器

242
00:12:57,778 --> 0:13:01,815
做词性标注的单词标记器

243
00:13:01,882 --> 0:13:05,886
针对某种我们尚未支持的语言

244
00:13:06,420 --> 0:13:10,924
而有了自定义模型的支持 你就可以

245
00:13:12,259 --> 0:13:14,261
或者命名实体识别

246
00:13:14,728 --> 0:13:16,730
我们提供了内置的命名实体识别功能

247
00:13:16,797 --> 0:13:20,634
它能够识别人名、地名和组织名称

248
00:13:21,368 --> 0:13:22,936
但若你对其它类型名字

249
00:13:23,003 --> 0:13:26,173
而这类名字我们碰巧不支持

250
00:13:26,473 --> 0:13:28,575
例如产品名称

251
00:13:29,009 --> 0:13:31,912
你可以训练你自己的

252
00:13:31,979 --> 0:13:36,383
作为可以识别你特别感兴趣的

253
00:13:36,450 --> 0:13:38,886
名称或其他术语的单词标记器

254
00:13:40,587 --> 0:13:43,590
再者 对于你的自动旅行代理

255
00:13:43,657 --> 0:13:45,726
一旦你知道用户在问什么

256
00:13:46,159 --> 0:13:48,161
可能你想知道的下一件事是

257
00:13:48,228 --> 0:13:50,464
他们的请求中有哪些相关信息

258
00:13:50,597 --> 0:13:54,434
例如 如果这是航班请求

259
00:13:55,502 --> 0:14:00,908
单词标记器可以

260
00:13:55,502 --> 0:14:00,908
单词标记器可以

261
00:14:02,309 --> 0:14:04,444
又或者假设有另一个app

262
00:14:04,511 --> 0:14:07,581
你需要把一个句子分成若干短语

263
00:14:07,648 --> 0:14:10,617
名词短语、动词短语、命题短语

264
00:14:10,984 --> 0:14:15,589
有了适当的标签 你可以训练

265
00:14:15,656 --> 0:14:22,029
以及许多其他类型的

266
00:14:22,095 --> 0:14:26,600
为文本块打上标签

267
00:14:26,667 --> 0:14:29,903
还是文本分类器中的文本块

268
00:14:33,674 --> 0:14:36,944
这些都是有监督机器学习模型

269
00:14:37,010 --> 0:14:40,047
所以总是包括两个阶段

270
00:14:40,214 --> 0:14:43,684
第一阶段是训练

271
00:14:43,750 --> 0:14:47,721
训练是你在开发过程中需要做的部分

272
00:14:48,188 --> 0:14:51,058
你将带标签的训练数据

273
00:14:51,892 --> 0:14:55,896
输入Create ML

274
00:14:57,231 --> 0:15:00,367
推理就是当你在运行时

275
00:14:57,231 --> 0:15:00,367
推理就是当你在运行时

276
00:15:00,434 --> 0:15:04,538
将该模型整合到你的app中后

277
00:15:04,605 --> 0:15:07,407
当它遇到来自用户的一些数据时

278
00:15:07,808 --> 0:15:09,176
它会分析这些数据

279
00:15:09,243 --> 0:15:11,311
并预测适当的标签

280
00:15:12,012 --> 0:15:13,847
让我们看看这些阶段是如何工作的

281
00:15:14,948 --> 0:15:18,852
让我们从训练开始

282
00:15:19,419 --> 0:15:23,557
你将你的训练数据输入到

283
00:15:23,624 --> 0:15:29,429
Playground或脚本

284
00:15:30,264 --> 0:15:32,199
如你在Create ML演讲中

285
00:15:32,633 --> 0:15:34,101
Create ML在底层调用

286
00:15:34,168 --> 0:15:37,304
Natural Language

287
00:15:38,005 --> 0:15:44,545
其输出的是一个Core ML模型

288
00:15:45,979 --> 0:15:48,348
让我们看看这些数据是什么样子的

289
00:15:49,750 --> 0:15:52,920
Create ML支持

290
00:15:53,987 --> 0:15:58,692
在这里我们使用JSON显示数据

291
00:16:00,093 --> 0:16:03,830
这是一部分训练数据

292
00:16:03,897 --> 0:16:07,668
被用来训练文本分类器

293
00:16:07,901 --> 0:16:10,103
每个训练的样例

294
00:16:11,104 --> 0:16:12,139
比如这个

295
00:16:12,206 --> 0:16:15,142
都由两部分组成 一块文本

296
00:16:15,509 --> 0:16:18,111
以及与其对应的标签

297
00:16:18,679 --> 0:16:21,415
例如这是一个表达正面情感的句子

298
00:16:21,481 --> 0:16:24,852
所以其标签为“积极”

299
00:16:27,754 --> 0:16:33,193
当你开始使用Create ML时

300
00:16:33,260 --> 0:16:36,930
极其简单的只需几行代码

301
00:16:36,997 --> 0:16:42,803
第一行 我们只是从JSON文件

302
00:16:42,870 --> 0:16:48,976
我们给它一个JSON文件的URL

303
00:16:49,943 --> 0:16:55,649
然后仅在一行代码中 使用这些数据

304
00:16:55,782 --> 0:16:59,686
你需要告诉它的只是字段名称

305
00:17:01,455 --> 0:17:02,589
一旦训练完成

306
00:17:02,656 --> 0:17:05,291
你就可以用一行代码

307
00:17:07,261 --> 0:17:09,630
训练一个单词标记器的方法与这类似

308
00:17:09,963 --> 0:17:12,199
只是数据稍微复杂一些

309
00:17:12,266 --> 0:17:15,068
因为每个示例不是一块单独的文本

310
00:17:15,301 --> 0:17:17,838
而是一个token序列

311
00:17:18,704 --> 0:17:21,375
并且标签也是一个

312
00:17:21,441 --> 0:17:24,611
与token序列具有相同数量标签

313
00:17:24,944 --> 0:17:29,883
例如 这是训练

314
00:17:29,950 --> 0:17:35,722
它可以进行命名实体识别每个单词

315
00:17:36,023 --> 0:17:42,095
若是“NONE”则不是一个名称

316
00:17:42,162 --> 0:17:45,532
若是“PROD”则是产品名称

317
00:17:45,599 --> 0:17:47,901
以及还有许多你想要识别的其他标签

318
00:17:48,268 --> 0:17:49,937
每个token都有一个标签

319
00:17:50,737 --> 0:17:55,475
每个样本由一个token序列

320
00:17:55,542 --> 0:17:57,044
和它所对应的标签组成

321
00:17:58,579 --> 0:18:02,983
用来训练它的Create ML

322
00:17:58,579 --> 0:18:02,983
用来训练它的Create ML

323
00:18:03,951 --> 0:18:08,355
你将训练数据

324
00:18:10,190 --> 0:18:13,927
然后你创建并训练

325
00:18:13,994 --> 0:18:15,429
而非之前的文本分类器对象

326
00:18:15,863 --> 0:18:17,931
然后将其写入磁盘

327
00:18:18,298 --> 0:18:23,504
Create ML中还有许多

328
00:18:23,570 --> 0:18:25,305
我鼓励你 如果你还没有的话

329
00:18:25,372 --> 0:18:28,876
看看昨天举办的

330
00:18:28,942 --> 0:18:32,246
以及Create ML文档

331
00:18:33,046 --> 0:18:36,550
现在 一旦你训练好了模型

332
00:18:36,717 --> 0:18:40,120
你把你的模型拖到

333
00:18:40,187 --> 0:18:44,091
Xcode将编译并将其

334
00:18:44,458 --> 0:18:48,929
然后你在运行时做什么呢？

335
00:18:48,996 --> 0:18:50,998
你可以像使用其他任何

336
00:18:51,431 --> 0:18:56,270
但有趣的是这些模型能够很好地

337
00:18:56,570 --> 0:19:01,441
就像是我们自己的

338
00:18:56,570 --> 0:19:01,441
就像是我们自己的

339
00:19:01,508 --> 0:19:05,279
提供了NLP功能的内置模型一样

340
00:19:06,613 --> 0:19:07,447
所以…

341
00:19:08,115 --> 0:19:10,384
数据将进来

342
00:19:11,251 --> 0:19:15,856
你将它传递给Natural Language

343
00:19:15,923 --> 0:19:19,993
来找出所有的标签

344
00:19:20,060 --> 0:19:23,830
然后为一个分类器传回单个标签

345
00:19:23,897 --> 0:19:27,167
或为一个标记器传回一个标签序列

346
00:19:30,370 --> 0:19:33,740
你如何在Natural Language API中

347
00:19:34,341 --> 0:19:37,945
你首先需要做的是

348
00:19:38,011 --> 0:19:41,348
在app资源中找到该模型

349
00:19:41,415 --> 0:19:44,852
Natural Language中的一个类

350
00:19:45,986 --> 0:19:48,822
然后 你可以用它做的最简单的事

351
00:19:48,889 --> 0:19:53,861
至少对于一个分类器来说 就是向它

352
00:19:54,695 --> 0:19:59,066
但更有趣的是你可以

353
00:19:59,132 --> 0:20:00,434
在NLTagger中使用这些模型

354
00:19:59,132 --> 0:20:00,434
在NLTagger中使用这些模型

355
00:20:01,468 --> 0:20:05,105
其方式与你使用

356
00:20:05,639 --> 0:20:07,708
内置模型中的功能的方式完全相同

357
00:20:08,175 --> 0:20:09,543
让我向你展示这如何工作

358
00:20:10,344 --> 0:20:13,647
除了我们现有的标签方案

359
00:20:13,714 --> 0:20:16,350
像命名实体识别 词性标注

360
00:20:16,817 --> 0:20:20,020
你可以创建自己的自定义标签方案

361
00:20:21,788 --> 0:20:23,924
然后你可以创建一个包含任意数量的

362
00:20:24,424 --> 0:20:26,860
不同标签方案的标记器

363
00:20:27,094 --> 0:20:29,796
它可以包括自定义标签方案

364
00:20:29,863 --> 0:20:30,697
或者它们全部

365
00:20:32,266 --> 0:20:35,302
然后你所要做的就是告诉标记器

366
00:20:35,369 --> 0:20:38,272
使用自定义模型作为自定义标签方案

367
00:20:39,873 --> 0:20:42,776
接下来你只需要正常使用它

368
00:20:43,210 --> 0:20:46,647
你将一个字符串传给标记器

369
00:20:46,713 --> 0:20:48,115
然后你可以

370
00:20:49,650 --> 0:20:53,620
以最合适你的模型的单位

371
00:20:54,488 --> 0:20:56,990
标记器会自动

372
00:20:57,257 --> 0:21:01,094
根据需要调用该模型以获取标签

373
00:20:57,257 --> 0:21:01,094
根据需要调用该模型以获取标签

374
00:21:01,161 --> 0:21:05,399
并且还会执行NLTagger

375
00:21:05,465 --> 0:21:08,635
像语言识别、分词等等

376
00:21:10,070 --> 0:21:14,107
我想通过一个简单的例子

377
00:21:14,641 --> 0:21:21,014
这个假设的例子是这样一个app

378
00:21:21,081 --> 0:21:24,251
保存他们所遇到的文章的书签

379
00:21:24,318 --> 0:21:26,253
用户可能打算稍后阅读这些文章

380
00:21:27,187 --> 0:21:30,357
但是这个app目前的问题是

381
00:21:30,424 --> 0:21:32,459
这个书签列表

382
00:21:32,526 --> 0:21:35,095
只是一个未经组织的长列表

383
00:21:35,529 --> 0:21:36,597
若我们可以自动分类这些文章

384
00:21:36,663 --> 0:21:39,800
并根据主题将它们组织起来

385
00:21:40,167 --> 0:21:42,803
这不是很好吗？

386
00:21:43,504 --> 0:21:46,340
我们可以训练一个分类器

387
00:21:47,040 --> 0:21:49,743
另一件事是 当我们看这些文章时

388
00:21:49,810 --> 0:21:51,478
它们是一段很长的文本

389
00:21:52,346 --> 0:21:56,750
也许我们想在这些文章中

390
00:21:56,817 --> 0:21:58,385
比如名字

391
00:21:58,752 --> 0:22:02,823
我们已经对人名、地名和组织名称

392
00:21:58,752 --> 0:22:02,823
我们已经对人名、地名和组织名称

393
00:22:02,890 --> 0:22:05,425
提供了内置的命名实体识别功能

394
00:22:06,260 --> 0:22:09,162
但也许我们也想突出显示产品的名称

395
00:22:09,229 --> 0:22:13,467
我们可以训练一个自定义单词标记器

396
00:22:15,369 --> 0:22:17,271
现在让我切换到演示机

397
00:22:22,809 --> 0:22:25,379
这是我们在

398
00:22:25,445 --> 0:22:29,149
app任何自然语言处理技术

399
00:22:29,383 --> 0:22:33,153
正如你所看到的

400
00:22:33,220 --> 0:22:36,490
以及我们右边文章的大块文本

401
00:22:36,557 --> 0:22:37,491
让我们来解决这个问题

402
00:22:38,759 --> 0:22:41,061
让我们进入…

403
00:22:42,162 --> 0:22:46,667
训练模型的第一部分是数据

404
00:22:47,167 --> 0:22:50,671
幸运的是 我在Apple有一些

405
00:22:50,737 --> 0:22:54,508
他们收集了一些训练数据

406
00:22:54,741 --> 0:22:57,811
第一个模型是一个文本分类器

407
00:22:58,145 --> 0:23:00,480
它将根据主题对文章进行分类

408
00:22:58,145 --> 0:23:00,480
它将根据主题对文章进行分类

409
00:23:00,848 --> 0:23:03,217
这是一部分训练数据的样子

410
00:23:03,717 --> 0:23:09,523
每个训练示例都包括一个文本块

411
00:23:09,590 --> 0:23:12,626
娱乐、政治、体育等等

412
00:23:15,495 --> 0:23:20,601
我还有一些用来训练单词标记器的

413
00:23:21,235 --> 0:23:25,839
这个标记器将被用来

414
00:23:26,206 --> 0:23:28,175
这些训练数据非常简单

415
00:23:28,675 --> 0:23:33,947
每个例子都包含一个token序列

416
00:23:34,014 --> 0:23:37,885
以及一个标签序列 每个标签

417
00:23:37,951 --> 0:23:41,388
要么是“PROD” 代表是产品名

418
00:23:43,624 --> 0:23:46,493
我们试着用这些数据进行训练

419
00:23:47,160 --> 0:23:48,896
我想要做的第一件事

420
00:23:49,663 --> 0:23:54,067
是启动一个运行Create ML

421
00:23:54,935 --> 0:23:57,604
这个Playground将会加载

422
00:23:58,372 --> 0:24:01,542
我的产品单词标记器

423
00:23:58,372 --> 0:24:01,542
我的产品单词标记器

424
00:24:01,742 --> 0:24:05,279
它会加载训练数据

425
00:24:05,879 --> 0:24:08,348
并将其写入磁盘

426
00:24:09,483 --> 0:24:10,817
现在让我们运行它

427
00:24:11,151 --> 0:24:16,056
它加载了数据 我们在底层

428
00:24:16,123 --> 0:24:19,126
自动处理了所有的分词 特征提取

429
00:24:19,459 --> 0:24:21,795
我们实现了这个训练过程

430
00:24:22,162 --> 0:24:28,302
所以它不需要很长时间来训练

431
00:24:28,368 --> 0:24:32,906
自动将我的模型保存到我的桌面上

432
00:24:36,109 --> 0:24:37,544
好的 这是其中一个模型

433
00:24:38,579 --> 0:24:42,850
这里有另一个Playground

434
00:24:43,116 --> 0:24:46,153
如你所见 它看起来非常相似

435
00:24:47,421 --> 0:24:50,424
从中创建一个文本分类器

436
00:24:51,692 --> 0:24:52,826
现在运行它

437
00:24:53,393 --> 0:24:59,266
同样 Natural Language

438
00:24:59,633 --> 0:25:00,901
并从中提取特征

439
00:24:59,633 --> 0:25:00,901
并从中提取特征

440
00:25:01,201 --> 0:25:04,471
这是一个更大的模型

441
00:25:04,538 --> 0:25:07,574
我们让它跑去吧 同时

442
00:25:08,175 --> 0:25:12,112
我们看看在运行时

443
00:25:12,713 --> 0:25:16,617
我写了两个非常小的类

444
00:25:17,117 --> 0:25:23,857
第一个通过在我的app资源中

445
00:25:24,157 --> 0:25:25,859
并为其创建一个NLModel对象

446
00:25:26,793 --> 0:25:29,162
然后 当我碰到一篇文章时

447
00:25:30,430 --> 0:25:31,899
我只是让模型返回

448
00:25:31,965 --> 0:25:36,637
为该文章预测的标签

449
00:25:38,472 --> 0:25:43,577
使用单词标记器的代码稍多一些

450
00:25:44,144 --> 0:25:47,214
正如你之前所见

451
00:25:47,948 --> 0:25:50,350
自定义标签方案

452
00:25:50,918 --> 0:25:54,621
我真正感兴趣的唯一标签是产品标签

453
00:25:54,688 --> 0:25:56,890
我为此创建了一个自定义标签

454
00:25:58,325 --> 0:26:01,962
同样 我必须在捆绑资源中

455
00:25:58,325 --> 0:26:01,962
同样 我必须在捆绑资源中

456
00:26:03,030 --> 0:26:04,498
为它创建一个NLModel对象

457
00:26:05,232 --> 0:26:06,733
然后创建一个NLTagger

458
00:26:07,067 --> 0:26:10,304
在这个NLTagger中

459
00:26:10,370 --> 0:26:15,509
第一种是内置名称类型方案

460
00:26:15,776 --> 0:26:18,412
第二个是我的自定义产品标签方案

461
00:26:18,478 --> 0:26:20,681
它们都以完全相同的方式运行

462
00:26:21,548 --> 0:26:23,650
然后 我只需让那个标记器

463
00:26:23,717 --> 0:26:26,820
将我的自定义模型

464
00:26:27,721 --> 0:26:29,523
现在 如果我要支持多种语言

465
00:26:29,590 --> 0:26:32,326
我可能会在这个方案中有多个模型

466
00:26:34,528 --> 0:26:40,334
然后 我要做的是突出显示

467
00:26:40,667 --> 0:26:44,304
这篇文章中被识别为一种名称的文本

468
00:26:44,505 --> 0:26:47,274
我会得到一个可变属性字符串

469
00:26:47,341 --> 0:26:49,176
我将向它添加一些属性

470
00:26:50,043 --> 0:26:53,547
首先获取

471
00:26:53,847 --> 0:26:55,215
将其赋值给我的标记器

472
00:26:55,949 --> 0:26:59,253
然后我将对标签进行几轮遍历

473
00:26:59,653 --> 0:27:03,123
第一轮使用内置的名称类型方案

474
00:26:59,653 --> 0:27:03,123
第一轮使用内置的名称类型方案

475
00:27:03,490 --> 0:27:06,860
来为人物、地点和组织

476
00:27:07,361 --> 0:27:12,165
如果我找到标记为

477
00:27:12,699 --> 0:27:15,969
我将添加一个属性到这个属性字符串

478
00:27:16,236 --> 0:27:18,071
这会给它设置一些颜色

479
00:27:20,240 --> 0:27:24,144
然后我们可以用我们的自定义模型

480
00:27:24,845 --> 0:27:28,182
我们将使用我们的

481
00:27:29,583 --> 0:27:32,186
在这种情况下 如果我们发现有东西

482
00:27:32,252 --> 0:27:34,021
被我们的自定义产品标签所标记

483
00:27:34,321 --> 0:27:37,891
就可以以完全相同的方式

484
00:27:39,059 --> 0:27:43,363
所以你可以在Natural Language API中

485
00:27:43,730 --> 0:27:47,000
就像你使用内置模型一样

486
00:27:47,568 --> 0:27:49,169
现在 让我们回到

487
00:27:49,903 --> 0:27:53,273
我们看到模型训练已经完成

488
00:27:53,340 --> 0:27:56,143
现在有两个模型显示在我的桌面上

489
00:27:58,045 --> 0:28:01,281
我需要做的就是将它们

490
00:27:58,045 --> 0:28:01,281
我需要做的就是将它们

491
00:28:02,082 --> 0:28:06,320
让我们把这个拖到项目中

492
00:28:08,322 --> 0:28:09,189
好了

493
00:28:11,892 --> 0:28:17,431
我们把这个也拖进来

494
00:28:18,632 --> 0:28:22,569
Xcode会自动编译它们

495
00:28:22,836 --> 0:28:26,073
我所要做的就是构建并运行它

496
00:28:31,378 --> 0:28:34,314
让我们隐藏这个

497
00:28:34,915 --> 0:28:38,886
这是我的新app

498
00:28:39,119 --> 0:28:42,289
全部按主题自动分类

499
00:28:45,859 --> 0:28:50,464
如果我进去看看其中一篇文章

500
00:28:50,697 --> 0:28:54,067
你会注意到名称在其中突出显示

501
00:28:54,134 --> 0:28:56,937
你可以看到

502
00:28:57,004 --> 0:28:59,940
我们突出显示了人名、地名和组织名

503
00:29:00,274 --> 0:29:01,642
但进一步来看

504
00:29:02,409 --> 0:29:06,180
你可以看到它使用了

505
00:29:06,580 --> 0:29:11,818
突显了iPad、MacBook

506
00:29:13,520 --> 0:29:18,625
这显示了训练你自己的自定义模型

507
00:29:18,692 --> 0:29:22,563
并将它们与Natural Language API

508
00:29:30,904 --> 0:29:34,341
现在我要把话筒交给Vivek

509
00:29:34,408 --> 0:29:37,811
来谈论训练模型的一些重要考虑因素

510
00:29:44,017 --> 0:29:46,887
感谢Doug向我们展示如何使用

511
00:29:46,954 --> 0:29:50,224
我们非常高兴能将Natural Language

512
00:29:50,290 --> 0:29:53,293
以及Core ML栈紧密整合

513
00:29:53,861 --> 0:29:57,631
我们希望你能用这个新API

514
00:29:58,765 --> 0:30:02,169
现在我想再次转移话题并谈论性能

515
00:29:58,765 --> 0:30:02,169
现在我想再次转移话题并谈论性能

516
00:30:03,103 --> 0:30:07,508
正如我之前提到的 Natural Language

517
00:30:08,108 --> 0:30:12,379
它也能为你提供我们称之为

518
00:30:13,146 --> 0:30:15,682
所以让我们再花点时间

519
00:30:16,383 --> 0:30:19,319
若你看看不使用Create ML

520
00:30:19,386 --> 0:30:22,222
你会从哪里开始呢？

521
00:30:22,289 --> 0:30:24,458
你会从一些训练数据开始

522
00:30:25,292 --> 0:30:27,694
你会获取训练数据

523
00:30:27,761 --> 0:30:29,263
还可能会提取一些特征

524
00:30:29,630 --> 0:30:32,799
这对中文和日文等语言非常重要

525
00:30:32,866 --> 0:30:34,434
它们的分词效果对训练结果至关重要

526
00:30:35,369 --> 0:30:37,704
你会把这些东西丢到

527
00:30:38,472 --> 0:30:41,141
然后你会得到一个机器学习模型

528
00:30:41,975 --> 0:30:43,577
现在 为了在Apple设备上

529
00:30:43,644 --> 0:30:44,945
使用该机器学习模型

530
00:30:45,012 --> 0:30:47,147
你必须将其转换为

531
00:30:47,981 --> 0:30:50,817
你会怎么做？你会使用

532
00:30:51,585 --> 0:30:56,523
这是从数据到模型

533
00:30:56,590 --> 0:30:58,225
整个训练过程

534
00:30:59,893 --> 0:31:00,727
现在

535
00:30:59,893 --> 0:31:00,727
现在

536
00:31:01,261 --> 0:31:04,998
在推理阶段

537
00:31:05,399 --> 0:31:06,466
但这不是全部

538
00:31:07,234 --> 0:31:08,569
你也必须确保

539
00:31:09,169 --> 0:31:13,207
你编写的用于分词和特征提取的代码

540
00:31:13,273 --> 0:31:14,741
与训练时所用代码效果一致

541
00:31:16,543 --> 0:31:18,879
这需要付出很大的努力

542
00:31:18,946 --> 0:31:20,681
最大限度地提高模型的保真度

543
00:31:20,814 --> 0:31:24,785
确保在训练和推理阶段都使用

544
00:31:24,852 --> 0:31:27,154
相同的分词和特征提取方法非常重要

545
00:31:27,888 --> 0:31:31,291
但现有了Natural Language

546
00:31:31,792 --> 0:31:35,929
如果你看一下训练的流程

547
00:31:37,231 --> 0:31:40,334
你可通过我们讨论过的API

548
00:31:41,134 --> 0:31:43,971
Create ML在底层调用

549
00:31:44,037 --> 0:31:47,708
后者进行分词 特征提取

550
00:31:47,774 --> 0:31:52,045
完成所有这些工作

551
00:31:53,080 --> 0:31:56,850
在推理阶段 你做的事仍然是

552
00:31:58,151 --> 0:32:00,721
但你不必关心分词 特征提取

553
00:31:58,151 --> 0:32:00,721
但你不必关心分词 特征提取

554
00:32:00,787 --> 0:32:04,024
或其他任何东西

555
00:32:04,091 --> 0:32:07,060
因为Natural Language

556
00:32:07,361 --> 0:32:11,298
你只需专注于你的app和任务

557
00:32:13,834 --> 0:32:17,304
正如我之前提到的

558
00:32:17,371 --> 0:32:19,540
它针对Apple硬件

559
00:32:20,007 --> 0:32:22,676
我们来看几个例子

560
00:32:23,810 --> 0:32:26,547
Doug谈到了命名实体识别和分块

561
00:32:27,114 --> 0:32:28,615
这里有两个不同的基准

562
00:32:28,682 --> 0:32:32,920
这些分别是我们使用

563
00:32:32,986 --> 0:32:35,389
和Natural Language建立的模型

564
00:32:35,689 --> 0:32:38,559
模型由相同的训练数据训练而成

565
00:32:38,625 --> 0:32:40,394
并在相同的测试数据上进行测试

566
00:32:40,827 --> 0:32:42,429
它们实现了相同的功能

567
00:32:42,496 --> 0:32:45,132
这两个模型所获得的准确度是相同的

568
00:32:45,732 --> 0:32:49,002
但是你看看Natural Language

569
00:32:49,403 --> 0:32:53,307
它的命名实体识别模型

570
00:32:53,373 --> 0:32:56,143
分块只用了1.8兆字节

571
00:32:56,543 --> 0:33:00,113
这为你的app节省了大量的空间

572
00:32:56,543 --> 0:33:00,113
这为你的app节省了大量的空间

573
00:33:02,950 --> 0:33:04,885
就机器学习算法而言

574
00:33:05,752 --> 0:33:07,521
我们支持两种不同的选项

575
00:33:08,455 --> 0:33:10,090
我们可为文本分类指定这些选项

576
00:33:10,157 --> 0:33:12,559
对于文本分类

577
00:33:12,960 --> 0:33:16,063
一个是maxEnt

578
00:33:16,563 --> 0:33:20,701
在NLP中 我们认为maxEnt本质上

579
00:33:20,934 --> 0:33:23,036
我们在NLP领域中直接将其称为

580
00:33:23,871 --> 0:33:25,305
另一个是CRF

581
00:33:25,372 --> 0:33:27,674
这是Conditional Random Field的缩写

582
00:33:28,642 --> 0:33:31,512
这两种算法的选择实际上

583
00:33:31,912 --> 0:33:35,382
因此我们鼓励你尝试

584
00:33:37,184 --> 0:33:38,585
就单词标记而言

585
00:33:38,919 --> 0:33:41,688
Conditional Random Field是默认选项

586
00:33:41,955 --> 0:33:44,224
当你实例化一个MLWordTagger

587
00:33:44,291 --> 0:33:49,162
你将使用的默认模型就是

588
00:33:50,531 --> 0:33:52,399
正如我所提到的

589
00:33:52,466 --> 0:33:53,734
实际上取决于你的任务

590
00:33:54,168 --> 0:33:55,536
但我想强调一下

591
00:33:55,602 --> 0:34:00,073
这与你的传统开发过程有点类似

592
00:33:55,602 --> 0:34:00,073
这与你的传统开发过程有点类似

593
00:34:00,307 --> 0:34:04,111
当你有一个app的新想法时

594
00:34:04,278 --> 0:34:08,114
你可以把机器学习看成是一种

595
00:34:08,982 --> 0:34:10,751
你从哪里开始呢 从数据开始

596
00:34:11,752 --> 0:34:14,888
当你有数据之后

597
00:34:15,621 --> 0:34:18,725
你必须验证你的训练数据

598
00:34:18,792 --> 0:34:21,460
你的数据中没有虚假示例

599
00:34:22,329 --> 0:34:23,330
一旦你这样做

600
00:34:23,397 --> 0:34:26,500
你可以检视每个类的训练实例的数量

601
00:34:26,567 --> 0:34:29,369
假设你在训练一个情感分类模型

602
00:34:29,436 --> 0:34:31,471
你有一千个积极情绪的例子

603
00:34:31,538 --> 0:34:33,373
却只有五个负面情绪的例子

604
00:34:33,873 --> 0:34:36,510
你无法训练出健壮的模型

605
00:34:36,577 --> 0:34:39,246
来确定或区分这两个类

606
00:34:39,513 --> 0:34:41,648
你必须确保训练样本的数量

607
00:34:41,715 --> 0:34:43,851
对于每个类都是平衡的

608
00:34:44,918 --> 0:34:48,188
一旦你准备好了数据

609
00:34:48,789 --> 0:34:49,922
如前所述

610
00:34:49,989 --> 0:34:53,159
我们的建议是你运行可选的不同选项

611
00:34:53,694 --> 0:34:54,962
并弄清楚哪些是好的

612
00:34:55,462 --> 0:34:57,297
但你如何定义什么是好的呢？

613
00:34:57,664 --> 0:35:01,835
你必须对模型进行评估才能找出

614
00:34:57,664 --> 0:35:01,835
你必须对模型进行评估才能找出

615
00:35:02,169 --> 0:35:05,305
因此工作流程中的下一步就是评估

616
00:35:07,207 --> 0:35:10,477
机器学习的传统评估方法是这样

617
00:35:10,544 --> 0:35:14,548
当你获得训练数据时

618
00:35:14,915 --> 0:35:17,317
一个验证集和一个测试集

619
00:35:17,751 --> 0:35:19,987
你通常会使用验证集调整算法的参数

620
00:35:20,053 --> 0:35:22,723
然后在测试集上对其进行测试

621
00:35:23,090 --> 0:35:26,093
我们鼓励你做同样的事情 即app

622
00:35:26,159 --> 0:35:29,096
这种长期以来一直被使用的

623
00:35:29,997 --> 0:35:33,867
我们鼓励你做的另一件事是

624
00:35:34,134 --> 0:35:35,102
这是什么意思

625
00:35:35,502 --> 0:35:38,939
当你有一个app想法时

626
00:35:39,006 --> 0:35:41,608
将被你的机器学习模型摄入

627
00:35:42,276 --> 0:35:45,612
现在假设你正在构建一个

628
00:35:45,679 --> 0:35:50,517
你想将酒店评论分为不同的等级

629
00:35:51,485 --> 0:35:54,888
这时用户抛出一个

630
00:35:54,955 --> 0:35:57,624
也许这是一条餐厅评论

631
00:35:57,691 --> 0:36:00,727
或电影评论

632
00:35:57,691 --> 0:36:00,727
或电影评论

633
00:36:01,595 --> 0:36:03,430
这是一个你应该问自己的问题

634
00:36:04,097 --> 0:36:07,868
最后一步 在传统的开发流程中

635
00:36:07,935 --> 0:36:11,705
你会编写补丁程序 修复错误

636
00:36:12,439 --> 0:36:13,907
在机器学习中如何做到这点？

637
00:36:16,043 --> 0:36:20,147
解决机器学习问题的方法就是找出

638
00:36:20,214 --> 0:36:22,382
你的模型何时表现不佳

639
00:36:22,449 --> 0:36:24,718
然后你必须用正确的数据来完善它

640
00:36:25,219 --> 0:36:29,656
通过添加数据并重新训练你的模型

641
00:36:29,823 --> 0:36:33,493
所以 正如我所提到的

642
00:36:33,560 --> 0:36:35,495
它们几乎是平行的

643
00:36:35,562 --> 0:36:39,700
所以如果你正在app中

644
00:36:39,766 --> 0:36:40,734
基础结构的一部分

645
00:36:40,801 --> 0:36:43,570
你可以将其融入开发流程本身之中

646
00:36:45,973 --> 0:36:48,842
我想在这里强调的最后一件事是隐私

647
00:36:49,543 --> 0:36:51,345
你在本次演讲中看到的所有内容

648
00:36:52,246 --> 0:36:55,182
所有的机器学习和自然语言处理

649
00:36:55,382 --> 0:36:57,284
都完全发生在设备上

650
00:36:57,918 --> 0:37:00,220
我们Apple非常注重隐私

651
00:36:57,918 --> 0:37:00,220
我们Apple非常注重隐私

652
00:37:00,287 --> 0:37:02,689
而完全在设备上使用机器学习技术

653
00:37:02,756 --> 0:37:06,026
可以很好的保护用户的隐私

654
00:37:06,693 --> 0:37:07,594
因此

655
00:37:08,595 --> 0:37:10,330
Natural Language

656
00:37:10,397 --> 0:37:12,399
隐私保护型机器学习的另一步

657
00:37:12,466 --> 0:37:14,301
但这次我们将其app于NLP领域

658
00:37:16,203 --> 0:37:17,104
总而言之

659
00:37:18,539 --> 0:37:21,742
我们谈到了一个名为

660
00:37:22,376 --> 0:37:25,012
它与Apple机器学习技术栈

661
00:37:25,579 --> 0:37:29,950
你现可使用Create ML来训练模型

662
00:37:30,017 --> 0:37:32,920
或Natural Language

663
00:37:34,421 --> 0:37:37,291
我们使用Natural Language

664
00:37:37,357 --> 0:37:40,227
具有优秀的性能 并在所有平台上

665
00:37:40,294 --> 0:37:41,628
针对Apple硬件进行了优化

666
00:37:42,229 --> 0:37:46,867
最后 它支持隐私保护

667
00:37:46,934 --> 0:37:48,402
都发生在用户的设备上

668
00:37:51,071 --> 0:37:54,474
屏幕上有更多信息 明天还有一个

669
00:37:54,541 --> 0:37:58,378
我们鼓励你尝试这些API并与我们交流

670
00:37:58,445 --> 0:38:01,682
你想要哪些改进的建议

671
00:37:58,445 --> 0:38:01,682
你想要哪些改进的建议

672
00:38:01,748 --> 0:38:02,816
的一些问题

673
00:38:03,750 --> 0:38:05,519
我们也有一个机器学习聚会

674
00:38:05,586 --> 0:38:09,690
并且随后还有一个

675
00:38:09,990 --> 0:38:13,126
因此你可以来实验室继续与我们交谈

676
00:38:13,594 --> 0:38:16,296
感谢你的关注
