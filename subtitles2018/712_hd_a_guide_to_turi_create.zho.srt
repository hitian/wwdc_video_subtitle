1
00:00:06,516 --> 0:00:15,500
[ 音乐 ]

2
00:00:21,836 --> 0:00:23,076
&gt;&gt; [ 掌声 ] 嘿 大家好

3
00:00:25,266 --> 0:00:25,736
[ 掌声 ] 谢谢

4
00:00:25,736 --> 0:00:27,126
下午好 欢迎来到

5
00:00:27,126 --> 0:00:28,726
我们的 Turi Create 会议

6
00:00:30,286 --> 0:00:31,676
本会议将基于

7
00:00:31,676 --> 0:00:33,586
昨天的 Create ML 会议

8
00:00:34,076 --> 0:00:35,316
昨天的会议涵盖了很多

9
00:00:35,316 --> 0:00:37,336
Swift 中机器学习的基础

10
00:00:37,336 --> 0:00:38,596
所以如果你昨天没有出席

11
00:00:38,596 --> 0:00:40,006
我建议你把它

12
00:00:40,006 --> 0:00:40,916
添加到观看列表中

13
00:00:42,486 --> 0:00:44,396
Turi Create 的目标是

14
00:00:44,396 --> 0:00:46,236
帮助你为你的 App 

15
00:00:46,236 --> 0:00:48,866
添加智能用户体验

16
00:00:49,516 --> 0:00:52,606
例如 你可能想要拍摄一张

17
00:00:52,606 --> 0:00:53,266
早餐的照片后

18
00:00:53,526 --> 0:00:54,916
点击不同的食物项目

19
00:00:54,916 --> 0:00:56,726
看看你摄入了

20
00:00:56,726 --> 0:00:57,386
多少卡路里

21
00:00:59,076 --> 0:01:01,136
或者 也许你想

22
00:00:59,076 --> 0:01:01,136
或者 也许你想

23
00:01:01,136 --> 0:01:03,496
使用你的 iPhone 和

24
00:01:03,496 --> 0:01:04,486
简单的手势来进行控制灯泡

25
00:01:07,356 --> 0:01:08,736
也许你想实时跟踪

26
00:01:08,736 --> 0:01:11,096
一个物体 比如一条狗

27
00:01:11,156 --> 0:01:12,866
或者狗的图片

28
00:01:12,866 --> 0:01:13,976
因为办公室里没有狗

29
00:01:14,516 --> 0:01:17,266
[ 笑声 ]

30
00:01:17,766 --> 0:01:20,116
也许你的游戏中

31
00:01:20,116 --> 0:01:21,566
有自定义的头像

32
00:01:21,696 --> 0:01:22,516
而你想要提供

33
00:01:22,516 --> 0:01:24,136
个性化的建议

34
00:01:24,496 --> 0:01:26,186
比如基于用户已选胡须

35
00:01:26,186 --> 0:01:26,826
推荐发型

36
00:01:28,216 --> 0:01:29,676
或者 也许你想让你的用户

37
00:01:29,676 --> 0:01:31,846
在自己的照片中

38
00:01:31,846 --> 0:01:33,756
应用艺术风格或滤镜

39
00:01:35,096 --> 0:01:37,806
这些是非常不同的用户体验

40
00:01:38,256 --> 0:01:40,136
但它们有几点是相同的

41
00:01:41,046 --> 0:01:43,536
首先 它们使用了机器学习

42
00:01:44,846 --> 0:01:46,556
创建这些体验

43
00:01:46,556 --> 0:01:49,906
只需要很少的数据

44
00:01:50,036 --> 0:01:51,516
所有这些模型都是用

45
00:01:51,516 --> 0:01:53,646
Turi Create 制作的 并用 Core ML 

46
00:01:53,646 --> 0:01:54,186
部署的

47
00:01:55,656 --> 0:01:57,176
它们都是按照五步创建的 

48
00:01:57,176 --> 0:01:59,096
我们今天会介绍

49
00:01:59,096 --> 0:02:00,226
这五个步骤

50
00:01:59,096 --> 0:02:00,226
这五个步骤

51
00:02:01,776 --> 0:02:02,906
所有这些演示 App

52
00:02:02,906 --> 0:02:04,366
都可以在我们的实验室中使用

53
00:02:04,366 --> 0:02:06,056
所以请大家今天或星期五

54
00:02:06,056 --> 0:02:08,326
前往 ML 实验室

55
00:02:08,326 --> 0:02:09,376
亲身体验这些 App

56
00:02:11,696 --> 0:02:14,026
Turi Create 是一个 Python 包

57
00:02:14,436 --> 0:02:16,186
帮助你创建 Core ML 模型

58
00:02:17,436 --> 0:02:19,446
它使用方便

59
00:02:19,446 --> 0:02:20,816
你不用成为 ML 专家

60
00:02:20,816 --> 0:02:22,066
甚至无需机器学习背景

61
00:02:22,066 --> 0:02:23,326
就可以创造这些

62
00:02:23,326 --> 0:02:24,676
激动人心的用户体验

63
00:02:25,626 --> 0:02:27,366
它使用方便 是因为

64
00:02:27,366 --> 0:02:29,646
它把关注任务

65
00:02:29,646 --> 0:02:30,206
放在了首位

66
00:02:30,206 --> 0:02:32,906
我们把复杂的机器学习算法

67
00:02:32,906 --> 0:02:34,776
抽象化了

68
00:02:34,776 --> 0:02:36,746
所以你可以专心于 想要创建的用户体验

69
00:02:38,056 --> 0:02:39,796
Turi Create 是跨平台的

70
00:02:39,796 --> 0:02:42,226
在 Mac 和 Linux 上都可以使用

71
00:02:43,066 --> 0:02:44,436
它也是开源的

72
00:02:45,726 --> 0:02:47,446
我们在 GitHub 上有一个代码仓库

73
00:02:47,446 --> 0:02:48,056
希望你们可以访问

74
00:02:48,056 --> 0:02:49,406
那里有很多很棒的资源

75
00:02:49,406 --> 0:02:50,186
可以帮助你们入门

76
00:02:51,456 --> 0:02:52,786
我们期待着与你

77
00:02:52,786 --> 0:02:54,156
和开发者社区的其他人

78
00:02:54,156 --> 0:02:55,716
一起努力

79
00:02:55,716 --> 0:02:57,856
让 Turi Create 变得越来越好

80
00:02:58,676 --> 0:03:00,276
今天我们很高兴地宣布

81
00:02:58,676 --> 0:03:00,276
今天我们很高兴地宣布

82
00:03:00,276 --> 0:03:01,886
Turi Create 5.0 Beta 版本

83
00:03:01,886 --> 0:03:04,216
现已可用

84
00:03:04,986 --> 0:03:06,576
它有一些强大的新功能

85
00:03:06,896 --> 0:03:08,336
比如 GPU 加速等

86
00:03:08,556 --> 0:03:09,846
我们将在今天晚些时候

87
00:03:09,846 --> 0:03:11,396
详细研究这些功能

88
00:03:12,776 --> 0:03:14,756
今天的重点主要是

89
00:03:14,756 --> 0:03:17,086
通过五个步骤

90
00:03:17,086 --> 0:03:18,366
创建 Core ML 模型

91
00:03:18,746 --> 0:03:20,306
我先要从高层次

92
00:03:20,306 --> 0:03:21,676
讨论这些步骤

93
00:03:22,086 --> 0:03:23,196
然后我们会深入讨论

94
00:03:23,196 --> 0:03:24,486
演示和代码

95
00:03:25,026 --> 0:03:28,746
所以你需要的第一步是

96
00:03:28,746 --> 0:03:31,126
理解你想要完成的任务

97
00:03:31,566 --> 0:03:33,276
以及我们如何使用

98
00:03:33,276 --> 0:03:34,316
机器学习的术语描述该任务

99
00:03:35,686 --> 0:03:37,536
其次 你需要明白

100
00:03:37,866 --> 0:03:39,656
完成这个任务

101
00:03:39,656 --> 0:03:40,616
所需的数据类型

102
00:03:41,026 --> 0:03:42,526
还有需要多少数据

103
00:03:43,696 --> 0:03:46,156
第三 你需要创建模型

104
00:03:48,056 --> 0:03:50,626
第四 你需要评估创建的模型

105
00:03:50,766 --> 0:03:52,066
这意味着了解

106
00:03:52,066 --> 0:03:53,536
模型的质量

107
00:03:53,536 --> 0:03:54,926
以及它是否可以投入生产环境

108
00:03:56,106 --> 0:03:57,946
最后 当你的模型

109
00:03:57,946 --> 0:03:59,566
可以进行部署时

110
00:03:59,566 --> 0:04:00,856
你可以轻松地使用 Core ML

111
00:03:59,566 --> 0:04:00,856
你可以轻松地使用 Core ML

112
00:04:02,356 --> 0:04:04,786
让我们深入每一个步骤

113
00:04:06,076 --> 0:04:07,656
Turi Create 可以让你完成

114
00:04:07,656 --> 0:04:10,566
各种各样常见的机器学习任务

115
00:04:10,836 --> 0:04:11,976
你也可以处理很多

116
00:04:11,976 --> 0:04:13,306
不同类型的数据

117
00:04:13,926 --> 0:04:16,296
例如 如果你有图像数据 

118
00:04:16,616 --> 0:04:18,646
你可能会对图像分类

119
00:04:18,805 --> 0:04:19,815
或对象检测感兴趣

120
00:04:20,856 --> 0:04:23,796
121
00:04:24,976 --> 0:04:25,876


122
00:04:25,876 --> 0:04:27,756
自动检测活动

123
00:04:27,756 --> 0:04:30,226
比如步行或伸展跳跃

124
00:04:30,416 --> 0:04:33,056
你可能想要了解

125
00:04:33,056 --> 0:04:35,426
用户针对给定文本的情绪反应

126
00:04:36,256 --> 0:04:37,606
或者你可能对

127
00:04:37,606 --> 0:04:39,006
更传统的机器学习算法

128
00:04:39,006 --> 0:04:40,306
感兴趣

129
00:04:40,306 --> 0:04:42,316
比如分类和回归

130
00:04:44,636 --> 0:04:46,316
我知道现在

131
00:04:46,316 --> 0:04:47,806
那些机器学习的新手

132
00:04:47,806 --> 0:04:49,236
可能会很迷惑

133
00:04:49,696 --> 0:04:51,906
所以我们尝试

134
00:04:51,906 --> 0:04:53,866
在文档中为你们简化这部分内容

135
00:04:54,266 --> 0:04:56,986
我们从帮助你了解可能的

136
00:04:57,286 --> 0:04:59,156
任务类型开始

137
00:04:59,156 --> 0:05:00,436
然后是如何使用机器学习术语

138
00:04:59,156 --> 0:05:00,436
然后是如何使用机器学习术语

139
00:05:00,436 --> 0:05:01,176
描述它们

140
00:05:01,716 --> 0:05:03,196
所以我们现在要做的是

141
00:05:03,196 --> 0:05:04,596
重新审视那些

142
00:05:04,596 --> 0:05:05,326
本次演讲开始时

143
00:05:05,326 --> 0:05:06,606
提到的智能体验

144
00:05:06,956 --> 0:05:08,176
并将它们对应到

145
00:05:08,176 --> 0:05:09,026
各个机器学习任务

146
00:05:09,626 --> 0:05:10,856
例如 如果你想

147
00:05:10,856 --> 0:05:12,616
识别照片中

148
00:05:12,616 --> 0:05:14,676
不同类型的花朵

149
00:05:14,676 --> 0:05:15,826
这称为图像分类

150
00:05:17,236 --> 0:05:19,136
如果你想拍下

151
00:05:19,406 --> 0:05:20,766
你的早餐

152
00:05:20,766 --> 0:05:22,096
并查看不同的食物对象

153
00:05:22,096 --> 0:05:24,876
这称为对象检测

154
00:05:25,436 --> 0:05:27,986
如果你想将艺术风格

155
00:05:27,986 --> 0:05:30,246
应用到自己的照片中

156
00:05:30,246 --> 0:05:31,546
我们称之为风格转移

157
00:05:33,606 --> 0:05:35,256
如果你想使用

158
00:05:35,356 --> 0:05:37,046
不同的设备的传感器

159
00:05:37,046 --> 0:05:38,816
识别手势 动作或不同活动

160
00:05:38,816 --> 0:05:41,896
我们称之为活动分类

161
00:05:43,996 --> 0:05:45,616
最后 如果你想向用户

162
00:05:45,656 --> 0:05:46,906
提供个性化的建议

163
00:05:46,906 --> 0:05:48,886
我们称这个任务为

164
00:05:49,106 --> 0:05:50,086
推荐系统

165
00:05:50,766 --> 0:05:53,936
现在很棒的一点是

166
00:05:53,936 --> 0:05:55,756
我们刚刚提到过的

167
00:05:55,756 --> 0:05:57,596
五个步骤方法 也适用于

168
00:05:57,596 --> 0:05:58,106
代码编写

169
00:05:59,156 --> 0:06:01,236
我们从导入 Turi Create 开始

170
00:05:59,156 --> 0:06:01,236
我们从导入 Turi Create 开始

171
00:06:02,526 --> 0:06:04,796
然后把我们的数据加载到

172
00:06:04,796 --> 0:06:06,466
SFrame 数据结构中

173
00:06:06,816 --> 0:06:07,796
我们稍后会进一步

174
00:06:07,796 --> 0:06:09,156
详细讨论 SFrame

175
00:06:09,156 --> 0:06:10,006
数据结构

176
00:06:10,486 --> 0:06:13,106
然后使用一个简单的函数 

177
00:06:13,106 --> 0:06:14,736
.create

178
00:06:14,816 --> 0:06:15,446
创建我们的模型

179
00:06:15,966 --> 0:06:18,116
这个函数把

180
00:06:18,116 --> 0:06:19,336
复杂的机器学习

181
00:06:19,336 --> 0:06:22,066
藏在了幕后

182
00:06:22,956 --> 0:06:24,966
之后我们使用

183
00:06:24,966 --> 0:06:26,916
简单的函数 .evaluate 评估我们的模型

184
00:06:27,476 --> 0:06:30,266
最后我们把最终模型

185
00:06:30,266 --> 0:06:32,586
导出为 Core ML 的

186
00:06:32,626 --> 0:06:34,396
mlmodel 格式

187
00:06:34,396 --> 0:06:36,686
可以被拖拽到 Xcode 中

188
00:06:37,356 --> 0:06:39,226
现在我想提的是

189
00:06:39,226 --> 0:06:41,166
这样的五步模板

190
00:06:41,166 --> 0:06:42,866
适用于 Turi Create 中

191
00:06:42,866 --> 0:06:43,506
所有不同的任务

192
00:06:44,296 --> 0:06:45,146
所以无论你在做的是

193
00:06:45,146 --> 0:06:47,186
对象检测 图像分类

194
00:06:47,186 --> 0:06:49,716
或活动分类

195
00:06:49,716 --> 0:06:51,896
代码模板

196
00:06:51,896 --> 0:06:52,806
是通用的

197
00:06:52,806 --> 0:06:56,826
我们今天的第一个演示

198
00:06:57,066 --> 0:06:59,846
是一个卡路里计算 App

199
00:06:59,846 --> 0:07:01,196
它使用了对象检测模型

200
00:06:59,846 --> 0:07:01,196
它使用了对象检测模型

201
00:07:01,746 --> 0:07:02,866
我们想要识别

202
00:07:03,186 --> 0:07:04,486
图像中的不同食物

203
00:07:04,726 --> 0:07:05,636
我们需要知道它们在哪里

204
00:07:05,636 --> 0:07:07,046
在图像的哪个位置

205
00:07:07,046 --> 0:07:08,396
然后才能轻点它们

206
00:07:08,396 --> 0:07:10,000
查看不同的卡路里数值

207
00:07:13,196 --> 0:07:14,636
所以让我们来看看

208
00:07:14,636 --> 0:07:16,036
创建这个机器学习模型

209
00:07:16,036 --> 0:07:17,846
210
00:07:18,436 --> 0:07:20,906


211
00:07:20,906 --> 0:07:21,866
如果我们只是建立一个

212
00:07:21,866 --> 0:07:24,006
简单的图像分类器模型 

213
00:07:24,306 --> 0:07:25,286
那我们只需要一套图像

214
00:07:25,286 --> 0:07:28,356
和描述图像的标签

215
00:07:29,366 --> 0:07:30,506
但是因为我们要进行

216
00:07:30,746 --> 0:07:32,506
对象检测

217
00:07:32,506 --> 0:07:33,316
我们需要更多信息

218
00:07:33,956 --> 0:07:35,416
我们不仅需要了解

219
00:07:35,416 --> 0:07:36,226
图像中有什么

220
00:07:36,496 --> 0:07:37,766
还有那些物体在哪里

221
00:07:38,146 --> 0:07:40,126
现在 如果我们仔细看一个例子

222
00:07:40,126 --> 0:07:42,596
可以看到红色框圈出了

223
00:07:42,646 --> 0:07:43,756
一杯咖啡

224
00:07:44,616 --> 0:07:46,376
绿色框圈出了羊角面包

225
00:07:47,336 --> 0:07:48,916
我们称这些方框为边界框

226
00:07:48,916 --> 0:07:50,996
并用 JSON 格式

227
00:07:50,996 --> 0:07:51,936
写出来

228
00:07:52,296 --> 0:07:53,806
设置一个标签

229
00:07:53,806 --> 0:07:56,086
然后写出 x y 坐标 宽度和高度

230
00:07:56,656 --> 0:07:58,186
其中 x 和 y 坐标指的是

231
00:07:58,186 --> 0:07:59,926
该边界框的中心

232
00:08:00,216 --> 0:08:01,426
还有一点值得注意

233
00:08:01,426 --> 0:08:03,066
通过对象检测

234
00:08:03,066 --> 0:08:05,196
你可以找到或检测

235
00:08:05,196 --> 0:08:07,996
多张图像中 每个图像里的多个对象

236
00:08:07,996 --> 0:08:11,086
所以我提到我们会

237
00:08:11,086 --> 0:08:12,816
将数据加载到

238
00:08:12,816 --> 0:08:14,686
这种表格数据结构中 称为 SFrame

239
00:08:15,406 --> 0:08:16,716
在这个例子中

240
00:08:16,716 --> 0:08:17,926
我们的表格最终包含两列

241
00:08:18,136 --> 0:08:19,836
第一列是你的图像

242
00:08:20,466 --> 0:08:22,086
第二列是

243
00:08:22,086 --> 0:08:24,000
以 JSON 格式写出的注释

244
00:08:27,476 --> 0:08:29,306
现在你可能会好奇

245
00:08:29,306 --> 0:08:30,886
什么是 SFrame

246
00:08:30,886 --> 0:08:32,506
所以让我们退一步 

247
00:08:32,506 --> 0:08:34,706
一起了解它

248
00:08:34,706 --> 0:08:36,596
SFrame 是一种基于磁盘的

249
00:08:36,596 --> 0:08:37,376
表格数据结构

250
00:08:37,566 --> 0:08:39,006
而这意味着你可以

251
00:08:39,395 --> 0:08:40,976
在笔记本上

252
00:08:40,976 --> 0:08:41,806
创建机器学习模型

253
00:08:41,966 --> 0:08:43,015
即使你有巨大的

254
00:08:43,015 --> 0:08:45,226
数据量

255
00:08:45,366 --> 0:08:46,656
SFrame 允许你执行

256
00:08:46,656 --> 0:08:48,676
常规的数据操作任务

257
00:08:49,026 --> 0:08:50,816
像连接两个 SFrame 或

258
00:08:50,816 --> 0:08:53,476
过滤到特定的数据行或数据列

259
00:08:55,296 --> 0:08:57,976
SFrames 可让你整合不同的数据类型

260
00:08:58,926 --> 0:08:59,986
一旦你将数据

261
00:09:00,046 --> 0:09:02,486
加载到一个 SFrame 中

262
00:09:02,486 --> 0:09:04,446
就很容易可视化探索和检查

263
00:09:04,446 --> 0:09:05,000
你的数据

264
00:09:08,936 --> 0:09:10,426
让我们再进一步 了解

265
00:09:10,426 --> 0:09:11,796
SFrame 提供了哪些可能

266
00:09:12,796 --> 0:09:13,946
用我们的物体探测器

267
00:09:13,946 --> 0:09:14,396
作为例子

268
00:09:15,446 --> 0:09:17,026
在我们导入 Turi Create 之后 

269
00:09:17,426 --> 0:09:18,436
针对我们的对象探测器

270
00:09:18,436 --> 0:09:20,206
我们需要

271
00:09:20,276 --> 0:09:21,606
加载两个不同的 SFrame

272
00:09:22,086 --> 0:09:23,406
第一个包含我们的注释

273
00:09:23,406 --> 0:09:27,166
第二个包含我们的图像

274
00:09:27,896 --> 0:09:29,556
有一个简单的函数

275
00:09:29,556 --> 0:09:31,526
.explore 可以让你

276
00:09:31,526 --> 0:09:33,276
可视化检查你导入的数据

277
00:09:34,276 --> 0:09:36,896
我们可以做到访问特定的行

278
00:09:37,386 --> 0:09:38,496
或访问特定的数据列

279
00:09:39,866 --> 0:09:40,976
当然我们可以完成常规操作

280
00:09:40,976 --> 0:09:43,266
比如把两个 SFrame

281
00:09:43,266 --> 0:09:44,286
连接成一个

282
00:09:44,826 --> 0:09:46,546
并保存所产生的 SFrame

283
00:09:46,986 --> 0:09:51,356
供以后使用或与同事分享

284
00:09:51,486 --> 0:09:52,746
下一步是创建我们的模型

285
00:09:53,146 --> 0:09:54,306
我刚刚提到

286
00:09:54,396 --> 0:09:56,746
有一个简单的函数 .create 

287
00:09:56,746 --> 0:09:58,126
创造实际模型的

288
00:09:58,126 --> 0:09:59,576
所有重任

289
00:10:00,016 --> 0:10:01,486
我们在幕后做的

290
00:10:01,486 --> 0:10:03,026
就是创建的模型

291
00:10:03,026 --> 0:10:04,546
是为你的任务

292
00:10:04,546 --> 0:10:06,496
量身定制的 像是艺术品

293
00:10:06,496 --> 0:10:07,916
这意味着我们尽力

294
00:10:07,956 --> 0:10:10,016
保证它的高质量 高准确度

295
00:10:10,016 --> 0:10:12,256
无论你的数据规模是大还是小

296
00:10:12,256 --> 0:10:14,206
我们都可以做到

297
00:10:14,516 --> 0:10:16,336
对我们而言重要的是

298
00:10:16,386 --> 0:10:17,926
所有的任务都可以正常工作

299
00:10:17,926 --> 0:10:19,846
就算每个

300
00:10:19,846 --> 0:10:22,116
你想要检测的

301
00:10:22,176 --> 0:10:23,266
对象类中的项目

302
00:10:23,266 --> 0:10:24,676
只有 40 张图像

303
00:10:25,106 --> 0:10:26,276
在对象检测的例子中

304
00:10:26,826 --> 0:10:30,866
让我们进行下一步 评估

305
00:10:31,236 --> 0:10:32,446
我提到有一个简单的

306
00:10:32,446 --> 0:10:34,936
函数 .evaluate

307
00:10:34,936 --> 0:10:36,566
它会告诉你模型的

308
00:10:36,566 --> 0:10:37,106
质量如何

309
00:10:38,216 --> 0:10:40,006
在这个例子中

310
00:10:40,416 --> 0:10:42,086
我们有两个考虑因素

311
00:10:42,406 --> 0:10:43,846
首先 我们想知道

312
00:10:43,846 --> 0:10:44,766
标签匹配正确吗

313
00:10:45,386 --> 0:10:46,966
但我们也必须知道

314
00:10:46,966 --> 0:10:48,306
框住对象的边界框

315
00:10:48,666 --> 0:10:49,476
是否正确

316
00:10:50,616 --> 0:10:51,876
所以我们可以建立

317
00:10:51,876 --> 0:10:53,846
对这两个因素的衡量标准

318
00:10:53,846 --> 0:10:55,906
并通过测试数据集

319
00:10:55,906 --> 0:10:57,696
对预测进行评分

320
00:10:57,696 --> 0:11:00,616
基于完全正确的已知数据

321
00:10:57,696 --> 0:11:00,616
基于完全正确的已知数据

322
00:11:01,446 --> 0:11:02,726
所以我们希望

323
00:11:02,726 --> 0:11:04,026
标签都是正确的

324
00:11:04,506 --> 0:11:07,046
并且对边界框的

325
00:11:07,046 --> 0:11:08,906
衡量标准是

326
00:11:08,906 --> 0:11:10,616
预测边界框

327
00:11:10,616 --> 0:11:12,756
至少有 50% 与完全正确的边界框重叠

328
00:11:13,206 --> 0:11:14,676
我们来看几个例子

329
00:11:15,236 --> 0:11:18,296
在这个预测中 可以看到

330
00:11:18,296 --> 0:11:19,806
模型得出了正确的标签

331
00:11:20,336 --> 0:11:21,316
是一杯咖啡

332
00:11:21,906 --> 0:11:25,016
但边界框 并未框住整杯咖啡

333
00:11:25,016 --> 0:11:27,286
与完全正确的边界框只有 10% 重合

334
00:11:27,726 --> 0:11:29,256
所以我们会认为

335
00:11:29,666 --> 0:11:31,676
这是一个失败的预测

336
00:11:31,676 --> 0:11:33,136
这是一个非常准确的

337
00:11:33,136 --> 0:11:35,106
边界框

338
00:11:35,106 --> 0:11:35,816
但标签错了

339
00:11:35,896 --> 0:11:36,786
那不是香蕉

340
00:11:37,206 --> 0:11:38,706
所以我们认为这也不是一个

341
00:11:38,706 --> 0:11:39,896
成功的预测

342
00:11:41,006 --> 0:11:42,236
这是我们想要看到的

343
00:11:42,236 --> 0:11:42,866
处于中间的例子

344
00:11:43,336 --> 0:11:44,906
70% 重叠于

345
00:11:44,906 --> 0:11:46,836
绝对正确的边界框

346
00:11:46,836 --> 0:11:47,896
和正确的标签 咖啡

347
00:11:48,796 --> 0:11:49,776
所以我们做的就是

348
00:11:49,776 --> 0:11:51,416
运用测试数据集

349
00:11:51,416 --> 0:11:53,066
系统地分析所有预测

350
00:11:53,656 --> 0:11:55,026
获得新模型准确性的

351
00:11:55,026 --> 0:11:56,806
整体评分

352
00:11:57,356 --> 0:12:01,196
最后一步是部署

353
00:11:57,356 --> 0:12:01,196
最后一步是部署

354
00:12:01,896 --> 0:12:03,146
这是一个导出到 Core ML 的函数

355
00:12:03,146 --> 0:12:04,556
能将你的模型保存为

356
00:12:04,626 --> 0:12:06,386
Core ML 的 mlmodel 格式

357
00:12:06,816 --> 0:12:08,056
然后你可以将该模型

358
00:12:08,056 --> 0:12:09,486
拖拽到 Xcode 中

359
00:12:10,696 --> 0:12:12,046
本周其实我们推出了

360
00:12:12,046 --> 0:12:13,806
激动人心的新功能

361
00:12:13,806 --> 0:12:15,296
与物体检测相关

362
00:12:15,856 --> 0:12:16,876
所以我鼓励你参加

363
00:12:16,876 --> 0:12:18,716
明天的 Vision with Core ML 会议

364
00:12:18,716 --> 0:12:20,506
以了解更多信息

365
00:12:20,876 --> 0:12:21,886
在那个会议上

366
00:12:21,886 --> 0:12:23,076
演讲者会使用今天我们构建的

367
00:12:23,076 --> 0:12:24,036
对象检测模型

368
00:12:24,036 --> 0:12:26,146
并且详细介绍

369
00:12:26,146 --> 0:12:27,706
部署选项

370
00:12:28,316 --> 0:12:30,996
这就是

371
00:12:31,536 --> 0:12:33,826
Turi Create 的五个步骤

372
00:12:35,516 --> 0:12:38,946
[ 掌声 ]

373
00:12:39,446 --> 0:12:40,036
谢谢

374
00:12:40,316 --> 0:12:41,256
现在我要将话筒传给

375
00:12:41,256 --> 0:12:42,896
我的同事 Zach Nation 

376
00:12:42,896 --> 0:12:43,426
他会进行演示

377
00:12:45,516 --> 0:12:50,436
[ 掌声 ]

378
00:12:50,936 --> 0:12:51,536
&gt;&gt; 谢谢 Aaron

379
00:12:52,466 --> 0:12:54,616
我想我们就直接进入代码部分

380
00:12:54,616 --> 0:12:55,616
今天现场

381
00:12:55,616 --> 0:12:56,516
有谁想写代码 

382
00:12:56,946 --> 0:12:58,096
我们将继续

383
00:12:58,096 --> 0:13:00,000
构建一个对象检测器模型

384
00:13:10,046 --> 0:13:11,956
所以我要从访达 开始

385
00:13:12,336 --> 0:13:14,216
这里有一个图像文件夹

386
00:13:14,596 --> 0:13:16,266
我想用它来训练一个模型

387
00:13:17,206 --> 0:13:18,546
我们可以看到这个文件夹叫 Data

388
00:13:18,546 --> 0:13:22,296
里面全是早餐食品的图像

389
00:13:22,786 --> 0:13:25,936
这里有牛角面包 鸡蛋等等

390
00:13:26,516 --> 0:13:29,006
这是一个很好的早餐食物

391
00:13:29,006 --> 0:13:29,736
数据集

392
00:13:29,736 --> 0:13:31,746
那么我们开始写一些代码

393
00:13:33,016 --> 0:13:34,806
我要切换到这个环境

394
00:13:34,806 --> 0:13:36,466
叫做 Jupyter Notebook

395
00:13:37,096 --> 0:13:38,546
它是一个交互式的 Python 环境

396
00:13:38,546 --> 0:13:40,576
你可以在此运行

397
00:13:40,576 --> 0:13:42,026
Python 代码片段

398
00:13:42,026 --> 0:13:43,256
并立即看到输出结果

399
00:13:43,526 --> 0:13:45,126
所以这是一个很好的方法

400
00:13:45,126 --> 0:13:46,526
可以交互使用模型

401
00:13:46,776 --> 0:13:50,066
它的概念与 Xcode Playgrounds 非常相似

402
00:13:51,056 --> 0:13:52,116
我们要做的第一件事是

403
00:13:52,116 --> 0:13:55,996
导入 Turi Create 并称之为 tc

404
00:13:56,396 --> 0:14:00,376
这样在剩下的

405
00:13:56,396 --> 0:14:00,376
这样在剩下的

406
00:14:00,376 --> 0:14:02,416
代码中都可以称它为 tc

407
00:14:03,576 --> 0:14:05,326
现在 第一个任务

408
00:14:06,166 --> 0:14:07,336
是加载数据

409
00:14:07,916 --> 0:14:12,086
我们将以 SFrame 格式

410
00:14:12,086 --> 0:14:13,356
加载数据

411
00:14:14,256 --> 0:14:15,846
首先我们我们将 images

412
00:14:15,846 --> 0:14:18,046
赋值为 tc.loadimages

413
00:14:18,536 --> 0:14:19,386
参数为 我刚刚展示

414
00:14:19,386 --> 0:14:21,616
访达中的文件夹 Data

415
00:14:22,166 --> 0:14:26,476
Turi Create 提供了

416
00:14:26,476 --> 0:14:28,206
工具 可以让我们交互式

417
00:14:28,206 --> 0:14:29,766
探索和可视化数据

418
00:14:30,006 --> 0:14:31,346
所以让我们确保

419
00:14:31,346 --> 0:14:32,866
正确加载这些图像

420
00:14:32,866 --> 0:14:34,496
然后我们得到了想要的 SFrame

421
00:14:35,216 --> 0:14:36,696
我将调用 .explore 

422
00:14:37,456 --> 0:14:38,826
这将打开一个

423
00:14:38,826 --> 0:14:40,346
可视化窗口

424
00:14:40,346 --> 0:14:41,976
我们在这里可以看到

425
00:14:41,976 --> 0:14:42,696
我们的 SFrame 有两列

426
00:14:43,166 --> 0:14:44,746
第一个叫做 path

427
00:14:44,746 --> 0:14:46,256
这是相对路径

428
00:14:46,256 --> 0:14:47,106
指向磁盘上的图像

429
00:14:47,536 --> 0:14:49,296
第二列叫做 image

430
00:14:49,566 --> 0:14:51,866
而这其实就是图像内容本身

431
00:14:52,096 --> 0:14:53,166
我们可以看到我们的早餐食物

432
00:14:53,206 --> 0:14:53,906
就在这里

433
00:14:54,676 --> 0:14:55,586
看起来数据加载正确

434
00:14:55,586 --> 0:14:56,956
所以我要继续

435
00:14:56,956 --> 0:14:57,356
下一步

436
00:14:57,906 --> 0:15:01,026
回到 Jupyter Notebook

437
00:14:57,906 --> 0:15:01,026
回到 Jupyter Notebook

438
00:15:01,416 --> 0:15:02,786
现在我要加载

439
00:15:02,786 --> 0:15:04,996
第二个 SFrame 叫 annotations

440
00:15:05,536 --> 0:15:09,416
我打算调用

441
00:15:09,416 --> 0:15:11,066
SFrame 构造函数

442
00:15:11,066 --> 0:15:13,896
并提供一个文件名 annotations.csv

443
00:15:14,326 --> 0:15:16,286
这是一个 CSV 文件

444
00:15:16,286 --> 0:15:18,546
包含与图像对应的注释

445
00:15:19,236 --> 0:15:23,256
让我们看一看

446
00:15:23,876 --> 0:15:25,206
就在 Jupyter Notebook 中

447
00:15:25,206 --> 0:15:26,296
可以看到这个 SFrame

448
00:15:26,296 --> 0:15:28,146
包含一个 path 列

449
00:15:28,146 --> 0:15:29,476
同样是相对路径

450
00:15:29,476 --> 0:15:30,706
指向磁盘上的图像

451
00:15:31,206 --> 0:15:32,926
还有一个 annotation 列

452
00:15:33,156 --> 0:15:34,606
包含一个 JSON 对象

453
00:15:34,806 --> 0:15:36,326
描述边界框和

454
00:15:36,326 --> 0:15:38,366
与图片对应的标签

455
00:15:39,806 --> 0:15:40,866
但现在我们有两个不同的

456
00:15:40,866 --> 0:15:42,636
数据来源

457
00:15:42,826 --> 0:15:44,776
我们需要提供一个数据源来训练模型

458
00:15:45,316 --> 0:15:46,406
让我们把它们合并起来

459
00:15:47,096 --> 0:15:48,986
在 Turi Create 中

460
00:15:48,986 --> 0:15:50,186
只要调用 join 方法就可以了

461
00:15:50,616 --> 0:15:52,626
我将 data 赋值为

462
00:15:52,956 --> 0:15:57,946
images.join(annotations)

463
00:15:58,066 --> 0:15:59,916
现在我们就有一个

464
00:16:00,036 --> 0:16:01,656
三列的 SFrame

465
00:16:02,216 --> 0:16:03,766
它将 path 列作为键值进行连接

466
00:16:04,016 --> 0:16:05,956
因此 它为每个具有路径的图像 

467
00:16:06,206 --> 0:16:08,246
添加了指向该路径的注释

468
00:16:09,006 --> 0:16:11,806
因此每张图像都有对应的注释

469
00:16:12,656 --> 0:16:13,786
现在我们可以训练模型了

470
00:16:14,386 --> 0:16:17,936
所以我要创建一个新节

471
00:16:17,936 --> 0:16:20,716
叫做 Train a model

472
00:16:23,406 --> 0:16:26,276
在这里写一行代码

473
00:16:26,276 --> 0:16:28,096
将 model 赋值为

474
00:16:28,426 --> 0:16:30,606
tc.objectdetector.create.

475
00:16:30,936 --> 0:16:31,896
这是我们用于对象检测的

476
00:16:31,896 --> 0:16:33,636
简单任务型 API

477
00:16:33,636 --> 0:16:35,696
它需要以这种形式传入数据

478
00:16:36,476 --> 0:16:37,906
我要传入刚刚创建的

479
00:16:37,906 --> 0:16:39,226
data SFrame

480
00:16:39,686 --> 0:16:41,126
为了今天的演示

481
00:16:41,126 --> 0:16:42,816
我会传入另一个参数

482
00:16:42,816 --> 0:16:44,686
称为 max_iterations

483
00:16:45,136 --> 0:16:46,706
通常你不需要

484
00:16:46,706 --> 0:16:48,046
传递这个参数

485
00:16:48,086 --> 0:16:49,366
因为 Turi Create 会为你

486
00:16:49,366 --> 0:16:51,076
选择正确的迭代次数

487
00:16:51,226 --> 0:16:52,676
次数是根据你提供的数据做出的

488
00:16:53,456 --> 0:16:54,916
针对这个演示 我要将

489
00:16:54,916 --> 0:16:56,876
最大迭代赋值为 1

490
00:16:56,876 --> 0:16:58,216
只是简单展示一下

491
00:16:58,216 --> 0:16:59,076
训练是什么样子的

492
00:16:59,886 --> 0:17:01,216
这要花费一些时间

493
00:16:59,886 --> 0:17:01,216
这要花费一些时间

494
00:17:01,216 --> 0:17:03,856
因为程序需要遍历并调整

495
00:17:03,856 --> 0:17:05,445
所有图像的大小

496
00:17:05,445 --> 0:17:07,435
从而运行神经网络

497
00:17:07,435 --> 0:17:09,665
这是在物体检测器后台发生的

498
00:17:10,465 --> 0:17:12,036
然后它会在这台 Mac GPO 上

499
00:17:12,036 --> 0:17:14,856
仅进行一次迭代

500
00:17:16,116 --> 0:17:17,965
但这可能不是

501
00:17:17,965 --> 0:17:19,435
得出的最好的模型

502
00:17:19,435 --> 0:17:21,306
因为我只能花几秒钟训练它

503
00:17:21,656 --> 0:17:22,906
然后我就要

504
00:17:22,906 --> 0:17:25,016
切换到烹饪节目模式

505
00:17:25,056 --> 0:17:26,406
从烤箱里拿出一个

506
00:17:26,406 --> 0:17:27,445
已经训练一个小时的

507
00:17:27,445 --> 0:17:28,036
成品 [ 笑声 ]

508
00:17:28,726 --> 0:17:30,826
[ 掌声 ] 所以我要输入

509
00:17:30,826 --> 0:17:34,676
tc.load_model

510
00:17:34,796 --> 0:17:36,696
并调用 breakfastmodel.model

511
00:17:36,696 --> 0:17:39,546
我花了较长的时间

512
00:17:39,546 --> 0:17:41,316
训练了这个模型

513
00:17:41,806 --> 0:17:43,466
所以我们 Notebook 中

514
00:17:43,466 --> 0:17:44,026
查看一下

515
00:17:44,266 --> 0:17:45,396
我们可以看到

516
00:17:45,396 --> 0:17:46,576
这是一个物体探测器模型

517
00:17:47,226 --> 0:17:48,356
它已经接受了六个类别的训练

518
00:17:48,386 --> 0:17:50,336
训练时间为

519
00:17:50,336 --> 0:17:51,486
55 分钟

520
00:17:52,026 --> 0:17:53,006
这意味着你

521
00:17:53,006 --> 0:17:54,296
可以在一小时以内

522
00:17:54,296 --> 0:17:55,966
使用你的 Mac

523
00:17:55,966 --> 0:17:58,000
524
00:18:01,096 --> 0:18:02,866


525
00:18:02,866 --> 0:18:05,000
这个模型的预测效果

526
00:18:11,046 --> 0:18:13,096
所以我会开始一个新节

527
00:18:13,166 --> 0:18:13,676
叫做 Inspect predictions

528
00:18:14,056 --> 0:18:15,506
然后加载一个

529
00:18:15,716 --> 0:18:17,436
测试数据集

530
00:18:18,026 --> 0:18:19,496
在这里我已经准备好了

531
00:18:19,496 --> 0:18:20,676
一个 SFrame 格式的数据

532
00:18:20,676 --> 0:18:21,716
所以我只是要加载它 

533
00:18:22,436 --> 0:18:23,266
文件名为

534
00:18:23,266 --> 0:18:25,046
test-breakfast-data.sframe

535
00:18:25,666 --> 0:18:26,606
这个测试 SFrame

536
00:18:26,606 --> 0:18:28,756
有两个重要的属性

537
00:18:29,146 --> 0:18:31,126
一个是它包含的图像类型

538
00:18:31,126 --> 0:18:33,256
该模型受训的图像类型

539
00:18:33,366 --> 0:18:34,316
完全一样

540
00:18:34,656 --> 0:18:36,216
但第二个属性是

541
00:18:36,216 --> 0:18:37,756
该模型从未见过

542
00:18:37,756 --> 0:18:39,266
这些测试图片

543
00:18:39,556 --> 0:18:41,136
所以这是一个很好的测试

544
00:18:41,136 --> 0:18:42,126
可以检测该模型能否

545
00:18:42,126 --> 0:18:44,176
推广到用户的真实数据

546
00:18:44,756 --> 0:18:48,466
我会调用 model.predict

547
00:18:48,566 --> 0:18:50,176
并传入测试 SFrame

548
00:18:50,176 --> 0:18:52,016
从而对整个测试集

549
00:18:52,016 --> 0:18:54,196
做预测

550
00:18:54,396 --> 0:18:56,546
我们会得到整个

551
00:18:57,096 --> 0:19:00,656
SFframe 的批量预测结果

552
00:18:57,096 --> 0:19:00,656
SFframe 的批量预测结果

553
00:19:00,656 --> 0:19:01,136
这只会花费数秒

554
00:19:01,996 --> 0:19:04,306
然后我们要查看结果

555
00:19:04,516 --> 0:19:06,346
我只是随便选一个预测结果

556
00:19:06,626 --> 0:19:08,856
假设下标为 2

557
00:19:09,606 --> 0:19:11,676
在这里我们可以看到预测出的

558
00:19:11,676 --> 0:19:13,346
JSON 对象

559
00:19:13,346 --> 0:19:14,966
与提供的训练数据

560
00:19:14,966 --> 0:19:16,106
格式相同

561
00:19:16,446 --> 0:19:18,316
所以这里有

562
00:19:18,486 --> 0:19:19,776
高度 宽度 x y 坐标

563
00:19:20,056 --> 0:19:21,196
还有标签 香蕉

564
00:19:21,796 --> 0:19:23,816
我们得到了模型给出的置信度评分

565
00:19:23,966 --> 0:19:25,876
对于这个数据 评分为 0.87

566
00:19:26,886 --> 0:19:28,466
我作为人类

567
00:19:28,466 --> 0:19:29,976
很难解读这个数据

568
00:19:30,436 --> 0:19:32,516
我真的不知道

569
00:19:32,516 --> 0:19:33,786
这个图象是否是香蕉

570
00:19:33,786 --> 0:19:35,446
或这些坐标指向的

571
00:19:35,446 --> 0:19:36,866
是否是香蕉

572
00:19:36,866 --> 0:19:38,526
在图像中的位置

573
00:19:39,686 --> 0:19:41,526
Turi Create 有一个函数

574
00:19:41,706 --> 0:19:42,996
可以将预测的边界框

575
00:19:42,996 --> 0:19:44,476
或绝对正确的边界框

576
00:19:44,476 --> 0:19:47,096
绘制在图像上

577
00:19:47,576 --> 0:19:48,836
这是我们需要的

578
00:19:49,516 --> 0:19:50,976
我要在测试 SFrame 中

579
00:19:51,046 --> 0:19:52,846
创建一个新列

580
00:19:52,906 --> 0:19:53,856
叫 predicted_image

581
00:19:54,936 --> 0:19:56,926
并调用物体检测器的实用工具

582
00:19:56,926 --> 0:19:58,906
draw_bounding_boxes

583
00:19:58,906 --> 0:20:00,896
为它赋值

584
00:19:58,906 --> 0:20:00,896
为它赋值

585
00:20:01,756 --> 0:20:03,736
我将向 draw_bounding_boxes 函数

586
00:20:03,736 --> 0:20:06,946
传入测试的 image 列

587
00:20:07,016 --> 0:20:09,176
也就是图像本身

588
00:20:09,176 --> 0:20:11,616
并传入

589
00:20:11,616 --> 0:20:13,626
刚刚从模型中得到的预测

590
00:20:13,766 --> 0:20:15,616
这个函数会将

591
00:20:15,656 --> 0:20:17,316
预测的边界框

592
00:20:17,316 --> 0:20:18,126
画到每张图片上

593
00:20:18,656 --> 0:20:19,996
现在我们来看看这个

594
00:20:19,996 --> 0:20:21,286
2 号预测

595
00:20:21,566 --> 0:20:23,096
这次是以图像形式

596
00:20:24,676 --> 0:20:25,586
所以我输入

597
00:20:25,586 --> 0:20:28,396
test[‘predicted_image’][2].show

598
00:20:28,836 --> 0:20:30,786
Notebook 中就会显示结果

599
00:20:31,516 --> 0:20:38,016
[ 掌声 ]

600
00:20:38,516 --> 0:20:39,946
这样的抽样调查很棒

601
00:20:39,946 --> 0:20:41,596
因为我们知道了

602
00:20:41,596 --> 0:20:43,146
至少对这张图片来说 模型是正确的

603
00:20:43,616 --> 0:20:44,706
但我们并不知道它对于接下来

604
00:20:44,706 --> 0:20:45,996
可能传入的 50,000 张图片

605
00:20:45,996 --> 0:20:47,786
能否得出正确结果

606
00:20:48,636 --> 0:20:50,916
为此 我们将会对模型进行

607
00:20:50,976 --> 0:20:51,846
量化评估

608
00:20:52,446 --> 0:20:53,966
我在 Notebook 上

609
00:20:53,966 --> 0:20:55,106
开始一个新节

610
00:20:55,106 --> 0:20:56,326
称为 Evaluate the model

611
00:20:56,426 --> 0:20:58,286
而我们要做的是

612
00:20:58,286 --> 0:21:01,226
调用 model.evaluate

613
00:20:58,286 --> 0:21:01,226
调用 model.evaluate

614
00:21:01,226 --> 0:21:04,186
再一次 我将会传入整个测试数据集

615
00:21:05,936 --> 0:21:08,096
这里的评估函数会

616
00:21:08,096 --> 0:21:09,436
依照刚刚 Aaron 所描述的

617
00:21:09,436 --> 0:21:11,526
衡量标准

618
00:21:11,526 --> 0:21:12,546
检查边界框

619
00:21:12,546 --> 0:21:14,556
是否有 50% 的重叠度

620
00:21:14,556 --> 0:21:15,586
以及标签是否正确

621
00:21:15,586 --> 0:21:17,226
它会给我们结果

622
00:21:17,226 --> 0:21:19,926
这个结果是 六个已训类别中的一个

623
00:21:20,516 --> 0:21:22,036
在这里我们可以看到

624
00:21:22,356 --> 0:21:24,096
对于百吉饼 边界框重叠度达标

625
00:21:24,096 --> 0:21:25,636
且标签正确的情况

626
00:21:25,736 --> 0:21:27,696
有 80%

627
00:21:28,106 --> 0:21:31,276
香蕉的正确率为 67%

628
00:21:32,456 --> 0:21:34,016
结果很好

629
00:21:34,096 --> 0:21:35,616
现在我想知道 这个模型

630
00:21:35,616 --> 0:21:37,226
能否在实际的 App 中工作

631
00:21:37,866 --> 0:21:39,526
我打算调用

632
00:21:39,806 --> 0:21:42,366
export_coreml 来创建一个 Core ML 模型

633
00:21:42,366 --> 0:21:44,076
也就是我们刚刚训练的的模型

634
00:21:44,226 --> 0:21:45,666
我决定把它命名为

635
00:21:45,666 --> 0:21:47,536
BreakfastModel.mlmodel.

636
00:21:47,826 --> 0:21:49,036
然后 一旦完成

637
00:21:49,036 --> 0:21:50,546
训练 我就可以在

638
00:21:50,546 --> 0:21:51,656
访达中打开它

639
00:21:52,236 --> 0:21:56,000
对不起口误了 是一旦完成 导出

640
00:22:00,046 --> 0:22:01,686
所以在访达里

641
00:22:01,686 --> 0:22:03,316
我已经得到了 BreakfastModel.mlmodel

642
00:22:03,316 --> 0:22:05,636
当我在 Xcode 中打开它时

643
00:22:05,636 --> 0:22:07,106
它看起来就像

644
00:22:07,106 --> 0:22:08,306
任何 Core ML 模型

645
00:22:08,896 --> 0:22:12,176
它需要一个输入图像

646
00:22:12,176 --> 0:22:15,206
然后输出置信度和坐标

647
00:22:15,616 --> 0:22:16,706
这将告诉我们

648
00:22:16,706 --> 0:22:18,336
预测的边界框和

649
00:22:18,336 --> 0:22:19,436
图像的标签

650
00:22:20,376 --> 0:22:22,206
现在让我们切换到

651
00:22:22,246 --> 0:22:23,646
iPhone App

652
00:22:23,646 --> 0:22:24,616
我们要使用这个模型

653
00:22:25,186 --> 0:22:30,306
在我的 iPhone 上

654
00:22:30,306 --> 0:22:31,716
有一个名为 Food Predictor 的 App

655
00:22:32,356 --> 0:22:33,336
它使用的是

656
00:22:33,336 --> 0:22:34,456
我们刚刚训练的模型

657
00:22:35,356 --> 0:22:37,096
在这里 我要选择 相片

658
00:22:37,416 --> 0:22:39,026
我有今天早上

659
00:22:39,026 --> 0:22:40,036
早餐的照片

660
00:22:40,546 --> 0:22:41,506
这是我非常典型的早餐

661
00:22:41,506 --> 0:22:43,326
包含咖啡和香蕉

662
00:22:43,796 --> 0:22:45,546
好吧 我经常不吃香蕉

663
00:22:46,316 --> 0:22:48,856
假设今天早上我吃了

664
00:22:48,856 --> 0:22:49,346
一根香蕉吧

665
00:22:50,456 --> 0:22:53,796
我们可以直接点击图像

666
00:22:53,796 --> 0:22:54,976
因为我们看到了边界框

667
00:22:54,976 --> 0:22:58,386
我们可以识别边界框内的对象

668
00:22:58,386 --> 0:22:59,716
我们看到模型告诉我们

669
00:22:59,716 --> 0:23:02,976
这是一根香蕉 这是一杯咖啡

670
00:22:59,716 --> 0:23:02,976
这是一根香蕉 这是一杯咖啡

671
00:23:03,516 --> 0:23:09,500
[ 掌声 ]

672
00:23:16,136 --> 0:23:17,886
所以让我们回顾一下刚刚的内容

673
00:23:19,886 --> 0:23:21,756
首先 我们以 SFrame 格式

674
00:23:21,756 --> 0:23:23,896
加载图像和注释

675
00:23:24,146 --> 0:23:25,626
并调用简单的函数

676
00:23:25,626 --> 0:23:26,556
把它们连接起来

677
00:23:27,296 --> 0:23:28,976
我们使用 .explore 方法

678
00:23:28,976 --> 0:23:30,786
交互式探索数据

679
00:23:31,826 --> 0:23:33,616
我们创建了一个模型

680
00:23:33,616 --> 0:23:35,606
仅仅是通过简单的高级 API 

681
00:23:35,606 --> 0:23:37,286
传入包含图像

682
00:23:37,286 --> 0:23:39,936
边界框和标签的数据对象

683
00:23:40,906 --> 0:23:42,676
然后我们评估了这个模型

684
00:23:42,836 --> 0:23:43,956
既进行了量化评估

685
00:23:44,026 --> 0:23:45,596
又进行了模仿人类的

686
00:23:45,596 --> 0:23:46,176
抽样输出检查

687
00:23:46,556 --> 0:23:48,566
并得出了一个

688
00:23:48,566 --> 0:23:50,486
适用于所做任务的

689
00:23:50,486 --> 0:23:51,526
量化衡量标准

690
00:23:52,326 --> 0:23:54,206
然后我们将该模型导出为

691
00:23:54,206 --> 0:23:58,446
Core ML 格式 在 App 中使用

692
00:23:58,726 --> 0:24:00,306
接下来 我想换个话题

693
00:23:58,726 --> 0:24:00,306
接下来 我想换个话题

694
00:24:00,576 --> 0:24:01,976
谈论 Turi Create 5.0 的

695
00:24:01,976 --> 0:24:04,836
一些令人兴奋的新功能

696
00:24:06,776 --> 0:24:09,806
Turi Create 5.0 推出了一项新任务

697
00:24:10,076 --> 0:24:11,186
叫做风格转移

698
00:24:12,556 --> 0:24:13,716
我们对 Mac 上的

699
00:24:13,716 --> 0:24:16,126
本地 GPU 加速

700
00:24:16,126 --> 0:24:18,166
做了重大性能优化

701
00:24:19,016 --> 0:24:20,626
我们提供了新的部署选项

702
00:24:20,626 --> 0:24:24,626
包括个性化推荐模型

703
00:24:24,676 --> 0:24:25,956
和基于视觉特征提取的模型

704
00:24:25,956 --> 0:24:27,466
帮助你

705
00:24:27,466 --> 0:24:29,956
利用已存在于操作系统的模型

706
00:24:29,956 --> 0:24:31,386
减少 App 的大小

707
00:24:31,906 --> 0:24:34,696
让我们再谈谈

708
00:24:34,696 --> 0:24:36,176
风格转移任务

709
00:24:37,116 --> 0:24:39,186
想象一下 我们有一些风格图像

710
00:24:39,186 --> 0:24:41,296
它们真的很酷

711
00:24:41,296 --> 0:24:44,376
是辨识度很强的风格化图片

712
00:24:45,016 --> 0:24:46,826
在这里 我们已经有一个

713
00:24:46,826 --> 0:24:48,156
浅色的蜂巢图案

714
00:24:48,156 --> 0:24:49,426
和一个非常鲜艳的花卉图案

715
00:24:49,666 --> 0:24:51,406
我们希望将这些滤镜应用于

716
00:24:51,406 --> 0:24:53,416
我们自己用相机

717
00:24:53,416 --> 0:24:54,246
拍摄的图像

718
00:24:54,836 --> 0:24:57,846
这里有一张小狗的照片

719
00:24:57,896 --> 0:25:01,496
应用两种风格后的图片

720
00:24:57,896 --> 0:25:01,496
应用两种风格后的图片

721
00:25:01,496 --> 0:25:02,236
分别是这样的

722
00:25:02,586 --> 0:25:05,006
使用风格转移模型 

723
00:25:05,196 --> 0:25:06,956
我们可以将相同的风格

724
00:25:06,956 --> 0:25:08,296
应用于更多照片

725
00:25:08,646 --> 0:25:10,246
这里有一只猫和另一只狗的照片

726
00:25:10,916 --> 0:25:13,000
这就是得到的效果

727
00:25:16,046 --> 0:25:17,566
这是一个例子

728
00:25:17,566 --> 0:25:19,646
这个 App 使用风格转移

729
00:25:19,816 --> 0:25:21,946
为用户照片添加滤镜

730
00:25:24,556 --> 0:25:26,526
创建风格转移模型的代码

731
00:25:26,526 --> 0:25:28,386
同样遵循

732
00:25:28,516 --> 0:25:30,466
五步方法 就像其他

733
00:25:30,466 --> 0:25:32,046
Turi Create 高级任务一样

734
00:25:32,296 --> 0:25:33,956
所以你可以从导入

735
00:25:33,956 --> 0:25:36,076
Turi Create 开始

736
00:25:36,076 --> 0:25:38,166
将数据加载为 SFrame 格式

737
00:25:38,166 --> 0:25:40,176
并使用一个简单的高级 API 创建模型

738
00:25:41,326 --> 0:25:42,906
然后做出预测

739
00:25:42,906 --> 0:25:44,166
在本例中

740
00:25:44,166 --> 0:25:46,186
使用 .stylize 函数

741
00:25:46,186 --> 0:25:47,536
在图像上应用风格滤镜

742
00:25:48,166 --> 0:25:49,746
最后 我们可以导出它

743
00:25:49,746 --> 0:25:51,576
部署为 Core ML 格式 

744
00:25:51,576 --> 0:25:53,000
就像 Turi Create 中的其他模型一样

745
00:25:56,266 --> 0:25:57,926
我们来看看另一个演示

746
00:25:58,146 --> 0:26:00,106
这一次 我们要构建

747
00:25:58,146 --> 0:26:00,106
这一次 我们要构建

748
00:26:00,106 --> 0:26:02,000
风格转移模型

749
00:26:14,476 --> 0:26:15,926
所以切换回

750
00:26:15,926 --> 0:26:17,196
Jupyter Notebook 环境

751
00:26:17,546 --> 0:26:19,386
我将再次从

752
00:26:19,386 --> 0:26:25,000
导入 Turi Create 作为 tc 开始

753
00:26:29,056 --> 0:26:30,556
然后 我要加载两个 SFrame

754
00:26:30,556 --> 0:26:32,836
每个都包含图像

755
00:26:33,276 --> 0:26:35,236
一个是风格图像

756
00:26:35,236 --> 0:26:36,766
调用 tc.loadimages

757
00:26:36,766 --> 0:26:38,416
并传入目录名称 style

758
00:26:39,106 --> 0:26:41,466
另一个是内容图像

759
00:26:42,956 --> 0:26:44,226
模型的工作方式是

760
00:26:44,266 --> 0:26:46,106
风格图像是

761
00:26:46,106 --> 0:26:47,236
你想变成的

762
00:26:47,236 --> 0:26:48,376
可应用的滤镜风格

763
00:26:48,376 --> 0:26:50,586
内容图像可以是

764
00:26:50,686 --> 0:26:51,596
任何你想要

765
00:26:51,596 --> 0:26:53,286
应用此类滤镜的

766
00:26:53,286 --> 0:26:55,836
照片类型的代表

767
00:26:56,266 --> 0:26:57,596
所以在这种情况下

768
00:26:57,596 --> 0:26:58,896
可以是各种各样的照片

769
00:26:59,796 --> 0:27:01,776
我们将 content 文件夹

770
00:26:59,796 --> 0:27:01,776
我们将 content 文件夹

771
00:27:01,776 --> 0:27:03,546
加载到这个

772
00:27:03,546 --> 0:27:04,146
SFrame 中

773
00:27:05,226 --> 0:27:07,556
然后我们继续训练模型

774
00:27:08,386 --> 0:27:10,276
我将模型赋值为

775
00:27:10,846 --> 0:27:13,366
tc.styletransfer.create

776
00:27:13,786 --> 0:27:15,986
然后传入 style 和 content

777
00:27:16,226 --> 0:27:19,116
这就是所有内容

778
00:27:19,486 --> 0:27:21,096
但是今天这个演示

779
00:27:21,096 --> 0:27:22,806
需要的训练时间较长

780
00:27:23,276 --> 0:27:24,796
所以我要再一次

781
00:27:24,796 --> 0:27:25,746
像烹饪节目那样

782
00:27:25,746 --> 0:27:27,766
加载烤箱里完成的成品

783
00:27:28,526 --> 0:27:29,936
我将 model 赋值为

784
00:27:29,936 --> 0:27:32,426
tc.loadmodel

785
00:27:32,426 --> 0:27:35,296
加载已经训练好的风格转移模型

786
00:27:35,826 --> 0:27:38,546
我们来看看

787
00:27:38,546 --> 0:27:40,026
一些风格图像

788
00:27:40,026 --> 0:27:41,876
看看这个模型应该输出什么

789
00:27:42,876 --> 0:27:46,476
我们的 style SFrame 中

790
00:27:46,476 --> 0:27:47,336
有一个 image 列

791
00:27:47,746 --> 0:27:49,026
先来看看

792
00:27:49,026 --> 0:27:50,946
三号样式是什么

793
00:27:51,796 --> 0:27:54,056
有点像一堆柴火

794
00:27:54,416 --> 0:27:57,036
这很风格化

795
00:27:57,266 --> 0:27:59,626
如果我们将它作为滤镜应用到另一个图像上

796
00:27:59,626 --> 0:28:01,326
我认为应该很有辨识度

797
00:27:59,626 --> 0:28:01,326
我认为应该很有辨识度

798
00:28:02,676 --> 0:28:04,666
现在我们来看看一些

799
00:28:04,666 --> 0:28:05,566
内容图像

800
00:28:06,016 --> 0:28:07,916
我要加载一个测试数据集

801
00:28:08,126 --> 0:28:10,566
再次重申 这个数据集

802
00:28:10,566 --> 0:28:13,936
代表着用户将在 App 运行时

803
00:28:13,936 --> 0:28:15,326
提供的图像类型

804
00:28:15,776 --> 0:28:18,606
重点是 该模型将这些图像

805
00:28:18,606 --> 0:28:19,346
用作训练材料

806
00:28:19,656 --> 0:28:21,366
所以通过评估测试图像的结果

807
00:28:21,366 --> 0:28:22,836
我们就会知道该模型

808
00:28:22,836 --> 0:28:25,096
是否可以推广到用户数据 

809
00:28:26,206 --> 0:28:28,636
我现在再一次使用

810
00:28:29,166 --> 0:28:30,496
tc.loadimages 函数

811
00:28:30,606 --> 0:28:33,086
加载测试数据集

812
00:28:33,656 --> 0:28:34,906
我们将 test 文件夹

813
00:28:34,906 --> 0:28:36,006
作为参数传入

814
00:28:37,046 --> 0:28:38,406
现在我要将测试数据集中的

815
00:28:38,406 --> 0:28:39,696
一张图像当做样本

816
00:28:39,696 --> 0:28:40,736
设为 sample_image

817
00:28:41,216 --> 0:28:44,576
就选第一张图像吧

818
00:28:45,156 --> 0:28:48,016
我将调用 .show

819
00:28:48,016 --> 0:28:51,446
所以我们可以看到

820
00:28:51,446 --> 0:28:52,526
没有应用任何滤镜的情况下

821
00:28:52,526 --> 0:28:53,256
图像是什么样子的

822
00:28:54,016 --> 0:28:58,216
那是我的猫 九只猫中的老七

823
00:28:59,046 --> 0:29:02,306
它总是这个样子

824
00:28:59,046 --> 0:29:02,306
它总是这个样子

825
00:29:02,306 --> 0:29:04,546
我们将继续

826
00:29:04,546 --> 0:29:06,096
使用刚刚训练的模型

827
00:29:06,096 --> 0:29:07,036
风格化该图像

828
00:29:08,516 --> 0:29:10,526
所以我要将 stylized_image

829
00:29:10,526 --> 0:29:13,236
赋值为 model.stylize

830
00:29:13,956 --> 0:29:15,876
这个例子中

831
00:29:15,876 --> 0:29:17,486
函数名为 .stylize

832
00:29:17,486 --> 0:29:19,386
因为该模型是针对

833
00:29:19,386 --> 0:29:20,186
风格转移任务的

834
00:29:20,416 --> 0:29:23,606
我们输入 sample_image

835
00:29:23,956 --> 0:29:25,416
我要将 style 赋值为 3

836
00:29:25,416 --> 0:29:27,206
因为这是

837
00:29:27,206 --> 0:29:28,956
我们之前选择的风格

838
00:29:28,956 --> 0:29:30,146
看起来像柴火的那张

839
00:29:32,116 --> 0:29:34,656
所以让我们看看 stylized_image 是什么样的

840
00:29:35,196 --> 0:29:38,646
我来调用 .show

841
00:29:38,646 --> 0:29:40,746
这张图像中 我的猫看起来像一堆柴火

842
00:29:41,516 --> 0:29:46,426
[ 掌声 ]

843
00:29:46,926 --> 0:29:48,376
让我们确保

844
00:29:48,376 --> 0:29:49,256
其他风格也一样奏效

845
00:29:49,946 --> 0:29:52,336
我要继续

846
00:29:52,336 --> 0:29:58,496
基于样本图像

847
00:29:58,496 --> 0:29:59,256
制作风格化图像

848
00:29:59,576 --> 0:30:02,966
我将 style 赋值为 7

849
00:29:59,576 --> 0:30:02,966
我将 style 赋值为 7

850
00:30:03,556 --> 0:30:05,986
然后让我们看看

851
00:30:05,986 --> 0:30:07,000
图片是什么样子

852
00:30:13,056 --> 0:30:13,896
看上去很好

853
00:30:13,896 --> 0:30:15,236
我想知道刚刚应用的

854
00:30:15,236 --> 0:30:16,236
是什么风格

855
00:30:16,716 --> 0:30:18,496
让我们来看看

856
00:30:20,826 --> 0:30:21,000
风格图像

857
00:30:25,306 --> 0:30:26,516
七号风格图像

858
00:30:27,046 --> 0:30:30,066
我们可以再次调用

859
00:30:30,066 --> 0:30:31,436
.show 看看风格图像

860
00:30:31,436 --> 0:30:33,496
是什么样子的

861
00:30:33,496 --> 0:30:35,746
它看上去很像 刚刚用于猫的滤镜

862
00:30:36,426 --> 0:30:38,696
现在我们已经有了一个

863
00:30:38,696 --> 0:30:40,886
很好的风格转移模型

864
00:30:41,216 --> 0:30:43,716
我们可以调用 model.exportcoreml

865
00:30:43,716 --> 0:30:45,206
就像对其他模型一样 

866
00:30:45,206 --> 0:30:47,000
将其保存为 Core ML 格式

867
00:30:52,296 --> 0:30:55,436
现在 让我们切换到 iPhone

868
00:30:55,436 --> 0:30:57,306
里面有一个风格转移 App 

869
00:30:57,306 --> 0:30:58,306
可以使用该模型中的滤镜

870
00:30:58,886 --> 0:31:03,726
我又拿出了我的 iPhone

871
00:30:58,886 --> 0:31:03,726
我又拿出了我的 iPhone

872
00:31:03,726 --> 0:31:05,936
这里有一个 App 叫做 StyleTransfer

873
00:31:06,696 --> 0:31:08,066
我要从我的照片库中

874
00:31:08,066 --> 0:31:09,946
选择一张照片

875
00:31:09,946 --> 0:31:11,256
来应用这些样式

876
00:31:11,796 --> 0:31:13,846
这些是我的狗

877
00:31:16,136 --> 0:31:19,696
这是 Ryker 

878
00:31:19,696 --> 0:31:20,656
看看 App 中

879
00:31:20,656 --> 0:31:21,696
有什么样的风格可用

880
00:31:22,206 --> 0:31:23,706
我们可以滚动浏览所有的风格

881
00:31:23,706 --> 0:31:26,126
需要注意的是

882
00:31:26,126 --> 0:31:27,766
这些图像文件

883
00:31:27,766 --> 0:31:29,596
被用于训练一个

884
00:31:29,596 --> 0:31:30,636
风格转移模型

885
00:31:30,976 --> 0:31:32,836
一个模型可以包含

886
00:31:32,836 --> 0:31:33,676
任意数量的样式

887
00:31:34,126 --> 0:31:35,636
所以你可以拥有多个滤镜

888
00:31:35,636 --> 0:31:37,116
而无需大大增加

889
00:31:37,166 --> 0:31:37,976
你 App 的大小

890
00:31:39,156 --> 0:31:40,376
让我们看看这些风格

891
00:31:40,376 --> 0:31:43,036
应用到 Ryker 身上是怎样的

892
00:31:43,716 --> 0:31:46,000
很酷

893
00:31:52,646 --> 0:31:52,976
所以

894
00:31:53,516 --> 0:31:58,316
[ 掌声 ]

895
00:31:58,816 --> 0:32:01,266
回顾一下我们刚刚看到的

896
00:31:58,816 --> 0:32:01,266
回顾一下我们刚刚看到的

897
00:32:01,266 --> 0:32:03,336
我们将图像加载到 SFrame 格式

898
00:32:03,646 --> 0:32:05,576
这个例子中的风格图像和内容图像

899
00:32:05,576 --> 0:32:07,346
被分成两个 SFrame

900
00:32:07,836 --> 0:32:09,656
我们使用高级 API

901
00:32:09,656 --> 0:32:10,966
创建了一个

902
00:32:10,966 --> 0:32:12,816
风格转移模型

903
00:32:12,946 --> 0:32:14,576
它可以直接运行于一组风格图像

904
00:32:14,576 --> 0:32:15,646
和一组内容图像上

905
00:32:16,436 --> 0:32:18,956
然后 我们将图片风格化

906
00:32:19,256 --> 0:32:20,836
以检查该模型是否正确运行

907
00:32:21,356 --> 0:32:22,876
我们在 Turi Create

908
00:32:22,876 --> 0:32:23,706
将预测可视化

909
00:32:24,226 --> 0:32:25,686
最后我们导出了

910
00:32:25,686 --> 0:32:27,566
Core ML 格式的模型

911
00:32:27,566 --> 0:32:29,996
在 App 中使用

912
00:32:30,636 --> 0:32:31,566
换一个话题

913
00:32:31,616 --> 0:32:32,656
我想谈谈 Turi Create 5.0 中的

914
00:32:32,656 --> 0:32:34,336
其他一些功能

915
00:32:35,066 --> 0:32:37,186
我们现在有 Mac GPU 加速

916
00:32:37,536 --> 0:32:39,626
在图像分类上

917
00:32:39,626 --> 0:32:41,586
达到了高达 12 倍的性能提升

918
00:32:41,756 --> 0:32:43,966
对象检测提升了 9 倍

919
00:32:43,966 --> 0:32:45,226
这都是在 iMac Pro 上做到的

920
00:32:46,516 --> 0:32:50,586
[ 掌声 ]

921
00:32:51,086 --> 0:32:53,096
我们还有一个可用的新任务

922
00:32:53,096 --> 0:32:54,616
可供导出为 Core ML 格式

923
00:32:54,876 --> 0:32:55,776
就是个性化

924
00:32:56,466 --> 0:32:58,096
这个任务是基于

925
00:32:58,096 --> 0:33:00,496
用户的历史偏好

926
00:32:58,096 --> 0:33:00,496
用户的历史偏好

927
00:33:00,496 --> 0:33:01,686
为用户推荐项目

928
00:33:02,896 --> 0:33:04,636
这种类型的模型部署

929
00:33:04,636 --> 0:33:06,506
需使用 Core ML 的新自定义模型支持

930
00:33:06,506 --> 0:33:08,586
该支持在 macOS Mojave

931
00:33:08,586 --> 0:33:11,026
和 iOS 12 上可用

932
00:33:11,686 --> 0:33:12,966
这是在 Turi Create 开源后

933
00:33:12,966 --> 0:33:14,576
呼声最高的

934
00:33:14,576 --> 0:33:15,546
社区功能请求

935
00:33:15,806 --> 0:33:16,956
所以我很高兴

936
00:33:16,956 --> 0:33:17,576
今天向你们介绍它

937
00:33:18,516 --> 0:33:23,546
[ 掌声 ]

938
00:33:24,046 --> 0:33:25,846
Core ML 中的推荐模型

939
00:33:26,076 --> 0:33:27,956
看起来就和任何其他 Core ML 模型一样

940
00:33:28,266 --> 0:33:29,656
但值得注意的是

941
00:33:29,656 --> 0:33:30,876
底部有一个部分

942
00:33:30,876 --> 0:33:32,496
称为 Dependencies

943
00:33:33,046 --> 0:33:34,416
这一部分中 你可以看到

944
00:33:34,416 --> 0:33:36,156
该模型使用了叫做

945
00:33:36,156 --> 0:33:37,986
TCRecommender 的

946
00:33:37,986 --> 0:33:39,006
自定义模型

947
00:33:39,506 --> 0:33:40,886
这是 Turi Create

948
00:33:41,036 --> 0:33:42,056
通过自定义模型 API 提供的

949
00:33:42,056 --> 0:33:45,346
对 Core ML 中 Recommender 的 支持

950
00:33:46,016 --> 0:33:49,476
在 Core ML 中使用该模型

951
00:33:49,536 --> 0:33:51,776
与使用任何其他 Core ML 模型 非常相似

952
00:33:52,316 --> 0:33:53,506
你可以将模型实例化

953
00:33:53,506 --> 0:33:55,696
创建你的输入

954
00:33:55,776 --> 0:33:57,696
在这个例子中

955
00:33:57,696 --> 0:33:59,046
我们有一个头像创建 App

956
00:33:59,386 --> 0:34:01,066
用户可能选择了

957
00:33:59,386 --> 0:34:01,066
用户可能选择了

958
00:34:01,066 --> 0:34:02,626
棕色胡须 棕色八字胡

959
00:34:02,626 --> 0:34:04,276
和棕色长头发

960
00:34:04,276 --> 0:34:05,966
作为头像

961
00:34:06,346 --> 0:34:08,426
我们可以把这些交互 作为输入

962
00:34:08,626 --> 0:34:10,886
让模型进行预测

963
00:34:11,315 --> 0:34:13,416
从而得出

964
00:34:13,416 --> 0:34:14,996
基于这些输入的 k10 

965
00:34:15,346 --> 0:34:16,426
也就是排名前十的预测

966
00:34:17,045 --> 0:34:21,116
回顾一下我们今天学到的内容

967
00:34:22,286 --> 0:34:24,255
Turi Create 允许你创建

968
00:34:24,255 --> 0:34:26,196
Core ML 模型

969
00:34:26,196 --> 0:34:27,755
用来在你的 App 中

970
00:34:27,985 --> 0:34:28,286
提供智能功能

971
00:34:28,606 --> 0:34:30,775
通过五个简单的步骤就可以完成

972
00:34:30,775 --> 0:34:34,275
首先是确认你正在做的任务

973
00:34:34,485 --> 0:34:36,496
并将其映射至一个机器学习任务

974
00:34:37,025 --> 0:34:39,045
收集和注释用于

975
00:34:39,226 --> 0:34:41,126
训练该模型的数据

976
00:34:42,146 --> 0:34:43,946
使用一个针对任务的

977
00:34:43,946 --> 0:34:47,505
简单的高级 API 来训练模型

978
00:34:48,466 --> 0:34:50,235
在 Turi Create 中对模型

979
00:34:50,235 --> 0:34:52,826
进行定量和定性评估

980
00:34:53,366 --> 0:34:56,406
最后 部署到 Core ML 格式

981
00:34:58,936 --> 0:35:01,196
这五个步骤可以映射到代码编写

982
00:34:58,936 --> 0:35:01,196
这五个步骤可以映射到代码编写

983
00:35:01,196 --> 0:35:03,646
首先是导入 Turi Create

984
00:35:04,406 --> 0:35:06,526
你可以将数据加载到 SFrame 格式

985
00:35:07,026 --> 0:35:08,566
使用针对任务的 API 

986
00:35:08,596 --> 0:35:10,026
创建一个模型

987
00:35:11,126 --> 0:35:12,726
使用针对任务的

988
00:35:12,726 --> 0:35:14,076
评估函数

989
00:35:14,076 --> 0:35:16,086
对模型进行评估

990
00:35:16,646 --> 0:35:18,096
最后调用 export_coreml 函数

991
00:35:18,356 --> 0:35:20,066
导出模型进行部署

992
00:35:20,536 --> 0:35:23,576
Turi Create 支持类型多样的

993
00:35:23,576 --> 0:35:25,296
机器学习任务

994
00:35:25,736 --> 0:35:27,196
从高层次的

995
00:35:27,196 --> 0:35:29,286
图像分类和

996
00:35:29,286 --> 0:35:31,296
文本分类

997
00:35:31,296 --> 0:35:32,896
到低级别的

998
00:35:32,896 --> 0:35:33,436
机器学习基础

999
00:35:33,436 --> 0:35:34,186
如任何数据类型的

1000
00:35:34,186 --> 0:35:36,246
回归和分类

1001
00:35:38,006 --> 0:35:39,806
你可以使用制作的模型 

1002
00:35:40,106 --> 0:35:42,986
为你的 App 添加智能功能

1003
00:35:42,986 --> 0:35:45,036
比如对象检测

1004
00:35:45,036 --> 0:35:47,196
或作为滤镜使用的风格转移

1005
00:35:48,216 --> 0:35:50,306
更多有关信息 请参见

1006
00:35:50,306 --> 0:35:52,606
developer.apple.com 

1007
00:35:52,806 --> 0:35:53,306
会议网址

1008
00:35:53,716 --> 0:35:55,316
欢迎我们的实验室

1009
00:35:55,316 --> 0:35:56,736
今天下午和周五下午

1010
00:35:56,886 --> 0:35:58,056
各有一个活动日程

1011
00:35:58,306 --> 0:35:59,726
我们欢迎你的反馈

1012
00:36:00,096 --> 0:36:02,126
并且很高兴回答大家的任何问题

1013
00:36:02,386 --> 0:36:04,136
今天所有的演示

1014
00:36:04,136 --> 0:36:06,376
都可以在实验室中 供大家探索

1015
00:36:07,186 --> 0:36:07,506
谢谢 

1016
00:36:08,516 --> 0:36:11,500
[ 掌声 ]
