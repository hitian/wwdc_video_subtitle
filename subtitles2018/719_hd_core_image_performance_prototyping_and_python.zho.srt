1
00:00:17,384 --> 0:00:21,555
（Core Image：

2
00:00:21,622 --> 0:00:22,623
（演讲719）

3
00:00:23,524 --> 0:00:24,358
好

4
00:00:24,791 --> 0:00:25,626
谢谢

5
00:00:27,294 --> 0:00:28,395
大家下午好

6
00:00:28,462 --> 0:00:31,098
感谢今天参加

7
00:00:31,398 --> 0:00:32,533
我叫David Hayward

8
00:00:32,698 --> 0:00:35,802
我很高兴能够向大家介绍

9
00:00:35,869 --> 0:00:39,373
添加到Core Image的

10
00:00:39,439 --> 0:00:40,541
新性能及原型功能

11
00:00:41,041 --> 0:00:43,744
我们有很多内容

12
00:00:44,511 --> 0:00:46,713
今天要谈的第一件事就是

13
00:00:46,780 --> 0:00:49,116
我们添加到Core Image的

14
00:00:49,183 --> 0:00:51,785
用以提高app的性能

15
00:00:52,319 --> 0:00:55,122
之后 我们将转入另一个话题

16
00:00:55,189 --> 0:00:56,657
即如何使用Core Image

17
00:00:56,723 --> 0:00:58,792
以帮助原型新算法的开发

18
00:00:59,193 --> 0:01:02,362
最后 我们将讨论

19
00:00:59,193 --> 0:01:02,362
最后 我们将讨论

20
00:01:02,629 --> 0:01:05,632
配合各种机器学习app

21
00:01:07,568 --> 0:01:09,803
好 让我们开始

22
00:01:09,870 --> 0:01:11,505
首先我们来说说性能API

23
00:01:11,572 --> 0:01:14,241
今年 我们重点在两个领域

24
00:01:14,775 --> 0:01:15,676
致力于提高性能

25
00:01:15,742 --> 0:01:18,278
首先 我们新添了一些对插入

26
00:01:18,512 --> 0:01:19,813
中间缓冲区的控制

27
00:01:19,980 --> 0:01:21,615
我们将详细讨论这个问题

28
00:01:21,949 --> 0:01:23,684
第二 我们将谈谈

29
00:01:23,750 --> 0:01:28,021
你可以利用的

30
00:01:28,088 --> 0:01:31,358
我们先来谈谈中间缓冲区

31
00:01:33,227 --> 0:01:35,495
若你曾用过Core Image

32
00:01:35,562 --> 0:01:39,833
Core Image让你轻松地

33
00:01:40,167 --> 0:01:43,770
Core Image中每个过滤器

34
00:01:44,071 --> 0:01:46,173
Core Image的一项重要的

35
00:01:46,240 --> 0:01:49,376
提高性能的功能是连接内核

36
00:01:49,443 --> 0:01:51,979
以减少中间缓冲区的数量

37
00:01:52,145 --> 0:01:54,882
许多情况下

38
00:01:54,948 --> 0:01:56,550
你需要尽量减少缓冲区数

39
00:01:57,484 --> 0:01:59,486
但是 有一些情况

40
00:01:59,786 --> 0:02:03,190
你不希望最大量地连接

41
00:01:59,786 --> 0:02:03,190
你不希望最大量地连接

42
00:02:03,857 --> 0:02:06,793
例如 你的app里

43
00:02:06,860 --> 0:02:08,461
在过滤器链的早期

44
00:02:09,329 --> 0:02:10,864
你的app的用户

45
00:02:10,931 --> 0:02:13,333
在某个时刻可能正在调整

46
00:02:13,400 --> 0:02:14,768
在图中跟随它的过滤器

47
00:02:15,135 --> 0:02:16,703
这是一个经典的情况

48
00:02:16,770 --> 0:02:19,173
中间缓冲区是个好主意

49
00:02:20,007 --> 0:02:22,109
在介于两者之间的位置

50
00:02:22,809 --> 0:02:25,913
通过设这个中间缓冲区

51
00:02:26,180 --> 0:02:28,182
调整辅助过滤器时

52
00:02:28,415 --> 0:02:30,551
无需两次付出

53
00:02:30,717 --> 0:02:33,554
昂贵的过滤器的成本

54
00:02:34,087 --> 0:02:35,956
那么如何在app中操作？

55
00:02:36,023 --> 0:02:38,325
我们有一个新的API 顾名思义

56
00:02:38,859 --> 0:02:40,027
insertingIntermediate

57
00:02:40,794 --> 0:02:43,664
我们谈谈这会如何影响我们的结果

58
00:02:43,730 --> 0:02:45,432
我们所做的不是

59
00:02:45,499 --> 0:02:46,500
尽可能多地连接

60
00:02:46,667 --> 0:02:49,136
我们会尊重中间缓冲区的位置

61
00:02:49,369 --> 0:02:51,772
并尽可能多地连接它

62
00:02:53,207 --> 0:02:54,241
这里有几点说明

63
00:02:54,308 --> 0:02:55,442
要记住一件事

64
00:02:55,709 --> 0:02:57,244
默认情况下

65
00:02:57,311 --> 0:02:59,413
Core Image

66
00:02:59,479 --> 0:03:02,249
为后续生成作准备

67
00:02:59,479 --> 0:03:02,249
为后续生成作准备

68
00:03:02,516 --> 0:03:03,717
使之速度会更快

69
00:03:04,051 --> 0:03:05,986
但是 有些时候

70
00:03:06,053 --> 0:03:08,856
你会想关闭中间缓冲区的缓存

71
00:03:09,389 --> 0:03:13,093
例如 如果你的app将要批量导出

72
00:03:13,160 --> 0:03:14,428
100张图片

73
00:03:14,928 --> 0:03:17,364
缓存第一个无益

74
00:03:17,431 --> 0:03:20,601
因为后续生成的图像将完全不同

75
00:03:20,667 --> 0:03:22,669
所以 你可以在你的app中实现它

76
00:03:22,736 --> 0:03:25,472
使用上下文选项

77
00:03:25,539 --> 0:03:27,040
并将该值设置为false

78
00:03:28,542 --> 0:03:31,311
但如果你也在使用这个我们刚谈到的

79
00:03:31,378 --> 0:03:32,279
新API

80
00:03:32,713 --> 0:03:35,582
你仍然可以打开中间缓冲区的缓存

81
00:03:35,649 --> 0:03:37,951
即使此上下文选项是关闭的

82
00:03:38,318 --> 0:03:40,787
所以 这可以让你真正确保

83
00:03:40,854 --> 0:03:42,756
缓存需要的 不缓存任何其它内容

84
00:03:45,526 --> 0:03:47,461
我想谈的下一个主题

85
00:03:47,528 --> 0:03:50,797
是我们添加到内核语言的

86
00:03:51,732 --> 0:03:53,600
一些应用图像处理的新功能

87
00:03:55,068 --> 0:03:57,304
请记住 我们有两种方法

88
00:03:57,371 --> 0:03:59,706
在Core Image中编写内核

89
00:04:00,307 --> 0:04:03,510
传统的方法是CI内核语言

90
00:04:03,944 --> 0:04:06,813
在这种情况下

91
00:04:06,880 --> 0:04:09,249
你的Swift代码

92
00:04:09,583 --> 0:04:11,652
在运行时 你调用

93
00:04:11,718 --> 0:04:13,754
内核及源代码

94
00:04:14,688 --> 0:04:18,325
稍后 当你基于该内核创建图像时

95
00:04:18,492 --> 0:04:21,228
你可以生成任何类型的CI上下文

96
00:04:21,295 --> 0:04:25,566
不论该上下文是由Metal

97
00:04:26,934 --> 0:04:30,337
然而 当生成时 需要翻译该源

98
00:04:30,404 --> 0:04:33,240
需要将其翻译为

99
00:04:33,607 --> 0:04:35,609
并且这个步骤有成本

100
00:04:36,310 --> 0:04:40,113
最后 该代码被编译为GPU指令集

101
00:04:40,180 --> 0:04:41,181
然后执行

102
00:04:42,616 --> 0:04:44,785
从去年的iOS 11开始

103
00:04:44,852 --> 0:04:46,987
我们添加了一种

104
00:04:47,054 --> 0:04:48,956
具有一些显著优势

105
00:04:49,122 --> 0:04:52,059
这就是基于

106
00:04:52,593 --> 0:04:55,596
这种情况下 你的项目中有源代码

107
00:04:55,662 --> 0:05:00,367
并且此源是在build时

108
00:04:55,662 --> 0:05:00,367
并且此源是在build时

109
00:05:01,502 --> 0:05:05,606
和以前一样

110
00:05:06,106 --> 0:05:10,277
使用带有Metal函数名

111
00:05:12,012 --> 0:05:16,383
其优势点是可以应用此数据

112
00:05:16,450 --> 0:05:18,886
而无需耗用额外编译资源

113
00:05:19,486 --> 0:05:23,690
需要注意的是

114
00:05:24,258 --> 0:05:26,126
但它带来了巨大的性能优势

115
00:05:27,928 --> 0:05:29,897
所以 从这个版本开始

116
00:05:29,963 --> 0:05:33,333
我们将把CI内核语言标为已弃用

117
00:05:33,700 --> 0:05:36,303
因为 虽然我们会继续支持这种语言

118
00:05:37,237 --> 0:05:39,706
我们认为编写

119
00:05:39,773 --> 0:05:42,142
为作为开发人员的你提供了很多优势

120
00:05:42,376 --> 0:05:45,479
首先 你获得了

121
00:05:45,546 --> 0:05:50,083
它同时还提供了

122
00:05:50,150 --> 0:05:52,619
和优秀的调试工具的优势

123
00:05:52,920 --> 0:05:55,489
如果你使用Metal源的话

124
00:05:57,958 --> 0:05:59,092
好

125
00:06:03,630 --> 0:06:06,900
考虑到这一点 我想谈谈其它几个

126
00:06:06,967 --> 0:06:09,469
我们添加到内核语言中的功能

127
00:06:09,536 --> 0:06:11,738
首先 我们增加了半浮动支持

128
00:06:12,139 --> 0:06:14,541
很多情况下

129
00:06:14,741 --> 0:06:17,778
当你的CI内核可完全

130
00:06:18,278 --> 0:06:20,547
满足于半浮动带来的精度

131
00:06:20,781 --> 0:06:22,816
如果你使用RGB颜色值

132
00:06:22,883 --> 0:06:24,852
半浮点精度绰绰有余

133
00:06:25,419 --> 0:06:27,421
在内核中使用半浮点数的优点

134
00:06:27,487 --> 0:06:29,523
是它使操作运行得更快

135
00:06:29,590 --> 0:06:31,258
尤其是在A11设备上

136
00:06:31,491 --> 0:06:32,626
如iPhone 10

137
00:06:33,360 --> 0:06:35,996
在内核中用半浮点数的另一个优点

138
00:06:36,063 --> 0:06:37,764
它允许更小的寄存器

139
00:06:37,831 --> 0:06:40,200
增加了GPU的利用率

140
00:06:40,267 --> 0:06:41,635
这也有助于提高性能

141
00:06:42,236 --> 0:06:45,038
今年我们在内核语言中

142
00:06:45,105 --> 0:06:47,040
即对组读取的支持

143
00:06:47,274 --> 0:06:49,443
只用一条指令

144
00:06:49,510 --> 0:06:52,045
来自输入图像的四个

145
00:06:52,412 --> 0:06:54,114
单通道读取

146
00:06:54,181 --> 0:06:55,382
这真的有很大帮助

147
00:06:56,517 --> 0:06:58,252
作为补充

148
00:06:58,318 --> 0:07:00,721
我们还可以写像素组

149
00:06:58,318 --> 0:07:00,721
我们还可以写像素组

150
00:07:01,088 --> 0:07:04,157
即只需在着色器中一条指令

151
00:07:04,458 --> 0:07:06,960
写入图像的四个像素

152
00:07:08,428 --> 0:07:10,264
所有这三个功能

153
00:07:10,330 --> 0:07:15,302
都可以用于着色器中极大地提高性能

154
00:07:15,369 --> 0:07:18,071
我来谈一谈如何运作的例子

155
00:07:18,772 --> 0:07:22,976
想象一下你有一个简单的

156
00:07:23,710 --> 0:07:26,547
用于一个图像的一个通道

157
00:07:26,613 --> 0:07:28,315
这是一种相当常见的操作

158
00:07:28,382 --> 0:07:31,084
例如要锐化图像的亮度

159
00:07:31,485 --> 0:07:35,522
在这样的内核中

160
00:07:35,923 --> 0:07:39,326
它负责产生一个输出像素

161
00:07:39,860 --> 0:07:42,129
但是因为这是一个三乘三的卷积

162
00:07:42,629 --> 0:07:45,132
你的内核需要读取9个像素

163
00:07:45,699 --> 0:07:47,234
以达到这个效果

164
00:07:47,301 --> 0:07:50,103
因此 我们每写一个像素

165
00:07:51,371 --> 0:07:52,673
但我们通过新的组写功能

166
00:07:52,739 --> 0:07:55,909
改进这一点

167
00:07:56,310 --> 0:07:57,945
使用新的组写功能

168
00:07:58,011 --> 0:08:02,950
你的内核可以一次调用

169
00:07:58,011 --> 0:08:02,950
你的内核可以一次调用

170
00:08:03,383 --> 0:08:06,053
当然这二乘二小组有点大

171
00:08:06,119 --> 0:08:07,788
所以不再是三乘三

172
00:08:08,121 --> 0:08:11,124
而是四乘四像素读取

173
00:08:11,191 --> 0:08:13,627
以写出这四个像素

174
00:08:14,394 --> 0:08:15,529
我们算一下

175
00:08:15,896 --> 0:08:19,700
这意味着我们有16像素读取

176
00:08:19,766 --> 0:08:22,135
所以我们已经看到了这方面的优势

177
00:08:24,972 --> 0:08:28,642
我们的另一个功能是收集

178
00:08:29,076 --> 0:08:33,547
在这个例子中

179
00:08:33,614 --> 0:08:34,615
有了这个功能

180
00:08:34,780 --> 0:08:38,818
我们只需要四条指令

181
00:08:39,753 --> 0:08:41,554
如果你计算一下

182
00:08:41,621 --> 0:08:43,490
这意味着我们每写入四个像素

183
00:08:43,557 --> 0:08:44,925
只进行了四次读取

184
00:08:45,259 --> 0:08:47,628
这确实有助于提高性能

185
00:08:47,794 --> 0:08:50,731
我们通过实际内核代码

186
00:08:51,932 --> 0:08:55,736
这是一个简单卷积的例子

187
00:08:55,802 --> 0:08:57,037
就像我刚才描述的

188
00:08:57,437 --> 0:08:59,673
这里 我们从输入图像

189
00:08:59,740 --> 0:09:01,241
做九个样本

190
00:08:59,740 --> 0:09:01,241
做九个样本

191
00:09:01,441 --> 0:09:03,310
我们只用它的红色通道

192
00:09:04,144 --> 0:09:05,879
一旦我们得到这九个值

193
00:09:05,946 --> 0:09:07,514
我们将对这九个值进行平均

194
00:09:07,581 --> 0:09:09,283
并以传统方式写出来

195
00:09:09,349 --> 0:09:12,119
返回单个vec4像素值

196
00:09:14,154 --> 0:09:17,024
加速的第一步

197
00:09:17,090 --> 0:09:18,325
这实际上很简单

198
00:09:18,392 --> 0:09:20,394
我们从像这样的代码开始

199
00:09:20,460 --> 0:09:22,462
这是我们传统的CI内核语言

200
00:09:22,529 --> 0:09:24,965
如果在代码中进行一些搜索和替换

201
00:09:25,032 --> 0:09:29,203
你可以将其更新为

202
00:09:29,269 --> 0:09:31,371
这里请注意几件重要的事情

203
00:09:31,438 --> 0:09:34,908
我们为内核添加了一个目标参数

204
00:09:34,975 --> 0:09:35,876
这对我们很重要

205
00:09:35,943 --> 0:09:39,680
如果我们要检查着色器中的目标坐标

206
00:09:39,746 --> 0:09:42,216
像这样的类似卷积的内核

207
00:09:42,983 --> 0:09:45,085
我们用新的、更现代的语法

208
00:09:45,152 --> 0:09:49,990
只需说s.sample和s.transform

209
00:09:51,124 --> 0:09:53,327
我们在更新此代码时做的最后一件事

210
00:09:53,393 --> 0:09:57,064
是更改传统的vec4

211
00:09:57,130 --> 0:09:59,233
到float4和float2

212
00:10:00,701 --> 0:10:02,870
但我们看到 代码的整体架构

213
00:10:02,936 --> 0:10:04,738
内核的流程是一样的

214
00:10:06,773 --> 0:10:09,610
好 第二步是使用半浮动

215
00:10:10,077 --> 0:10:12,579
这个例子我们可以

216
00:10:12,646 --> 0:10:14,481
只使用半浮点数的精度

217
00:10:14,548 --> 0:10:16,517
因为我们只是处理颜色值

218
00:10:16,583 --> 0:10:19,786
我们将再次对代码

219
00:10:20,220 --> 0:10:25,058
基本上代码中曾使用浮点精度的位置

220
00:10:25,125 --> 0:10:27,227
我们将使用半浮点精度

221
00:10:27,294 --> 0:10:30,397
这表示sampler参数

222
00:10:30,464 --> 0:10:32,666
有一个_h后缀

223
00:10:33,367 --> 0:10:37,237
以及代码中的float4

224
00:10:38,071 --> 0:10:39,973
这很简单易行

225
00:10:40,040 --> 0:10:43,110
还有一件事要注意

226
00:10:43,177 --> 0:10:45,279
确保在它们的末尾加h

227
00:10:45,345 --> 0:10:47,014
比如除以9.0

228
00:10:48,849 --> 0:10:50,617
这也很简单

229
00:10:51,084 --> 0:10:52,853
为了获得此示例中的最佳性能

230
00:10:52,920 --> 0:10:55,088
我们要做的最后一件事

231
00:10:55,155 --> 0:10:57,291
是利用组读取和组写入

232
00:10:57,357 --> 0:10:59,726
我们看看完成这个的代码

233
00:11:00,661 --> 0:11:03,897
我们想写一个二乘二的像素组

234
00:11:03,964 --> 0:11:07,201
并且我们需要从四乘四像素组中读取

235
00:11:08,101 --> 0:11:11,271
首先我们想要指定一个组目的地

236
00:11:11,338 --> 0:11:13,807
我们看一下函数声明

237
00:11:13,874 --> 0:11:15,576
它现在有一个组目的地

238
00:11:16,143 --> 0:11:17,444
h数据类型

239
00:11:18,345 --> 0:11:20,914
我们将像以前一样获得目标坐标

240
00:11:20,981 --> 0:11:22,883
指向像素的中心

241
00:11:22,950 --> 0:11:25,586
但该坐标实际上代表了

242
00:11:25,953 --> 0:11:29,590
一组二乘二像素的坐标

243
00:11:30,657 --> 0:11:32,025
接下来为了填充这组

244
00:11:32,226 --> 0:11:35,395
二乘二像素 我们要做的是

245
00:11:35,462 --> 0:11:37,164
从图像中作一堆读取

246
00:11:37,965 --> 0:11:39,833
所以 第一次收集读取

247
00:11:40,167 --> 0:11:42,736
将从二乘二像素组中读

248
00:11:43,170 --> 0:11:46,440
这里 我们16像素的左下角

249
00:11:47,074 --> 0:11:53,714
它将以half4数组

250
00:11:54,848 --> 0:11:57,618
这四个参数将按此顺序存储

251
00:11:57,684 --> 0:12:02,456
即x、y、z、w

252
00:11:57,684 --> 0:12:02,456
即x、y、z、w

253
00:12:02,623 --> 0:12:04,758
如果你熟悉Metal中的收集操作

254
00:12:04,825 --> 0:12:08,896
这与Metal中使用的方向相同

255
00:12:10,364 --> 0:12:11,832
所以用一条指令

256
00:12:11,899 --> 0:12:14,668
我们完成了四次读取

257
00:12:14,735 --> 0:12:16,036
重复此过程

258
00:12:16,103 --> 0:12:20,307
我们可以得到第二

259
00:12:20,774 --> 0:12:22,609
现在我们完成了所有16次读取

260
00:12:22,676 --> 0:12:25,846
我们需要弄清楚哪些值在哪些位置

261
00:12:26,146 --> 0:12:27,648
所以我们首先要做的是

262
00:12:27,714 --> 0:12:31,685
得到这个三乘三子组的适当通道

263
00:12:32,553 --> 0:12:34,121
并将它们平均在一起

264
00:12:34,354 --> 0:12:36,456
然后我们把这些频道

265
00:12:36,890 --> 0:12:38,792
存入r1变量

266
00:12:39,526 --> 0:12:40,994
我们将重复这一过程

267
00:12:41,061 --> 0:12:46,700
写入其它四个结果像素：

268
00:12:47,501 --> 0:12:50,637
我们要做的最后一件事就是目标写入

269
00:12:51,004 --> 0:12:53,740
在一次操作中写入四个像素

270
00:12:54,274 --> 0:12:57,177
注意 这与传统的CI内核略有不同

271
00:12:57,244 --> 0:13:00,147
过去我们从内核返回一个值

272
00:12:57,244 --> 0:13:00,147
过去我们从内核返回一个值

273
00:13:00,214 --> 0:13:03,750
而现在我们将调用目标写入

274
00:13:05,552 --> 0:13:08,422
好 这一切的精彩之处是

275
00:13:08,722 --> 0:13:10,224
只需很少的努力

276
00:13:10,290 --> 0:13:13,794
我们可以在同样的着色器中

277
00:13:13,861 --> 0:13:14,828
这是一个非常简单的着色器

278
00:13:14,895 --> 0:13:16,797
你可获得类似的结果

279
00:13:16,864 --> 0:13:18,065
可在许多其它类型的着色器中实现

280
00:13:18,131 --> 0:13:20,200
尤其是作卷积的那些

281
00:13:20,634 --> 0:13:24,304
这是为内核提高性能的好方法

282
00:13:25,172 --> 0:13:27,441
我想告诉大家

283
00:13:27,508 --> 0:13:31,345
来看看这个很棒的内核语言新文档

284
00:13:31,645 --> 0:13:33,347
不论是传统的CI内核语言

285
00:13:33,413 --> 0:13:36,450
还是基于Metal的CI内核语言

286
00:13:36,517 --> 0:13:39,052
我强烈建议你阅读本文档

287
00:13:39,419 --> 0:13:41,655
现在我们讲过了为内核运行

288
00:13:41,722 --> 0:13:42,956
提高性能的问题

289
00:13:43,490 --> 0:13:46,960
我想请Emmanuel上台

290
00:13:47,027 --> 0:13:49,796
来讲如何使你的新算法的

291
00:13:49,863 --> 0:13:50,864
开发过程更快

292
00:13:55,702 --> 0:13:56,537
谢谢 David

293
00:13:59,139 --> 0:14:00,307
大家下午好

294
00:13:59,139 --> 0:14:00,307
大家下午好

295
00:14:00,774 --> 0:14:01,775
很高兴来到这里

296
00:14:01,842 --> 0:14:04,344
我叫Emmanuel

297
00:14:05,412 --> 0:14:07,447
本场会议的下半场时间

298
00:14:07,648 --> 0:14:10,217
我们将把注意力

299
00:14:10,284 --> 0:14:14,154
转而探索用Core Image

300
00:14:14,788 --> 0:14:16,657
我们还会看看

301
00:14:16,723 --> 0:14:19,860
如何在机器学习app中

302
00:14:19,927 --> 0:14:20,894
我们开始吧

303
00:14:22,329 --> 0:14:24,064
既然我们谈到原型设计

304
00:14:24,131 --> 0:14:27,868
我们先看看图像处理过滤器的

305
00:14:30,137 --> 0:14:33,440
比如我们想做

306
00:14:33,507 --> 0:14:35,742
前景背景分割

307
00:14:35,809 --> 0:14:39,980
这意味着我们想得到一个掩码

308
00:14:40,047 --> 0:14:43,717
前景为1.0

309
00:14:43,784 --> 0:14:45,485
二者之间有连续值

310
00:14:46,753 --> 0:14:48,989
实现此类过滤器的难度

311
00:14:49,056 --> 0:14:51,592
很大程度上取决于数据的特性

312
00:14:51,658 --> 0:14:56,129
例如 如果你有一个

313
00:14:56,296 --> 0:14:58,298
与你的RGB图像一起

314
00:14:58,565 --> 0:15:00,267
事情可以变得更容易

315
00:14:58,565 --> 0:15:00,267
事情可以变得更容易

316
00:15:00,534 --> 0:15:04,338
如果你有兴趣将RGB图像

317
00:15:04,872 --> 0:15:07,241
我强烈建议你查看

318
00:15:07,307 --> 0:15:09,243
用深度创建照片和视频效果的演讲

319
00:15:10,444 --> 0:15:14,114
今天我不想专注于这些其它信息来源

320
00:15:14,181 --> 0:15:16,450
我想专注于一般的原型设计

321
00:15:18,852 --> 0:15:23,290
假设我们已经完成了这个过滤器

322
00:15:23,357 --> 0:15:25,559
我们知道我们想要达到的效果

323
00:15:25,626 --> 0:15:28,395
在这种特殊情况下 前景和背景掩码

324
00:15:28,462 --> 0:15:31,298
下一步我们自然而然想实现它

325
00:15:31,465 --> 0:15:33,667
选择你最喜欢的原型

326
00:15:33,934 --> 0:15:35,135
然后就开始尝试了

327
00:15:35,736 --> 0:15:38,906
并将不同的过滤器组合在一起并显示

328
00:15:38,972 --> 0:15:42,409
以达到你寻找的过滤效果

329
00:15:43,877 --> 0:15:45,345
假设你这么做了

330
00:15:45,412 --> 0:15:50,551
这里我们有一个

331
00:15:51,552 --> 0:15:53,754
如你在iOS或macOS环境中

332
00:15:54,054 --> 0:15:57,591
下一个步骤自然而然是实施该算法

333
00:15:57,658 --> 0:16:01,295
你可以使用各种生成后端

334
00:15:57,658 --> 0:16:01,295
你可以使用各种生成后端

335
00:16:01,361 --> 0:16:02,196
如Core Image

336
00:16:04,631 --> 0:16:06,466
Metal及Metal性能着色器

337
00:16:06,700 --> 0:16:09,236
及vImage

338
00:16:10,337 --> 0:16:14,408
从原型到产品的初始转换

339
00:16:14,474 --> 0:16:18,512
第一次生成可能看起来

340
00:16:19,313 --> 0:16:21,648
有各种各样的原因

341
00:16:21,715 --> 0:16:23,584
可能导致这些像素差异

342
00:16:23,650 --> 0:16:25,452
其中一个就是

343
00:16:25,519 --> 0:16:28,021
过滤器在不同框架的实现方式

344
00:16:28,088 --> 0:16:29,122
可能完全不同

345
00:16:29,590 --> 0:16:31,458
我们看左边这个例子

346
00:16:31,525 --> 0:16:34,328
我们有一个恒定的模糊

347
00:16:34,595 --> 0:16:36,029
从前台到背景

348
00:16:36,530 --> 0:16:39,733
这个过滤器的示例

349
00:16:39,800 --> 0:16:42,336
可以显示各种性能优化

350
00:16:42,402 --> 0:16:43,570
使其加速

351
00:16:44,338 --> 0:16:47,508
这些优化会引入数字误差

352
00:16:47,574 --> 0:16:49,476
而在过滤器堆栈中传播

353
00:16:50,077 --> 0:16:53,981
从而可能会对过滤器输出

354
00:16:55,649 --> 0:16:58,785
当你写代码时

355
00:16:58,852 --> 0:17:00,654
是在原型环境中

356
00:16:58,852 --> 0:17:00,654
是在原型环境中

357
00:17:00,721 --> 0:17:02,489
很多内存管理都是自动发生的

358
00:17:02,556 --> 0:17:05,526
因此你不会经常遇到内存压力

359
00:17:05,592 --> 0:17:08,161
直到开发的后期

360
00:17:10,297 --> 0:17:15,736
当然 另一个需要考虑的主题是性能

361
00:17:16,369 --> 0:17:18,972
通常 原型已经在使用CPU代码

362
00:17:19,205 --> 0:17:23,143
我们经常高估

363
00:17:23,210 --> 0:17:25,512
将CP代码指向GP代码的性能提高

364
00:17:25,579 --> 0:17:27,681
以为一切都会变得实时

365
00:17:28,482 --> 0:17:31,685
如果我们能够尽早抓住这些问题呢？

366
00:17:31,752 --> 0:17:34,221
早到原型设计和工作流程中？

367
00:17:35,522 --> 0:17:37,424
我们相信有这个办法

368
00:17:37,491 --> 0:17:39,426
它叫PyCoreImage

369
00:17:39,593 --> 0:17:41,228
Core Image的

370
00:17:42,262 --> 0:17:46,366
这是结合Core Image的

371
00:17:46,800 --> 0:17:50,270
和Python编程语言的灵活性

372
00:17:51,038 --> 0:17:52,239
用Core Image时

373
00:17:52,306 --> 0:17:55,676
你还继承了对iOS

374
00:17:55,976 --> 0:17:58,245
以及200多个内置过滤器

375
00:17:58,912 --> 0:18:02,282
我们来看看

376
00:17:58,912 --> 0:18:02,282
我们来看看

377
00:18:04,184 --> 0:18:06,653
PyCoreImage

378
00:18:07,754 --> 0:18:10,224
它用Core Image

379
00:18:10,891 --> 0:18:13,794
用Python作为编程接口

380
00:18:14,862 --> 0:18:18,799
它还有一层薄薄NumPy连接代码

381
00:18:18,866 --> 0:18:21,602
以期与现有代码库互操作

382
00:18:23,170 --> 0:18:25,706
我们相信

383
00:18:25,772 --> 0:18:28,375
你的原型设计和产品代码之间的摩擦

384
00:18:29,209 --> 0:18:31,211
如你想留在

385
00:18:31,278 --> 0:18:33,780
使用Swift Playground

386
00:18:33,847 --> 0:18:35,449
我们鼓励你查看

387
00:18:35,516 --> 0:18:38,919
创建自己的

388
00:18:41,822 --> 0:18:45,425
我们来看看

389
00:18:46,159 --> 0:18:50,297
因此 PyCoreImage利用Python

390
00:18:50,731 --> 0:18:51,865
而且有趣的是

391
00:18:52,232 --> 0:18:55,202
我们自macOS 10.5

392
00:18:56,670 --> 0:18:58,972
它最初是作为Python

393
00:18:59,039 --> 0:19:00,440
双向桥实现的

394
00:18:59,039 --> 0:19:00,440
双向桥实现的

395
00:19:00,741 --> 0:19:03,310
特别是在Coco app

396
00:19:03,377 --> 0:19:06,847
但从那以后扩展到

397
00:19:09,383 --> 0:19:12,085
PyObjC的调用语法非常简单

398
00:19:12,152 --> 0:19:15,489
获取现有Objective C代码

399
00:19:15,789 --> 0:19:17,157
还有一些细节

400
00:19:17,224 --> 0:19:20,227
如果你想了解更多

401
00:19:20,994 --> 0:19:23,830
我们以CIVector类为例

402
00:19:24,331 --> 0:19:25,832
这里有一些

403
00:19:25,899 --> 0:19:27,534
我们创建CIVector的实例

404
00:19:27,601 --> 0:19:28,735
调用CIVector

405
00:19:29,703 --> 0:19:31,905
带X、Y、Z、W的向量

406
00:19:32,840 --> 0:19:34,374
我们来看看PyObjC代码

407
00:19:34,675 --> 0:19:36,577
这非常相似

408
00:19:36,643 --> 0:19:38,178
导入CIVector

409
00:19:39,046 --> 0:19:42,349
我们可以直接调用带X、Y、Z、W

410
00:19:44,218 --> 0:19:45,786
你要注意的是这些代码

411
00:19:45,853 --> 0:19:47,454
并不完全像Python一样

412
00:19:47,921 --> 0:19:50,324
我们将在几分钟内谈这个问题

413
00:19:53,227 --> 0:19:55,896
现在我们来看看

414
00:19:56,230 --> 0:19:58,365
生成后端用Core Image

415
00:19:58,432 --> 0:20:00,400
Core Image非常接近硬件

416
00:19:58,432 --> 0:20:00,400
Core Image非常接近硬件

417
00:20:00,667 --> 0:20:02,436
因此可以重定向过滤的方程

418
00:20:02,503 --> 0:20:04,505
到最合适的生成后端

419
00:20:04,571 --> 0:20:06,607
为你提供尽可能高的性能

420
00:20:07,374 --> 0:20:09,343
PyObjC存在于

421
00:20:09,409 --> 0:20:12,880
它可以通过Core Image的

422
00:20:13,180 --> 0:20:15,082
由Quartz伞包提供

423
00:20:15,649 --> 0:20:18,819
Quartz伞包同时包含

424
00:20:18,886 --> 0:20:21,788
各种其它图像处理框架

425
00:20:21,855 --> 0:20:23,991
以及使用

426
00:20:24,057 --> 0:20:26,627
例如CIVector、CIImages

427
00:20:28,662 --> 0:20:35,235
PyCoreImage位于PyObjC之上

428
00:20:35,669 --> 0:20:37,504
与Core Image通信

429
00:20:37,571 --> 0:20:40,307
并为你做了很多简化

430
00:20:40,741 --> 0:20:44,144
以便你在用Core Image时

431
00:20:44,211 --> 0:20:46,046
我们稍后会看一下这个

432
00:20:47,014 --> 0:20:49,349
这里很多都是通过CIMG类完成的

433
00:20:49,416 --> 0:20:53,153
你用它通过供应商方程

434
00:20:53,787 --> 0:20:56,223
你也可以包装NumPy缓冲区

435
00:20:56,456 --> 0:20:58,325
直接使用类构造函数

436
00:21:00,260 --> 0:21:01,895
让我们举一个例子

437
00:21:01,962 --> 0:21:03,797
看如何用

438
00:21:03,864 --> 0:21:06,567
你会看到这个框架多么简单和强大

439
00:21:07,134 --> 0:21:08,402
你首先要做的是

440
00:21:08,468 --> 0:21:11,271
从PyCoreImage包

441
00:21:12,072 --> 0:21:14,208
我们可以用它从文件加载图像

442
00:21:15,409 --> 0:21:18,679
注意 此时我们没有像素缓冲区

443
00:21:19,012 --> 0:21:20,647
Core Image

444
00:21:20,714 --> 0:21:22,516
在这种特殊情况下

445
00:21:22,583 --> 0:21:26,320
这个配方只是提供

446
00:21:27,754 --> 0:21:29,356
你可以用过滤器

447
00:21:29,423 --> 0:21:30,657
创建更复杂的图表

448
00:21:30,724 --> 0:21:32,960
只需在其上调用CI过滤器名称

449
00:21:33,026 --> 0:21:35,529
并传递输入原色

450
00:21:35,696 --> 0:21:38,131
可看到我们正组装一个更复杂的图形

451
00:21:38,198 --> 0:21:39,299
如果我们放大它

452
00:21:39,533 --> 0:21:41,235
我们可以看到模糊处理器

453
00:21:41,301 --> 0:21:42,202
就在中间

454
00:21:43,670 --> 0:21:45,739
如果你想获得像素缓冲区表示

455
00:21:45,806 --> 0:21:47,608
你可以在CIMG实例上

456
00:21:47,674 --> 0:21:48,909
调用生成

457
00:21:48,976 --> 0:21:52,012
你会得到一个合适的

458
00:21:55,782 --> 0:21:56,984
为了做到这一点

459
00:21:57,050 --> 0:22:00,120
我们需要对Core Image的

460
00:21:57,050 --> 0:22:00,120
我们需要对Core Image的

461
00:22:00,187 --> 0:22:01,922
或为你做一些设置代码

462
00:22:02,489 --> 0:22:05,993
对于已经熟悉

463
00:22:06,727 --> 0:22:08,762
这不会让人感到意外

464
00:22:08,829 --> 0:22:10,631
但对于不熟悉它的人

465
00:22:10,964 --> 0:22:12,432
我们一起看看步骤

466
00:22:12,499 --> 0:22:17,237
你将看到我们作的一些简化

467
00:22:18,805 --> 0:22:22,242
Core Image是一个

468
00:22:22,309 --> 0:22:24,378
同时支持iOS和macOS

469
00:22:24,444 --> 0:22:26,713
以及各种生成后端

470
00:22:27,881 --> 0:22:29,583
支持大多数像素格式

471
00:22:30,417 --> 0:22:32,319
这当然意味着位图数据

472
00:22:32,386 --> 0:22:35,122
以及来自各供应商的原始文件

473
00:22:36,590 --> 0:22:39,359
支持大多数文件格式

474
00:22:40,694 --> 0:22:44,898
就像刚才说的 来自各种供应商的

475
00:22:44,965 --> 0:22:46,400
支持大多数像素格式

476
00:22:46,466 --> 0:22:49,903
例如 你可以用无符号8位加载图像

477
00:22:50,237 --> 0:22:52,172
通过计算和半浮动

478
00:22:52,339 --> 0:22:54,908
并在最终生成期间

479
00:22:56,343 --> 0:22:58,879
Core Image可以为你

480
00:22:58,946 --> 0:23:03,917
例如 捕获时间

481
00:22:58,946 --> 0:23:03,917
例如 捕获时间

482
00:23:03,984 --> 0:23:07,020
例如人像地图和人像深度信息

483
00:23:09,356 --> 0:23:11,692
Core Image

484
00:23:11,758 --> 0:23:15,262
这是一个高难度的问题

485
00:23:16,263 --> 0:23:18,498
Core Image

486
00:23:18,832 --> 0:23:20,100
无限图像

487
00:23:20,334 --> 0:23:22,769
并且有200多个内置过滤器供使用

488
00:23:22,836 --> 0:23:24,471
你可以拿来即用

489
00:23:25,272 --> 0:23:26,773
好 我不需要说服你

490
00:23:26,840 --> 0:23:28,275
那是很多信息

491
00:23:28,342 --> 0:23:30,143
并且如果你尝试

492
00:23:30,444 --> 0:23:32,079
使用Core Image

493
00:23:33,614 --> 0:23:35,148
学习曲线可能相当陡峭

494
00:23:35,215 --> 0:23:37,684
所以我们所做的就是

495
00:23:38,051 --> 0:23:39,453
进行了一些简化

496
00:23:39,653 --> 0:23:41,221
请记住 这些简化

497
00:23:41,288 --> 0:23:42,956
都可以随时被覆盖

498
00:23:43,123 --> 0:23:44,925
因为我们会给你加权代码

499
00:23:44,992 --> 0:23:46,693
你其实可以对这些更改进行硬编码

500
00:23:46,760 --> 0:23:48,495
如果这适合你的原型堆栈

501
00:23:49,696 --> 0:23:51,465
我们做的第一件事就是我们还有

502
00:23:51,532 --> 0:23:54,401
Core Image的高性能功能

503
00:23:54,468 --> 0:23:56,003
我们仍生成到Metal后端

504
00:23:56,470 --> 0:23:58,639
仍然支持几乎所有输入输出格式

505
00:23:59,072 --> 0:24:01,108
我们仍然可以提取数据的捕获时间

506
00:23:59,072 --> 0:24:01,108
我们仍然可以提取数据的捕获时间

507
00:24:01,175 --> 0:24:04,811
以及纵向深度和褪光信息

508
00:24:05,512 --> 0:24:08,982
最后一个重点

509
00:24:09,850 --> 0:24:11,952
我们做的第一个更改是 默认情况下

510
00:24:12,019 --> 0:24:14,988
所有生成都用

511
00:24:16,890 --> 0:24:20,260
第二个更改

512
00:24:21,662 --> 0:24:25,032
第三 所有的边界条件都将

513
00:24:25,098 --> 0:24:28,869
这意味着 如果你正在应用卷积运算

514
00:24:29,536 --> 0:24:31,672
例如你的图片无限重复

515
00:24:32,172 --> 0:24:33,340
将应用过滤器

516
00:24:33,540 --> 0:24:36,376
并将生成的图像裁剪回输入尺寸

517
00:24:36,977 --> 0:24:40,480
这也是一个可以一次覆盖的设置

518
00:24:42,282 --> 0:24:44,685
最后 无限的图像变得有限

519
00:24:44,852 --> 0:24:47,487
这样我们可以获取其像素缓冲区表示

520
00:24:49,590 --> 0:24:53,026
这就是为何PyCoreImage

521
00:24:54,061 --> 0:24:54,895
所以…

522
00:24:55,495 --> 0:24:58,932
我们将作精彩演示

523
00:24:58,999 --> 0:25:02,703
在此之前 我想快速过一下

524
00:24:58,999 --> 0:25:02,703
在此之前 我想快速过一下

525
00:25:02,769 --> 0:25:04,204
我们来看看API

526
00:25:04,872 --> 0:25:07,875
正如你之前看到的

527
00:25:07,941 --> 0:25:09,309
导入了CIMG类

528
00:25:10,143 --> 0:25:13,180
我们可以调用fromFile

529
00:25:14,114 --> 0:25:16,517
你如果想知道的话

530
00:25:16,583 --> 0:25:18,585
你可以用

531
00:25:20,821 --> 0:25:23,857
你可以使用fromFile

532
00:25:23,924 --> 0:25:25,259
以及肖像深度

533
00:25:25,325 --> 0:25:28,762
只需使用可选参数

534
00:25:31,298 --> 0:25:35,435
你可以通过把NumPy缓冲区

535
00:25:35,502 --> 0:25:37,037
来解释NumPy

536
00:25:37,404 --> 0:25:40,007
或直接在CIImage实例下

537
00:25:40,073 --> 0:25:41,241
此为另一个选择

538
00:25:43,443 --> 0:25:44,344
如果你用Swift

539
00:25:44,411 --> 0:25:45,879
还有一些代码要写

540
00:25:45,946 --> 0:25:48,115
你需要先创建一个

541
00:25:48,549 --> 0:25:50,851
确保你预先分配了缓冲区

542
00:25:51,718 --> 0:25:53,820
和提供正确的缓冲区属性

543
00:25:53,887 --> 0:25:58,292
创建CIContext

544
00:25:59,626 --> 0:26:01,728
这些都是在幕后处理的

545
00:25:59,626 --> 0:26:01,728
这些都是在幕后处理的

546
00:26:02,829 --> 0:26:05,165
Core Image

547
00:26:05,232 --> 0:26:07,201
例如从颜色创建图像

548
00:26:07,768 --> 0:26:09,469
或从生成器创建图像

549
00:26:11,805 --> 0:26:13,774
现在我们看一下如何应用过滤器

550
00:26:14,942 --> 0:26:16,677
应用过滤器再简单不过了

551
00:26:16,743 --> 0:26:18,078
拿一个CIImage实例

552
00:26:18,345 --> 0:26:22,282
直接在上调用过滤器名

553
00:26:22,916 --> 0:26:27,721
每个CIImage实例都增加了

554
00:26:28,121 --> 0:26:30,991
直接映射到

555
00:26:31,925 --> 0:26:32,826
如果你用Swift

556
00:26:32,893 --> 0:26:34,962
这是你之前看到的语法

557
00:26:35,028 --> 0:26:39,499
应用过滤器

558
00:26:39,566 --> 0:26:41,568
以键值对的字典方式

559
00:26:43,604 --> 0:26:47,441
要应用内核 可以在CIMG实例中

560
00:26:47,908 --> 0:26:50,677
传入包含内核代码的源字符串

561
00:26:51,345 --> 0:26:53,847
以及输入参数列表到该内核

562
00:26:53,914 --> 0:26:55,949
我们等会儿再看一看

563
00:26:57,417 --> 0:26:59,820
然后你只需指定应用该内核的范围

564
00:26:59,887 --> 0:27:03,957
以及你在缓冲区中采样的感兴趣区域

565
00:26:59,887 --> 0:27:03,957
以及你在缓冲区中采样的感兴趣区域

566
00:27:04,024 --> 0:27:05,292
采样源

567
00:27:07,160 --> 0:27:11,031
PyCoreImage

568
00:27:11,098 --> 0:27:12,666
如复合操作

569
00:27:12,733 --> 0:27:13,867
这是一个来源…

570
00:27:14,368 --> 0:27:17,271
以及翻译等几何操作

571
00:27:17,604 --> 0:27:19,673
缩放 旋转…

572
00:27:20,240 --> 0:27:21,074
和裁剪

573
00:27:23,410 --> 0:27:28,415
我想在GPU内核上再花一点时间

574
00:27:28,482 --> 0:27:31,652
因为这是一个非常强大的功能

575
00:27:31,718 --> 0:27:33,554
我们这里有一个字符串

576
00:27:33,620 --> 0:27:36,156
包含GPU片段着色器的代码

577
00:27:36,690 --> 0:27:39,326
我们所拥有的基本上是一种方式

578
00:27:39,393 --> 0:27:41,995
让你实时原型化那种效果

579
00:27:43,664 --> 0:27:45,599
这是5抽头拉普拉斯算子的一个例子

580
00:27:45,832 --> 0:27:48,135
我们将使用它进行锐化

581
00:27:48,502 --> 0:27:51,305
我们在每个像素的邻域中

582
00:27:51,772 --> 0:27:53,941
以计算局部导数的方式组合它们

583
00:27:54,007 --> 0:27:55,409
这将成为我们的细节

584
00:27:55,475 --> 0:27:58,045
我们添加回中心像素的顶部

585
00:27:58,779 --> 0:28:01,782
我不想太过关注过滤器本身

586
00:27:58,779 --> 0:28:01,782
我不想太过关注过滤器本身

587
00:28:02,149 --> 0:28:05,719
所以 我们称之为

588
00:28:06,520 --> 0:28:08,021
低音源代码

589
00:28:08,088 --> 0:28:11,091
只是在那里的

590
00:28:12,459 --> 0:28:15,262
传递我们将要应用内核的范围

591
00:28:17,164 --> 0:28:18,565
并定义感兴趣的区域

592
00:28:18,632 --> 0:28:21,335
和我们将要采样的表达式

593
00:28:21,802 --> 0:28:24,972
如果你不熟悉目标域的概念

594
00:28:25,038 --> 0:28:26,607
以及感兴趣的地区

595
00:28:26,840 --> 0:28:29,476
我建议你查看

596
00:28:29,543 --> 0:28:31,612
以及之前的WWDC演讲

597
00:28:32,112 --> 0:28:34,181
但这是卷积内核

598
00:28:34,348 --> 0:28:36,250
我们正在距离边界一个像素读取

599
00:28:36,316 --> 0:28:39,253
我们需要指示Core Image

600
00:28:39,319 --> 0:28:41,655
以便它可以正确处理边界条件

601
00:28:43,023 --> 0:28:43,857
好

602
00:28:43,924 --> 0:28:45,125
这里有很多信息

603
00:28:45,192 --> 0:28:48,495
并且看API总是有点枯燥

604
00:28:48,562 --> 0:28:51,765
所以我们来看一个演示

605
00:29:01,808 --> 0:29:02,876
好 在演示期间

606
00:29:02,943 --> 0:29:04,811
我将用

607
00:29:05,112 --> 0:29:08,682
这是一个基于浏览器的

608
00:29:09,449 --> 0:29:11,585
你将看到的所有结果

609
00:29:11,652 --> 0:29:14,755
都是用后端的

610
00:29:14,821 --> 0:29:16,356
而不是预先计算过

611
00:29:16,423 --> 0:29:17,658
这一切都是现场完成的

612
00:29:18,292 --> 0:29:19,927
我想在这里做的第一件事

613
00:29:19,993 --> 0:29:23,530
导入我们将要用的实用程序类

614
00:29:23,730 --> 0:29:25,632
这里最重要的是CIMG类

615
00:29:25,699 --> 0:29:27,034
用于我的PyCoreImage包

616
00:29:27,968 --> 0:29:29,336
然后我们只需一些设置代码

617
00:29:29,403 --> 0:29:32,306
以便我们可视化该笔记本中的图像

618
00:29:32,906 --> 0:29:33,774
我们开始

619
00:29:35,342 --> 0:29:37,911
第一是如何加载图像

620
00:29:38,512 --> 0:29:39,813
在此用fromFile

621
00:29:40,214 --> 0:29:45,619
我们看到我的对象类型是

622
00:29:46,053 --> 0:29:47,387
我们可以看到它后面的支持

623
00:29:47,454 --> 0:29:50,691
是一个正确的

624
00:29:51,558 --> 0:29:54,661
我们可以对图像进行生成并

625
00:29:56,697 --> 0:29:59,833
查看实际的像素表示

626
00:30:00,133 --> 0:30:01,401
这是我们的输入图片

627
00:30:02,436 --> 0:30:05,405
现在我想在其上应用过滤器

628
00:30:05,472 --> 0:30:07,741
我们来看看这200多个

629
00:30:07,808 --> 0:30:09,710
过滤器

630
00:30:13,046 --> 0:30:15,949
比如说我想在这里应用高斯模糊

631
00:30:16,016 --> 0:30:17,451
我想知道哪些参数

632
00:30:17,518 --> 0:30:18,685
被该过滤器支持

633
00:30:18,752 --> 0:30:20,988
所以我在我的CIMG类上调用输入

634
00:30:21,555 --> 0:30:23,991
我看到它支持输入图像

635
00:30:24,324 --> 0:30:26,660
不奇怪的是 还有标准差

636
00:30:27,327 --> 0:30:28,795
所以 我将在这里做

637
00:30:29,763 --> 0:30:30,864
拍摄输入图像

638
00:30:31,365 --> 0:30:34,701
在其上应用高斯模糊过滤器

639
00:30:35,135 --> 0:30:36,703
然后并排显示两个图像

640
00:30:38,739 --> 0:30:41,808
非常简单 对吧？

641
00:30:42,075 --> 0:30:43,911
好 我们继续吧

642
00:30:45,112 --> 0:30:47,281
如我之前提到 你可以生成过程图像

643
00:30:47,347 --> 0:30:48,182
用Core Image

644
00:30:48,248 --> 0:30:50,617
我们来看看

645
00:30:51,485 --> 0:30:54,621
第一件事是我们调用

646
00:30:54,688 --> 0:30:56,256
指定生成器的名称

647
00:30:56,323 --> 0:30:57,691
在这里CIQRCode

648
00:30:58,358 --> 0:31:01,562
并在我们尝试编码的消息中传递它们

649
00:30:58,358 --> 0:31:01,562
并在我们尝试编码的消息中传递它们

650
00:31:02,296 --> 0:31:03,397
这是实时的

651
00:31:03,463 --> 0:31:06,333
所以我可以对该消息进行更改

652
00:31:06,400 --> 0:31:09,570
并查看它如何影响正在生成的QR码

653
00:31:11,605 --> 0:31:13,974
Core Image

654
00:31:14,041 --> 0:31:16,210
你可以用

655
00:31:16,977 --> 0:31:18,345
这里有个例子

656
00:31:18,912 --> 0:31:21,849
WWDC并使用SFLO字体

657
00:31:23,050 --> 0:31:24,518
好 我们继续

658
00:31:25,385 --> 0:31:29,356
刚才提到过

659
00:31:29,423 --> 0:31:31,525
这是我们要做的第一件事

660
00:31:32,159 --> 0:31:34,962
我们将从图像开始并应用一些有趣的

661
00:31:35,028 --> 0:31:36,096
且有明显影响的变化

662
00:31:36,163 --> 0:31:37,698
这种情况下 是一个涡旋畸变

663
00:31:39,299 --> 0:31:40,534
接下来我们要做的

664
00:31:40,601 --> 0:31:41,902
我们将生成该缓冲区

665
00:31:44,271 --> 0:31:46,139
从中获取NumPy区域

666
00:31:46,206 --> 0:31:47,441
这里我们看到它的类型

667
00:31:47,808 --> 0:31:48,842
和它的形状

668
00:31:49,443 --> 0:31:50,377
它的深度

669
00:31:51,144 --> 0:31:52,613
以及一些统计数据

670
00:31:52,679 --> 0:31:54,181
这是最小值 中值

671
00:31:54,481 --> 0:31:55,949
以及它的最大值

672
00:31:58,719 --> 0:32:00,254
我们也可以走另一条路

673
00:31:58,719 --> 0:32:00,254
我们也可以走另一条路

674
00:32:00,320 --> 0:32:02,022
从NumPy到CoreImage

675
00:32:03,090 --> 0:32:05,225
让我们从NumPy数组开始

676
00:32:05,292 --> 0:32:06,260
这不是件小事情

677
00:32:06,326 --> 0:32:08,829
这里 一个随机缓冲区

678
00:32:08,896 --> 0:32:11,899
其中75%的值已经渐变为黑色

679
00:32:13,634 --> 0:32:17,337
我首先将我的NuPy数组

680
00:32:17,671 --> 0:32:20,407
可以看到我们又有了

681
00:32:20,741 --> 0:32:22,409
和支持它的CIImage

682
00:32:24,711 --> 0:32:26,113
现在我有了CIImage

683
00:32:26,180 --> 0:32:27,848
我可以在其上应用各种过滤器

684
00:32:28,182 --> 0:32:30,918
我首先应用这个模糊化

685
00:32:31,351 --> 0:32:33,453
我将使用电线滤波器

686
00:32:34,188 --> 0:32:35,622
改变图像的对比度

687
00:32:35,956 --> 0:32:38,859
调整曝光及伽玛值

688
00:32:39,860 --> 0:32:42,062
我们一起看看这些过滤器

689
00:32:42,896 --> 0:32:46,099
在模糊化、光隧道

690
00:32:46,500 --> 0:32:47,668
这是我们的最终效果

691
00:32:48,368 --> 0:32:50,137
非常有趣 非常易用

692
00:32:52,406 --> 0:32:53,674
我们把它们放在一起

693
00:32:53,740 --> 0:32:55,709
这里我开始一个新的图像

694
00:32:56,343 --> 0:32:58,946
我在下面这个演示中向你展示的是

695
00:32:59,012 --> 0:33:00,547
如何做弯曲处理

696
00:32:59,012 --> 0:33:00,547
如何做弯曲处理

697
00:33:01,014 --> 0:33:02,950
如果你熟悉Python的切片操作

698
00:33:03,016 --> 0:33:05,118
这正是我们要做的

699
00:33:05,185 --> 0:33:08,822
我们将在图像中定义带或切片

700
00:33:09,223 --> 0:33:11,658
我们只对这些切片应用过滤器

701
00:33:12,492 --> 0:33:14,494
让我们先来看一下代码

702
00:33:15,429 --> 0:33:16,964
这是我们的添加带功能

703
00:33:17,531 --> 0:33:19,666
我们可以看到它的最底层

704
00:33:20,400 --> 0:33:22,102
我们用两种复合材料生成图像

705
00:33:22,169 --> 0:33:23,637
这是实际的NumPy缓冲区

706
00:33:23,704 --> 0:33:25,672
但右边是CIImage

707
00:33:26,507 --> 0:33:27,708
通过使用这样的切片

708
00:33:27,774 --> 0:33:30,577
我们强制Core Image

709
00:33:30,644 --> 0:33:31,778
而不是整个图片

710
00:33:32,045 --> 0:33:35,382
因此效率更高

711
00:33:37,551 --> 0:33:40,721
我们这样做并在我们的图像中

712
00:33:40,787 --> 0:33:42,222
并显示最终的合成

713
00:33:45,092 --> 0:33:47,794
非常棒

714
00:33:48,996 --> 0:33:51,298
对应于应用的过滤器

715
00:33:51,865 --> 0:33:54,101
使用PyCoreImage

716
00:33:54,434 --> 0:33:56,370
好的

717
00:33:56,436 --> 0:33:58,505
所以让我们快速看看这个

718
00:33:59,306 --> 0:34:00,240
我想给你看的第一个是

719
00:33:59,306 --> 0:34:00,240
我想给你看的第一个是

720
00:34:00,307 --> 0:34:03,377
每当你在CIImage实例上

721
00:34:03,710 --> 0:34:06,547
NumPy被预处理并缓存

722
00:34:07,047 --> 0:34:08,649
例如 我们在这里创建一个图像

723
00:34:08,715 --> 0:34:11,251
我们按比例缩小

724
00:34:11,585 --> 0:34:13,520
第一次调用历时56毫秒

725
00:34:13,587 --> 0:34:15,088
第二次只需两毫秒

726
00:34:15,989 --> 0:34:18,725
让我们来看看大卷积

727
00:34:18,792 --> 0:34:20,494
Core Image非常快

728
00:34:20,960 --> 0:34:23,096
并且能够处理大型卷积

729
00:34:23,163 --> 0:34:24,264
轻松搞定

730
00:34:24,531 --> 0:34:26,466
这里我们用CIBlur

731
00:34:26,766 --> 0:34:32,005
一个CIGaussianBlur

732
00:34:32,072 --> 0:34:32,906
这很大

733
00:34:33,206 --> 0:34:34,741
这里给大家一个概念

734
00:34:34,808 --> 0:34:36,643
我向你展示这个图像时

735
00:34:36,909 --> 0:34:40,179
我实际用scikit-image

736
00:34:40,480 --> 0:34:42,549
我们的运行时间是16秒

737
00:34:42,949 --> 0:34:45,052
但这次使用

738
00:34:45,351 --> 0:34:46,954
一百三十毫秒

739
00:34:47,221 --> 0:34:48,388
是的 就是这么快

740
00:34:48,455 --> 0:34:49,755
200倍 耶

741
00:34:50,324 --> 0:34:51,158
谢谢

742
00:34:52,525 --> 0:34:53,560
好吧 我们继续

743
00:34:53,627 --> 0:34:56,663
PyCoreImage

744
00:34:56,730 --> 0:35:00,200
是内联创建自定义GP内核的能力

745
00:34:56,730 --> 0:35:00,200
是内联创建自定义GP内核的能力

746
00:35:00,267 --> 0:35:01,535
并在动态中执行

747
00:35:01,602 --> 0:35:02,936
并动态修改

748
00:35:03,303 --> 0:35:04,571
我们来看看

749
00:35:08,842 --> 0:35:09,676
好

750
00:35:10,544 --> 0:35:12,980
我首先想要展示的是

751
00:35:13,313 --> 0:35:16,216
因此颜色内核是仅输入一个像素

752
00:35:16,283 --> 0:35:17,518
并输出一个像素的内核

753
00:35:17,818 --> 0:35:20,854
并且不围绕该像素制作任何其它样本

754
00:35:21,455 --> 0:35:23,657
这是我们的输入图像

755
00:35:23,724 --> 0:35:27,561
所以我们实际得到的是一种颜色

756
00:35:28,228 --> 0:35:30,998
我们来看看这个效果

757
00:35:31,064 --> 0:35:33,267
我要把我的红色和蓝色通道

758
00:35:33,333 --> 0:35:34,835
与我的蓝色和红色频道互换

759
00:35:34,902 --> 0:35:36,270
我要反转它们

760
00:35:36,703 --> 0:35:38,172
不是太令人兴奋的效果

761
00:35:38,238 --> 0:35:40,574
但我要告诉你的是我可以

762
00:35:42,676 --> 0:35:45,679
开始打字 然后说

763
00:35:45,746 --> 0:35:46,780
用蓝色频道

764
00:35:47,347 --> 0:35:51,618
我想尝试这里的缩放量

765
00:35:51,685 --> 0:35:53,320
我们可以从.25开始

766
00:35:53,921 --> 0:35:56,089
随意提到相当高的值

767
00:35:56,423 --> 0:35:58,225
并生成有趣的效果

768
00:35:59,026 --> 0:36:01,395
它非常强大

769
00:35:59,026 --> 0:36:01,395
它非常强大

770
00:36:01,461 --> 0:36:03,530
所以你可通过这种方式

771
00:36:03,597 --> 0:36:06,300
并确保达到你正在寻找的效果

772
00:36:08,635 --> 0:36:11,405
我们来看一个更复杂的内核

773
00:36:11,471 --> 0:36:12,873
我们来看一下通用内核

774
00:36:12,940 --> 0:36:15,609
这有点像我之前展示的

775
00:36:15,676 --> 0:36:18,979
这是一个在每个像素附近

776
00:36:19,446 --> 0:36:21,148
所以从文件中的图像开始

777
00:36:21,215 --> 0:36:22,916
这是我们之前看到的同一图像

778
00:36:23,116 --> 0:36:25,219
这里有我们的内核代码

779
00:36:25,285 --> 0:36:26,386
我们略去细节

780
00:36:26,453 --> 0:36:27,654
这是一个双边过滤器

781
00:36:27,721 --> 0:36:29,656
是模糊滤镜的边缘

782
00:36:30,891 --> 0:36:32,793
我们把代码放进去

783
00:36:33,193 --> 0:36:35,262
并带有一些参数调用

784
00:36:36,897 --> 0:36:42,302
可以获得非常好的效果

785
00:36:42,369 --> 0:36:43,904
我们在这里做的 基本上

786
00:36:44,137 --> 0:36:48,342
是剪切图像中的无冗余高频

787
00:36:48,408 --> 0:36:49,409
如果我们看看…

788
00:36:50,043 --> 0:36:51,945
我们更仔细地看一下

789
00:36:53,213 --> 0:36:54,047
看看这里的剪切

790
00:36:54,114 --> 0:36:56,650
我们可以看到强边缘还存在

791
00:36:56,717 --> 0:36:58,919
但是非冗余的精细频率

792
00:36:58,986 --> 0:37:00,020
被冲走了

793
00:36:58,986 --> 0:37:00,020
被冲走了

794
00:37:00,721 --> 0:37:04,258
双边滤波器可用于许多不同目的

795
00:37:04,324 --> 0:37:06,527
在这种情况下

796
00:37:06,927 --> 0:37:08,896
并使用此过滤器实现锐化

797
00:37:09,196 --> 0:37:10,898
我们可以简单地拿左边的图像

798
00:37:11,164 --> 0:37:12,633
并减去右边的图像

799
00:37:12,699 --> 0:37:15,669
为我们提供了图像中

800
00:37:15,736 --> 0:37:16,870
我们这样做

801
00:37:17,905 --> 0:37:20,073
我在这里做的是生成我的图像

802
00:37:20,307 --> 0:37:21,375
它是一个NumPy缓冲区

803
00:37:21,675 --> 0:37:26,146
生成我过滤后的图片

804
00:37:26,713 --> 0:37:29,716
并且用运算符重载将它们一起减去

805
00:37:29,783 --> 0:37:31,151
这是随NumPy提供的操作

806
00:37:31,718 --> 0:37:33,353
让我们来看一下细节层

807
00:37:34,922 --> 0:37:37,691
如果你的左侧有整个图像的细节

808
00:37:37,758 --> 0:37:39,626
和图像中心的裁剪

809
00:37:40,727 --> 0:37:43,730
现在 我们可以做的就是将它添加到

810
00:37:43,797 --> 0:37:44,932
原始图像的顶部

811
00:37:45,866 --> 0:37:47,334
这正是我们要做的

812
00:37:47,401 --> 0:37:49,169
我们将两次加它

813
00:37:50,170 --> 0:37:52,206
通过这样做 我们实现了形成锐化

814
00:37:52,940 --> 0:37:54,041
就是这么简单

815
00:37:54,408 --> 0:37:57,444
如果我想

816
00:37:58,078 --> 0:38:00,981
并开始任意实时进行更改

817
00:37:58,078 --> 0:38:00,981
并开始任意实时进行更改

818
00:38:03,250 --> 0:38:07,221
我还想演示如何从图像中加载元数据

819
00:38:07,788 --> 0:38:09,456
这里我有一张图片

820
00:38:09,523 --> 0:38:11,124
加载了人像效果褪光

821
00:38:11,191 --> 0:38:12,893
以及纵向深度数据

822
00:38:14,094 --> 0:38:15,829
以下是并排的l图片

823
00:38:16,763 --> 0:38:18,665
左侧的图像是RGB图像

824
00:38:18,732 --> 0:38:20,100
中心是深度数据

825
00:38:20,167 --> 0:38:22,503
右侧是高质量的人像效果图

826
00:38:22,569 --> 0:38:24,838
我们今天在另一个演讲上介绍了

827
00:38:26,006 --> 0:38:27,474
我们还可以查看EXIF标记

828
00:38:27,541 --> 0:38:30,344
直接通过查看下层的CIImage

829
00:38:31,545 --> 0:38:34,081
来自相同的G实例和调用属性

830
00:38:35,215 --> 0:38:38,018
这里 我们获得有关捕获本身的信息

831
00:38:39,953 --> 0:38:42,389
像我说的 我们介绍了人像效果褪光

832
00:38:42,456 --> 0:38:44,224
在另一个演讲 演讲503

833
00:38:44,291 --> 0:38:45,993
我强烈建议你去看看那个演讲

834
00:38:46,293 --> 0:38:48,028
所以这里我们略去细节

835
00:38:48,662 --> 0:38:50,230
我将要实现这个过滤器

836
00:38:50,297 --> 0:38:52,833
如果你有兴趣了解如何做到的

837
00:38:53,333 --> 0:38:55,869
我强烈建议你查看本次演讲

838
00:38:57,137 --> 0:38:58,138
非常有意思的东西

839
00:39:00,641 --> 0:39:01,475
谢谢

840
00:39:05,879 --> 0:39:06,713
好

841
00:39:07,080 --> 0:39:08,615
让我们回到本次演讲

842
00:39:08,682 --> 0:39:10,851
我想在这里稍微换档

843
00:39:11,351 --> 0:39:16,490
谈谈将CoreImage

844
00:39:23,363 --> 0:39:27,968
如果你想获得

845
00:39:28,302 --> 0:39:30,737
和人像深度信息

846
00:39:30,804 --> 0:39:33,774
我鼓励你仔细查看有关

847
00:39:35,008 --> 0:39:37,744
我们看看将Core Image

848
00:39:38,846 --> 0:39:41,248
今年 我们非常高兴地宣布

849
00:39:41,315 --> 0:39:43,016
我们推出了一个新的过滤器

850
00:39:43,584 --> 0:39:45,252
CICoreMLModelFilter

851
00:39:45,719 --> 0:39:47,988
这是一个非常简单

852
00:39:48,055 --> 0:39:49,089
需要两个输入

853
00:39:49,957 --> 0:39:53,360
第一个输入是带有滤镜的图像本身

854
00:39:54,361 --> 0:39:55,729
并输入CoreML模型

855
00:39:58,465 --> 0:40:00,501
并且你获得了一个输出

856
00:39:58,465 --> 0:40:00,501
并且你获得了一个输出

857
00:40:00,567 --> 0:40:01,735
已被潜在神经网络处理的输出

858
00:40:01,802 --> 0:40:04,037
这真的很简单 很强大

859
00:40:04,438 --> 0:40:07,708
为了展示代码有多简单

860
00:40:09,142 --> 0:40:10,978
我们在左侧有一个输入图像

861
00:40:11,044 --> 0:40:12,913
你要做的就是调用过滤器

862
00:40:13,413 --> 0:40:15,782
传入我们今年推出的新过滤器

863
00:40:16,216 --> 0:40:18,385
并提供预编译的ML模型

864
00:40:18,452 --> 0:40:19,586
就是这么简单

865
00:40:20,053 --> 0:40:21,855
如果你想看看其它方式

866
00:40:21,922 --> 0:40:24,658
在图像处理app中利用机器学习

867
00:40:24,725 --> 0:40:27,594
我鼓励你看看其它演讲

868
00:40:27,661 --> 0:40:30,531
关于Turi Create指南

869
00:40:33,000 --> 0:40:34,401
一个相关的话题

870
00:40:34,735 --> 0:40:37,804
我们在训练数据集中的常见操作之一

871
00:40:37,871 --> 0:40:39,840
是机器学习中的数据增强

872
00:40:40,541 --> 0:40:42,109
而数据增强

873
00:40:42,643 --> 0:40:46,213
可以显着提高神经网络的稳健性

874
00:40:46,280 --> 0:40:49,716
在这种情况下

875
00:40:50,250 --> 0:40:51,818
我们正在努力确定

876
00:40:51,885 --> 0:40:54,421
该图像是桥还是有水

877
00:40:56,890 --> 0:41:01,161
对原始趋势数据集进行扩充

878
00:40:56,890 --> 0:41:01,161
对原始趋势数据集进行扩充

879
00:41:01,395 --> 0:41:04,064
将增加该数据集中的图像数量

880
00:41:04,131 --> 0:41:06,767
而无需收集新图片

881
00:41:07,301 --> 0:41:08,836
你基本上可以免费得到

882
00:41:09,403 --> 0:41:11,305
所以 你可以携带很多操作

883
00:41:11,371 --> 0:41:13,073
其中一个只是改变它的外观

884
00:41:13,140 --> 0:41:14,808
例如 色调 温度

885
00:41:14,875 --> 0:41:16,343
和图像的白点

886
00:41:17,110 --> 0:41:19,980
通过添加噪声改变图像的光谱属性

887
00:41:21,348 --> 0:41:24,151
或通过应用变换

888
00:41:24,985 --> 0:41:28,188
事实证明 用Core Image

889
00:41:28,856 --> 0:41:30,290
让我们来看几个过滤器

890
00:41:30,357 --> 0:41:33,193
以及如何将它们用于数据增强

891
00:41:34,695 --> 0:41:36,597
我们在左侧有输入图像

892
00:41:37,798 --> 0:41:39,333
我们可以改变温度和色调

893
00:41:39,399 --> 0:41:40,901
用CITemperatureAndTint

894
00:41:41,702 --> 0:41:43,770
我们可以调整亮度 对比度

895
00:41:43,837 --> 0:41:47,875
及用CIColorControls

896
00:41:48,942 --> 0:41:51,578
用CIDither更改图像的频谱

897
00:41:51,645 --> 0:41:53,046
还有CIGaussianBlur

898
00:41:54,648 --> 0:41:57,718
还有用仿射变换更改图像的几何图形

899
00:41:59,186 --> 0:42:00,754
我们来看看实践中的所有这些

900
00:41:59,186 --> 0:42:00,754
我们来看看实践中的所有这些

901
00:42:08,996 --> 0:42:11,231
好 我们回到

902
00:42:11,298 --> 0:42:13,100
与之前相同的设置

903
00:42:13,467 --> 0:42:15,502
我想向你展示的是

904
00:42:15,569 --> 0:42:16,436
作批量增强

905
00:42:17,037 --> 0:42:18,572
我们正在加载图片

906
00:42:19,239 --> 0:42:21,775
我们将在这里定义我们的增强功能

907
00:42:21,842 --> 0:42:23,510
我们要做的主要是

908
00:42:23,577 --> 0:42:24,645
来自随机空间的

909
00:42:24,912 --> 0:42:26,713
为我在这里定义的每个过滤器的抽样

910
00:42:27,181 --> 0:42:30,851
我们将用GaussianBlur

911
00:42:31,251 --> 0:42:33,287
一些调整 曝光调整

912
00:42:33,554 --> 0:42:35,856
纤维以及噪音抖动

913
00:42:37,758 --> 0:42:39,660
好了？让我们缓存该功能

914
00:42:40,460 --> 0:42:41,328
再来看看

915
00:42:41,395 --> 0:42:44,531
对该增强的一些实现

916
00:42:46,567 --> 0:42:47,968
所以我的滑块在这里控制

917
00:42:48,035 --> 0:42:50,337
我在后端使用的数字生成器种子

918
00:42:52,673 --> 0:42:53,807
好 非常酷

919
00:42:53,874 --> 0:42:55,309
我不确定效率如何

920
00:42:55,375 --> 0:42:58,612
所以这里我将实时处理

921
00:42:58,979 --> 0:43:01,148
我们将在这里看看它们如何

922
00:42:58,979 --> 0:43:01,148
我们将在这里看看它们如何

923
00:43:01,481 --> 0:43:03,183
实时保存到硬盘

924
00:43:03,250 --> 0:43:04,218
我们来试试吧

925
00:43:04,685 --> 0:43:06,453
让你了解它有多快

926
00:43:10,390 --> 0:43:11,558
这真的很厉害

927
00:43:15,128 --> 0:43:15,963
好

928
00:43:16,864 --> 0:43:21,068
下面我想展示的是如何通过

929
00:43:21,935 --> 0:43:25,072
首先是加载Core ML模型

930
00:43:25,272 --> 0:43:26,139
我们在这里做的

931
00:43:27,341 --> 0:43:29,710
我们有一个玻璃模型

932
00:43:30,277 --> 0:43:32,045
产生一个有趣的效果

933
00:43:32,112 --> 0:43:34,014
让我们从过程图像开始

934
00:43:34,348 --> 0:43:35,549
我们之前见过这个

935
00:43:36,850 --> 0:43:38,252
然后让它变得更有趣

936
00:43:38,318 --> 0:43:39,586
我们为它添加一些纹理

937
00:43:40,787 --> 0:43:42,956
我们在上面添加多频段噪音

938
00:43:45,425 --> 0:43:46,727
以及一些羽化

939
00:43:47,327 --> 0:43:48,762
和一些小插图

940
00:43:50,631 --> 0:43:51,732
好 这是输入图像

941
00:43:51,798 --> 0:43:53,367
我们把它喂给我们的神经网络

942
00:43:53,433 --> 0:43:57,804
和另一个我们预先训练过的

943
00:43:59,106 --> 0:44:00,774
好吗？让我们来运行吧

944
00:43:59,106 --> 0:44:00,774
好吗？让我们来运行吧

945
00:44:05,279 --> 0:44:06,113
和…

946
00:44:09,683 --> 0:44:12,519
就这样

947
00:44:13,720 --> 0:44:15,722
好 说到这儿

948
00:44:16,323 --> 0:44:19,059
我要感谢大家今天参加这个会议

949
00:44:19,693 --> 0:44:22,062
我希望你们喜欢这个演讲

950
00:44:22,129 --> 0:44:23,697
就像我们享受为你准备演讲的过程

951
00:44:24,431 --> 0:44:26,767
我强烈建议你明天来和我们谈谈

952
00:44:26,834 --> 0:44:28,969
下午三点

953
00:44:30,103 --> 0:44:31,672
非常感谢
