1
00:00:16,783 --> 0:00:22,089
（用Metal框架加速机器学习

2
00:00:29,830 --> 0:00:31,265
大家下午好

3
00:00:31,698 --> 0:00:34,668
欢迎来到“Metal框架

4
00:00:35,469 --> 0:00:37,171
我是Anna Tikhonova

5
00:00:37,237 --> 0:00:39,306
我是GPU软件团队的工程师

6
00:00:42,943 --> 0:00:44,678
Metal性能着色器框架

7
00:00:44,745 --> 0:00:45,979
是基于Metal而建立

8
00:00:46,580 --> 0:00:48,949
为GPU提供更快速的原语

9
00:00:49,016 --> 0:00:51,785
并已为iOS和macOS优化

10
00:00:52,819 --> 0:00:55,155
我们提供的原语包括图像处理

11
00:00:55,455 --> 0:00:57,558
线性代数和机器学习

12
00:00:58,625 --> 0:01:02,396
我们曾讲过大量有关推理的内容

13
00:00:58,625 --> 0:01:02,396
我们曾讲过大量有关推理的内容

14
00:01:02,796 --> 0:01:04,364
这里我只是再强调一下

15
00:01:06,433 --> 0:01:09,369
今年新增的训练支持

16
00:01:09,570 --> 0:01:11,038
iOS和macOS

17
00:01:15,909 --> 0:01:16,810
谢谢

18
00:01:18,612 --> 0:01:21,315
还有更快速的光线追踪

19
00:01:21,381 --> 0:01:22,282
添加到了平台

20
00:01:22,649 --> 0:01:26,353
我们为此做过一整场专题演讲

21
00:01:26,653 --> 0:01:29,122
主题是

22
00:01:30,057 --> 0:01:33,293
演讲的视频很快就会上线

23
00:01:34,294 --> 0:01:37,331
今天演讲的主要内容是关于机器学习

24
00:01:37,764 --> 0:01:39,099
特别是训练

25
00:01:42,102 --> 0:01:43,871
我提过训练和推断

26
00:01:44,705 --> 0:01:47,307
深度学习算法由这两个阶段构成

27
00:01:47,608 --> 0:01:49,510
第一个阶段是训练阶段

28
00:01:50,511 --> 0:01:53,213
举个例子 比如训练一个模型

29
00:01:53,714 --> 0:01:55,749
对图像分类

30
00:01:56,183 --> 0:01:58,519
比如猫、狗、长颈鹿等等

31
00:01:59,987 --> 0:02:03,156
那么为了训练模型能识别猫

32
00:01:59,987 --> 0:02:03,156
那么为了训练模型能识别猫

33
00:02:03,223 --> 0:02:06,493
就要输入大量标签为猫的图片

34
00:02:07,060 --> 0:02:10,097
再以同样的方法

35
00:02:10,163 --> 0:02:11,999
让模型去识别

36
00:02:14,101 --> 0:02:17,337
训练的计算量很大而且是很耗时的

37
00:02:17,404 --> 0:02:18,505
迭代进程

38
00:02:19,339 --> 0:02:21,842
训练的结果是已训练的参数

39
00:02:24,745 --> 0:02:27,080
已训练的参数是下一阶段的必备条件

40
00:02:27,147 --> 0:02:28,048
也就是推断阶段

41
00:02:28,782 --> 0:02:31,618
这个阶段中 模型会看到一张新图

42
00:02:31,685 --> 0:02:33,086
之前从未见过

43
00:02:33,153 --> 0:02:35,822
它需要对其分类

44
00:02:36,223 --> 0:02:37,191
这是只猫

45
00:02:38,292 --> 0:02:40,427
GPU加速现在可以

46
00:02:40,494 --> 0:02:42,896
同时用于训练阶段和推断阶段

47
00:02:45,832 --> 0:02:47,334
但在讲训练之前

48
00:02:47,401 --> 0:02:51,371
我要先谈谈CNN推断优化

49
00:02:51,939 --> 0:02:55,042
现在FP16计算可以支持

50
00:02:55,108 --> 0:02:58,111
卷积和卷积转置原语

51
00:02:58,946 --> 0:03:03,250
Apple A11 Bionic

52
00:02:58,946 --> 0:03:03,250
Apple A11 Bionic

53
00:03:04,351 --> 0:03:08,322
我们发现FP16计算推断

54
00:03:08,655 --> 0:03:10,958
就精度而言完全足够

55
00:03:11,892 --> 0:03:14,161
适合常用的神经网络

56
00:03:15,562 --> 0:03:20,534
FP16计算更为精确还十分省电

57
00:03:20,601 --> 0:03:24,204
所以请一定要把它运用到推断中

58
00:03:25,572 --> 0:03:29,176
这个例子展示了

59
00:03:29,243 --> 0:03:30,744
用于卷积原语

60
00:03:30,811 --> 0:03:34,181
你只需设置

61
00:03:36,617 --> 0:03:40,854
现在我们开始深入讲解

62
00:03:41,188 --> 0:03:42,422
神经网络训练

63
00:03:43,156 --> 0:03:45,792
我们从卷积神经网络讲起

64
00:03:48,929 --> 0:03:52,332
这里有一个简单的

65
00:03:53,233 --> 0:03:56,069
以手写数字图像为输入

66
00:03:56,870 --> 0:03:59,373
放入十个类中的一个

67
00:03:59,439 --> 0:04:00,507
从0到9

68
00:03:59,439 --> 0:04:00,507
从0到9

69
00:04:01,608 --> 0:04:04,711
这个例子中

70
00:04:04,778 --> 0:04:06,580
数字7的图片

71
00:04:09,316 --> 0:04:13,120
推断时用已训练的参数

72
00:04:13,954 --> 0:04:16,557
已训练的参数添加权重

73
00:04:16,623 --> 0:04:19,293
到卷积和全连接原语

74
00:04:20,327 --> 0:04:23,730
训练算法的目的

75
00:04:23,797 --> 0:04:28,535
让网络可以用它们让输入数据

76
00:04:30,370 --> 0:04:33,407
训练进程开始的时候

77
00:04:33,473 --> 0:04:34,608
我们需要计算

78
00:04:35,075 --> 0:04:36,176
所以第一步

79
00:04:36,543 --> 0:04:39,479
初始化权重

80
00:04:40,013 --> 0:04:41,682
现在可以开始

81
00:04:42,149 --> 0:04:45,319
这里列出了

82
00:04:48,121 --> 0:04:49,957
训练是一个迭代进程

83
00:04:50,023 --> 0:04:53,126
每次训练的迭代

84
00:04:53,994 --> 0:04:55,929
第一步是正向传播

85
00:04:55,996 --> 0:04:59,166
这时候将输入

86
00:04:59,233 --> 0:05:00,367
产生输出

87
00:04:59,233 --> 0:05:00,367
产生输出

88
00:05:01,068 --> 0:05:02,536
类似推断进程

89
00:05:04,238 --> 0:05:05,939
然后计算缺失

90
00:05:06,573 --> 0:05:08,876
损失直观地衡量了

91
00:05:08,942 --> 0:05:11,245
网络输出值

92
00:05:13,313 --> 0:05:16,450
训练算法的目标

93
00:05:18,819 --> 0:05:20,854
下一步是梯度传播

94
00:05:21,488 --> 0:05:24,558
就是反向传播

95
00:05:24,825 --> 0:05:27,361
标准值的误差

96
00:05:27,794 --> 0:05:29,096
再更新权重

97
00:05:29,963 --> 0:05:33,267
理念是随着训练不断进行

98
00:05:33,333 --> 0:05:35,202
网络会越来越准确

99
00:05:35,269 --> 0:05:38,906
所以最好能用

100
00:05:39,806 --> 0:05:41,675
从而最小化误差

101
00:05:43,210 --> 0:05:44,478
以上是概述

102
00:05:44,778 --> 0:05:47,748
下面分别看看

103
00:05:50,350 --> 0:05:53,654
正向传播指

104
00:05:54,054 --> 0:05:55,155
以计算输出

105
00:05:56,190 --> 0:05:58,692
如你所见

106
00:05:59,092 --> 0:06:00,627
网络的表现不是很好

107
00:05:59,092 --> 0:06:00,627
网络的表现不是很好

108
00:06:01,795 --> 0:06:03,764
结果明显是错误的

109
00:06:03,830 --> 0:06:05,098
为何这么糟糕？

110
00:06:05,566 --> 0:06:06,767
其实也不意外

111
00:06:06,834 --> 0:06:09,770
因为初始权重

112
00:06:09,837 --> 0:06:12,039
网络还没有被训练

113
00:06:13,941 --> 0:06:16,476
现在要用权重来量化

114
00:06:16,844 --> 0:06:19,646
网络表现的好坏程度

115
00:06:20,247 --> 0:06:21,849
我们可以用这个信息

116
00:06:22,349 --> 0:06:25,552
来提高权重

117
00:06:25,619 --> 0:06:28,055
能训练网络

118
00:06:30,257 --> 0:06:32,426
为了衡量表现如何

119
00:06:32,492 --> 0:06:34,127
我们需要一个正确答案

120
00:06:34,795 --> 0:06:37,631
就是标准值

121
00:06:38,098 --> 0:06:41,502
它会与图像

122
00:06:42,236 --> 0:06:44,505
这个例子中

123
00:06:44,571 --> 0:06:46,940
正确类的值为1

124
00:06:47,274 --> 0:06:49,009
其他类均为0

125
00:06:51,645 --> 0:06:54,548
网络的输出

126
00:06:54,882 --> 0:06:55,849
每类给一个值

127
00:06:56,517 --> 0:06:59,052
在这个训练场景下

128
00:06:59,119 --> 0:07:02,923
网络输出一个很低的值

129
00:06:59,119 --> 0:07:02,923
网络输出一个很低的值

130
00:07:03,490 --> 0:07:06,860
而把最高值

131
00:07:07,394 --> 0:07:09,930
因此网络返回的

132
00:07:11,465 --> 0:07:13,166
现在把所有信息

133
00:07:13,467 --> 0:07:15,669
传递给损失原语

134
00:07:18,705 --> 0:07:20,374
我之前讲过

135
00:07:21,441 --> 0:07:24,811
损失衡量的差值

136
00:07:25,145 --> 0:07:26,380
较之标准值的误差

137
00:07:27,548 --> 0:07:30,350
而训练算法的目标

138
00:07:32,352 --> 0:07:34,488
这时就要需要

139
00:07:36,590 --> 0:07:37,724
下半部分图形

140
00:07:37,858 --> 0:07:40,060
包括梯度原语

141
00:07:40,527 --> 0:07:42,262
对应每个正向原语

142
00:07:43,330 --> 0:07:44,431
梯度原语

143
00:07:45,098 --> 0:07:47,601
计算更新权重所需的梯度

144
00:07:49,937 --> 0:07:51,038
损失原语

145
00:07:52,506 --> 0:07:53,941
计算第一梯度

146
00:07:54,508 --> 0:07:56,510
就是选定的

147
00:07:56,577 --> 0:07:57,845
基于输出

148
00:07:58,312 --> 0:07:59,646
然后将这个梯度

149
00:07:59,980 --> 0:08:01,782
反向传播

150
00:07:59,980 --> 0:08:01,782
反向传播

151
00:08:02,549 --> 0:08:03,717
通过网络

152
00:08:04,184 --> 0:08:06,086
通过第一个…

153
00:08:06,987 --> 0:08:09,489
梯度原语向后传递

154
00:08:09,556 --> 0:08:12,826
这个例子中

155
00:08:14,027 --> 0:08:15,495
要用到链式法则

156
00:08:15,562 --> 0:08:18,065
链式法则允许反向传播梯度

157
00:08:18,131 --> 0:08:19,333
通过网络向后走

158
00:08:20,467 --> 0:08:22,302
同时计算梯度

159
00:08:22,369 --> 0:08:23,737
以更新权重

160
00:08:24,271 --> 0:08:27,374
因此权重的增量很小

161
00:08:27,975 --> 0:08:29,276
在每次迭代中

162
00:08:31,311 --> 0:08:33,480
然后用更新后的权重

163
00:08:33,547 --> 0:08:35,115
进行下次训练迭代

164
00:08:35,883 --> 0:08:38,184
希望误差值会变小

165
00:08:38,251 --> 0:08:39,753
这是我们努力的方向

166
00:08:43,557 --> 0:08:45,692
实际上

167
00:08:46,326 --> 0:08:48,462
不可能只处理一张图像

168
00:08:49,062 --> 0:08:52,299
而是处理

169
00:08:52,366 --> 0:08:55,135
比如32或64的批大小

170
00:08:55,869 --> 0:08:59,439
还要有相应的一批标签

171
00:08:59,506 --> 0:09:00,674
用于计算损失

172
00:08:59,506 --> 0:09:00,674
用于计算损失

173
00:09:00,741 --> 0:09:03,277
这个例子里

174
00:09:03,343 --> 0:09:06,780
正确类的值为1

175
00:09:09,550 --> 0:09:11,285
每个训练场景

176
00:09:11,351 --> 0:09:13,620
会使用不同的批图像

177
00:09:13,687 --> 0:09:16,056
和相应的一批标签

178
00:09:16,123 --> 0:09:18,859
现在就来运行

179
00:09:21,495 --> 0:09:23,630
对第一批图像

180
00:09:23,697 --> 0:09:25,032
做正向传播

181
00:09:25,098 --> 0:09:28,101
计算损失

182
00:09:28,936 --> 0:09:30,037
再更新权重

183
00:09:30,604 --> 0:09:32,372
那么第二批呢？

184
00:09:32,439 --> 0:09:34,208
完全一样的流程

185
00:09:34,274 --> 0:09:36,510
正向传播

186
00:09:36,577 --> 0:09:38,679
梯度传播

187
00:09:40,080 --> 0:09:42,182
训练迭代过程中

188
00:09:43,016 --> 0:09:45,319
我们希望网络的损失

189
00:09:45,385 --> 0:09:46,320
能降低

190
00:09:46,653 --> 0:09:49,323
网络准确度能提高

191
00:09:49,590 --> 0:09:52,292
所以继续训练

192
00:09:52,359 --> 0:09:53,827
某个阈值以下

193
00:09:54,228 --> 0:09:57,598
网络的准确度

194
00:09:58,765 --> 0:10:00,834
这时我们就知道网络已训练

195
00:09:58,765 --> 0:10:00,834
这时我们就知道网络已训练

196
00:10:00,901 --> 0:10:03,070
我们可以用

197
00:10:03,403 --> 0:10:04,338
去推断了

198
00:10:04,738 --> 0:10:07,674
现在看几个必要步骤

199
00:10:07,741 --> 0:10:11,078
Metal性能着色器框架(MPS)

200
00:10:12,012 --> 0:10:15,549
神经网络通常会用

201
00:10:16,116 --> 0:10:19,353
MPS中的神经网络就以图形描述

202
00:10:20,888 --> 0:10:23,223
第一步就是创建训练图

203
00:10:24,424 --> 0:10:26,326
我们要准备好输入数据

204
00:10:26,393 --> 0:10:27,928
确定权重

205
00:10:27,995 --> 0:10:29,329
然后执行训练图

206
00:10:29,396 --> 0:10:30,864
运行正向路径

207
00:10:31,298 --> 0:10:34,768
计算损失、梯度传播

208
00:10:35,903 --> 0:10:37,704
训练是一个迭代进程

209
00:10:38,639 --> 0:10:41,108
训练网络需要多次迭代

210
00:10:41,175 --> 0:10:43,844
因此还要知道

211
00:10:44,077 --> 0:10:45,979
现在就来研究每个课题的

212
00:10:46,280 --> 0:10:47,314
具体内容

213
00:10:47,814 --> 0:10:50,551
首先是创建训练图

214
00:10:52,719 --> 0:10:55,956
我说过MPS中

215
00:10:56,023 --> 0:10:58,425
一个图形

216
00:10:59,193 --> 0:11:01,161
这是可视化的

217
00:10:59,193 --> 0:11:01,161
这是可视化的

218
00:11:01,461 --> 0:11:04,031
手写数字识别网络

219
00:11:04,665 --> 0:11:06,099
这个图形里

220
00:11:06,166 --> 0:11:07,901
你能看到图像节点

221
00:11:07,968 --> 0:11:09,303
就是白色的小节点

222
00:11:10,904 --> 0:11:13,073
图像节点用于数据

223
00:11:13,373 --> 0:11:16,677
输入输出和所有中间结果

224
00:11:18,846 --> 0:11:21,949
它们描述了不同操作时

225
00:11:22,716 --> 0:11:24,585
然后处理数据

226
00:11:24,651 --> 0:11:26,220
比如卷积或池化

227
00:11:27,087 --> 0:11:29,957
以过滤节点表示

228
00:11:30,924 --> 0:11:33,193
我们支持所有必要的节点

229
00:11:33,260 --> 0:11:35,829
以创建常用的神经网络

230
00:11:37,231 --> 0:11:39,132
现在看看怎么简单地

231
00:11:39,199 --> 0:11:40,767
使用神经网络图形API

232
00:11:41,702 --> 0:11:46,440
这个例子就是

233
00:11:46,507 --> 0:11:48,141
通过神经网络图形API

234
00:11:48,675 --> 0:11:51,011
这是如何创建卷积节点

235
00:11:51,078 --> 0:11:52,346
通过图形API

236
00:11:53,380 --> 0:11:55,916
对于每个正向节点

237
00:11:55,983 --> 0:11:59,386
提供相应的训练梯度节点

238
00:11:59,720 --> 0:12:02,923
只要一行代码

239
00:11:59,720 --> 0:12:02,923
只要一行代码

240
00:12:02,990 --> 0:12:04,024
对应正向节点

241
00:12:04,091 --> 0:12:08,362
这个例子展示了

242
00:12:08,428 --> 0:12:09,663
基于卷积节点

243
00:12:13,100 --> 0:12:14,735
现在创建整个图形

244
00:12:16,203 --> 0:12:18,372
这里有个很小的网络

245
00:12:18,438 --> 0:12:21,241
一个卷积节点

246
00:12:21,308 --> 0:12:22,943
随后是另一个卷积节点

247
00:12:23,911 --> 0:12:25,679
怎样连接这些节点

248
00:12:26,813 --> 0:12:27,681
到图形中？

249
00:12:27,915 --> 0:12:28,949
很简单

250
00:12:29,616 --> 0:12:31,685
我们将结果节点

251
00:12:32,352 --> 0:12:34,521
一个节点的输出图像

252
00:12:34,588 --> 0:12:37,758
以源图片形式

253
00:12:38,859 --> 0:12:41,528
这就形成全连接图形

254
00:12:42,729 --> 0:12:44,731
现在创建训练图形

255
00:12:45,766 --> 0:12:48,735
首先在图形中

256
00:12:50,037 --> 0:12:52,005
再添加梯度节点

257
00:12:52,072 --> 0:12:54,274
我说过 只要一行代码

258
00:12:54,341 --> 0:12:55,943
就能创建梯度节点

259
00:12:56,210 --> 0:12:57,978
对应正向节点

260
00:12:58,345 --> 0:13:00,380
然后跟之前一样连接它们

261
00:12:58,345 --> 0:13:00,380
然后跟之前一样连接它们

262
00:13:00,447 --> 0:13:02,616
完整的训练图就做好了

263
00:13:05,752 --> 0:13:07,588
通过这个例子 你能看到

264
00:13:07,654 --> 0:13:10,524
图形API简单易用

265
00:13:11,558 --> 0:13:13,393
训练图可以自动做很多事

266
00:13:13,460 --> 0:13:15,495
它能处理所有中间结果

267
00:13:16,797 --> 0:13:18,365
甚至输出图像

268
00:13:19,166 --> 0:13:22,870
它能最小化网络的内存占用

269
00:13:22,936 --> 0:13:26,607
通过将所有的中间图像折叠

270
00:13:26,673 --> 0:13:27,808
借助Metal堆

271
00:13:28,809 --> 0:13:30,410
它还能融合图形节点

272
00:13:30,477 --> 0:13:34,181
例如它可以融合

273
00:13:34,615 --> 0:13:36,416
它还能优化away节点

274
00:13:36,717 --> 0:13:39,219
比如优化切割

275
00:13:40,387 --> 0:13:43,156
它还可以自动处理填充

276
00:13:43,223 --> 0:13:44,958
管理状态对象

277
00:13:45,025 --> 0:13:46,727
这些稍后会讲到

278
00:13:47,561 --> 0:13:49,930
所以请好好利用图形API

279
00:13:54,868 --> 0:13:57,104
了解如何创建训练图后

280
00:13:57,471 --> 0:14:01,308
现在看看

281
00:13:57,471 --> 0:14:01,308
现在看看

282
00:14:02,576 --> 0:14:04,878
这里就要讲到编码命令

283
00:14:04,945 --> 0:14:07,414
将图形编码到GPU

284
00:14:09,049 --> 0:14:11,818
我说过 我们不会只发送一张图像

285
00:14:11,885 --> 0:14:13,086
给每次训练

286
00:14:13,153 --> 0:14:16,323
我们要处理一组或一批图像

287
00:14:16,523 --> 0:14:18,192
那么输入数据之一

288
00:14:18,458 --> 0:14:19,760
就是一批图像

289
00:14:20,794 --> 0:14:23,664
你一定记得每批图像

290
00:14:23,730 --> 0:14:27,467
都对应一批标签 用于计算损失

291
00:14:29,770 --> 0:14:33,807
计算损失的标签

292
00:14:34,174 --> 0:14:37,978
代码命令也会把一批状态作为输入

293
00:14:38,779 --> 0:14:41,548
现在来讲讲批和状态

294
00:14:41,882 --> 0:14:43,584
是什么意思？

295
00:14:44,484 --> 0:14:48,188
批是一组图像或状态

296
00:14:48,255 --> 0:14:51,091
这是我们今年特地为训练增加的支持

297
00:14:52,092 --> 0:14:56,029
现在有两个新的MPS类型可用

298
00:14:56,096 --> 0:14:57,731
和MPSStateBatch

299
00:14:58,565 --> 0:15:01,568
下面这个例子

300
00:14:58,565 --> 0:15:01,568
下面这个例子

301
00:15:01,635 --> 0:15:02,769
创建单张图像

302
00:15:04,071 --> 0:15:06,773
用现有的Metal纹理创建图像

303
00:15:08,275 --> 0:15:10,277
这个例子展示了如何使用

304
00:15:10,577 --> 0:15:14,781
API创建批图像

305
00:15:14,848 --> 0:15:16,283
传给训练图

306
00:15:18,485 --> 0:15:20,254
状态对象是什么？

307
00:15:21,255 --> 0:15:24,791
MPS状态是不透明的数据容器

308
00:15:25,792 --> 0:15:29,096
训练中 常要用它捕捉

309
00:15:29,162 --> 0:15:30,264
正向节点的状态

310
00:15:31,565 --> 0:15:32,399
在调用时

311
00:15:32,766 --> 0:15:36,036
所以它之后可以用作梯度节点

312
00:15:37,104 --> 0:15:39,706
训练图会处理所有状态对象

313
00:15:39,773 --> 0:15:40,807
所以作为开发者

314
00:15:40,908 --> 0:15:42,943
你一般不用担心状态

315
00:15:43,010 --> 0:15:44,778
但了解下工作原理也不错

316
00:15:44,845 --> 0:15:46,680
我们用具体例子说明

317
00:15:49,049 --> 0:15:51,885
回到上个手写数字识别网络

318
00:15:53,287 --> 0:15:55,722
特别注意下退出

319
00:15:55,789 --> 0:15:57,391
和退出梯度节点

320
00:16:00,761 --> 0:16:03,864
正向退出节点

321
00:16:03,931 --> 0:16:06,533
以某个特定概率输入值

322
00:16:07,334 --> 0:16:09,236
退出状态对象

323
00:16:09,603 --> 0:16:12,606
捕捉正向退出处理的信息

324
00:16:13,574 --> 0:16:16,343
之后可用于梯度节点

325
00:16:17,044 --> 0:16:18,612
因为它清零

326
00:16:19,913 --> 0:16:23,717
输出梯度值的位置

327
00:16:23,784 --> 0:16:25,786
与正向清零的位置一样

328
00:16:28,889 --> 0:16:31,458
所以我说你不用担心状态

329
00:16:31,525 --> 0:16:32,960
训练图都会帮你处理

330
00:16:33,794 --> 0:16:35,963
但是由于计算损失的标签

331
00:16:36,330 --> 0:16:37,965
以状态的形式传递给训练图

332
00:16:39,066 --> 0:16:40,701
而且需要用户输入数据

333
00:16:40,767 --> 0:16:43,504
就是标准值或正确结果

334
00:16:44,004 --> 0:16:47,007
你需要创建一批标签用于计算损失

335
00:16:47,241 --> 0:16:49,209
再输入给训练图

336
00:16:50,143 --> 0:16:53,046
下面这个例子

337
00:16:53,480 --> 0:16:54,882
用于计算损失

338
00:16:55,249 --> 0:16:57,584
首先要创建损失数据描述符

339
00:16:57,985 --> 0:17:00,821
描述标签数据在内存里的情况

340
00:16:57,985 --> 0:17:00,821
描述标签数据在内存里的情况

341
00:17:01,722 --> 0:17:05,392
然后创建

342
00:17:05,459 --> 0:17:06,593
用这个描述符

343
00:17:08,161 --> 0:17:10,196
然后创建批对象用于训练

344
00:17:10,897 --> 0:17:12,965
GPU运行完图形后

345
00:17:13,467 --> 0:17:17,204
批标签会包含每张图像的损失值

346
00:17:17,971 --> 0:17:18,839
对这批图像

347
00:17:19,039 --> 0:17:20,440
你检查这些值

348
00:17:20,507 --> 0:17:22,943
或计算一个单一值给整个批

349
00:17:23,010 --> 0:17:24,178
再检查那个值

350
00:17:27,714 --> 0:17:29,283
那么现在有了训练图

351
00:17:29,349 --> 0:17:32,586
下面就是如何输入数据

352
00:17:32,653 --> 0:17:34,755
我们看看如何将权重

353
00:17:34,821 --> 0:17:36,523
添加到需要权重的图形节点上

354
00:17:39,026 --> 0:17:42,696
唯一能添加权重给卷积、全连接

355
00:17:42,763 --> 0:17:46,934
批归一化和实例正则化节点

356
00:17:47,000 --> 0:17:49,303
是通过数据源提供器协议

357
00:17:50,938 --> 0:17:53,841
这个例子就是如何创建卷积节点

358
00:17:53,907 --> 0:17:55,309
通过数据源提供器

359
00:17:56,176 --> 0:18:00,280
你需要部署一个符合协议规则的类

360
00:17:56,176 --> 0:18:00,280
你需要部署一个符合协议规则的类

361
00:18:00,347 --> 0:18:02,216
这里就叫做MyWeights

362
00:18:04,685 --> 0:18:08,155
数据源提供器在许多方面都很好用

363
00:18:08,589 --> 0:18:09,623
比如

364
00:18:09,857 --> 0:18:12,593
如果在网络里你有许多卷积节点

365
00:18:13,260 --> 0:18:16,396
网络的整体权重会相当可观

366
00:18:16,964 --> 0:18:20,234
但我们并不想让所有卷积节点的权重

367
00:18:20,300 --> 0:18:22,035
同时存入内存

368
00:18:22,769 --> 0:18:25,506
我们希望网络的内存占用

369
00:18:25,572 --> 0:18:26,673
越低越好

370
00:18:27,407 --> 0:18:29,576
数据源提供器就派上用场了

371
00:18:30,010 --> 0:18:32,679
因为它们能及时载入

372
00:18:32,913 --> 0:18:34,681
和清除权重数据

373
00:18:35,616 --> 0:18:38,118
所以我们加载权重给一个卷积核

374
00:18:38,752 --> 0:18:39,987
在处理时

375
00:18:40,053 --> 0:18:43,524
清除它们后

376
00:18:46,260 --> 0:18:48,629
MyWeights这样实施

377
00:18:49,429 --> 0:18:50,531
你要提供

378
00:18:51,198 --> 0:18:53,867
初始化方法

379
00:18:53,934 --> 0:18:56,103
拉入内存并做好准备

380
00:18:56,170 --> 0:18:58,672
然后训练图会调用load函数

381
00:18:59,139 --> 0:19:01,408
当purge函数被调用时

382
00:18:59,139 --> 0:19:01,408
当purge函数被调用时

383
00:19:01,608 --> 0:19:02,843
权重就被释放了

384
00:19:03,644 --> 0:19:06,580
数据源提供器对训练也很重要

385
00:19:06,647 --> 0:19:08,515
这个我们稍后讲

386
00:19:11,919 --> 0:19:13,654
那么我们有了训练图

387
00:19:13,720 --> 0:19:16,423
也准备好了输入和具体权重

388
00:19:16,490 --> 0:19:18,559
就可以在GPU上执行图形了

389
00:19:20,360 --> 0:19:22,362
要在GPU上执行训练图

390
00:19:22,429 --> 0:19:24,831
首先要完成Metal设置

391
00:19:25,432 --> 0:19:27,501
我们要初始化训练图

392
00:19:27,935 --> 0:19:29,469
准备好输入

393
00:19:29,736 --> 0:19:32,072
开始在GPU上训练网络吧

394
00:19:35,209 --> 0:19:36,944
训练是迭代进程

395
00:19:38,011 --> 0:19:39,780
因此要设置训练回路

396
00:19:40,581 --> 0:19:44,117
通常我们要执行训练图

397
00:19:44,885 --> 0:19:47,287
轮次次数是总次数…

398
00:19:48,088 --> 0:19:50,958
是对整个数据集的迭代次数

399
00:19:51,792 --> 0:19:54,828
每个轮次应该有多个迭代

400
00:19:54,895 --> 0:19:57,764
所以迭代的次数是图像总数

401
00:19:57,831 --> 0:20:01,268
在数据集中

402
00:19:57,831 --> 0:20:01,268
在数据集中

403
00:20:02,236 --> 0:20:04,805
现在我们来看每次训练迭代

404
00:20:07,107 --> 0:20:08,609
每次训练迭代中

405
00:20:09,910 --> 0:20:11,912
我们对一批图像编码用于训练

406
00:20:13,146 --> 0:20:16,450
但我们不想让CPU等GPU

407
00:20:16,517 --> 0:20:20,020
跑完一次训练图

408
00:20:20,087 --> 0:20:21,421
处理一批图像

409
00:20:21,755 --> 0:20:25,526
然后CPU才开始编码

410
00:20:25,592 --> 0:20:26,827
给下一次图形运行

411
00:20:27,494 --> 0:20:29,830
我们希望CPU和GPU

412
00:20:29,897 --> 0:20:31,031
同时工作

413
00:20:31,331 --> 0:20:33,500
为此我们要用到双缓冲

414
00:20:34,434 --> 0:20:37,070
那么设置中

415
00:20:37,671 --> 0:20:40,474
计数信号量

416
00:20:40,541 --> 0:20:44,344
这是因为我们只要

417
00:20:45,679 --> 0:20:48,715
然后在输入

418
00:20:48,782 --> 0:20:50,717
就会调用信号量权重

419
00:20:50,784 --> 0:20:51,952
进行自减

420
00:20:52,920 --> 0:20:56,323
当计数值减到0

421
00:20:56,390 --> 0:20:58,225
就等待

422
00:20:59,593 --> 0:21:00,928
之后对图形编码

423
00:20:59,593 --> 0:21:00,928
之后对图形编码

424
00:21:01,361 --> 0:21:03,564
编码命令即刻返回

425
00:21:04,264 --> 0:21:06,333
用户指定的回调函数会被调用

426
00:21:06,767 --> 0:21:08,602
在GPU完成图形运行的时候

427
00:21:09,369 --> 0:21:11,705
这样我们就知道GPU运行完了

428
00:21:12,105 --> 0:21:16,577
CPU可以继续为GPU工作编码

429
00:21:17,711 --> 0:21:20,113
就是之前在信号量上

430
00:21:21,315 --> 0:21:22,816
为什么使用双缓冲呢？

431
00:21:22,883 --> 0:21:27,487
为什么不能同时对GPU的

432
00:21:28,822 --> 0:21:31,258
因为编码命令用时少

433
00:21:31,325 --> 0:21:33,360
命令缓冲比运行训练图快

434
00:21:33,660 --> 0:21:36,363
所以不会编码

435
00:21:36,430 --> 0:21:38,465
为了减少内存占用

436
00:21:41,268 --> 0:21:43,837
我们讲过了如何执行训练图

437
00:21:43,904 --> 0:21:46,540
执行图形时 我们做正向传播

438
00:21:46,607 --> 0:21:49,276
计算损失 再梯度传播

439
00:21:49,343 --> 0:21:51,211
然后图形会更新权重

440
00:21:51,545 --> 0:21:53,747
现在说说权重更新

441
00:21:55,883 --> 0:21:59,353
我说过数据源提供器很重要

442
00:21:59,987 --> 0:22:00,921
对训练而言

443
00:21:59,987 --> 0:22:00,921
对训练而言

444
00:22:01,488 --> 0:22:04,758
所有权重更新都使用可选的更新方法

445
00:22:04,825 --> 0:22:06,527
通过数据源提供器

446
00:22:07,761 --> 0:22:10,497
图形自动调用更新函数

447
00:22:11,098 --> 0:22:13,567
那么更新权重的步骤都有哪些呢？

448
00:22:13,634 --> 0:22:14,635
来看一下

449
00:22:17,037 --> 0:22:19,940
回想在梯度传播阶段的梯度计算

450
00:22:20,007 --> 0:22:22,643
在每个训练场景

451
00:22:22,709 --> 0:22:24,077
添加少许增量给权重

452
00:22:25,479 --> 0:22:27,481
如何将增量分配给权重

453
00:22:27,548 --> 0:22:30,017
由优化器决定

454
00:22:30,584 --> 0:22:33,520
它只是个函数将原来的权重

455
00:22:33,587 --> 0:22:35,455
和计算过的梯度作为输入

456
00:22:35,923 --> 0:22:39,193
输出更新后的权重

457
00:22:41,228 --> 0:22:43,730
优化器要在更新函数中使用

458
00:22:43,797 --> 0:22:45,032
在数据源提供器内

459
00:22:45,999 --> 0:22:47,835
我们也支持几种不同的变体

460
00:22:47,901 --> 0:22:51,371
来更新GPU权重

461
00:22:51,438 --> 0:22:54,374
StochasticGradientDescent

462
00:22:54,842 --> 0:22:59,346
你甚至可以自定义

463
00:22:59,913 --> 0:23:03,650
那么就来看看

464
00:22:59,913 --> 0:23:03,650
那么就来看看

465
00:23:06,320 --> 0:23:09,289
你记得数据源提供器

466
00:23:09,656 --> 0:23:11,959
这里就是创建优化器的地方

467
00:23:12,025 --> 0:23:13,894
因为你只需要创建一次

468
00:23:15,295 --> 0:23:17,431
现在看看如何执行

469
00:23:17,497 --> 0:23:18,498
更新函数

470
00:23:19,533 --> 0:23:20,634
更新函数

471
00:23:20,901 --> 0:23:24,104
接收源状态

472
00:23:26,173 --> 0:23:28,509
源状态包含原始权重

473
00:23:28,575 --> 0:23:31,078
梯度状态

474
00:23:31,678 --> 0:23:34,081
现在就能用这个数据

475
00:23:34,548 --> 0:23:37,484
最后一步是将源状态返回

476
00:23:37,551 --> 0:23:39,253
其中是更新后的权重

477
00:23:39,520 --> 0:23:40,554
很简单吧

478
00:23:43,657 --> 0:23:45,926
现在还有最后一步

479
00:23:46,360 --> 0:23:48,395
我说过 训练时迭代进程

480
00:23:48,462 --> 0:23:51,198
训练网络需要多次迭代

481
00:23:52,766 --> 0:23:54,701
你要知道何时停止训练

482
00:23:55,202 --> 0:23:58,438
现在就来讨论下

483
00:23:58,505 --> 0:24:00,140
以训练循环为环境

484
00:23:58,505 --> 0:24:00,140
以训练循环为环境

485
00:24:03,343 --> 0:24:05,078
这是训练回路

486
00:24:05,145 --> 0:24:07,681
正在训练神经网络

487
00:24:09,149 --> 0:24:13,253
为确定何时停止训练

488
00:24:13,320 --> 0:24:18,025
测试图集内的图像不是用于训练

489
00:24:18,091 --> 0:24:21,595
只用于评估

490
00:24:22,362 --> 0:24:26,066
每个轮次后

491
00:24:26,133 --> 0:24:29,169
…等待GPU

492
00:24:29,803 --> 0:24:33,140
然后使用当前的已训练的参数

493
00:24:33,740 --> 0:24:35,676
初始化推断网络

494
00:24:36,877 --> 0:24:39,880
然后在测试图集上

495
00:24:40,380 --> 0:24:41,949
你可以选择停止训练

496
00:24:42,249 --> 0:24:44,852
当测试集显示

497
00:24:45,185 --> 0:24:46,453
达到某个水平时

498
00:24:50,023 --> 0:24:52,359
我们已经讨论过所有步骤

499
00:24:52,659 --> 0:24:55,596
关于在MPS训练神经网络

500
00:24:56,063 --> 0:24:56,997
是时候展示一下了

501
00:24:58,632 --> 0:25:01,768
平台状态汇总中提过

502
00:24:58,632 --> 0:25:01,768
平台状态汇总中提过

503
00:25:02,736 --> 0:25:05,405
Metal性能着色器框架可以驱动

504
00:25:06,340 --> 0:25:09,076
Core ML、Create ML

505
00:25:10,277 --> 0:25:13,180
Turi Create

506
00:25:13,814 --> 0:25:17,718
灵活且高性能的工具组

507
00:25:18,352 --> 0:25:21,655
以完成一些任务

508
00:25:21,722 --> 0:25:25,058
对象检测和推荐等等

509
00:25:25,325 --> 0:25:27,127
有关Turi Create的

510
00:25:27,594 --> 0:25:30,731
请查看“Turi Create

511
00:25:32,266 --> 0:25:33,534
我们准备了一个演示

512
00:25:34,034 --> 0:25:38,505
用一个…

513
00:25:39,006 --> 0:25:41,942
通过MPS驱动的

514
00:25:43,043 --> 0:25:45,479
平台状态汇总中提到过

515
00:25:46,013 --> 0:25:49,116
用MPS的速度比不用快9倍

516
00:25:50,117 --> 0:25:51,685
对象检查网络

517
00:25:52,152 --> 0:25:55,155
在被识别的对象周围绘制边框

518
00:26:01,328 --> 0:26:02,429
这个演示中

519
00:26:04,865 --> 0:26:08,235
我用的MacBook Pro

520
00:26:09,870 --> 0:26:13,006
Turi Create

521
00:26:13,407 --> 0:26:17,978
外部GPU用MPS训练网络

522
00:26:18,946 --> 0:26:21,949
这个例子可以很好地演示

523
00:26:22,015 --> 0:26:24,585
提高MacBook Pro的

524
00:26:25,285 --> 0:26:28,288
我们使用的外部GPU

525
00:26:29,356 --> 0:26:30,524
在演示配置中

526
00:26:30,591 --> 0:26:32,526
我已经导入

527
00:26:32,826 --> 0:26:36,129
并提前加载了

528
00:26:36,196 --> 0:26:37,464
还有一个训练数据集

529
00:26:37,865 --> 0:26:39,066
那么现在开始

530
00:26:40,501 --> 0:26:42,669
训练网络用十次迭代

531
00:26:44,872 --> 0:26:46,940
现在整个对象检测网络

532
00:26:47,007 --> 0:26:50,344
所有的原语

533
00:26:52,379 --> 0:26:54,748
所有的都在外部GPU上运行

534
00:26:58,185 --> 0:27:00,554
好了 十次训练迭代已完成

535
00:26:58,185 --> 0:27:00,554
好了 十次训练迭代已完成

536
00:27:01,288 --> 0:27:03,724
也许十次迭代不足以完成

537
00:27:03,790 --> 0:27:05,559
但在此我们就这样吧

538
00:27:06,059 --> 0:27:07,861
我现在要做的

539
00:27:07,928 --> 0:27:11,131
是加载一个提前训练过的网络

540
00:27:11,365 --> 0:27:12,966
用来运行测试图集

541
00:27:13,033 --> 0:27:14,668
展示部分结果

542
00:27:14,735 --> 0:27:15,869
看一下

543
00:27:18,372 --> 0:27:20,274
好了 这是香蕉

544
00:27:20,340 --> 0:27:22,276
分类十分正确

545
00:27:22,576 --> 0:27:24,044
而且画上了边框

546
00:27:24,945 --> 0:27:28,715
这么美好的早餐

547
00:27:29,216 --> 0:27:31,652
还有一枚不好看的鸡蛋

548
00:27:34,321 --> 0:27:36,423
以上就是

549
00:27:43,463 --> 0:27:44,631
谢谢大家

550
00:27:47,534 --> 0:27:51,371
现在换个话题

551
00:27:52,339 --> 0:27:55,576
首先简单讲讲

552
00:27:57,211 --> 0:28:00,247
卷积神经网络的一大缺陷

553
00:27:57,211 --> 0:28:00,247
卷积神经网络的一大缺陷

554
00:28:00,314 --> 0:28:04,384
是它们无法记忆之前发生的事情

555
00:28:05,319 --> 0:28:06,620
它们可以接收一个输入

556
00:28:06,687 --> 0:28:10,324
例如图像

557
00:28:10,390 --> 0:28:13,527
例如一组概率值定义图像内容

558
00:28:16,630 --> 0:28:17,965
RNN就不一样

559
00:28:19,066 --> 0:28:19,900
它能记忆

560
00:28:19,967 --> 0:28:23,804
它们善于处理

561
00:28:24,705 --> 0:28:27,107
比如它们可以用一组概率值

562
00:28:27,174 --> 0:28:28,709
也就是图像内容

563
00:28:29,243 --> 0:28:30,878
CNN产生的结果

564
00:28:31,345 --> 0:28:33,313
然后产生一序列输出

565
00:28:33,580 --> 0:28:36,683
就是一序列文字

566
00:28:38,418 --> 0:28:40,787
它们也可用一组输入

567
00:28:40,854 --> 0:28:44,224
比如文字序列就是一个句子

568
00:28:44,525 --> 0:28:46,260
产生一组输出

569
00:28:46,860 --> 0:28:51,064
句子没变

570
00:28:51,131 --> 0:28:52,699
比如俄语或芬兰语

571
00:28:54,868 --> 0:28:57,704
我们支持几个不同的RNN

572
00:28:58,438 --> 0:28:59,973
最常用的一个

573
00:29:00,040 --> 0:29:02,376
是长短期记忆RNN

574
00:29:02,442 --> 0:29:03,744
简称LSTM

575
00:29:04,611 --> 0:29:06,847
去年WWDC演讲中

576
00:29:06,914 --> 0:29:10,150
我们讲过大量关于

577
00:29:10,284 --> 0:29:13,153
演示过LSTM推断过程

578
00:29:13,754 --> 0:29:17,991
所以请查看那场演讲

579
00:29:19,593 --> 0:29:22,229
今年新增的训练支持

580
00:29:22,296 --> 0:29:24,231
所有这些RNN

581
00:29:25,165 --> 0:29:26,433
本场演讲中

582
00:29:26,600 --> 0:29:29,303
我会讲到LSTM的训练

583
00:29:32,606 --> 0:29:34,074
看个具体例子

584
00:29:34,708 --> 0:29:37,110
这是一个活动分类网络

585
00:29:37,744 --> 0:29:40,480
以动作感官数据为输入

586
00:29:40,547 --> 0:29:44,985
就是读取传感器数据

587
00:29:45,619 --> 0:29:47,287
网络然后使用这些数据

588
00:29:47,721 --> 0:29:50,691
识别用户所做的运动

589
00:29:51,124 --> 0:29:54,061
比如我们想确定用户是在骑行

590
00:29:54,361 --> 0:29:55,929
滑雪还是散步

591
00:29:59,132 --> 0:30:01,201
你看到网络的

592
00:29:59,132 --> 0:30:01,201
你看到网络的

593
00:30:02,135 --> 0:30:03,537
配置很有趣

594
00:30:03,604 --> 0:30:08,175
它含有一系列CNN原语

595
00:30:08,242 --> 0:30:10,244
随后是LSTM原语

596
00:30:10,310 --> 0:30:12,312
再后面是更多的CNN原语

597
00:30:12,579 --> 0:30:14,648
为什么这样设置？

598
00:30:16,984 --> 0:30:19,553
尽管输入的是感官数据

599
00:30:20,487 --> 0:30:23,156
但显示的是一批1D图像

600
00:30:23,223 --> 0:30:24,291
6个特征通道

601
00:30:24,358 --> 0:30:28,128
一个特征通道

602
00:30:28,195 --> 0:30:29,663
和陀螺仪上的数据

603
00:30:30,631 --> 0:30:33,967
每张1D图像为2000像素

604
00:30:34,034 --> 0:30:37,171
你可以将它们当作即时样本

605
00:30:37,738 --> 0:30:40,474
因为我们要识别的动作

606
00:30:40,541 --> 0:30:41,775
是随时发生的

607
00:30:44,645 --> 0:30:48,415
然后通过1D卷积原语

608
00:30:49,283 --> 0:30:53,820
它将2000个样本压缩到20个

609
00:30:56,123 --> 0:30:58,292
但它要占用几个特征通道

610
00:30:58,358 --> 0:31:01,328
这样就不会丢失

611
00:30:58,358 --> 0:31:01,328
这样就不会丢失

612
00:31:03,230 --> 0:31:05,832
然后新的数据图像

613
00:31:06,133 --> 0:31:09,303
被传递给LSTM原语

614
00:31:10,404 --> 0:31:12,406
然后运行20个LSTM迭代

615
00:31:12,906 --> 0:31:15,776
于是LSTM处理的

616
00:31:15,843 --> 0:31:17,077
而不是2000

617
00:31:17,144 --> 0:31:20,514
而且是更高级的数据特征表达

618
00:31:22,549 --> 0:31:24,685
后面还有几个CNN原语

619
00:31:25,419 --> 0:31:28,355
精细化数据特征

620
00:31:29,389 --> 0:31:32,893
序列的最后一个原语

621
00:31:33,193 --> 0:31:36,263
分配概率值给不同的动作类别

622
00:31:36,330 --> 0:31:37,731
这就是网络的输出

623
00:31:38,632 --> 0:31:40,901
现在看看怎样训练它

624
00:31:42,202 --> 0:31:44,938
我们还是需要一个损失原语

625
00:31:45,005 --> 0:31:46,507
将网络的输出

626
00:31:46,573 --> 0:31:48,008
和标签作为输入

627
00:31:48,542 --> 0:31:50,410
然后是下半部分图形

628
00:31:51,111 --> 0:31:54,481
在下半部分还是梯度原语

629
00:31:54,548 --> 0:31:56,350
对应正向原语

630
00:31:56,416 --> 0:31:58,218
包括LSTM原语

631
00:31:59,052 --> 0:32:00,287
那么训练

632
00:31:59,052 --> 0:32:00,287
那么训练

633
00:32:01,722 --> 0:32:04,224
先是运行网络正向传播

634
00:32:04,825 --> 0:32:06,527
然后计算损失

635
00:32:07,594 --> 0:32:09,530
然后梯度传播

636
00:32:09,596 --> 0:32:12,132
计算梯度用于更新权重

637
00:32:12,633 --> 0:32:14,468
这个设置很像

638
00:32:15,335 --> 0:32:17,037
CNN训练的设置

639
00:32:17,104 --> 0:32:19,406
最后一步当然也是更新权重

640
00:32:19,873 --> 0:32:22,176
大家知道LSTM也有权重

641
00:32:22,242 --> 0:32:23,677
也需要更新

642
00:32:26,079 --> 0:32:30,617
现在看看在MPS中

643
00:32:30,684 --> 0:32:33,620
首先来看

644
00:32:33,687 --> 0:32:35,522
用我们的框架

645
00:32:36,657 --> 0:32:39,493
第一步是创建LSTM层级描述符

646
00:32:40,594 --> 0:32:44,131
用初始训练参数

647
00:32:44,731 --> 0:32:46,066
通过数据源提供器

648
00:32:46,400 --> 0:32:48,502
初始的训练参数是

649
00:32:48,569 --> 0:32:51,305
随机的小数字或检查点值

650
00:32:52,406 --> 0:32:54,208
训练中描述符的设置

651
00:32:54,274 --> 0:32:56,810
跟推断完全一样

652
00:32:58,612 --> 0:33:01,615
我们以前讨论过层描述符的设置

653
00:32:58,612 --> 0:33:01,615
我们以前讨论过层描述符的设置

654
00:33:01,915 --> 0:33:05,052
在去年的WWDC演讲

655
00:33:05,118 --> 0:33:08,255
所以推荐大家去看那场演讲了解更多

656
00:33:08,322 --> 0:33:10,390
关于LSTM

657
00:33:11,158 --> 0:33:12,626
有了描述符之后

658
00:33:13,894 --> 0:33:17,798
就要用它来创建LSTM训练层

659
00:33:19,766 --> 0:33:22,636
MPS会添加训练权重

660
00:33:22,936 --> 0:33:25,572
使用描述符定义的数据源

661
00:33:26,206 --> 0:33:28,141
还需要一些矩阵

662
00:33:28,242 --> 0:33:29,710
实现梯度计算

663
00:33:30,644 --> 0:33:33,747
你要用

664
00:33:33,814 --> 0:33:34,648
API

665
00:33:34,715 --> 0:33:37,217
在训练层上

666
00:33:37,751 --> 0:33:39,520
然后训练权重

667
00:33:39,887 --> 0:33:42,389
会被用于正向和梯度传播中

668
00:33:42,890 --> 0:33:44,658
然后被传递给优化器

669
00:33:44,725 --> 0:33:47,194
与计算好的梯度一起用于更新权重

670
00:33:49,396 --> 0:33:53,534
现在要准备一些输入和输出

671
00:33:54,535 --> 0:33:56,470
这个例子展示了如何创建

672
00:33:56,937 --> 0:33:59,840
矩阵去管理输入和输出序列

673
00:33:59,907 --> 0:34:02,276
在正向和梯度传播中

674
00:33:59,907 --> 0:34:02,276
在正向和梯度传播中

675
00:34:02,342 --> 0:34:04,678
每个需要20个矩阵

676
00:34:05,712 --> 0:34:09,149
这是如何初始化矩阵数据

677
00:34:11,784 --> 0:34:14,855
现在就可以训练活动分类网络了

678
00:34:15,255 --> 0:34:16,089
用MPS

679
00:34:16,156 --> 0:34:17,157
这个代码样本中

680
00:34:17,224 --> 0:34:19,760
我只强调LSTM过滤器

681
00:34:20,127 --> 0:34:21,395
因为时间有限

682
00:34:23,563 --> 0:34:26,600
在正向传播中

683
00:34:26,667 --> 0:34:28,835
正向通过LSTM训练层

684
00:34:29,735 --> 0:34:31,170
然后反向传播

685
00:34:31,237 --> 0:34:34,440
运行20个矩阵的序列

686
00:34:34,507 --> 0:34:35,641
计算梯度

687
00:34:36,577 --> 0:34:38,978
现在已有训练权重

688
00:34:39,246 --> 0:34:40,848
计算好的梯度

689
00:34:40,914 --> 0:34:44,016
就可以将它们传递到

690
00:34:45,686 --> 0:34:47,754
最后我要补充一点

691
00:34:49,389 --> 0:34:52,726
卷积神经网络对图像的处理

692
00:34:52,793 --> 0:34:55,062
和对LSTM的运行是基于矩阵

693
00:34:56,063 --> 0:34:58,632
我们会提供便利内核给这个框架

694
00:34:59,199 --> 0:35:02,236
方便来回转换图像和矩阵

695
00:34:59,199 --> 0:35:02,236
方便来回转换图像和矩阵

696
00:35:03,136 --> 0:35:04,438
那么要复制

697
00:35:05,205 --> 0:35:06,607
一张图像到矩阵

698
00:35:06,673 --> 0:35:10,077
需要使用

699
00:35:10,143 --> 0:35:11,812
这是创建方法

700
00:35:12,145 --> 0:35:15,883
以及如何给一批图像编码

701
00:35:17,084 --> 0:35:21,955
目的矩阵的每行都含有一个源图像

702
00:35:23,056 --> 0:35:25,459
要从矩阵复制到图像

703
00:35:25,926 --> 0:35:29,162
需要内核

704
00:35:29,229 --> 0:35:30,697
这一部分是创建

705
00:35:30,998 --> 0:35:33,267
这部分是在GPU上编码

706
00:35:35,302 --> 0:35:40,807
大家已经了解了如何使用MPS

707
00:35:41,808 --> 0:35:44,344
也看过了

708
00:35:44,411 --> 0:35:46,180
现在由MPS驱动

709
00:35:46,246 --> 0:35:47,881
现在再看一个演示

710
00:35:49,550 --> 0:35:51,218
我们在与Google合作

711
00:35:51,285 --> 0:35:53,987
添加Metal性能着色器框架

712
00:35:54,054 --> 0:35:56,323
给TensorFlow…

713
00:35:57,090 --> 0:35:59,193
以提升macOS机器学习的速度

714
00:35:59,259 --> 0:36:01,495
也给大家带来了动态演示

715
00:35:59,259 --> 0:36:01,495
也给大家带来了动态演示

716
00:36:01,562 --> 0:36:03,864
具体来说 我们要演示的是

717
00:36:03,931 --> 0:36:07,034
训练InceptionV3

718
00:36:08,135 --> 0:36:10,737
使用TensorFlow

719
00:36:11,638 --> 0:36:12,739
这个演示中

720
00:36:14,608 --> 0:36:18,545
我还是使用MacBook Pro

721
00:36:19,313 --> 0:36:22,883
TensorFlow

722
00:36:23,317 --> 0:36:27,454
外部GPU

723
00:36:27,921 --> 0:36:29,056
演示设置

724
00:36:29,623 --> 0:36:31,358
我己安装了

725
00:36:31,658 --> 0:36:34,761
也预先加载了

726
00:36:34,862 --> 0:36:36,196
和训练数据集

727
00:36:36,263 --> 0:36:39,499
现在训练网络30次迭代

728
00:36:41,001 --> 0:36:42,970
你看速度多快

729
00:36:43,437 --> 0:36:44,705
同样 整个网络

730
00:36:44,838 --> 0:36:47,808
所有原语

731
00:36:48,075 --> 0:36:50,277
都是在外部GPU上运行

732
00:36:50,777 --> 0:36:51,912
这就完成了

733
00:36:52,479 --> 0:36:53,714
大家看到

734
00:36:53,780 --> 0:36:57,117
训练速度大概是

735
00:36:57,784 --> 0:37:00,721
平台状态汇总中说过

736
00:36:57,784 --> 0:37:00,721
平台状态汇总中说过

737
00:37:01,188 --> 0:37:03,557
训练InceptionV3网络

738
00:37:04,157 --> 0:37:06,226
用MPS驱动的

739
00:37:06,727 --> 0:37:10,364
要比不用MPS

740
00:37:11,231 --> 0:37:13,367
以上就是TensorFlow演示

741
00:37:16,203 --> 0:37:17,404
谢谢大家

742
00:37:22,042 --> 0:37:23,710
现在做个总结

743
00:37:24,845 --> 0:37:27,648
今年新添加了

744
00:37:28,081 --> 0:37:30,984
给卷积和卷积转置原语

745
00:37:31,552 --> 0:37:34,621
提升CNN推断的性能

746
00:37:35,255 --> 0:37:37,691
我们还添加了GPU加速原语

747
00:37:37,891 --> 0:37:39,359
用于训练神经网络

748
00:37:39,426 --> 0:37:43,330
这些原语都已优化

749
00:37:44,765 --> 0:37:47,534
我们还为训练添加了

750
00:37:48,468 --> 0:37:51,538
简化了GPU上对神经网络的训练

751
00:37:51,839 --> 0:37:53,040
并让我们可以

752
00:37:53,106 --> 0:37:56,243
让不同的GPU

753
00:37:58,745 --> 0:38:02,115
本场演讲的更多信息

754
00:37:58,745 --> 0:38:02,115
本场演讲的更多信息

755
00:38:02,182 --> 0:38:03,984
请访问开发者网站

756
00:38:05,586 --> 0:38:08,689
在明早9点的

757
00:38:09,089 --> 0:38:12,092
希望能见到你们

758
00:38:13,861 --> 0:38:17,965
谢谢大家的到来
