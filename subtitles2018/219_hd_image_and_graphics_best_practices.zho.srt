1
00:00:16,750 --> 0:00:23,023
（图像和图形最佳实践

2
00:00:24,925 --> 0:00:26,059
大家好

3
00:00:26,126 --> 0:00:28,595
欢迎来到图像和图形最佳实践

4
00:00:28,896 --> 0:00:31,064
我叫Kyle 我在UIKit工作

5
00:00:31,565 --> 0:00:33,800
今天我将与你分享关于如何

6
00:00:33,867 --> 0:00:35,802
在你的app中高效使用图形内容的

7
00:00:35,869 --> 0:00:38,438
一些技术以及策略

8
00:00:39,773 --> 0:00:41,642
我们将浏览整个框架栈

9
00:00:41,708 --> 0:00:45,212
首先 我们将从UIImage

10
00:00:45,279 --> 0:00:47,915
这些都是UIKit的高级工具

11
00:00:47,981 --> 0:00:50,184
用于在你的app中使用图形内容

12
00:00:51,084 --> 0:00:55,022
接着我们将重点关注

13
00:00:55,088 --> 0:00:57,191
使用UIKit最优地

14
00:00:57,991 --> 0:00:59,993
最后 我们将简要地介绍一下

15
00:01:00,060 --> 0:01:04,031
如何将先进的CPU和GPU技术

16
00:01:04,096 --> 0:01:05,364
集成到你的app中

17
00:01:06,667 --> 0:01:09,036
在整个演讲中 我们将主要关注

18
00:01:09,102 --> 0:01:15,509
如何使用设备上的两个稀缺资源

19
00:01:16,109 --> 0:01:19,580
我们倾向于将这些东西视为

20
00:01:19,646 --> 0:01:22,049
它们在调试导航栏中

21
00:01:22,115 --> 0:01:25,485
它们在工具app中

22
00:01:25,853 --> 0:01:27,888
但实际上

23
00:01:29,356 --> 0:01:34,328
很明显

24
00:01:34,895 --> 0:01:37,464
将会对电池寿命和

25
00:01:37,831 --> 0:01:39,700
具有负面的影响

26
00:01:40,601 --> 0:01:44,304
但可能不那么明显的是

27
00:01:44,671 --> 0:01:48,208
和系统上的其他app消耗更多内存

28
00:01:48,275 --> 0:01:51,245
也会导致更高的CPU使用率

29
00:01:51,612 --> 0:01:55,983
这对电池寿命和性能

30
00:01:56,049 --> 0:01:59,319
因此 我们将重点关注

31
00:02:01,688 --> 0:02:03,757
讨论这个问题还能有什么

32
00:02:03,824 --> 0:02:06,793
比一个需要处理大量

33
00:02:06,860 --> 0:02:09,329
更好的背景呢

34
00:02:10,163 --> 0:02:11,865
你看 我们正在这里编辑一张照片

35
00:02:12,332 --> 0:02:15,269
正如我之前提到的

36
00:02:15,335 --> 0:02:18,605
都是用于处理图像数据的高级类

37
00:02:18,672 --> 0:02:22,643
我们用一个UIImage

38
00:02:23,577 --> 0:02:27,447
我们倾向于将app中的图形内容

39
00:02:27,514 --> 0:02:30,651
富内容 如这张照片

40
00:02:31,351 --> 0:02:34,087
UIImage也是

41
00:02:34,154 --> 0:02:37,991
用来表示某些事物

42
00:02:39,893 --> 0:02:41,762
如前所述

43
00:02:42,362 --> 0:02:45,599
UIImageView

44
00:02:45,666 --> 0:02:47,134
用于显示UIImage的类

45
00:02:50,337 --> 0:02:52,139
若采用经典的MVC模型进行类比

46
00:02:52,506 --> 0:02:55,409
UIImage可以被看作模型对象

47
00:02:55,475 --> 0:02:58,679
当然 正如名称所暗示

48
00:02:59,513 --> 0:03:02,449
而这些对象作为模型和视图

49
00:02:59,513 --> 0:03:02,449
而这些对象作为模型和视图

50
00:03:02,516 --> 0:03:04,251
肩负着其在经典模型中的责任

51
00:03:04,918 --> 0:03:07,855
UIImage负责加载图片内容

52
00:03:08,355 --> 0:03:11,825
UIImageView

53
00:03:13,460 --> 0:03:15,529
现在 我们可以将其理解为

54
00:03:15,596 --> 0:03:17,097
我们建立的简单关系

55
00:03:17,164 --> 0:03:18,532
这是一种单向关系

56
00:03:19,166 --> 0:03:22,035
但实际情况却比这复杂一点

57
00:03:23,136 --> 0:03:26,006
除了渲染是一个连续的过程

58
00:03:26,073 --> 0:03:27,508
而不是一次性事件之外

59
00:03:28,242 --> 0:03:32,412
这里的理解其实有一个隐藏的阶段

60
00:03:32,479 --> 0:03:34,581
对衡量app的性能至关重要

61
00:03:35,115 --> 0:03:36,750
这个阶段被称为解码

62
00:03:37,818 --> 0:03:39,686
但为了讨论解码

63
00:03:39,753 --> 0:03:42,189
我首先需要讨论

64
00:03:43,590 --> 0:03:45,859
缓冲区只是一段连续的内存区域

65
00:03:46,360 --> 0:03:48,195
但我们倾向于使用术语“缓冲区”

66
00:03:48,262 --> 0:03:52,065
来表示由一系列元素组成的内存

67
00:03:52,533 --> 0:03:56,470
这些元素具有相同尺寸

68
00:03:57,838 --> 0:04:00,440
而我们关注的重点

69
00:03:57,838 --> 0:04:00,440
而我们关注的重点

70
00:04:01,008 --> 0:04:02,042
即图像缓冲区

71
00:04:02,409 --> 0:04:04,211
我们用这个术语

72
00:04:04,278 --> 0:04:07,781
来表示一种特定缓冲区

73
00:04:08,815 --> 0:04:10,484
此缓冲区的每个元素

74
00:04:10,551 --> 0:04:15,889
描述了图像中

75
00:04:17,057 --> 0:04:20,494
因此这个缓冲区在内存中的大小

76
00:04:20,560 --> 0:04:23,997
与它包含的图像大小成正比

77
00:04:25,332 --> 0:04:30,404
缓冲区的一个特别重要的例子

78
00:04:31,338 --> 0:04:34,708
帧缓冲区负责在你的app中

79
00:04:34,775 --> 0:04:35,709
保存实际渲染后的输出

80
00:04:36,910 --> 0:04:39,680
因此 当你的app更新

81
00:04:40,013 --> 0:04:44,551
UIKit将重新渲染app的窗口

82
00:04:44,952 --> 0:04:46,220
到帧缓冲区中

83
00:04:47,187 --> 0:04:50,591
该帧缓冲区提供每个像素的颜色信息

84
00:04:50,657 --> 0:04:52,092
显示硬件将读取这些信息

85
00:04:52,159 --> 0:04:55,095
以便点亮显示器上对应的像素

86
00:04:55,529 --> 0:04:58,198
（图像缓冲区）

87
00:04:58,265 --> 0:05:00,801
最后一部分以固定的时间间隔发生

88
00:04:58,265 --> 0:05:00,801
最后一部分以固定的时间间隔发生

89
00:05:01,835 --> 0:05:05,439
它可能以每秒60帧的频率发生

90
00:05:05,772 --> 0:05:08,509
或在配备ProMotion

91
00:05:08,575 --> 0:05:11,945
它的速度可以达到

92
00:05:13,814 --> 0:05:16,950
如果你的app中没有任何改变

93
00:05:17,017 --> 0:05:19,653
会将它上次看到的相同的数据

94
00:05:19,720 --> 0:05:20,921
从帧缓冲区中取出

95
00:05:21,788 --> 0:05:23,390
但是当你改变

96
00:05:24,091 --> 0:05:26,460
app中视图的内容

97
00:05:26,527 --> 0:05:29,963
例如 你为图像视图指定

98
00:05:31,064 --> 0:05:34,001
UIKit将重新渲染

99
00:05:34,067 --> 0:05:35,135
并将其放入帧缓冲区

100
00:05:35,836 --> 0:05:38,605
下一次显示硬件从帧缓冲区中取出时

101
00:05:38,672 --> 0:05:40,107
它将会得到你的新内容

102
00:05:41,842 --> 0:05:45,979
现在 你可以将图像缓冲区

103
00:05:46,046 --> 0:05:48,815
这只是一种包含一系列字节的缓冲区

104
00:05:49,917 --> 0:05:54,588
在我们的例子中 我们关心的是

105
00:05:54,655 --> 0:05:56,523
也许我们已经从网络上下载了

106
00:05:56,590 --> 0:05:58,125
或者我们从磁盘加载它们

107
00:05:58,192 --> 0:05:59,626
（数据缓冲区）

108
00:05:59,693 --> 0:06:03,897
包含图像文件的数据缓冲区

109
00:05:59,693 --> 0:06:03,897
包含图像文件的数据缓冲区

110
00:06:03,964 --> 0:06:06,967
这些元数据描述了

111
00:06:07,935 --> 0:06:10,103
然后 包含图像数据本身

112
00:06:10,170 --> 0:06:14,508
图像数据以某种形式编码

113
00:06:16,143 --> 0:06:19,379
这意味着该元数据后面的字节

114
00:06:19,646 --> 0:06:23,851
实际上并不直接描述图像中

115
00:06:26,987 --> 0:06:30,490
因此 我们可以深入了解一下

116
00:06:30,958 --> 0:06:32,626
这里有一个UIImageView

117
00:06:32,693 --> 0:06:34,795
并且我们已经突出显示了

118
00:06:34,862 --> 0:06:38,165
这块区域将由图像视图进行渲染填充

119
00:06:38,699 --> 0:06:41,034
我们已经为这个图像视图

120
00:06:41,101 --> 0:06:42,236
（管道实战）

121
00:06:42,302 --> 0:06:45,606
它有一个表示图像文件内容的

122
00:06:45,672 --> 0:06:48,509
其可能是从网络下载或从磁盘读取的

123
00:06:49,343 --> 0:06:54,348
但我们需要用每个像素的数据

124
00:06:55,382 --> 0:06:56,517
为了做到这一点

125
00:06:57,184 --> 0:07:00,087
UIImage将分配

126
00:06:57,184 --> 0:07:00,087
UIImage将分配

127
00:07:00,587 --> 0:07:03,257
其大小等于包含在数据缓冲区中的

128
00:07:03,323 --> 0:07:04,858
图像的大小

129
00:07:05,526 --> 0:07:07,728
并执行称为解码的操作

130
00:07:08,428 --> 0:07:13,133
这将JPEG或PNG

131
00:07:13,534 --> 0:07:16,436
转换为每个像素的图像信息

132
00:07:17,604 --> 0:07:20,007
然后 取决于我们的图像视图

133
00:07:20,741 --> 0:07:22,876
当UIKit要求

134
00:07:23,810 --> 0:07:28,015
它会在将数据复制到帧缓冲区

135
00:07:28,382 --> 0:07:30,184
对来自图像缓冲区的数据

136
00:07:32,486 --> 0:07:34,288
现在 解码阶段

137
00:07:34,721 --> 0:07:38,058
是CPU密集型的

138
00:07:38,559 --> 0:07:43,163
因此 不是每次UIKit要求

139
00:07:43,964 --> 0:07:48,702
UIImage绑定在图像缓冲区上

140
00:07:49,469 --> 0:07:53,273
因此 你的app

141
00:07:53,340 --> 0:07:56,543
都可能会持续存在大量的内存分配

142
00:07:56,610 --> 0:07:57,911
（解码注意事项）

143
00:07:57,978 --> 0:08:00,247
正如我前面提到的那样

144
00:07:57,978 --> 0:08:00,247
正如我前面提到的那样

145
00:08:00,314 --> 0:08:03,016
这种内存分配与输入图像的大小

146
00:08:03,083 --> 0:08:05,219
而与帧缓冲区中实际渲染的

147
00:08:05,285 --> 0:08:07,154
图像视图的大小没有必然联系

148
00:08:08,255 --> 0:08:11,258
而这会对性能

149
00:08:12,426 --> 0:08:16,597
app地址空间中的大块内存分配

150
00:08:16,663 --> 0:08:19,099
可能会迫使其他相关内容

151
00:08:19,166 --> 0:08:22,135
远离它想要引用的内容

152
00:08:22,202 --> 0:08:23,537
这种情况被称为碎片

153
00:08:23,604 --> 0:08:25,839
（滥用内存的后果）

154
00:08:25,906 --> 0:08:30,110
最终 如果你的app开始

155
00:08:30,410 --> 0:08:31,812
操作系统将会介入

156
00:08:31,879 --> 0:08:35,616
并开始透明地压缩物理内存的内容

157
00:08:36,717 --> 0:08:39,419
CPU需要参与这个操作

158
00:08:39,720 --> 0:08:42,890
因此 除了你自己的app

159
00:08:43,357 --> 0:08:47,394
你可能会增加你无法控制的

160
00:08:48,962 --> 0:08:52,799
最终 你的app可能会

161
00:08:53,100 --> 0:08:55,869
以至于操作系统需要启动终止进程

162
00:08:56,403 --> 0:08:59,306
它将从低优先级的后台进程开始

163
00:09:00,140 --> 0:09:03,243
最终 如果你的app消耗了

164
00:09:03,610 --> 0:09:05,646
你的app本身可能会被终止

165
00:09:06,313 --> 0:09:07,681
而其中被终止的后台进程

166
00:09:07,748 --> 0:09:09,783
可能正代表用户执行某些重要工作

167
00:09:09,850 --> 0:09:12,553
因此 它们可能一终止就立即

168
00:09:13,587 --> 0:09:15,155
所以 即使你的app

169
00:09:15,455 --> 0:09:18,025
可能只会在短时间内消耗内存

170
00:09:18,425 --> 0:09:22,963
它也可能对CPU使用率

171
00:09:24,064 --> 0:09:27,401
因此 我们希望减少app的

172
00:09:27,467 --> 0:09:31,104
我们可以用一种称为向下采样的技术

173
00:09:32,739 --> 0:09:36,910
现在 我们来看一下

174
00:09:36,977 --> 0:09:40,480
包括我们要在其中显示图像的

175
00:09:40,547 --> 0:09:44,384
实际上比要显示的图像小的这一事实

176
00:09:44,985 --> 0:09:47,788
通常

177
00:09:47,855 --> 0:09:50,290
在渲染阶段

178
00:09:50,357 --> 0:09:51,692
将负责缩小该图像

179
00:09:52,259 --> 0:09:55,696
但我们可以通过使用这种下采样技术

180
00:09:56,063 --> 0:09:59,733
本质上 我们要做的就是捕捉

181
00:10:00,734 --> 0:10:02,269
并将其放入缩略图的对象中

182
00:10:03,270 --> 0:10:08,609
最终我们将会降低内存开销

183
00:10:08,675 --> 0:10:11,278
因为我们将有一个较小的

184
00:10:12,713 --> 0:10:15,749
这样 我们设置了一个图像源

185
00:10:16,350 --> 0:10:19,987
然后将解码图像缓冲区

186
00:10:20,053 --> 0:10:22,489
并将该UIImage

187
00:10:23,423 --> 0:10:25,492
接着 我们就可以丢弃原来的

188
00:10:25,559 --> 0:10:26,927
包含我们图片的数据缓冲区

189
00:10:26,994 --> 0:10:30,063
其结果是我们的app

190
00:10:30,130 --> 0:10:31,231
将具有一个更小的长期内存占用足迹

191
00:10:31,598 --> 0:10:34,968
执行该操作的代码有几个步骤

192
00:10:35,035 --> 0:10:37,838
我不打算讲述非常低级的细节

193
00:10:37,905 --> 0:10:39,573
但我会重点介绍一些重要的部分

194
00:10:40,374 --> 0:10:42,809
首先 我们要创建一个

195
00:10:44,178 --> 0:10:47,748
CGImageSourceCreate

196
00:10:47,814 --> 0:10:49,783
我们这里要传递的重要选项参数

197
00:10:49,850 --> 0:10:51,985
是这个ShouldCache标志

198
00:10:52,052 --> 0:10:54,254
这就告诉了

199
00:10:54,321 --> 0:10:55,822
我们只是在创建一个对象

200
00:10:55,889 --> 0:11:00,694
来表示存储在该URL的

201
00:10:55,889 --> 0:11:00,694
来表示存储在该URL的

202
00:11:01,728 --> 0:11:04,531
不要立即解码这个图像

203
00:11:04,598 --> 0:11:06,200
只需创建一个表示它的对象

204
00:11:06,266 --> 0:11:08,769
我们将需要来自此URL的信息

205
00:11:11,104 --> 0:11:14,875
然后 我们将在水平和垂直轴上

206
00:11:14,942 --> 0:11:16,376
该计算基于期望的图片大小

207
00:11:16,443 --> 0:11:18,946
以及我们要渲染的像素和点大小

208
00:11:19,847 --> 0:11:22,015
这是以像素为单位的较大维度

209
00:11:22,683 --> 0:11:24,117
计算这些信息

210
00:11:24,718 --> 0:11:27,454
然后为我们的缩略图

211
00:11:28,255 --> 0:11:30,057
这里列出了几个选项

212
00:11:30,123 --> 0:11:32,926
你可以在文档中

213
00:11:32,993 --> 0:11:37,097
但非常重要的是

214
00:11:38,465 --> 0:11:41,668
通过在这里传递这个选项

215
00:11:41,735 --> 0:11:44,171
当我要求你创建缩略图时

216
00:11:44,238 --> 0:11:48,509
这就是你应该为我创建

217
00:11:49,610 --> 0:11:50,911
因此我们可以确切地控制

218
00:11:50,978 --> 0:11:53,080
何时调用CPU来进行解码

219
00:11:56,016 --> 0:12:00,220
接着我们创建缩略图

220
00:11:56,016 --> 0:12:00,220
接着我们创建缩略图

221
00:12:00,687 --> 0:12:02,189
将其包装在UIImage中

222
00:12:02,256 --> 0:12:03,924
从我们在此编写的

223
00:12:05,993 --> 0:12:09,196
为了让你了解这项技术

224
00:12:09,796 --> 0:12:11,765
我们只在这里显示全屏图像

225
00:12:11,832 --> 0:12:14,434
这是一张大小为

226
00:12:14,501 --> 0:12:15,836
如果我们不做优化

227
00:12:15,903 --> 0:12:19,606
只是将UIImageView放入

228
00:12:20,007 --> 0:12:24,144
这个app占用了31.5兆

229
00:12:25,879 --> 0:12:27,814
现在 使用这种下采样技术

230
00:12:27,881 --> 0:12:31,652
并且只创建一个实际显示大小的

231
00:12:32,152 --> 0:12:33,921
我们可以得到这个app的

232
00:12:33,987 --> 0:12:36,390
内存使用情况

233
00:12:36,857 --> 0:12:39,726
这大大减少了内存使用量

234
00:12:44,331 --> 0:12:46,567
谢谢大家 但你们都应该

235
00:12:46,633 --> 0:12:48,468
使用此技术而得到掌声

236
00:12:49,770 --> 0:12:52,739
你可以想象这对于一个

237
00:12:52,806 --> 0:12:56,276
一小块空间里显示大量

238
00:12:56,844 --> 0:12:58,779
的app来说有多么重要

239
00:12:59,446 --> 0:13:00,514
例如Camera Roll

240
00:12:59,446 --> 0:13:00,514
例如Camera Roll

241
00:13:02,616 --> 0:13:05,519
你可以使用UICollectionView

242
00:13:05,586 --> 0:13:08,422
因此我们为indexPath中

243
00:13:09,089 --> 0:13:11,859
并且我们使用之前写的辅助函数

244
00:13:11,925 --> 0:13:15,863
将图像向下采样使之缩小到

245
00:13:15,929 --> 0:13:18,165
它们将要显示的大小

246
00:13:19,733 --> 0:13:22,135
你认为这是一件很好的事情 对吧？

247
00:13:22,202 --> 0:13:25,339
我们实际上减少了内存的使用量

248
00:13:25,405 --> 0:13:27,007
这些大的内存区域

249
00:13:27,407 --> 0:13:30,511
不幸的是 这并不能解决我们的

250
00:13:30,577 --> 0:13:34,314
这些问题在可滚动视图 比如

251
00:13:35,415 --> 0:13:37,084
你可能曾经见过这种情况

252
00:13:37,150 --> 0:13:40,487
你在app中滚动页面

253
00:13:41,188 --> 0:13:42,422
这里发生的情况是

254
00:13:42,823 --> 0:13:48,529
当我们滚动页面时

255
00:13:49,096 --> 0:13:50,130
或它所做的工作

256
00:13:50,197 --> 0:13:54,902
可以在显示硬件需要帧缓冲的

257
00:13:55,536 --> 0:13:59,473
所以当帧缓冲区被更新时

258
00:13:59,540 --> 0:14:02,342
并且显示硬件能够及时获得新帧

259
00:13:59,540 --> 0:14:02,342
并且显示硬件能够及时获得新帧

260
00:14:03,310 --> 0:14:06,013
但现在 我们即将显示另一行图像

261
00:14:06,346 --> 0:14:09,583
在将单元格交回

262
00:14:10,350 --> 0:14:12,553
我们要求Core Graphics

263
00:14:13,453 --> 0:14:15,155
这将会花费很长的CPU时间

264
00:14:16,356 --> 0:14:19,726
以至于我们不得不重新渲染帧缓冲区

265
00:14:20,861 --> 0:14:23,063
但显示器硬件按固定的时间间隔运行

266
00:14:23,830 --> 0:14:27,467
因此 从用户的角度来看

267
00:14:27,534 --> 0:14:29,203
在可滚动视图中进行解码

268
00:14:29,269 --> 0:14:30,671
我们完成了对图像的解码

269
00:14:30,737 --> 0:14:33,740
我们可以将单元格提供给

270
00:14:35,042 --> 0:14:36,944
和以前一样 动画继续

271
00:14:37,878 --> 0:14:39,413
刚刚在那里看到了一个粘连

272
00:14:40,881 --> 0:14:42,049
现在 除了这种行为

273
00:14:42,115 --> 0:14:45,085
明显的响应性后果

274
00:14:45,886 --> 0:14:49,523
其对电池寿命有更细微的不利影响

275
00:14:50,390 --> 0:14:54,895
因为iOS非常擅长管理

276
00:14:55,562 --> 0:14:59,266
对电池的电量需求

277
00:14:59,733 --> 0:15:01,568
然而我们在这里可以看到峰值

278
00:14:59,733 --> 0:15:01,568
然而我们在这里可以看到峰值

279
00:15:02,035 --> 0:15:04,905
当新行即将进入滚动视图时

280
00:15:05,973 --> 0:15:10,310
我们会看到较高的CPU使用率

281
00:15:12,279 --> 0:15:16,950
我们可以使用两种技术

282
00:15:17,584 --> 0:15:18,819
第一个是预取

283
00:15:19,753 --> 0:15:23,190
如果你想知道更多关于预取的知识

284
00:15:23,257 --> 0:15:26,894
可以观看今年WWDC中的演讲

285
00:15:27,461 --> 0:15:28,862
这里的基本思想

286
00:15:28,929 --> 0:15:33,267
是预取允许CollectionView

287
00:15:33,700 --> 0:15:37,905
它当前不需要一个单元格

288
00:15:37,971 --> 0:15:40,607
因此如果你有任何工作要做

289
00:15:41,375 --> 0:15:44,044
这允许我们随时间推移

290
00:15:45,279 --> 0:15:47,848
因此我们减少了CPU使用的

291
00:15:49,650 --> 0:15:52,653
我们可以使用的另一种技术

292
00:15:53,287 --> 0:15:55,155
既然我们已经随时间分散了工作量

293
00:15:55,222 --> 0:15:57,858
我们也可以将这些工作

294
00:16:01,595 --> 0:16:02,829
这样做的效果

295
00:16:02,896 --> 0:16:05,399
是你的app具有更强的响应能力

296
00:16:05,732 --> 0:16:08,035
并且该设备具有更长的电池寿命

297
00:16:09,570 --> 0:16:11,071
为了在这里进行实际演示

298
00:16:11,438 --> 0:16:15,542
我们已经在数据源上实现了预取方法

299
00:16:16,610 --> 0:16:18,412
它将会调用我们的辅助函数

300
00:16:18,645 --> 0:16:21,248
来生成我们将要在

301
00:16:21,849 --> 0:16:25,485
所显示图片的下采样版本

302
00:16:27,254 --> 0:16:31,925
它通过将工作分派到

303
00:16:33,727 --> 0:16:35,195
很好 我们的工作正在后台进行

304
00:16:35,262 --> 0:16:36,697
这就是我们想要做的

305
00:16:37,564 --> 0:16:40,200
但这里有一个潜在的缺陷

306
00:16:40,734 --> 0:16:43,737
这是一个我们喜欢称之为

307
00:16:44,505 --> 0:16:47,908
当我们要求系统去做

308
00:16:48,408 --> 0:16:50,444
更多的工作时就会发生这种情况

309
00:16:51,411 --> 0:16:53,447
如果我们要显示大量的图像

310
00:16:53,514 --> 0:16:55,282
比如同时显示6张或8张图片

311
00:16:55,616 --> 0:16:58,018
但是我们在只有两个CPU的

312
00:16:58,619 --> 0:17:00,921
我们不能一次完成所有这些工作

313
00:16:58,619 --> 0:17:00,921
我们不能一次完成所有这些工作

314
00:17:00,988 --> 0:17:03,457
我们无法在不存在的CPU上

315
00:17:03,524 --> 0:17:04,958
（线程爆炸）

316
00:17:05,025 --> 0:17:06,159
现在 为了避免

317
00:17:06,627 --> 0:17:09,762
向一个全局队列中

318
00:17:10,263 --> 0:17:15,569
GCD将创建新线程来捕捉

319
00:17:16,236 --> 0:17:18,438
然后 CPU将花费大量时间

320
00:17:18,505 --> 0:17:20,040
在这些线程之间进行切换

321
00:17:20,339 --> 0:17:23,109
尝试在所有工作上取得我们

322
00:17:23,176 --> 0:17:25,244
要求操作系统为我们做的渐进式进展

323
00:17:25,712 --> 0:17:27,146
在这些线程之间不停切换

324
00:17:27,214 --> 0:17:29,016
实际上是相当大的开销

325
00:17:31,351 --> 0:17:34,688
如果有一个或多个CPU有机会

326
00:17:34,755 --> 0:17:38,058
一次处理完图片 效果会更好

327
00:17:39,193 --> 0:17:43,297
因此 我们将借鉴去年的

328
00:17:43,764 --> 0:17:46,300
演讲中所提出的一项技术

329
00:17:46,733 --> 0:17:47,935
我们将同步一些工作

330
00:17:48,001 --> 0:17:50,771
抱歉 不是同步

331
00:17:52,940 --> 0:17:57,444
因此 我们现在不是简单地

332
00:17:58,178 --> 0:17:59,880
而是创建一个串行队列

333
00:18:01,148 --> 0:18:03,817
并且在预取方法的实现中

334
00:18:05,285 --> 0:18:07,588
我们异步地将工作分派到该队列

335
00:18:07,888 --> 0:18:10,090
它的确意味着单个图像的加载

336
00:18:10,157 --> 0:18:12,860
可能要比以前晚才能开始取得进展

337
00:18:13,560 --> 0:18:16,430
但这也意味着CPU将花费更少时间

338
00:18:17,064 --> 0:18:19,166
在它可以做的小任务之间来回切换

339
00:18:19,967 --> 0:18:21,468
（图片来源）

340
00:18:21,535 --> 0:18:24,571
我们显示的这些图像

341
00:18:25,105 --> 0:18:27,241
它们可能是随app附带的

342
00:18:28,141 --> 0:18:30,177
在这种情况下

343
00:18:30,544 --> 0:18:33,180
或者可能存储在一个文件中

344
00:18:33,881 --> 0:18:35,349
或者它们可能来自网络

345
00:18:35,983 --> 0:18:37,651
或者是在app的

346
00:18:37,718 --> 0:18:40,587
文档目录的文档中

347
00:18:41,188 --> 0:18:42,656
它们可以存储在缓存中

348
00:18:43,690 --> 0:18:46,260
但是对于你的app所附带的图片

349
00:18:46,527 --> 0:18:50,030
我们强烈建议你使用

350
00:18:51,198 --> 0:18:52,733
这其中有很多原因

351
00:18:54,535 --> 0:18:58,238
图像素材针对基于名称和

352
00:18:58,639 --> 0:19:01,608
在素材目录中查找图片资源

353
00:18:58,639 --> 0:19:01,608
在素材目录中查找图片资源

354
00:19:01,675 --> 0:19:04,611
会比搜索具有特定命名格式的

355
00:19:04,678 --> 0:19:06,813
（预置图像素材）

356
00:19:06,880 --> 0:19:10,551
素材目录运行时在管理

357
00:19:10,617 --> 0:19:12,219
缓冲区大小方面也非常智能

358
00:19:13,854 --> 0:19:16,723
还有一些与运行时性能无关的特性

359
00:19:17,090 --> 0:19:18,992
是图像素材独有的

360
00:19:19,059 --> 0:19:21,261
包括针对不同设备瘦身的功能

361
00:19:21,328 --> 0:19:24,264
这意味着你的app只下载

362
00:19:24,331 --> 0:19:26,700
与其所运行的设备相关的图像资源

363
00:19:27,334 --> 0:19:28,468
还有矢量图形功能

364
00:19:30,904 --> 0:19:33,607
矢量图形是iOS 11中

365
00:19:33,674 --> 0:19:37,077
你可以在图像素材编辑器中

366
00:19:37,144 --> 0:19:39,246
选中“保留矢量数据”

367
00:19:40,180 --> 0:19:44,318
其效果是如果你的图像

368
00:19:44,384 --> 0:19:47,120
大于或小于图像的原始大小

369
00:19:47,454 --> 0:19:48,522
它也不会变得模糊

370
00:19:49,356 --> 0:19:52,659
这种图像实际上是从矢量图形

371
00:19:52,726 --> 0:19:54,528
因此它具有很好的边缘清晰度

372
00:19:55,762 --> 0:19:58,198
我们在操作系统中的一个地方

373
00:19:58,265 --> 0:20:01,368
若你在Accessibility

374
00:19:58,265 --> 0:20:01,368
若你在Accessibility

375
00:20:01,768 --> 0:20:03,270
到一个非常大的尺寸

376
00:20:03,570 --> 0:20:06,673
然后点击并按住标签栏中的项目

377
00:20:07,007 --> 0:20:09,977
将会出现一个小HUD

378
00:20:10,043 --> 0:20:12,846
显示当前你的手指所按住

379
00:20:14,081 --> 0:20:18,151
因此如果你希望你的图片在这样的

380
00:20:18,752 --> 0:20:21,655
那就选中图像素材管理器中的

381
00:20:21,722 --> 0:20:23,790
“保留向量插图”复选框

382
00:20:23,857 --> 0:20:25,993
抱歉 应该是

383
00:20:26,793 --> 0:20:29,930
它的工作方式与我们之前看到的

384
00:20:30,664 --> 0:20:34,601
只是这里不是一个解码阶段

385
00:20:34,668 --> 0:20:37,137
其负责获取矢量数据

386
00:20:37,204 --> 0:20:40,941
并将其转换为可复制到

387
00:20:41,008 --> 0:20:42,910
（矢量图形管道）

388
00:20:43,277 --> 0:20:44,978
（矢量图形优化）

389
00:20:45,045 --> 0:20:46,847
如果我们必须为你的app中

390
00:20:46,914 --> 0:20:50,817
所有矢量图形进行这项操作

391
00:20:50,884 --> 0:20:52,653
因此我们在这里做了一个优化

392
00:20:53,153 --> 0:20:56,657
如果你有一张选中了

393
00:20:57,291 --> 0:20:59,626
但你以正常尺寸渲染它

394
00:21:01,195 --> 0:21:06,600
实际上素材目录编译器已经生成了

395
00:21:06,667 --> 0:21:08,936
并将其存储在素材目录中

396
00:21:09,436 --> 0:21:11,939
因此并不需要做复杂的数学运算

397
00:21:12,005 --> 0:21:14,908
来将矢量图形栅格化为位图

398
00:21:15,209 --> 0:21:18,846
我们可以直接解码

399
00:21:19,580 --> 0:21:22,149
并将其直接渲染到帧缓冲区中

400
00:21:24,952 --> 0:21:29,489
如果你计划以几种固定大小呈现图像

401
00:21:29,556 --> 0:21:33,093
比如你有一个小图标和一个大图标

402
00:21:33,794 --> 0:21:37,130
你不需要依赖

403
00:21:37,731 --> 0:21:41,034
只需创建这两种你预先确定好

404
00:21:41,101 --> 0:21:43,070
需要渲染的尺寸的图片素材

405
00:21:44,972 --> 0:21:46,907
这将允许在编译期

406
00:21:47,741 --> 0:21:52,212
调用CPU对你的图片进行栅格化

407
00:21:52,613 --> 0:21:55,649
而不是每次将图像复制到帧缓冲区时

408
00:21:58,285 --> 0:22:01,755
我们已经看到了如何使用

409
00:21:58,285 --> 0:22:01,755
我们已经看到了如何使用

410
00:22:02,823 --> 0:22:05,926
但你的app所做的图形工作

411
00:22:05,993 --> 0:22:08,862
有时 app在运行时绘制内容

412
00:22:12,299 --> 0:22:13,800
这种情况的例子

413
00:22:14,268 --> 0:22:17,704
可以在如Photos app中的

414
00:22:17,771 --> 0:22:19,506
编辑视图中看到

415
00:22:21,275 --> 0:22:27,414
这个UIButton显示了一个图标

416
00:22:28,549 --> 0:22:32,085
但是UIButton在这里不支持

417
00:22:32,152 --> 0:22:35,322
以实现点击

418
00:22:36,223 --> 0:22:38,392
因此我们自己将不得不

419
00:22:39,326 --> 0:22:42,863
这里一个可能的实现是

420
00:22:43,397 --> 0:22:44,765
并实现draw方法

421
00:22:45,399 --> 0:22:49,236
这里的这个实现绘制一个

422
00:22:49,469 --> 0:22:51,538
绘制一些文字

423
00:22:53,640 --> 0:22:55,342
出于若干原因

424
00:22:56,210 --> 0:22:57,344
我们并不推荐这种方法

425
00:22:58,078 --> 0:23:03,417
我们将这个视图子类与

426
00:22:58,078 --> 0:23:03,417
我们将这个视图子类与

427
00:23:04,318 --> 0:23:08,155
你可能已经知道

428
00:23:08,222 --> 0:23:10,657
依赖Core Animation

429
00:23:11,692 --> 0:23:14,928
对于我们的图像视图

430
00:23:14,995 --> 0:23:17,831
要求图像创建解码图像缓冲区

431
00:23:19,032 --> 0:23:22,236
然后 将解码后的图像

432
00:23:22,736 --> 0:23:24,271
用作其所在层的内容

433
00:23:24,338 --> 0:23:26,139
（自定义绘图

434
00:23:26,206 --> 0:23:28,442
对于我们重写draw得到的

435
00:23:29,810 --> 0:23:31,578
它们很相似 但略有不同

436
00:23:31,645 --> 0:23:34,047
负责创建图像缓冲区

437
00:23:34,414 --> 0:23:36,617
来保存我们draw方法的内容

438
00:23:37,317 --> 0:23:40,053
以及我们视图的层

439
00:23:40,621 --> 0:23:43,524
并填充该图像缓冲区的内容

440
00:23:43,590 --> 0:23:45,759
这些内容接着根据显示硬件的需要

441
00:23:46,226 --> 0:23:47,928
被复制到帧缓冲区中

442
00:23:52,766 --> 0:23:54,935
（后备存储器存储开销）

443
00:23:55,002 --> 0:23:56,904
为了解这将产生多大的开销

444
00:23:56,970 --> 0:23:59,072
以及为什么我们不应该寻求

445
00:23:59,139 --> 0:24:00,374
实现这个UI的替代方法

446
00:23:59,139 --> 0:24:00,374
实现这个UI的替代方法

447
00:24:01,575 --> 0:24:03,510
我们在此使用的后备存储器

448
00:24:03,944 --> 0:24:06,813
即连接到CALayer

449
00:24:06,880 --> 0:24:09,783
其大小与我们正在显示的

450
00:24:11,118 --> 0:24:14,121
我们在iOS 12中引入了

451
00:24:14,988 --> 0:24:19,092
即后备存储器中元素的大小

452
00:24:19,493 --> 0:24:21,528
实际上会动态增长

453
00:24:21,595 --> 0:24:24,264
取决于你是否绘制任何有颜色的内容

454
00:24:24,331 --> 0:24:25,532
以及该颜色的内容

455
00:24:25,599 --> 0:24:28,468
是在标准色彩范围之内或之外

456
00:24:28,969 --> 0:24:33,173
因此如果你使用扩展的SRGB颜色

457
00:24:33,874 --> 0:24:36,176
则后备存储器实际上会比

458
00:24:37,077 --> 0:24:38,512
仅使用0到1范围内的颜色

459
00:24:38,579 --> 0:24:42,049
的后备存储器大

460
00:24:43,951 --> 0:24:46,053
在之前的iOS版本中

461
00:24:46,119 --> 0:24:49,556
你可以通过设置CALayer的

462
00:24:49,623 --> 0:24:51,225
来作为对Core Animation

463
00:24:51,291 --> 0:24:55,195
即我知道我不需要在这个视图中

464
00:24:55,262 --> 0:24:58,298
或我知道我需要在这个视图中

465
00:24:58,966 --> 0:25:01,502
如果你这样做 你实际上将会禁用

466
00:24:58,966 --> 0:25:01,502
如果你这样做 你实际上将会禁用

467
00:25:02,102 --> 0:25:05,038
我们在iOS 12中引入的优化

468
00:25:05,405 --> 0:25:08,709
因此 请检查

469
00:25:08,775 --> 0:25:11,478
确保你不会意外关闭这项优化

470
00:25:11,545 --> 0:25:14,348
该优化能够使你的运行

471
00:25:17,651 --> 0:25:20,053
但我们可以做得比仅仅提示我们

472
00:25:20,120 --> 0:25:23,557
是否需要一个支持广色域的

473
00:25:23,857 --> 0:25:26,293
我们实际上可以减少

474
00:25:26,360 --> 0:25:27,628
app所需的后备存储器总量

475
00:25:27,995 --> 0:25:32,199
我们可以通过将这个较大的视图

476
00:25:32,933 --> 0:25:36,336
并且减少或消除

477
00:25:36,403 --> 0:25:38,205
（减少后备存储器的使用）

478
00:25:38,272 --> 0:25:40,974
这将帮助我们消除

479
00:25:41,041 --> 0:25:42,242
内存中图像数据的重复副本

480
00:25:42,876 --> 0:25:46,146
并且这将允许我们利用

481
00:25:46,213 --> 0:25:47,714
其不需实现后备存储器

482
00:25:50,918 --> 0:25:53,120
因此 正如我所提到的

483
00:25:53,187 --> 0:25:56,223
将需要创建一个后备存储器

484
00:25:57,357 --> 0:25:59,726
但是即使你不重写draw方法

485
00:25:59,793 --> 0:26:01,395
UIView中的一些属性

486
00:25:59,793 --> 0:26:01,395
UIView中的一些属性

487
00:26:01,795 --> 0:26:04,731
例如设置UIView的背景颜色

488
00:26:04,798 --> 0:26:09,102
并不需要创建后备存储器

489
00:26:09,503 --> 0:26:11,305
因此我建议不要在UIView中

490
00:26:11,371 --> 0:26:13,440
使用具有背景颜色属性的图案颜色

491
00:26:15,142 --> 0:26:17,244
而应该创建

492
00:26:17,811 --> 0:26:22,115
将你的图像分配到该图像视图并使用

493
00:26:22,616 --> 0:26:24,651
恰当地设置平铺参数

494
00:26:27,921 --> 0:26:31,058
当我们想要剪切圆角矩形的角时

495
00:26:32,226 --> 0:26:34,995
我们希望使用CALayer的

496
00:26:35,829 --> 0:26:39,900
因为Core Animation

497
00:26:40,167 --> 0:26:42,436
而不需要额外的内存分配

498
00:26:43,437 --> 0:26:46,139
如果我们改用更强大的

499
00:26:46,206 --> 0:26:47,574
或maskLayer属性

500
00:26:48,308 --> 0:26:51,411
我们最终需要额外分配

501
00:26:53,680 --> 0:26:57,618
如果你有更复杂透明区域的背景

502
00:26:58,151 --> 0:27:00,687
并且不能通过cornerRadius属性

503
00:26:58,151 --> 0:27:00,687
并且不能通过cornerRadius属性

504
00:27:00,754 --> 0:27:02,823
你应该考虑使用

505
00:27:03,857 --> 0:27:06,026
将这些信息存储在你的素材目录中

506
00:27:06,093 --> 0:27:07,995
或在运行时渲染它

507
00:27:08,295 --> 0:27:10,531
并将其作为图像提供给图像视图

508
00:27:10,597 --> 0:27:12,533
而不应该使用maskView

509
00:27:15,202 --> 0:27:18,372
最后

510
00:27:19,540 --> 0:27:24,378
UIImageView

511
00:27:24,444 --> 0:27:26,647
而不需要额外的内存分配

512
00:27:28,182 --> 0:27:30,651
你要做的第一件事是勾选…

513
00:27:30,717 --> 0:27:31,618
不是勾选复选框

514
00:27:31,685 --> 0:27:34,555
而是在图片素材编辑器中

515
00:27:34,621 --> 0:27:37,157
将渲染模式属性设置为

516
00:27:37,724 --> 0:27:40,861
或在UIImageView上调用

517
00:27:41,261 --> 0:27:43,797
来创建一个渲染模式为

518
00:27:44,898 --> 0:27:48,435
然后将该图像分配给图像视图

519
00:27:48,869 --> 0:27:51,004
设置为你想要图像渲染的颜色

520
00:27:52,172 --> 0:27:55,442
在UIImage将图像渲染到

521
00:27:55,509 --> 0:27:59,947
它会在该复制操作中使用纯色

522
00:28:00,514 --> 0:28:03,650
而不需要持有一个

523
00:28:03,884 --> 0:28:05,419
app了纯色图像的单独副本

524
00:28:07,988 --> 0:28:10,991
UIKit提供的视图中

525
00:28:11,358 --> 0:28:17,764
UILabel可以在显示单色文本时

526
00:28:18,332 --> 0:28:20,367
减少75%的内存使用

527
00:28:21,835 --> 0:28:24,605
如果你想更详细地了解

528
00:28:24,671 --> 0:28:27,908
以及如何将其app于

529
00:28:28,408 --> 0:28:30,744
可以参考“iOS内存深潜”演讲

530
00:28:31,378 --> 0:28:34,982
其详细介绍了这种名为A8的

531
00:28:38,318 --> 0:28:42,523
有时候 你想渲染存储在内存中

532
00:28:42,956 --> 0:28:45,425
图像缓冲区中的图像

533
00:28:46,093 --> 0:28:49,897
UIKit为此提供的类

534
00:28:50,898 --> 0:28:55,369
还有另一个更旧的函数

535
00:28:55,435 --> 0:28:58,972
但请不要使用它

536
00:28:59,039 --> 0:29:02,176
能够正确渲染广色域内容

537
00:28:59,039 --> 0:29:02,176
能够正确渲染广色域内容

538
00:29:02,242 --> 0:29:03,844
（屏外绘制）

539
00:29:03,911 --> 0:29:07,314
你可以在app中

540
00:29:07,381 --> 0:29:09,183
渲染到屏幕外的地方

541
00:29:09,249 --> 0:29:12,886
然后使用UIImageView

542
00:29:15,088 --> 0:29:17,491
与我们在CALayer

543
00:29:17,824 --> 0:29:20,494
引入的优化类似

544
00:29:20,561 --> 0:29:23,697
我们也使

545
00:29:23,764 --> 0:29:26,867
能够动态增长其图像缓冲区的大小

546
00:29:26,934 --> 0:29:31,038
这取决于你在操作块中执行的操作

547
00:29:33,974 --> 0:29:37,811
如果你在iOS 12之前的

548
00:29:38,145 --> 0:29:39,746
你可以使用

549
00:29:39,813 --> 0:29:40,948
中的

550
00:29:41,014 --> 0:29:44,384
prefersExtendedRange属性

551
00:29:44,451 --> 0:29:46,954
你是否计划绘制广色域内容

552
00:29:50,524 --> 0:29:52,860
但这里有一个中间地带

553
00:29:53,393 --> 0:29:57,431
如果你主要将图像渲染

554
00:29:58,232 --> 0:30:00,567
该图像可能使用

555
00:29:58,232 --> 0:30:00,567
该图像可能使用

556
00:30:00,634 --> 0:30:05,105
超出SRGB色域的色彩空间值

557
00:30:06,073 --> 0:30:09,243
但实际上并不需要更大的元素

558
00:30:09,309 --> 0:30:10,444
来存储这些信息

559
00:30:10,944 --> 0:30:12,646
UIImage有一个可以用来获取一个预构建的

560
00:30:13,113 --> 0:30:15,649
UIGraphicsImageRendererFormat

561
00:30:15,716 --> 0:30:21,088
image renderer format属性

562
00:30:21,154 --> 0:30:22,656
进行最优化存储

563
00:30:26,960 --> 0:30:28,362
最后我们将谈一些

564
00:30:28,428 --> 0:30:31,999
有关如何在你的app中集成

565
00:30:32,065 --> 0:30:35,068
我们在iOS中提供的先进

566
00:30:37,504 --> 0:30:40,440
如果你需要使用

567
00:30:40,507 --> 0:30:44,945
对你的图片实时进行大量的高级处理

568
00:30:45,012 --> 0:30:45,913
（高级图像效果）

569
00:30:45,979 --> 0:30:48,182
Core Image

570
00:30:48,248 --> 0:30:51,285
它允许你创建处理图像的配方

571
00:30:51,652 --> 0:30:54,521
并在CPU或GPU上进行处理

572
00:30:55,722 --> 0:31:00,360
如果你从CIImage创建一个

573
00:30:55,722 --> 0:31:00,360
如果你从CIImage创建一个

574
00:31:00,727 --> 0:31:05,232
UIImageView将负责

575
00:31:06,733 --> 0:31:07,701
这非常高效 并且它可以

576
00:31:07,768 --> 0:31:10,771
保持CPU空闲从而能够

577
00:31:12,139 --> 0:31:14,775
为了使用它

578
00:31:15,209 --> 0:31:17,778
然后调用UIImage

579
00:31:18,512 --> 0:31:19,746
（高级图像处理）

580
00:31:19,813 --> 0:31:21,481
iOS上还有其他用于处理和渲染

581
00:31:21,548 --> 0:31:25,052
图形内容的高级框架

582
00:31:25,319 --> 0:31:29,823
包括Metal Vision

583
00:31:31,158 --> 0:31:35,195
这些框架中常见的数据类型之一

584
00:31:36,563 --> 0:31:40,801
这是一种数据类型

585
00:31:40,868 --> 0:31:43,437
正在使用的缓冲区

586
00:31:44,605 --> 0:31:46,340
构建这些像素缓冲区之一时

587
00:31:46,740 --> 0:31:48,575
确保使用最好的初始化程序

588
00:31:48,642 --> 0:31:51,678
即最接近你手头表述的那个

589
00:31:52,746 --> 0:31:55,115
不要展开任何解码工作

590
00:31:55,182 --> 0:31:58,051
这些工作已经由现有的

591
00:31:58,118 --> 0:32:00,287
UIImage

592
00:31:58,118 --> 0:32:00,287
UIImage

593
00:32:01,688 --> 0:32:04,791
在CPU和GPU之间移动数据时

594
00:32:04,858 --> 0:32:07,427
这样你就不会仅在两者之间

595
00:32:07,494 --> 0:32:10,097
实际上你可以让它们并行执行

596
00:32:11,598 --> 0:32:14,201
最后请关注一下

597
00:32:14,668 --> 0:32:17,337
如何正确格式化待处理缓冲区的

598
00:32:17,771 --> 0:32:20,207
Accelerate

599
00:32:22,809 --> 0:32:24,845
总结一下几个关键点

600
00:32:25,879 --> 0:32:28,615
在表视图和集合视图中实现预取

601
00:32:28,682 --> 0:32:31,485
以便可以事先完成一些工作

602
00:32:33,120 --> 0:32:37,724
确保你没有关闭UIKit提供的

603
00:32:37,791 --> 0:32:41,361
这些优化可以减少与视图关联的

604
00:32:42,095 --> 0:32:43,764
（总结）

605
00:32:43,830 --> 0:32:46,266
如果你将图像与app捆绑在一起

606
00:32:46,333 --> 0:32:48,168
将其存储在素材目录中

607
00:32:49,102 --> 0:32:51,905
不要将其存储在与你的app

608
00:32:53,841 --> 0:32:56,743
最后 如果你以不同大小

609
00:32:57,578 --> 0:33:00,514
不要过分依赖

610
00:32:57,578 --> 0:33:00,514
不要过分依赖

611
00:33:03,183 --> 0:33:06,353
欲了解更多信息

612
00:33:06,420 --> 0:33:12,025
包括一个调查性能问题的演讲

613
00:33:12,726 --> 0:33:16,230
明天和星期五我们还会有实验室讨论

614
00:33:16,296 --> 0:33:18,665
如果你有任何问题

615
00:33:19,833 --> 0:33:20,901
感谢你的收看
