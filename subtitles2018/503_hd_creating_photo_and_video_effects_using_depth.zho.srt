1
00:00:07,516 --> 0:00:15,500
[ 音乐 ]

2
00:00:18,516 --> 0:00:20,546
[ 掌声 ]

3
00:00:21,046 --> 0:00:23,856
&gt;&gt; 早上好 很高兴

4
00:00:23,856 --> 0:00:24,676
和你们在这里一起探讨

5
00:00:25,346 --> 0:00:26,386
我的名字是 Emmanuel

6
00:00:26,386 --> 0:00:27,476
是 Core Image 团队的一名工程师

7
00:00:28,586 --> 0:00:30,106
今天 我们将着眼于

8
00:00:30,206 --> 0:00:32,386
使用深度图创建照片和视频效果

9
00:00:32,866 --> 0:00:35,686
让我们开始吧

10
00:00:37,036 --> 0:00:38,976
在 iOS 11 中 我们开始

11
00:00:38,976 --> 0:00:40,726
将人像深度数据

12
00:00:40,726 --> 0:00:42,206
与静态人像图片一同传送

13
00:00:43,516 --> 0:00:45,386
在去年的 WWDC 会议期间

14
00:00:45,736 --> 0:00:46,746
我们展示了如何利用

15
00:00:46,746 --> 0:00:47,826
深度数据实现

16
00:00:47,826 --> 0:00:49,436
令人惊叹的效果 例如

17
00:00:49,436 --> 0:00:51,446
力度透视 模拟

18
00:00:51,446 --> 0:00:52,996
景深效果 以及

19
00:00:52,996 --> 0:00:53,806
各种前景和

20
00:00:53,806 --> 0:00:55,286
背景分离效果

21
00:00:56,716 --> 0:00:57,806
今年我们非常

22
00:00:57,806 --> 0:00:59,206
高兴地宣布

23
00:00:59,206 --> 0:01:01,976
我们将推出一个新的功能人像蒙版

24
00:00:59,206 --> 0:01:01,976
我们将推出一个新的功能人像蒙版

25
00:01:06,046 --> 0:01:07,036
因此 在此次会议的前半部分

26
00:01:07,036 --> 0:01:08,616
我们将着重于

27
00:01:08,616 --> 0:01:09,696
人物静态图像

28
00:01:09,696 --> 0:01:11,896
以及如何很好的使用它们的效果

29
00:01:12,956 --> 0:01:14,366
在接下来的一半时间里

30
00:01:14,366 --> 0:01:15,446
我的同事 Ron 来自视频工程的专家

31
00:01:15,446 --> 0:01:17,176
将着重于

32
00:01:17,176 --> 0:01:18,426
使用 TruthDepth 相机

33
00:01:18,426 --> 0:01:19,906
来实现实时视频效果

34
00:01:21,936 --> 0:01:24,076
好的 让我们来看看

35
00:01:24,076 --> 0:01:26,636
人像景深识别 API

36
00:01:27,236 --> 0:01:28,436
之前 我提到了人像蒙版

37
00:01:28,436 --> 0:01:29,526
那么人像蒙版是什么呢

38
00:01:29,526 --> 0:01:30,636
人像蒙版是

39
00:01:30,636 --> 0:01:32,476
把前景和背景

40
00:01:32,476 --> 0:01:33,856
分割开来 这意味着

41
00:01:33,856 --> 0:01:35,706
你有着一个

42
00:01:35,706 --> 0:01:37,706
前景为 1.0

43
00:01:37,706 --> 0:01:40,576
的遮罩 背景

44
00:01:40,576 --> 0:01:42,176
为 0.0 的遮罩 并且你可以在两者之间

45
00:01:42,176 --> 0:01:42,976
获得平缓且连续的数值

46
00:01:47,046 --> 0:01:47,646
人像蒙版有着

47
00:01:47,646 --> 0:01:49,116
极高的质量 并且

48
00:01:49,116 --> 0:01:50,626
能够很好的保留细节

49
00:01:50,676 --> 0:01:52,666
例如人物的卷发和

50
00:01:52,666 --> 0:01:53,696
头发上的轮廓

51
00:01:54,076 --> 0:01:55,446
这非常的了不起

52
00:01:56,716 --> 0:01:59,646
蒙版可以实现

53
00:01:59,646 --> 0:02:01,666
很多惊人的效果 此处

54
00:01:59,646 --> 0:02:01,666
很多惊人的效果 此处

55
00:02:01,666 --> 0:02:03,556
只是其中以一

56
00:02:03,556 --> 0:02:04,916
通过使背景变暗

57
00:02:04,916 --> 0:02:06,866
来实现前景和背景的分离

58
00:02:06,866 --> 0:02:09,806
我们把这个工具交与你手 这样你可以创造出

59
00:02:09,806 --> 0:02:12,256
惊人的 App 和新的

60
00:02:12,256 --> 0:02:13,836
效果 从而让你的用户满意

61
00:02:15,836 --> 0:02:18,466
好的 人像蒙版

62
00:02:18,466 --> 0:02:21,326
效果将可以在 iOS 12 中使用

63
00:02:22,056 --> 0:02:25,536
它适用于

64
00:02:25,536 --> 0:02:27,476
前置和后置相机

65
00:02:28,056 --> 0:02:31,516
此技术被使用于

66
00:02:31,516 --> 0:02:33,726
人物静止图像 并且

67
00:02:33,726 --> 0:02:34,766
此刻场景中

68
00:02:34,766 --> 0:02:35,616
必须有人物存在

69
00:02:37,426 --> 0:02:39,426
请注意 人像蒙版是

70
00:02:39,426 --> 0:02:41,086
线性编码 它并不是

71
00:02:41,086 --> 0:02:42,306
伽马编码 所以你得到

72
00:02:42,306 --> 0:02:43,346
的是一个灰度缓冲区

73
00:02:44,756 --> 0:02:46,966
而且也不能保证

74
00:02:46,966 --> 0:02:47,826
你会获得

75
00:02:47,826 --> 0:02:49,036
人像蒙版

76
00:02:49,036 --> 0:02:50,076
当你使用人像静止图片

77
00:02:50,116 --> 0:02:51,516
你总是能获得图像深度数据

78
00:02:51,866 --> 0:02:53,316
但是你需要测试

79
00:02:53,316 --> 0:02:54,196
去确保人像蒙版的存在

80
00:02:54,516 --> 0:02:57,176
现在 让我们来看看

81
00:02:57,176 --> 0:02:58,666
API 了解如何

82
00:02:58,666 --> 0:03:00,126
加载数据

83
00:02:58,666 --> 0:03:00,126
加载数据

84
00:03:00,586 --> 0:03:02,876
首先 ImageIO 提供了一个简易的

85
00:03:02,876 --> 0:03:04,286
API 允许你加载

86
00:03:04,516 --> 0:03:05,466
人像蒙版效果

87
00:03:05,766 --> 0:03:08,456
所以通过调用 CGImageSourceCopy

88
00:03:09,156 --> 0:03:10,426
传递一个新的变量

89
00:03:10,706 --> 0:03:12,576
kCGImageAuxiliaryData

90
00:03:12,576 --> 0:03:13,806
TypePortraitEffectsMatte

91
00:03:15,186 --> 0:03:16,046
这个调用将返回一个

92
00:03:16,046 --> 0:03:18,216
包含三个主要信息的结构

93
00:03:18,846 --> 0:03:20,426
图像本身数据定义为

94
00:03:20,426 --> 0:03:24,176
CFDataRef 与缓冲区本身

95
00:03:24,176 --> 0:03:25,496
相关的元数据为

96
00:03:25,496 --> 0:03:28,096
CFDictionary 以及

97
00:03:28,266 --> 0:03:31,146
与抓取本身相关的元数据

98
00:03:33,356 --> 0:03:35,056
AVFoundation 同时也提供了

99
00:03:35,056 --> 0:03:36,386
一个可以比 ImageIO

100
00:03:36,386 --> 0:03:38,186
更高级的 API

101
00:03:38,986 --> 0:03:42,286
因此从 CGImageSourceCopy 获得输出 然后

102
00:03:42,286 --> 0:03:43,976
你将它输入 AVPortrait effects matte 类

103
00:03:48,046 --> 0:03:49,656
你从中返回的东西

104
00:03:49,656 --> 0:03:51,326
非常的简单 它是一个 CV 像素

105
00:03:51,326 --> 0:03:53,596
缓冲器以及像素格式类型 

106
00:03:53,816 --> 0:03:54,946
因此你可以使用这个 CV

107
00:03:54,946 --> 0:03:56,626
像素缓冲器来满足你

108
00:03:56,626 --> 0:03:58,586
进一步的处理需求 

109
00:03:59,006 --> 0:04:00,296
这非常的简单

110
00:03:59,006 --> 0:04:00,296
这非常的简单

111
00:04:01,106 --> 0:04:02,676
AVFoundation 还支持

112
00:04:02,676 --> 0:04:04,966
在拍摄时提供人像蒙版

113
00:04:05,516 --> 0:04:07,176
典型的 AVFoundation 设置

114
00:04:07,176 --> 0:04:08,956
从 AVCaptureInput 开始

115
00:04:08,956 --> 0:04:11,296
然后 AVCaptureDevice

116
00:04:11,296 --> 0:04:12,126
以及 AVCaptureSession

117
00:04:12,706 --> 0:04:14,386
首先 你需要确保

118
00:04:14,386 --> 0:04:15,436
你的软件环境

119
00:04:15,436 --> 0:04:16,495
能够支持

120
00:04:16,495 --> 0:04:17,986
人像蒙版效果

121
00:04:18,206 --> 0:04:20,286
要做到这点 你需要

122
00:04:20,286 --> 0:04:21,636
检查是否支持

123
00:04:21,636 --> 0:04:23,036
深度数据传输 以及

124
00:04:23,036 --> 0:04:24,596
人像蒙版效果传输

125
00:04:25,136 --> 0:04:26,406
我们有这两个的原因

126
00:04:26,506 --> 0:04:27,636
是由于深度数据

127
00:04:27,636 --> 0:04:29,046
和人像蒙版同时存在

128
00:04:29,636 --> 0:04:31,286
你可以选择仅

129
00:04:31,286 --> 0:04:32,976
获取深度信息

130
00:04:32,976 --> 0:04:34,026
但只要你需求

131
00:04:34,026 --> 0:04:35,516
人像蒙版 你就需要激活

132
00:04:35,516 --> 0:04:37,216
深度数据的传输

133
00:04:38,126 --> 0:04:39,786
为了激活或者

134
00:04:39,786 --> 0:04:41,606
选择传输数据 你需要

135
00:04:41,606 --> 0:04:42,336
确保修改你的

136
00:04:42,336 --> 0:04:44,146
AVCapturePhotoSettings 并且

137
00:04:44,146 --> 0:04:45,336
启用 isPortraitEffects MatteDelivery 

138
00:04:45,336 --> 0:04:46,906
以及设置

139
00:04:46,906 --> 0:04:49,846
isDepthDataDeliveryEnabled 为 true

140
00:04:50,806 --> 0:04:52,266
然后抓取时间 你的

141
00:04:52,706 --> 0:04:53,776
ddiFinishProcessingPhoto

142
00:04:53,776 --> 0:04:55,086
回调函数将会

143
00:04:55,086 --> 0:04:57,346
给你人像蒙版效果

144
00:04:57,346 --> 0:04:59,316
就是如此的简单

145
00:05:00,256 --> 0:05:01,366
Core Image 还为你

146
00:05:01,366 --> 0:05:02,986
提供加载和

147
00:05:02,986 --> 0:05:04,626
保存你的人像蒙版效果的方法

148
00:05:05,546 --> 0:05:06,806
一个新的队列被引入

149
00:05:06,926 --> 0:05:07,726
auxiliaryPortrait

150
00:05:07,726 --> 0:05:09,106
EffectsMatte 你只需要传入

151
00:05:09,106 --> 0:05:13,386
imageWithContentsOFURL 到 CIImage

152
00:05:13,386 --> 0:05:14,776
就可以获取人像蒙版效果

153
00:05:19,046 --> 0:05:19,866
Core Image 同时还允许

154
00:05:19,866 --> 0:05:21,636
你的人像蒙版效果

155
00:05:21,636 --> 0:05:23,946
直接保存到你的文件中

156
00:05:24,426 --> 0:05:26,526
要做到这一点 这里有一个新的选择

157
00:05:26,526 --> 0:05:29,506
称为 portraitEffectsMatteImage 你传入

158
00:05:29,506 --> 0:05:30,876
在 CI Image 中的

159
00:05:30,876 --> 0:05:32,696
人像蒙版效果 然后你

160
00:05:32,696 --> 0:05:34,086
就可以例如用

161
00:05:34,086 --> 0:05:35,246
writeHEIFRepresntationOfImage

162
00:05:35,246 --> 0:05:36,576
写入你的磁盘

163
00:05:37,196 --> 0:05:39,246
这里有一件很重要

164
00:05:39,246 --> 0:05:41,136
的事情需要注意 关于

165
00:05:41,416 --> 0:05:42,826
三种图像 你的 RGB 图像

166
00:05:42,826 --> 0:05:44,796
深度图和

167
00:05:44,796 --> 0:05:47,116
人像蒙版图

168
00:05:47,116 --> 0:05:47,996
有着不同的分辨率

169
00:05:49,266 --> 0:05:50,426
例如 对于后置摄像机的

170
00:05:50,426 --> 0:05:51,876
人像蒙版

171
00:05:51,876 --> 0:05:53,866
是一半大小 对于深度图

172
00:05:53,866 --> 0:05:54,696
甚至更小

173
00:05:55,526 --> 0:05:56,386
所以让我们一起

174
00:05:56,386 --> 0:05:57,616
来看后置摄像头的

175
00:05:57,616 --> 0:05:58,516
三种图像

176
00:05:59,786 --> 0:06:00,816
这意味着在你的 App 中

177
00:05:59,786 --> 0:06:00,816
这意味着在你的 App 中

178
00:06:00,816 --> 0:06:02,076
你需要确保 要不将

179
00:06:02,076 --> 0:06:04,236
RGB 图像缩减为与

180
00:06:04,236 --> 0:06:06,076
你的人像深度图或者

181
00:06:06,076 --> 0:06:08,636
人像蒙版图一样的大小

182
00:06:09,336 --> 0:06:11,086
或者用相反的方法 将它们

183
00:06:11,086 --> 0:06:12,496
采样到与 RGB 图像相同的大小

184
00:06:13,256 --> 0:06:15,316
所以这就是我今天

185
00:06:15,316 --> 0:06:16,286
想要讨论的

186
00:06:16,286 --> 0:06:18,686
人像景深识别 API 并且我们准备了

187
00:06:18,686 --> 0:06:20,626
一个非常棒的演示

188
00:06:20,626 --> 0:06:24,986
让你们观看在这个演示中 我将

189
00:06:24,986 --> 0:06:26,376
使用 Jupiter Notebook

190
00:06:26,896 --> 0:06:28,276
它是一个基于浏览器的

191
00:06:33,306 --> 0:06:36,456
我们将 Python 与 Core Image 绑定起来

192
00:06:36,546 --> 0:06:37,646
我们将会在稍后的一个单独会议

193
00:06:37,646 --> 0:06:38,976
中介绍这些绑定

194
00:06:45,056 --> 0:06:46,626
让我们开始并加载一张

195
00:06:46,626 --> 0:06:48,686
包含人像深度数据和

196
00:06:48,686 --> 0:06:49,706
人像蒙版的图片

197
00:06:50,016 --> 0:06:50,906
所以这将是我们

198
00:06:50,906 --> 0:06:51,516
所要处理的图片

199
00:06:52,296 --> 0:06:54,956
首先 我想为你展示

200
00:06:54,956 --> 0:06:56,796
该图片的深度图

201
00:06:56,796 --> 0:06:57,906
看起来是什么样的

202
00:06:57,906 --> 0:06:59,196
让我们来看看这两张图

203
00:06:59,296 --> 0:07:00,436
在左侧我们有

204
00:06:59,296 --> 0:07:00,436
在左侧我们有

205
00:07:00,436 --> 0:07:02,206
人像深度图 在右侧有

206
00:07:02,206 --> 0:07:03,046
人像蒙版图 你可以

207
00:07:03,046 --> 0:07:04,796
看到它们的细节有多好

208
00:07:05,366 --> 0:07:07,496
我们将在一分钟内做一个

209
00:07:07,496 --> 0:07:09,896
缩放剪裁 以便你

210
00:07:09,896 --> 0:07:13,066
更好地欣赏它的质量

211
00:07:13,836 --> 0:07:15,686
接下来我们要做的是

212
00:07:15,686 --> 0:07:16,586
调整图像的大小

213
00:07:17,426 --> 0:07:18,966
你可以看到 RGB 图和深度图

214
00:07:18,966 --> 0:07:20,596
在大小上有很大的区别

215
00:07:22,006 --> 0:07:23,516
所以我们调整图像的大小

216
00:07:23,516 --> 0:07:25,126
让我们再一起看看它们

217
00:07:25,436 --> 0:07:26,686
所以在右侧我们有 RGB 图像和

218
00:07:26,686 --> 0:07:27,536
深度数据图

219
00:07:27,946 --> 0:07:29,076
在本演示的第一个部分中

220
00:07:29,076 --> 0:07:30,876
我将着重于深度数据图

221
00:07:31,326 --> 0:07:32,806
然后我们将看到

222
00:07:32,806 --> 0:07:33,946
事物在使用人像蒙版效果时

223
00:07:33,946 --> 0:07:34,846
会变得多么简单

224
00:07:35,596 --> 0:07:37,806
所以今天我将

225
00:07:37,806 --> 0:07:39,296
处理的效果是深度阈值 

226
00:07:39,296 --> 0:07:42,426
基本上我要做的是计算我的

227
00:07:42,426 --> 0:07:43,576
人像深度数据图中

228
00:07:43,576 --> 0:07:45,316
灰度值的直方图

229
00:07:45,316 --> 0:07:47,596
我将在这直方图中运用

230
00:07:47,596 --> 0:07:48,536
一个阈值或者一个剪切点

231
00:07:48,536 --> 0:07:49,636
所以一切都

232
00:07:49,636 --> 0:07:51,516
变为零或者一

233
00:07:51,516 --> 0:07:53,426
取决于它是否低于或高于该阈值

234
00:07:54,346 --> 0:07:55,886
我们将排除图片中的小型黑洞

235
00:07:55,886 --> 0:07:57,336
通过使用形态学

236
00:07:57,336 --> 0:07:59,116
闭运算操作

237
00:07:59,116 --> 0:08:01,386
然后模糊遮罩 以便

238
00:07:59,116 --> 0:08:01,386
然后模糊遮罩 以便

239
00:08:01,386 --> 0:08:03,006
获得漂亮的羽化

240
00:08:03,766 --> 0:08:05,456
让我们看看这个的实际情况

241
00:08:06,486 --> 0:08:07,456
记住 所有的这些都是用

242
00:08:07,456 --> 0:08:09,966
Core Image 作为后端从而

243
00:08:09,966 --> 0:08:11,396
在浏览器中执行

244
00:08:11,866 --> 0:08:13,836
首先 我想给你展示的

245
00:08:13,836 --> 0:08:15,356
是如何改变

246
00:08:15,356 --> 0:08:17,036
百分比点来改变我的遮罩

247
00:08:17,286 --> 0:08:19,216
所以越高的数值

248
00:08:19,216 --> 0:08:21,026
越不明显 我剪裁的是前景

249
00:08:21,276 --> 0:08:22,316
所以让我们选择一个合理

250
00:08:22,316 --> 0:08:24,466
的数值 也许可以选择这个

251
00:08:25,226 --> 0:08:26,556
你可以在这里

252
00:08:26,556 --> 0:08:28,246
看到是我们称之为

253
00:08:28,246 --> 0:08:29,376
插入到图片

254
00:08:29,716 --> 0:08:31,226
前景的区域

255
00:08:31,226 --> 0:08:32,176
这里也有一些我想

256
00:08:32,176 --> 0:08:33,086
去除掉的区域

257
00:08:33,296 --> 0:08:35,086
所以我会做的是添加

258
00:08:35,086 --> 0:08:36,446
一些形态学闭运算

259
00:08:36,926 --> 0:08:38,936
看看这是多么的神奇

260
00:08:38,976 --> 0:08:40,885
如果我的数值调的太大 明显的

261
00:08:40,885 --> 0:08:42,265
将失去我整个的目标 我不想这么做

262
00:08:43,066 --> 0:08:44,226
所以让我们选择这个点

263
00:08:44,916 --> 0:08:46,576
接下来我做的是通过

264
00:08:46,576 --> 0:08:47,876
在其上面做高斯模糊

265
00:08:47,876 --> 0:08:48,556
来改变羽化

266
00:08:49,196 --> 0:08:50,306
然后我们再看看 RGB 图

267
00:08:50,306 --> 0:08:51,266
在此上什么样

268
00:08:51,686 --> 0:08:52,906
这不是我们刚刚提出来的

269
00:08:52,906 --> 0:08:54,176
效果 只是为了了解

270
00:08:54,176 --> 0:08:55,166
遮罩是怎么被运用的

271
00:08:55,166 --> 0:08:56,306
让我们继续

272
00:08:57,186 --> 0:08:59,206
我在这里为阈值

273
00:08:59,206 --> 0:09:01,746
选择了一些参数

274
00:08:59,206 --> 0:09:01,746
选择了一些参数

275
00:09:01,906 --> 0:09:02,976
这些将用于我的前景中

276
00:09:07,256 --> 0:09:09,416
接下来 我只在我的前景中

277
00:09:09,416 --> 0:09:10,536
应用效果

278
00:09:10,536 --> 0:09:11,546
所以在这个特定的例子中

279
00:09:11,546 --> 0:09:12,936
我将使用 Core Image 的 photoEffectNoir

280
00:09:13,056 --> 0:09:14,396
它可以将所有变成灰度图

281
00:09:14,396 --> 0:09:15,556
并且具有一点对比度

282
00:09:16,186 --> 0:09:17,206
我正在进行

283
00:09:17,206 --> 0:09:19,816
曝光调整 以及

284
00:09:19,846 --> 0:09:21,156
稍微减弱饱和度

285
00:09:21,156 --> 0:09:23,196
并进一步增强对比度

286
00:09:23,936 --> 0:09:24,896
让我们看看结果

287
00:09:24,896 --> 0:09:25,716
这将是我要

288
00:09:25,716 --> 0:09:26,826
使用的前景

289
00:09:27,336 --> 0:09:28,936
我想做的是

290
00:09:29,016 --> 0:09:32,016
利用深度数据遮罩

291
00:09:32,016 --> 0:09:33,756
我将把这个

292
00:09:33,756 --> 0:09:35,446
前景合成到背景中

293
00:09:36,496 --> 0:09:37,866
我们需生成一个

294
00:09:37,866 --> 0:09:39,276
只是比原始图像

295
00:09:39,396 --> 0:09:40,236
较暗版本的背景

296
00:09:40,766 --> 0:09:43,816
然后 我们可以用

297
00:09:43,816 --> 0:09:45,146
Core Image 的滤镜 称为

298
00:09:45,146 --> 0:09:48,956
blendWithMask 将两者结合到一起

299
00:09:48,956 --> 0:09:50,186
然后我们得到了结果

300
00:09:50,186 --> 0:09:52,866
就是如此的简单 好的

301
00:09:52,866 --> 0:09:54,936
谢谢

302
00:09:55,516 --> 0:09:58,716
[ 掌声 ]

303
00:09:59,216 --> 0:10:02,926
如你所见 需要一点点烦琐地

304
00:09:59,216 --> 0:10:02,926
如你所见 需要一点点烦琐地

305
00:10:02,926 --> 0:10:04,096
修剪参数

306
00:10:04,096 --> 0:10:05,666
使其平滑

307
00:10:05,666 --> 0:10:06,096
如此这般

308
00:10:06,356 --> 0:10:07,366
这个人像蒙版效果

309
00:10:07,526 --> 0:10:10,406
使你能在没有实际做太多操作

310
00:10:10,406 --> 0:10:11,666
的情况下执行操作

311
00:10:11,666 --> 0:10:12,816
这非常令人兴奋

312
00:10:12,816 --> 0:10:13,386
让我们看看这个

313
00:10:13,666 --> 0:10:15,506
因此 我们从另一张

314
00:10:15,506 --> 0:10:19,086
图像开始 它同样

315
00:10:19,086 --> 0:10:20,646
有着人像深度信息

316
00:10:20,646 --> 0:10:22,386
和人像蒙版信息

317
00:10:22,386 --> 0:10:23,486
让我们来看看这些

318
00:10:25,066 --> 0:10:27,056
像我之前提到的

319
00:10:27,056 --> 0:10:29,666
这是一个非常高质量的前景遮罩

320
00:10:29,666 --> 0:10:31,056
所以让我们来看看这个

321
00:10:31,056 --> 0:10:33,376
头发上的细节

322
00:10:33,976 --> 0:10:36,846
看看这细节有多好

323
00:10:36,846 --> 0:10:37,456
非常的漂亮

324
00:10:37,626 --> 0:10:38,526
在最右侧

325
00:10:38,526 --> 0:10:39,676
是一个深度图像

326
00:10:39,676 --> 0:10:42,436
与人像蒙版对比

327
00:10:42,436 --> 0:10:43,586
它表明深度数据如何的粗糙

328
00:10:44,376 --> 0:10:46,036
所以在这里我们再做一个

329
00:10:46,036 --> 0:10:47,886
前景分离效果

330
00:10:47,886 --> 0:10:49,016
就像我们刚刚做的一样

331
00:10:49,016 --> 0:10:49,956
但是这次我们使用人像蒙版图

332
00:10:49,956 --> 0:10:50,816
而不是人像深度图

333
00:10:51,386 --> 0:10:53,736
因此 让我们看看我们

334
00:10:53,736 --> 0:10:55,606
与之前类似的前景图

335
00:10:55,606 --> 0:10:56,656
但是这次我们稍微

336
00:10:56,656 --> 0:10:57,856
降低一些前景的饱和度

337
00:10:57,856 --> 0:10:59,746
增加更多的对比度

338
00:10:59,746 --> 0:11:02,666
以及一些图像的振动

339
00:10:59,746 --> 0:11:02,666
以及一些图像的振动

340
00:11:03,406 --> 0:11:04,706
现在我们来创建一个背景

341
00:11:04,706 --> 0:11:06,006
这次我们将做一个

342
00:11:06,006 --> 0:11:07,236
discBlur 它是 Core Image

343
00:11:07,236 --> 0:11:08,836
的另一种滤镜 以及减少

344
00:11:08,836 --> 0:11:09,996
曝光 使图像变得

345
00:11:09,996 --> 0:11:10,746
非常的黑暗

346
00:11:10,746 --> 0:11:12,356
但是我们仍然有

347
00:11:12,356 --> 0:11:13,386
一些背景 它很微弱

348
00:11:13,386 --> 0:11:14,386
但仍然存在

349
00:11:15,446 --> 0:11:17,826
再次 我用了 Core Image 的

350
00:11:17,826 --> 0:11:19,216
blendWithMask 它将为

351
00:11:19,216 --> 0:11:20,716
我们合成图像

352
00:11:21,316 --> 0:11:22,216
然后我们就有了左右两张图

353
00:11:22,526 --> 0:11:23,776
这难道不美吗

354
00:11:24,516 --> 0:11:27,556
[ 掌声 ]

355
00:11:28,056 --> 0:11:29,276
谢谢

356
00:11:29,436 --> 0:11:30,476
好了 让我们看看

357
00:11:30,476 --> 0:11:32,386
另一个我们称之为 Big Head 的演示

358
00:11:32,946 --> 0:11:36,326
由于人像蒙版是

359
00:11:36,326 --> 0:11:37,806
如此的好 我们实际上可以

360
00:11:37,806 --> 0:11:39,306
做一些事情例如

361
00:11:39,306 --> 0:11:40,496
改变我们目标的大小

362
00:11:40,496 --> 0:11:41,966
相对于背景的大小

363
00:11:42,216 --> 0:11:44,506
让我们开始这样做

364
00:11:44,506 --> 0:11:45,006
我们现场做

365
00:11:46,096 --> 0:11:48,536
所以 左边这是我们的输入

366
00:11:48,536 --> 0:11:50,416
图像和右边的

367
00:11:50,416 --> 0:11:52,786
人像蒙版图

368
00:11:52,966 --> 0:11:55,056
我将要做的是

369
00:11:55,056 --> 0:11:57,146
我会改变在我框架中人物的

370
00:11:57,146 --> 0:11:59,616
大小 注意目标是

371
00:11:59,616 --> 0:12:02,416
如何的变大和变小

372
00:11:59,616 --> 0:12:02,416
如何的变大和变小

373
00:12:03,176 --> 0:12:04,946
你可以在你的

374
00:12:05,956 --> 0:12:07,096
框架中给这个目标

375
00:12:07,096 --> 0:12:09,046
更多的权重数值 你也可以做

376
00:12:09,046 --> 0:12:11,106
很酷的事情 就像现在

377
00:12:11,106 --> 0:12:12,456
我有着这个 让我选择

378
00:12:12,456 --> 0:12:14,966
我最喜欢的尺寸大小

379
00:12:14,966 --> 0:12:17,436
你可以通过在前景中

380
00:12:17,436 --> 0:12:19,346
提供更多对比度

381
00:12:19,346 --> 0:12:20,276
并使背景模糊

382
00:12:20,276 --> 0:12:22,076
来做类似仿真景深的事情

383
00:12:22,076 --> 0:12:22,916
从而为拍摄对象

384
00:12:22,916 --> 0:12:24,136
提供更多的突出点

385
00:12:26,296 --> 0:12:28,006
所以让我们来看看

386
00:12:28,006 --> 0:12:29,346
另一张图片

387
00:12:29,346 --> 0:12:30,506
看看这操作起来是多么的容易

388
00:12:30,506 --> 0:12:32,226
因为它们使用了完全

389
00:12:32,226 --> 0:12:33,176
相同的方法

390
00:12:33,176 --> 0:12:34,486
这是非常的简单 仅仅

391
00:12:34,536 --> 0:12:36,376
使用了人像蒙版图并用它

392
00:12:36,376 --> 0:12:38,856
去模糊前景和背景

393
00:12:38,856 --> 0:12:40,096
再次 我们输入图像

394
00:12:40,096 --> 0:12:42,586
改变它的大小

395
00:12:42,586 --> 0:12:44,966
使它变得更大

396
00:12:45,006 --> 0:12:47,736
然后应用一些对比度 来给我们的人像更多的焦点

397
00:12:48,706 --> 0:12:49,976
这很简单 令人兴奋

398
00:12:50,516 --> 0:12:55,216
[ 掌声 ]

399
00:12:55,716 --> 0:12:57,186
好吧 让我们看看

400
00:12:57,186 --> 0:12:58,956
另一个演示 我们称它为 Marching

401
00:12:59,226 --> 0:13:01,226
我甚至不会

402
00:12:59,226 --> 0:13:01,226
我甚至不会

403
00:13:01,226 --> 0:13:02,976
解释它的作用

404
00:13:02,976 --> 0:13:04,816
让我们来看看滤镜的实际操作

405
00:13:10,046 --> 0:13:12,516
你看 有趣的东西

406
00:13:12,516 --> 0:13:14,236
因为可以做到这一点

407
00:13:14,236 --> 0:13:15,696
所以我可以添加任何

408
00:13:15,696 --> 0:13:16,406
我想要的数量缝合在一起

409
00:13:16,406 --> 0:13:18,726
所以从只有一些贴近你

410
00:13:18,726 --> 0:13:20,526
到把它推到很远很远

411
00:13:21,966 --> 0:13:23,046
令人兴奋

412
00:13:23,456 --> 0:13:31,506
好的 这就是这个演示

413
00:13:31,506 --> 0:13:32,356
我希望你喜欢这个

414
00:13:33,966 --> 0:13:35,606
所以如果你想了解

415
00:13:35,606 --> 0:13:36,956
更多有关使用 Python 和

416
00:13:36,956 --> 0:13:38,126
Core Image 的东西 我建议你去

417
00:13:38,126 --> 0:13:39,426
参加今天下午的

418
00:13:39,796 --> 0:13:40,906
Core Image Performance

419
00:13:40,906 --> 0:13:42,066
Prototyping in Python 的会议

420
00:13:42,686 --> 0:13:45,616
这就是我今天所有的展示

421
00:13:45,616 --> 0:13:46,736
让我来介绍我的同事

422
00:13:46,736 --> 0:13:48,266
Ron 一名视频工程师

423
00:13:48,266 --> 0:13:49,676
将介绍使用 TrueDepth

424
00:13:49,676 --> 0:13:51,046
的实时视频效果

425
00:13:51,346 --> 0:13:51,976
谢谢大家

426
00:13:52,516 --> 0:13:56,500
[ 掌声 ]

427
00:13:59,286 --> 0:14:00,046
&gt;&gt; 谢谢你 Emmanuel

428
00:13:59,286 --> 0:14:00,046
&gt;&gt; 谢谢你 Emmanuel

429
00:14:01,186 --> 0:14:02,826
非常精彩的图像效果

430
00:14:02,826 --> 0:14:03,456
那么视频呢

431
00:14:04,866 --> 0:14:06,926
我的名字是 Ron Sokolovsky

432
00:14:06,926 --> 0:14:07,916
我是一名视频工程师

433
00:14:08,476 --> 0:14:11,946
在这个部分 我们将

434
00:14:11,946 --> 0:14:13,236
利用 TrueDepth 的相机

435
00:14:13,446 --> 0:14:15,576
为实时视频

436
00:14:15,576 --> 0:14:17,636
创造类似的效果

437
00:14:17,636 --> 0:14:20,426
例如此背景替换 App

438
00:14:21,856 --> 0:14:24,556
为了产生如此的效果

439
00:14:24,836 --> 0:14:26,486
我们将深入研究

440
00:14:26,486 --> 0:14:29,306
来自 TrueDepth 相机的特性

441
00:14:29,306 --> 0:14:32,066
最佳实践性和挑战

442
00:14:32,636 --> 0:14:35,316
我们将为你展示

443
00:14:35,316 --> 0:14:36,706
如何使用点云技术

444
00:14:36,706 --> 0:14:38,286
一个完全不同的方式

445
00:14:38,286 --> 0:14:40,546
来处理和渲染丰富的深度信息

446
00:14:41,056 --> 0:14:42,626
后台替换程序

447
00:14:42,846 --> 0:14:44,116
我们称之为 Backdrop

448
00:14:44,476 --> 0:14:45,516
我们将向你逐步

449
00:14:45,516 --> 0:14:46,756
展示如何实现

450
00:14:48,336 --> 0:14:51,446
但首先 TrueDepth 相机的流

451
00:14:51,446 --> 0:14:53,396
由帧组成

452
00:14:53,396 --> 0:14:55,326
每一帧都是一个深度图

453
00:14:55,326 --> 0:14:57,186
它是一个 2D 图像

454
00:14:57,426 --> 0:14:58,926
其中每一个像素都包含

455
00:14:59,236 --> 0:15:00,976
深度信息和沿该方向到场景的距离

456
00:14:59,236 --> 0:15:00,976
深度信息和沿该方向到场景的距离

457
00:15:05,046 --> 0:15:06,296
我们选择了特定的着色

458
00:15:06,296 --> 0:15:08,466
方法 近处像素

459
00:15:08,466 --> 0:15:11,056
用红色着色 而远处的像素

460
00:15:11,056 --> 0:15:12,306
用蓝色着色

461
00:15:12,886 --> 0:15:14,216
在它们之间有一个

462
00:15:14,216 --> 0:15:16,426
彩色光谱 因此你可以

463
00:15:16,776 --> 0:15:18,566
看到深度图的纹理

464
00:15:20,156 --> 0:15:21,686
同时还有黑色像素

465
00:15:22,156 --> 0:15:23,636
是那些在深度图中的黑色小洞

466
00:15:24,286 --> 0:15:25,946
对于这些像素 我们

467
00:15:25,946 --> 0:15:27,596
没有任何深度的信息

468
00:15:28,456 --> 0:15:30,796
今天 我们将发布一个

469
00:15:30,796 --> 0:15:32,936
新的工具 一个示例 App

470
00:15:32,936 --> 0:15:34,676
让你去探索这个流

471
00:15:34,676 --> 0:15:36,526
我们称之为 TrueDepth Streamer

472
00:15:37,076 --> 0:15:40,716
你可以在视频流和

473
00:15:40,716 --> 0:15:42,976
TrueDepth 流之间切换

474
00:15:47,046 --> 0:15:48,716
现在 由于 TrueDepth 相机

475
00:15:49,456 --> 0:15:51,936
即使在完全黑暗的情况下

476
00:15:51,936 --> 0:15:53,676
也具有主动照明

477
00:15:53,676 --> 0:15:56,966
所以 TrueDepth 相机

478
00:15:56,966 --> 0:15:59,026
仍然正常工作

479
00:16:01,716 --> 0:16:04,906
所以 现在你可以看到我 现在你不行

480
00:16:05,516 --> 0:16:09,266
[ 掌声 ]

481
00:16:09,766 --> 0:16:11,666
那么如何将 TrueDepth 相机

482
00:16:11,666 --> 0:16:13,986
中的数据流添加到你的 App 中

483
00:16:14,946 --> 0:16:17,526
首先你需要做的是

484
00:16:17,986 --> 0:16:19,346
找到 builtInTrueDepthCamera

485
00:16:19,346 --> 0:16:24,186
然后初始化设备捕捉输入

486
00:16:24,186 --> 0:16:27,416
然后你将 depthDataOutput

487
00:16:27,416 --> 0:16:28,766
添加进你的会话类中

488
00:16:29,606 --> 0:16:32,826
现在你可以开始进行会话类了

489
00:16:32,826 --> 0:16:33,706
并且会在会话中

490
00:16:33,706 --> 0:16:35,266
有着 TrueDepth 流

491
00:16:37,376 --> 0:16:39,286
这些流有着两种

492
00:16:39,286 --> 0:16:42,166
形式的数据视差和深度

493
00:16:42,846 --> 0:16:44,306
视差数据是深度数据的

494
00:16:44,306 --> 0:16:46,586
倒数 反之亦然

495
00:16:46,586 --> 0:16:47,396
所以你应该选择哪个呢

496
00:16:48,666 --> 0:16:51,366
良好的视差数据通常产生

497
00:16:51,366 --> 0:16:53,456
更好的结果

498
00:16:53,456 --> 0:16:54,596
特别是对于机器学习 App 来说

499
00:16:55,216 --> 0:16:56,646
但深度数据在

500
00:16:56,646 --> 0:16:58,926
实际测量方面具有更多意义

501
00:17:00,036 --> 0:17:01,666
你需要知道 当你处理深度时

502
00:17:01,746 --> 0:17:05,935
深度误差与深度的平方一致

503
00:17:06,036 --> 0:17:08,096
这意味着一个 1 米远的

504
00:17:08,096 --> 0:17:09,685
物体有着 4 倍于 2 米远

505
00:17:09,685 --> 0:17:11,976
物体的深度精度

506
00:17:16,286 --> 0:17:18,496
我们有视频流和深度流

507
00:17:18,496 --> 0:17:19,425
它们不一定

508
00:17:19,425 --> 0:17:21,136
分享相同的分辨率

509
00:17:21,646 --> 0:17:23,006
TrueDepth 相机的原始分辨率

510
00:17:23,006 --> 0:17:24,596
是 VGA 或者 640x480

511
00:17:24,596 --> 0:17:27,736
你将会获得这种分辨率

512
00:17:27,736 --> 0:17:30,176
如果你选择一个视频

513
00:17:30,656 --> 0:17:32,236
以屏幕高宽比 4:3 的预设

514
00:17:33,226 --> 0:17:35,516
但如果你选择 16x9 的屏幕高宽比

515
00:17:35,516 --> 0:17:40,246
你将会得到 640x360 的深度图

516
00:17:40,966 --> 0:17:42,916
在两种情况下 深度图

517
00:17:42,916 --> 0:17:44,856
都将覆盖整个 RGB

518
00:17:45,146 --> 0:17:46,146
图像的整个视野

519
00:17:46,666 --> 0:17:49,466
现在我们讨论的是

520
00:17:49,466 --> 0:17:51,116
视频 App 所以我们

521
00:17:51,116 --> 0:17:52,946
要非常快速地处理大量数据

522
00:17:52,946 --> 0:17:54,956
随着时间的推移 这可能

523
00:17:55,306 --> 0:17:57,266
对系统产生压力

524
00:17:57,936 --> 0:17:59,696
所以你可以测试你的 App

525
00:17:59,696 --> 0:18:01,306
并测试你系统压力

526
00:17:59,696 --> 0:18:01,306
并测试你系统压力

527
00:18:01,306 --> 0:18:04,006
水平 从轻松

528
00:18:04,006 --> 0:18:07,056
一般 负荷 超负荷 最后关机

529
00:18:07,476 --> 0:18:08,956
而责任掌握在你的手中

530
00:18:08,956 --> 0:18:10,886
因为系统会允许你一直测试

531
00:18:11,166 --> 0:18:12,326
直至它最终关机

532
00:18:12,326 --> 0:18:15,206
但是当这发生了

533
00:18:15,206 --> 0:18:17,326
所有的捕捉设备也都将受损

534
00:18:17,726 --> 0:18:22,026
另一件你可以做的事是

535
00:18:22,026 --> 0:18:24,006
采用退化方案

536
00:18:24,006 --> 0:18:25,496
如果压力水平变得严重

537
00:18:25,496 --> 0:18:27,206
你可以将帧速率

538
00:18:27,206 --> 0:18:29,736
降低到每秒 15 帧

539
00:18:29,736 --> 0:18:31,516
或者你可以选择更复杂的方案

540
00:18:31,896 --> 0:18:33,966
用更加柔和的退化方式

541
00:18:33,966 --> 0:18:37,356
每当压力提升 把每秒帧数

542
00:18:37,356 --> 0:18:39,976
从 30 24 20 一直降到 15

543
00:18:43,836 --> 0:18:45,026
而且我们在深度图中有着

544
00:18:45,026 --> 0:18:46,406
一些黑洞 我们可以做些什么呢

545
00:18:47,686 --> 0:18:49,456
实际上你可以得到

546
00:18:49,456 --> 0:18:51,496
一些已经过滤后的流

547
00:18:52,176 --> 0:18:53,936
这是一个名为

548
00:18:53,936 --> 0:18:55,546
isFilteringEnabled 的参数

549
00:18:55,546 --> 0:18:57,676
默认为真  它意味着

550
00:18:57,676 --> 0:18:59,236
你可以在空间和时间上

551
00:18:59,606 --> 0:19:01,576
平滑地过滤

552
00:18:59,606 --> 0:19:01,576
平滑地过滤

553
00:19:01,776 --> 0:19:03,536
深度图 并从 RGB 图像

554
00:19:03,536 --> 0:19:04,356
填充黑洞

555
00:19:05,466 --> 0:19:07,256
这对于摄影和分割

556
00:19:07,256 --> 0:19:08,616
App 非常有用

557
00:19:08,616 --> 0:19:10,206
因为每次

558
00:19:10,446 --> 0:19:12,386
查询像素时

559
00:19:12,386 --> 0:19:13,216
都知道深度值

560
00:19:13,776 --> 0:19:17,376
在 TrueDepth Streamer 中

561
00:19:17,376 --> 0:19:19,566
你可以切换到滤镜流

562
00:19:19,566 --> 0:19:21,876
从而查看它是否更平滑

563
00:19:21,876 --> 0:19:22,586
并且黑孔被填充

564
00:19:23,126 --> 0:19:27,526
这非常的好

565
00:19:27,526 --> 0:19:29,636
但它不适用于所有的情况

566
00:19:30,226 --> 0:19:31,676
如果你在处理点云

567
00:19:31,676 --> 0:19:34,606
或者任何类型的

568
00:19:34,836 --> 0:19:36,256
真实世界测量 你最好

569
00:19:36,256 --> 0:19:38,366
保持原始数据

570
00:19:38,366 --> 0:19:39,806
以保证最高的保真度

571
00:19:40,846 --> 0:19:42,726
如果你这样做的话 你会得到黑洞

572
00:19:42,906 --> 0:19:44,496
你会有像素被标记

573
00:19:44,496 --> 0:19:46,866
为零 它并不意味它们

574
00:19:46,866 --> 0:19:48,396
距离摄像机零米

575
00:19:48,396 --> 0:19:50,356
的距离 它只意味着我们

576
00:19:50,356 --> 0:19:52,296
没有关于它们的信息

577
00:19:53,336 --> 0:19:54,946
因此 你需要注意如

578
00:19:55,116 --> 0:19:56,506
求平均和

579
00:19:56,506 --> 0:19:57,606
降采样的操作 因为你不希望

580
00:19:57,606 --> 0:20:00,976
把真实值和这些零混合

581
00:19:57,606 --> 0:20:00,976
把真实值和这些零混合

582
00:20:03,756 --> 0:20:04,996
但是为什么我们会得到这些黑洞呢

583
00:20:05,536 --> 0:20:08,876
TrueDepth 相机

584
00:20:09,296 --> 0:20:11,456
可以探测大约 5 米

585
00:20:11,456 --> 0:20:14,056
的物体 但并不是所有的

586
00:20:14,056 --> 0:20:15,296
材料都是相同的

587
00:20:15,636 --> 0:20:17,496
一些材料有着低反射率

588
00:20:17,716 --> 0:20:20,126
它们吸收大部分的光线

589
00:20:21,476 --> 0:20:23,656
例如 这种极端的情景

590
00:20:23,706 --> 0:20:26,046
这是一块有着极低反射率的材料

591
00:20:26,046 --> 0:20:27,896
看看当我一边远离它一边获得深度图时

592
00:20:27,896 --> 0:20:29,686
一边获得深度图时

593
00:20:29,686 --> 0:20:31,766
会发生什么

594
00:20:33,346 --> 0:20:35,066
即使场景中存在

595
00:20:35,066 --> 0:20:37,466
距离较远的物体

596
00:20:37,796 --> 0:20:39,866
我们也可以在这块材料上看到

597
00:20:39,866 --> 0:20:41,436
黑孔洞 这是因为它

598
00:20:42,026 --> 0:20:42,766
吸收了大部分的光线

599
00:20:44,126 --> 0:20:45,446
如果切换到滤镜流

600
00:20:45,446 --> 0:20:47,616
并重复相同的

601
00:20:47,616 --> 0:20:49,246
动作 那么这些黑孔洞会被填满

602
00:20:49,786 --> 0:20:53,336
但是这不仅与反射回来的

603
00:20:53,336 --> 0:20:54,766
光的数量有关

604
00:20:55,326 --> 0:20:56,916
而且它也和反射

605
00:20:56,916 --> 0:20:58,056
的方向相关

606
00:20:59,116 --> 0:21:01,036
一些材料是镜面的

607
00:20:59,116 --> 0:21:01,036
一些材料是镜面的

608
00:21:01,036 --> 0:21:02,826
或是有光泽的

609
00:21:02,826 --> 0:21:04,166
它们本身反射光的方向

610
00:21:04,166 --> 0:21:05,046
就非常的挑剔

611
00:21:05,656 --> 0:21:08,406
这有一个

612
00:21:08,406 --> 0:21:11,816
极端的情况 你可以观看

613
00:21:11,816 --> 0:21:13,436
视频流以查看反射

614
00:21:14,616 --> 0:21:15,746
当我们切换到深度图时

615
00:21:15,746 --> 0:21:18,366
黑孔的形成取决于

616
00:21:18,366 --> 0:21:20,246
设备和屏幕之间的角度

617
00:21:21,556 --> 0:21:23,376
因此如果我们切换到

618
00:21:23,376 --> 0:21:25,216
滤镜流 这些黑孔洞将被填充

619
00:21:25,666 --> 0:21:26,976
但是保真度会降低

620
00:21:31,046 --> 0:21:32,916
另一个具有挑战性的场景

621
00:21:32,916 --> 0:21:35,306
就是室外 通常在室外场景中

622
00:21:35,306 --> 0:21:36,996
背景十分遥远

623
00:21:36,996 --> 0:21:38,736
所以我们不希望从背景中

624
00:21:38,736 --> 0:21:39,806
得到任何深度信息

625
00:21:40,456 --> 0:21:42,956
同时 太阳光被视为

626
00:21:42,956 --> 0:21:44,906
主动照明的影响因素

627
00:21:45,496 --> 0:21:48,696
为了证明这个 我在一个

628
00:21:48,696 --> 0:21:50,006
阳光非常明媚的下午

629
00:21:50,006 --> 0:21:51,556
去了外面 把自己

630
00:21:51,556 --> 0:21:52,326
置于阳光下

631
00:21:53,216 --> 0:21:54,286
当我们切换到深度图时

632
00:21:54,286 --> 0:21:55,926
你可以看到背景

633
00:21:55,926 --> 0:21:58,056
没有任何深度数据

634
00:21:58,056 --> 0:21:59,786
并且在框架的周围有着

635
00:21:59,786 --> 0:22:01,726
一些黑孔洞 

636
00:21:59,786 --> 0:22:01,726
一些黑孔洞 

637
00:22:01,726 --> 0:22:02,506
特别是头发

638
00:22:03,476 --> 0:22:05,556
但前景大部分深度数据

639
00:22:05,556 --> 0:22:07,696
仍然完好无损

640
00:22:08,256 --> 0:22:12,436
我想介绍的最后一点是

641
00:22:12,596 --> 0:22:14,616
从 TrueDepth 相机的

642
00:22:14,616 --> 0:22:15,736
角度来看

643
00:22:15,736 --> 0:22:17,516
投影的光线

644
00:22:17,516 --> 0:22:19,396
会在返回的路上

645
00:22:19,396 --> 0:22:21,306
撞击到物体

646
00:22:21,306 --> 0:22:23,006
所以我们会从

647
00:22:23,006 --> 0:22:26,096
投影机和相机之间的视差中得到阴影

648
00:22:26,096 --> 0:22:27,316
这个杯子的

649
00:22:27,316 --> 0:22:29,266
右侧就是一个例子

650
00:22:30,176 --> 0:22:31,576
但这里有些不同

651
00:22:32,676 --> 0:22:34,426
这不是一个深度图

652
00:22:34,426 --> 0:22:36,916
那我们为什么还会得到黑孔洞呢

653
00:22:37,096 --> 0:22:38,586
在 TrueDepth Streamer 中

654
00:22:38,586 --> 0:22:41,076
你可以从二维模式切换

655
00:22:41,076 --> 0:22:43,616
到三维 从而为我们提供点云视图

656
00:22:44,326 --> 0:22:45,956
有了点云我们可以

657
00:22:45,956 --> 0:22:47,426
动态地改变

658
00:22:47,426 --> 0:22:48,936
场景的视角

659
00:22:50,796 --> 0:22:53,506
从而当我们这么做时

660
00:22:54,106 --> 0:22:56,256
会产生更多黑孔洞

661
00:22:56,396 --> 0:22:58,226
现在我可以问你的是

662
00:22:58,226 --> 0:23:01,706
这杯子是半空的还是半满的

663
00:22:58,226 --> 0:23:01,706
这杯子是半空的还是半满的

664
00:23:01,706 --> 0:23:03,826
答案是我们不知道

665
00:23:05,256 --> 0:23:07,176
通过虚拟地改变

666
00:23:07,176 --> 0:23:08,606
相机的视角

667
00:23:08,606 --> 0:23:10,696
我们不添加新的信息

668
00:23:10,696 --> 0:23:11,966
这是因为 TrueDepth 相机

669
00:23:11,966 --> 0:23:13,656
可以做很多事情

670
00:23:13,656 --> 0:23:17,726
但是不包括将光线投射进杯子中

671
00:23:18,076 --> 0:23:18,786
让我们来观看现场演示

672
00:23:21,516 --> 0:23:24,500
[ 掌声 ]

673
00:23:32,046 --> 0:23:32,946
所以我开始视频展示

674
00:23:32,946 --> 0:23:34,736
并且我想让你关注于这个角落

675
00:23:35,636 --> 0:23:37,356
观察发生了什么 当我

676
00:23:37,356 --> 0:23:38,456
触摸屏幕 我将触碰我的

677
00:23:38,456 --> 0:23:39,636
前景 你可以看到

678
00:23:39,636 --> 0:23:41,456
深度的迹象

679
00:23:41,806 --> 0:23:44,466
如果当我移动手机

680
00:23:44,466 --> 0:23:46,036
你可以看到动态地变化

681
00:23:46,036 --> 0:23:47,606
我可以办到此事的原因是

682
00:23:47,606 --> 0:23:50,206
从 TrueDepth 相机

683
00:23:50,206 --> 0:23:51,346
的流也在运行

684
00:23:51,346 --> 0:23:53,836
你可以看到

685
00:23:53,836 --> 0:23:55,316
它覆盖在视频上

686
00:23:55,316 --> 0:23:58,976
所以我们有着每秒 30 帧的

687
00:23:58,976 --> 0:24:00,766
实况流 并且我们可以

688
00:23:58,976 --> 0:24:00,766
实况流 并且我们可以

689
00:24:00,766 --> 0:24:01,996
切换到滤镜视频

690
00:24:02,456 --> 0:24:06,026
然后使所有的黑孔洞都被填满

691
00:24:06,206 --> 0:24:07,446
如果我切换到点云视图

692
00:24:07,446 --> 0:24:10,076
我可以动态地改变

693
00:24:11,636 --> 0:24:13,296
场景的视角

694
00:24:14,276 --> 0:24:15,516
所以即使我直接

695
00:24:15,516 --> 0:24:17,786
看着设备

696
00:24:17,786 --> 0:24:19,846
它看起来像是有人从上面看我

697
00:24:21,336 --> 0:24:22,516
我们称之为点云的原因是

698
00:24:22,516 --> 0:24:25,076
如果我放大 你实际

699
00:24:25,076 --> 0:24:28,156
可以看到三维空间中的点

700
00:24:28,686 --> 0:24:32,016
但是在 WWDC 和你们在一起

701
00:24:32,466 --> 0:24:33,576
我觉得我必须要

702
00:24:33,576 --> 0:24:36,306
要让视角回到正常

703
00:24:39,516 --> 0:24:42,500
[ 掌声 ]

704
00:24:45,076 --> 0:24:48,446
谢谢 让我们看看点云

705
00:24:48,446 --> 0:24:49,306
我们如何创造它们

706
00:24:50,126 --> 0:24:51,426
我们从深度图开始

707
00:24:51,826 --> 0:24:54,236
这是一个二维图像

708
00:24:54,716 --> 0:24:57,056
其中深度 Z 是像素坐标 U 和 V 的函数

709
00:24:58,486 --> 0:25:00,076
而且我们想要将它在

710
00:24:58,486 --> 0:25:00,076
而且我们想要将它在

711
00:25:00,076 --> 0:25:01,586
三维空间 X Y Z 中转为

712
00:25:01,586 --> 0:25:03,486
新的坐标系

713
00:25:04,336 --> 0:25:06,256
我们已经有了 Z

714
00:25:06,256 --> 0:25:07,616
这是深度图的深度数据

715
00:25:07,616 --> 0:25:09,766
但是我们想要获得 X 和 Y

716
00:25:10,416 --> 0:25:13,606
因此 我们需要借助

717
00:25:13,606 --> 0:25:15,806
内参矩阵的帮忙

718
00:25:15,806 --> 0:25:17,196
该矩阵包含焦距

719
00:25:17,196 --> 0:25:18,346
和主点信息

720
00:25:19,376 --> 0:25:21,686
例如 我想要得到 X

721
00:25:21,686 --> 0:25:22,936
我需要从像素坐标 U 开始

722
00:25:22,936 --> 0:25:24,506
减去主元点 X0

723
00:25:24,506 --> 0:25:26,576
乘以深度 Z

724
00:25:26,576 --> 0:25:28,916
然后除以焦距 f

725
00:25:29,136 --> 0:25:30,416
当然 我也需要对

726
00:25:30,416 --> 0:25:31,256
另一个维度

727
00:25:31,256 --> 0:25:32,026
做同样的计算

728
00:25:33,196 --> 0:25:36,976
现在可以通过

729
00:25:36,976 --> 0:25:39,126
相机校准数据访问内参矩阵

730
00:25:39,716 --> 0:25:43,656
事实上 这个操作

731
00:25:44,786 --> 0:25:47,056
是在 TrueDepth 中的每一帧中完成的

732
00:25:47,506 --> 0:25:49,836
这么做的原因是

733
00:25:49,836 --> 0:25:51,656
视频流和深度流

734
00:25:51,656 --> 0:25:54,506
来自两个独立的摄像机

735
00:25:55,136 --> 0:25:57,246
但是由于 TrueDepth 相机

736
00:25:57,246 --> 0:25:58,936
为我们提供了一个深度图

737
00:25:58,936 --> 0:26:00,446
所以我们可以将其转为点云

738
00:25:58,936 --> 0:26:00,446
所以我们可以将其转为点云

739
00:26:00,876 --> 0:26:03,046
并将其重新投影到

740
00:26:03,046 --> 0:26:06,306
RGB 图像的视角

741
00:26:06,306 --> 0:26:07,756
所以深度流已经

742
00:26:07,756 --> 0:26:10,076
存在于视频流中

743
00:26:10,076 --> 0:26:13,556
这样你就能获得 RGBD 数据

744
00:26:14,146 --> 0:26:15,916
谢谢你们

745
00:26:16,496 --> 0:26:18,346
这非常的酷

746
00:26:20,066 --> 0:26:21,526
现在 这些类型的操作

747
00:26:21,626 --> 0:26:23,906
最好在 Metal Graphic Shaders 中完成

748
00:26:24,226 --> 0:26:25,476
并且你可以下载

749
00:26:25,476 --> 0:26:27,066
TrueDepth Streamer 的代码

750
00:26:27,066 --> 0:26:28,666
你要关注这两个方面

751
00:26:29,196 --> 0:26:32,286
在 Vertex Shader 中

752
00:26:32,286 --> 0:26:33,296
我们控制点的位置

753
00:26:33,486 --> 0:26:34,976
我们将从深度图开始

754
00:26:35,126 --> 0:26:36,696
并将其转换为真实世界

755
00:26:36,696 --> 0:26:37,986
坐标或者 X Y Z

756
00:26:39,186 --> 0:26:40,796
然后我们可以将它

757
00:26:40,796 --> 0:26:43,706
与视图矩阵相乘 用来改变视角

758
00:26:44,336 --> 0:26:49,066
在 Fragment Shader 中

759
00:26:49,066 --> 0:26:51,766
我们将得到 Vertex 中的输出

760
00:26:51,766 --> 0:26:53,866
但是我们必须检查它是否是真实值

761
00:26:54,096 --> 0:26:55,186
或者是一个在深度图中的黑孔洞

762
00:26:56,026 --> 0:26:57,476
如果它是一个黑孔洞 它被标记

763
00:26:57,476 --> 0:26:59,766
为零并且我们不知道它的深度

764
00:26:59,766 --> 0:27:01,516
所以我们无法将它转换到 X Y Z 坐标

765
00:26:59,766 --> 0:27:01,516
所以我们无法将它转换到 X Y Z 坐标

766
00:27:01,516 --> 0:27:02,856
因此我们要

767
00:27:02,856 --> 0:27:03,816
抛弃这个点

768
00:27:05,196 --> 0:27:06,786
如果它是一个真实值

769
00:27:06,786 --> 0:27:09,286
我们可以采样 RGB 纹理

770
00:27:09,286 --> 0:27:11,366
并为片段或者点

771
00:27:11,366 --> 0:27:14,746
添加颜色

772
00:27:14,956 --> 0:27:17,356
我明白这部分有点

773
00:27:17,356 --> 0:27:19,066
技术性 并且你们

774
00:27:19,066 --> 0:27:20,276
来自不同的专业背景

775
00:27:21,016 --> 0:27:22,876
不用担心

776
00:27:22,876 --> 0:27:25,056
我们为你提供 App 

777
00:27:25,056 --> 0:27:26,756
一款帮助你替换背景的 App

778
00:27:26,756 --> 0:27:40,926
让我们看看它的实况

779
00:27:41,136 --> 0:27:43,516
我可以将自己放在约塞米蒂国家公园

780
00:27:43,936 --> 0:27:46,466
我可以把自己放在

781
00:27:46,466 --> 0:27:47,466
更抽象的东西上

782
00:27:48,166 --> 0:27:51,466
我甚至可以一路去

783
00:27:51,466 --> 0:27:53,006
亚利桑那州的羚羊峡谷

784
00:27:53,006 --> 0:27:54,356
上次花了我 15 个小时到达那里

785
00:27:54,356 --> 0:27:55,846
现在我只要刷下屏幕就到达

786
00:27:55,846 --> 0:27:58,126
节省了我一大笔的油钱

787
00:27:59,546 --> 0:28:02,016
事实上 这个 App

788
00:27:59,546 --> 0:28:02,016
事实上 这个 App

789
00:28:02,016 --> 0:28:04,116
甚至可以将你放入

790
00:28:04,116 --> 0:28:05,876
一个没有人可以听到你的空间

791
00:28:11,516 --> 0:28:15,616
[ 掌声 ]

792
00:28:16,116 --> 0:28:19,036
所以我们如何实现这些的

793
00:28:19,256 --> 0:28:21,586
任何时候我们在处理

794
00:28:21,586 --> 0:28:23,706
视频 App 时

795
00:28:23,706 --> 0:28:25,476
都会根据每帧的情况进行

796
00:28:25,476 --> 0:28:28,456
其它操作 在这种情况下

797
00:28:28,456 --> 0:28:31,696
我们必须检测面部

798
00:28:31,696 --> 0:28:33,316
从深度图建立一个全新的遮罩

799
00:28:33,316 --> 0:28:36,056
将其平滑并升级为

800
00:28:36,056 --> 0:28:37,286
RGB 分辨率

801
00:28:37,736 --> 0:28:39,246
然后我们将这个前景

802
00:28:39,246 --> 0:28:41,536
遮罩再次放大

803
00:28:41,536 --> 0:28:42,636
直到低光背景图像

804
00:28:43,446 --> 0:28:44,616
然后我们可以混合或者

805
00:28:44,646 --> 0:28:46,876
组合它们 但是我们

806
00:28:46,876 --> 0:28:49,336
可以做些什么来减少

807
00:28:49,416 --> 0:28:50,416
一些复杂度

808
00:28:51,976 --> 0:28:54,466
如果每次我们加载背景图像

809
00:28:54,466 --> 0:28:56,306
我们只将其调整为

810
00:28:56,306 --> 0:28:57,756
RGB 分辨率

811
00:28:57,756 --> 0:28:59,556
而不是每帧一次

812
00:28:59,556 --> 0:29:01,446
那么我们就不需要第二次放大

813
00:28:59,556 --> 0:29:01,446
那么我们就不需要第二次放大

814
00:29:01,446 --> 0:29:02,926
并且以低分辨率完成混合

815
00:29:02,926 --> 0:29:04,886
这会产生很大的差异

816
00:29:06,276 --> 0:29:07,716
所以让我们深入

817
00:29:07,716 --> 0:29:08,086
这些深度数据

818
00:29:08,626 --> 0:29:10,606
首先我们需要找到

819
00:29:10,606 --> 0:29:11,856
脸部的中心

820
00:29:12,366 --> 0:29:14,406
在 iOS 中 有很多方法

821
00:29:14,646 --> 0:29:16,386
可以获得

822
00:29:16,386 --> 0:29:17,316
脸部元素组

823
00:29:18,296 --> 0:29:19,246
你可以使用 Core Image

824
00:29:19,246 --> 0:29:20,706
的探测器 或者 Vision

825
00:29:20,706 --> 0:29:22,796
Framework 但是在此情况下

826
00:29:22,976 --> 0:29:25,226
因为我们只需要

827
00:29:25,226 --> 0:29:26,366
脸部中间的像素

828
00:29:26,366 --> 0:29:29,056
我们可以使用 AV 元数据对象 类型为脸

829
00:29:30,426 --> 0:29:32,896
但它使我们成为 RGB 图像

830
00:29:32,896 --> 0:29:34,236
编码系统的中心

831
00:29:34,236 --> 0:29:36,086
我们需要将它

832
00:29:36,086 --> 0:29:38,196
映射到可能不是一样分辨率的

833
00:29:38,196 --> 0:29:39,106
深度图中

834
00:29:41,356 --> 0:29:43,316
一旦我们获得了

835
00:29:43,316 --> 0:29:45,886
人脸深度的值

836
00:29:45,886 --> 0:29:47,566
我们就可以使用它加上 25 厘米特征的边距

837
00:29:47,566 --> 0:29:50,656
来确定深度图的阈值

838
00:29:50,656 --> 0:29:52,306
并创造一个二进制

839
00:29:52,306 --> 0:29:54,076
掩码 前景为 1

840
00:29:54,476 --> 0:29:55,296
背景为 0

841
00:29:56,556 --> 0:29:58,456
事实上 我们可以在这里停下来

842
00:29:58,456 --> 0:30:00,956
我们可以使用这个二进制掩码并创建效果

843
00:29:58,456 --> 0:30:00,956
我们可以使用这个二进制掩码并创建效果

844
00:30:01,596 --> 0:30:02,816
从背景到前景

845
00:30:02,816 --> 0:30:04,166
的过度将非常的

846
00:30:04,166 --> 0:30:06,636
尖锐 但我们会在边缘周围

847
00:30:06,636 --> 0:30:07,826
得到一些差的数据

848
00:30:09,486 --> 0:30:10,856
所以我们想要滤波一下

849
00:30:11,826 --> 0:30:14,156
第一阶段将

850
00:30:14,156 --> 0:30:15,216
使用从背景到前景

851
00:30:15,216 --> 0:30:16,346
的一些平滑技术

852
00:30:16,346 --> 0:30:17,896
在此情况 用高斯模糊

853
00:30:18,626 --> 0:30:20,446
高斯模糊的半径

854
00:30:20,446 --> 0:30:22,716
将决定转换的斜率

855
00:30:22,716 --> 0:30:25,096
你可以使用该值

856
00:30:25,096 --> 0:30:28,526
来获得不同的效果

857
00:30:29,426 --> 0:30:31,126
另一个我们添加的处理阶段

858
00:30:31,346 --> 0:30:33,966
是伽马调节 它允许我们

859
00:30:33,966 --> 0:30:35,286
进一步微调

860
00:30:35,286 --> 0:30:36,976
从背景到前景的这种转变

861
00:30:37,426 --> 0:30:39,386
如果我们使用高于 1 的伽玛值

862
00:30:39,386 --> 0:30:41,576
我们将获得

863
00:30:41,576 --> 0:30:43,156
更窄的前景蒙板

864
00:30:44,176 --> 0:30:45,966
另一方面

865
00:30:45,966 --> 0:30:47,526
如果我们使用小于 1 的伽马值

866
00:30:47,526 --> 0:30:49,886
我们将得到更宽的前景蒙版

867
00:30:49,886 --> 0:30:51,026
也许会有一些光环

868
00:30:52,386 --> 0:30:53,646
所以你可以通过

869
00:30:53,646 --> 0:30:56,286
组合这两个参数来

870
00:30:56,446 --> 0:30:57,136
创建不同的效果

871
00:30:57,556 --> 0:31:01,156
如果你使用一个大的模糊半径

872
00:30:57,556 --> 0:31:01,156
如果你使用一个大的模糊半径

873
00:31:01,366 --> 0:31:02,866
和一个大的伽马值

874
00:31:02,866 --> 0:31:04,656
你就创建了一种透明

875
00:31:04,656 --> 0:31:06,726
的过度 让你看起来

876
00:31:06,726 --> 0:31:08,486
好像是空间中的全息图

877
00:31:09,546 --> 0:31:10,706
或者类似地 它可能是在

878
00:31:10,706 --> 0:31:13,336
水下 你可以调整

879
00:31:13,336 --> 0:31:15,576
这些数值来创造不同的效果

880
00:31:15,576 --> 0:31:17,936
如果我保持大的半径

881
00:31:18,116 --> 0:31:19,766
但将伽马值减小到

882
00:31:19,766 --> 0:31:22,186
很低的值 我就会创造出围绕

883
00:31:22,186 --> 0:31:22,756
在头上的光环

884
00:31:23,406 --> 0:31:24,376
所以你可以用这个来

885
00:31:24,376 --> 0:31:27,586
创造你自己的效果

886
00:31:27,586 --> 0:31:31,266
我们如何实现这一点

887
00:31:31,466 --> 0:31:33,026
在 Core Image 它非常的简单

888
00:31:33,026 --> 0:31:34,106
直接 我们可以

889
00:31:34,106 --> 0:31:36,166
把三个滤镜连接在一起

890
00:31:36,886 --> 0:31:38,516
首先是用 CIGaussianBlur

891
00:31:39,866 --> 0:31:42,656
然后添加 CIGammaAdjustment

892
00:31:42,656 --> 0:31:45,016
再升级到 RGB 分辨率

893
00:31:46,616 --> 0:31:48,306
但是 为了最好的实际操作

894
00:31:48,306 --> 0:31:49,756
这里我想强调

895
00:31:49,756 --> 0:31:50,686
一些小的方面

896
00:31:52,076 --> 0:31:54,176
无论何时 你使用

897
00:31:54,176 --> 0:31:55,696
一个基于高斯模糊

898
00:31:55,696 --> 0:31:57,436
的卷积操作

899
00:31:57,436 --> 0:31:59,466
最好的做法是从

900
00:31:59,466 --> 0:32:00,696
clampedtoExtent 开始

901
00:31:59,466 --> 0:32:00,696
clampedtoExtent 开始

902
00:32:01,856 --> 0:32:03,576
通过向外重复

903
00:32:03,576 --> 0:32:06,446
边界像素 我们可以确保

904
00:32:06,446 --> 0:32:07,566
图像所有的边界

905
00:32:07,566 --> 0:32:10,996
都被滤镜正确地处理

906
00:32:11,126 --> 0:32:13,236
而且 在滤镜之后

907
00:32:13,236 --> 0:32:14,616
和在升级分辨率之前

908
00:32:15,116 --> 0:32:16,286
最好的操作是

909
00:32:16,286 --> 0:32:18,386
修剪到原来的样子

910
00:32:18,886 --> 0:32:20,006
因为这是我们真正

911
00:32:20,006 --> 0:32:21,496
关心的图像中的部分

912
00:32:21,766 --> 0:32:25,816
在这一点上 我们有

913
00:32:25,816 --> 0:32:27,766
一个 alpha 前景蒙版

914
00:32:27,766 --> 0:32:29,096
你可以使用它为

915
00:32:29,096 --> 0:32:30,246
背景和前景创建

916
00:32:30,246 --> 0:32:31,336
不同的效果

917
00:32:31,796 --> 0:32:33,646
就像 Emmanuel 在上半场展示的一样

918
00:32:34,076 --> 0:32:39,266
在 Backdrop 中 我们使用

919
00:32:39,266 --> 0:32:41,136
从 TrueDepth 相机创建的

920
00:32:41,136 --> 0:32:43,186
alpha 蒙版将 RGB 流

921
00:32:43,186 --> 0:32:45,016
与加载的背景图像

922
00:32:45,016 --> 0:32:46,296
融合在一行

923
00:32:46,296 --> 0:32:48,706
Core Image 代码中

924
00:32:49,216 --> 0:32:50,236
以创建此背景替换效果

925
00:32:53,996 --> 0:32:57,056
所以这个 TrueDepth 相机

926
00:32:58,046 --> 0:32:59,416
给了我们每秒 30 帧

927
00:32:59,416 --> 0:33:02,576
640x480 分辨率的

928
00:32:59,416 --> 0:33:02,576
640x480 分辨率的

929
00:33:02,576 --> 0:33:05,936
深度图 并且它已经存在于视频流中

930
00:33:06,476 --> 0:33:09,496
你可以使用它来

931
00:33:09,496 --> 0:33:10,776
创建点云和动态地

932
00:33:10,776 --> 0:33:12,426
改变场景的透视图

933
00:33:12,486 --> 0:33:16,066
或者使用深度

934
00:33:16,336 --> 0:33:18,486
滤镜来创造不同的视频效果

935
00:33:21,476 --> 0:33:22,986
你可以访问网页并

936
00:33:22,986 --> 0:33:25,176
下载 Jupiter Notebook

937
00:33:25,466 --> 0:33:28,576
TrueDepth Streamer 和 Backdrop

938
00:33:29,246 --> 0:33:31,986
我们希望它能激发你

939
00:33:31,986 --> 0:33:34,876
在你的 App 中

940
00:33:34,876 --> 0:33:37,776
加入许多新奇炫酷的视频效果

941
00:33:39,316 --> 0:33:41,156
欢迎你们来 AVCapture 实验室

942
00:33:41,156 --> 0:33:42,976
非常感谢你的支持 祝你有美好的一天

943
00:33:43,516 --> 0:33:46,500
[ 掌声 ]
