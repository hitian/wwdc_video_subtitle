1
00:00:07,516 --> 0:00:15,500
[ 音乐 ]

2
00:00:17,516 --> 0:00:23,336
[ 掌声 ]

3
00:00:23,836 --> 0:00:24,826
&gt;&gt; 大家早上好

4
00:00:25,046 --> 0:00:26,676
我叫 Karol Gasinski 我是

5
00:00:26,676 --> 0:00:29,566
GPU 软件架构组的成员

6
00:00:29,566 --> 0:00:32,836
在本次会议的开头

7
00:00:32,836 --> 0:00:35,186
我们将简单概括

8
00:00:35,286 --> 0:00:38,196
macOS 中的新功能 主要和 VR 的应用有关

9
00:00:38,946 --> 0:00:40,826
然后 我们将深入探讨

10
00:00:41,046 --> 0:00:42,906
Metal 2 的新特性

11
00:00:43,136 --> 0:00:45,016
它是今年

12
00:00:45,016 --> 0:00:45,476
专为 VR 而设计的

13
00:00:46,756 --> 0:00:48,576
最后 在本次会议的结尾

14
00:00:48,576 --> 0:00:50,466
我们将讨论

15
00:00:50,626 --> 0:00:52,236
开发 VR App 的先进技术

16
00:00:53,856 --> 0:00:56,026
近来 我们推出了全新的 iMac 和 iMac Pro

17
00:00:56,116 --> 0:00:57,976
这两款产品使用了强大的

18
00:00:57,976 --> 0:01:00,776
图形处理器

19
00:00:57,976 --> 0:01:00,776
图形处理器

20
00:01:00,776 --> 0:01:01,936
iMac 如今配有基于 ARM 的

21
00:01:01,936 --> 0:01:05,636
图形处理器 并且拥有最高 8 GB

22
00:01:05,636 --> 0:01:06,976
的视频存储器

23
00:01:07,716 --> 0:01:09,946
而 iMac Pro 配有

24
00:01:09,946 --> 0:01:11,786
更先进且更大的

25
00:01:11,786 --> 0:01:15,586
图形处理器 视频存储器容量最高可达 16 GB

26
00:01:16,546 --> 0:01:18,636
这是多么强大的功能

27
00:01:18,636 --> 0:01:19,536
现在就掌握在大家的手中

28
00:01:20,386 --> 0:01:21,516
但我们并没有

29
00:01:21,516 --> 0:01:23,406
将服务限制在 iMac 上

30
00:01:24,166 --> 0:01:25,976
我们最近宣布

31
00:01:25,976 --> 0:01:28,456
扩展了图形处理器支持 这能让你

32
00:01:28,456 --> 0:01:30,816
将任何一台 Mac 变成强大的工作站

33
00:01:30,936 --> 0:01:34,376
它将赋予你超过

34
00:01:34,376 --> 0:01:35,116
10 倍更强大的

35
00:01:35,176 --> 0:01:36,376
处理能力

36
00:01:37,126 --> 0:01:37,886
我们做的还不止这些

37
00:01:39,106 --> 0:01:40,786
今天我们介绍的是

38
00:01:40,786 --> 0:01:43,276
HTC Vive 这款头戴式显示器

39
00:01:43,406 --> 0:01:44,406
的即插即用支持

40
00:01:45,196 --> 0:01:48,966
它有两块 1440x1600

41
00:01:48,966 --> 0:01:54,826
AMOLED 的屏幕和每英寸 615 像素

42
00:01:54,956 --> 0:01:58,366
和 Vive 相比

43
00:01:58,366 --> 0:02:01,516
分辨率提高了百分之 78

44
00:01:58,366 --> 0:02:01,516
分辨率提高了百分之 78

45
00:02:01,566 --> 0:02:03,616
像素密度提高了百分之 57

46
00:02:03,746 --> 0:02:06,676
更强大的屏幕

47
00:02:06,786 --> 0:02:09,086
为它的新前置双摄像头系统

48
00:02:09,186 --> 0:02:11,266
提供了支持

49
00:02:11,666 --> 0:02:13,526
这样 开发者们就可以

50
00:02:13,526 --> 0:02:14,886
用这些摄像头

51
00:02:14,956 --> 0:02:16,386
在 Mac 上

52
00:02:16,386 --> 0:02:18,036
尝试直通视频

53
00:02:18,236 --> 0:02:19,486
同时加上 Vive Pro 的支持

54
00:02:19,486 --> 0:02:21,966
就得到了更加先进的跟踪系统

55
00:02:23,456 --> 0:02:25,186
那么 你现在可能想知道如何

56
00:02:25,186 --> 0:02:26,426
在 macOS 上

57
00:02:26,426 --> 0:02:28,036
开始 VR App 的开发

58
00:02:28,906 --> 0:02:32,506
HTC Vive 和 Vive Pro

59
00:02:32,506 --> 0:02:34,526
同时能和 Valve 的

60
00:02:34,826 --> 0:02:37,456
SteamVR Runtime 一起运行 这能提供

61
00:02:37,456 --> 0:02:40,226
大量的服务 其中就包括 VR 生成器

62
00:02:40,676 --> 0:02:43,936
Valve 也能让开放的 VR

63
00:02:43,936 --> 0:02:46,016
框架运行于 macOS 上 

64
00:02:46,016 --> 0:02:49,576
这样你就能通过 SteamVR 建立地图

65
00:02:50,626 --> 0:02:54,876
我们一直和 Valve 以及 HTC 紧密合作

66
00:02:54,876 --> 0:02:57,516
确保 Vive Pro 在 macOS 上的

67
00:02:57,676 --> 0:03:00,356
SteamVR Runtime 中获得支持

68
00:02:57,676 --> 0:03:00,356
SteamVR Runtime 中获得支持

69
00:03:03,006 --> 0:03:04,796
那么 接下来我们来了解一下

70
00:03:04,796 --> 0:03:06,486
我们现在正在介绍的 Metal 新功能

71
00:03:06,486 --> 0:03:09,786
会如何开发 macOS Mojave 可以用来

72
00:03:09,786 --> 0:03:11,946
优化你的 VR App 的品质

73
00:03:12,036 --> 0:03:14,356
为了帮助大家回忆 让我们

74
00:03:15,086 --> 0:03:16,736
回顾一下当下

75
00:03:16,736 --> 0:03:18,786
App 和 VR 生成器之间的交互

76
00:03:18,896 --> 0:03:21,386
App 在启动时会

77
00:03:21,386 --> 0:03:23,106
将针对左眼和右眼的图像

78
00:03:23,106 --> 0:03:26,026
转换为 30 个多样本纹理

79
00:03:26,776 --> 0:03:28,306
然后它会将这些图像分解成

80
00:03:28,306 --> 0:03:30,556
iOS 表面背景纹理

81
00:03:30,726 --> 0:03:32,456
它可以进一步

82
00:03:32,456 --> 0:03:33,816
传递给 VR 生成器

83
00:03:33,816 --> 0:03:37,926
VR 生成器将会执行最终

84
00:03:37,986 --> 0:03:39,476
处理步骤

85
00:03:39,556 --> 0:03:42,446
其中包括镜头失真校正

86
00:03:42,446 --> 0:03:44,356
色差调整以及排序操作

87
00:03:44,986 --> 0:03:47,026
简单来说就是变形

88
00:03:48,426 --> 0:03:49,866
最终图像一旦生成

89
00:03:49,956 --> 0:03:52,066
就会被发送到

90
00:03:52,066 --> 0:03:53,846
头戴式设备或呈现的画面之中

91
00:03:54,936 --> 0:03:56,856
这里涉及的很多操作

92
00:03:56,916 --> 0:03:59,446
会发生两次 让我们来看一下

93
00:03:59,446 --> 0:04:02,456
你可不可以对此做些什么

94
00:03:59,446 --> 0:04:02,456
你可不可以对此做些什么

95
00:04:02,766 --> 0:04:04,126
看 如今有了 VR App 

96
00:04:04,126 --> 0:04:06,656
它想要从多样本中获益

97
00:04:07,236 --> 0:04:08,806
它需要针对每只眼睛使用

98
00:04:08,976 --> 0:04:12,016
专用纹理 或者都使用

99
00:04:12,016 --> 0:04:13,666
单一的共享纹理

100
00:04:13,716 --> 0:04:15,726
但是这些布局都并不完美

101
00:04:16,576 --> 0:04:18,386
专用纹理需要

102
00:04:18,386 --> 0:04:20,505
独立的绘图调用和通道

103
00:04:20,886 --> 0:04:21,846
这正如我们所见

104
00:04:23,166 --> 0:04:25,246
而直接纹理可以

105
00:04:25,246 --> 0:04:27,296
在单一渲染和结果通道中

106
00:04:27,656 --> 0:04:30,456
进行双眼的渲染

107
00:04:30,456 --> 0:04:32,206
这些纹理在

108
00:04:32,276 --> 0:04:34,196
后期处理和效果方面会产生一些问题

109
00:04:34,736 --> 0:04:36,986
对于分层纹理拥有

110
00:04:36,986 --> 0:04:38,956
专用纹理和共享布局

111
00:04:39,126 --> 0:04:41,556
的全部优势 但是

112
00:04:41,646 --> 0:04:44,056
当下它们不能和多重采样抗锯齿一起使用

113
00:04:45,816 --> 0:04:47,506
这促使 App 开发者们

114
00:04:47,566 --> 0:04:48,826
使用不同的渲染兼用布局

115
00:04:48,936 --> 0:04:50,876
具体取决于

116
00:04:51,096 --> 0:04:54,406
他们是否想使用多重采样抗锯齿

117
00:04:54,936 --> 0:04:57,646
或使用不同诀窍来解决这一问题

118
00:04:57,866 --> 0:04:59,416
那么我们就来看看 我们可以如何优化

119
00:04:59,466 --> 0:05:00,116
这一渲染

120
00:04:59,466 --> 0:05:00,116
这一渲染

121
00:05:02,166 --> 0:05:03,966
今天我们要介绍

122
00:05:04,056 --> 0:05:06,026
一个新的纹理

123
00:05:06,026 --> 0:05:07,396
2DMultisampleArray 纹理

124
00:05:08,366 --> 0:05:10,726
这一纹理类型拥有

125
00:05:10,726 --> 0:05:13,166
上述类型的所有优点

126
00:05:13,266 --> 0:05:15,336
而没有上述类型的任何缺点

127
00:05:15,476 --> 0:05:17,806
多亏有了它

128
00:05:17,806 --> 0:05:19,606
现在可以区分每一

129
00:05:19,606 --> 0:05:22,516
渲染空间

130
00:05:22,516 --> 0:05:24,696
这简化了后期处理

131
00:05:24,696 --> 0:05:28,286
效果 视图数

132
00:05:28,286 --> 0:05:30,016
这样 App 就可以

133
00:05:30,016 --> 0:05:33,536
轻松地返回单视场渲染

134
00:05:33,536 --> 0:05:35,406
并能控制抗锯齿模式

135
00:05:36,436 --> 0:05:38,786
作为结果 App 就能

136
00:05:38,786 --> 0:05:40,956
拥有单一渲染文件

137
00:05:40,956 --> 0:05:43,456
可以轻松运用于任何情形之中

138
00:05:43,556 --> 0:05:46,056
最重要的是

139
00:05:46,056 --> 0:05:48,206
在每种情景中 App 可以

140
00:05:48,206 --> 0:05:50,736
通过单一绘图和渲染通道

141
00:05:50,736 --> 0:05:51,056
被渲染

142
00:05:53,936 --> 0:05:55,686
那么这里我们可以看到

143
00:05:55,686 --> 0:05:57,916
创建上述 2DMultisampleArray

144
00:05:57,916 --> 0:05:59,126
纹理的代码片段

145
00:06:01,146 --> 0:06:03,446
我们将样本数设置为 4

146
00:06:03,446 --> 0:06:05,386
这样就能在质量和性能之间

147
00:06:05,426 --> 0:06:07,486
达到最佳平衡

148
00:06:07,486 --> 0:06:09,736
与此同时 我们将

149
00:06:09,826 --> 0:06:12,436
其他长度设置为 2 因为我们想

150
00:06:12,436 --> 0:06:16,346
将每只眼睛的图像存储为

151
00:06:16,446 --> 0:06:17,226
独立的切片

152
00:06:18,676 --> 0:06:21,776
那么让我们让来看看 管线会怎样

153
00:06:21,776 --> 0:06:22,376
发生变化

154
00:06:23,606 --> 0:06:25,126
我们现在可以将那些 2D

155
00:06:25,126 --> 0:06:27,396
多样本纹理用

156
00:06:27,396 --> 0:06:29,596
单一 2D 多样本阵列纹理

157
00:06:32,066 --> 0:06:32,156
纹理进行替换

158
00:06:33,136 --> 0:06:34,856
那么现在 App 就能

159
00:06:34,966 --> 0:06:38,396
在单一渲染通道进行双眼渲染

160
00:06:38,396 --> 0:06:40,686
而且如果它使用实例化

161
00:06:40,976 --> 0:06:42,356
它甚至可以在单一绘图代码中

162
00:06:42,356 --> 0:06:42,596
做到这一点

163
00:06:42,596 --> 0:06:45,606
这已经看起来很不错了

164
00:06:45,606 --> 0:06:47,266
但是我们仍然需要将那些

165
00:06:47,726 --> 0:06:49,976
2D 多样本阵列纹理切片

166
00:06:49,976 --> 0:06:52,346
变为独立的 iOS

167
00:06:52,406 --> 0:06:54,636
面部图像在我们将其传递到

168
00:06:54,636 --> 0:06:55,716
生成器之前

169
00:06:56,936 --> 0:06:59,156
那么让我们专注于我们自己的方式

170
00:06:59,156 --> 0:07:01,276
App 和生成器

171
00:06:59,156 --> 0:07:01,276
App 和生成器

172
00:07:01,306 --> 0:07:01,746
共享纹理

173
00:07:01,746 --> 0:07:04,676
那么现在 为了共享纹理

174
00:07:04,676 --> 0:07:05,826
我们使用 IOSurface

175
00:07:06,786 --> 0:07:08,316
它们在不同的进程空间

176
00:07:08,426 --> 0:07:10,086
和不同的图形处理器之间

177
00:07:10,796 --> 0:07:14,086
共享纹理 但是有着这样的

178
00:07:14,186 --> 0:07:15,466
灵活性会产生代价

179
00:07:16,436 --> 0:07:19,466
IOSurface 只可用于

180
00:07:19,466 --> 0:07:22,316
共享简单的 2D 纹理

181
00:07:22,316 --> 0:07:23,876
所以如果你有多样本纹理

182
00:07:24,266 --> 0:07:25,996
存储困难或者拥有

183
00:07:26,806 --> 0:07:27,736
复杂的纹理 它们不能被共享

184
00:07:29,046 --> 0:07:30,706
这就是为什么我们今天要介绍

185
00:07:30,706 --> 0:07:32,836
可共享的 Metal 纹理

186
00:07:32,836 --> 0:07:34,676
他们能让你的 App 

187
00:07:34,806 --> 0:07:36,486
在进程空间之间共享

188
00:07:36,796 --> 0:07:39,736
任意一种 Metal 纹理

189
00:07:39,836 --> 0:07:42,046
只要这些纹理位于

190
00:07:42,046 --> 0:07:43,106
单一图形处理器之中

191
00:07:43,996 --> 0:07:46,726
这个文件的特色是

192
00:07:46,856 --> 0:07:49,116
这些案例的高级视图

193
00:07:49,636 --> 0:07:51,956
例如 将场景的深度

194
00:07:52,036 --> 0:07:53,946
和 VR 生成器进行共享

195
00:07:54,486 --> 0:07:56,446
但是 当然并不仅限于此

196
00:07:57,256 --> 0:07:59,016
现在让我们看看如何

197
00:07:59,086 --> 0:08:00,236
来创建那些纹理

198
00:07:59,086 --> 0:08:00,236
来创建那些纹理

199
00:08:02,636 --> 0:08:03,906
因为可共享的纹理

200
00:08:03,996 --> 0:08:06,316
能让我们在进程之间

201
00:08:06,366 --> 0:08:08,296
传递复杂纹理 所以我们

202
00:08:08,296 --> 0:08:10,676
会创建 2D 阵列纹理

203
00:08:10,676 --> 0:08:12,936
我们会将其传递给 VR 生成器

204
00:08:13,216 --> 0:08:16,116
如你所见 我们为此

205
00:08:16,226 --> 0:08:18,126
使用了新方式

206
00:08:18,206 --> 0:08:19,426
用这个创建工具创建了新的共享纹理

207
00:08:19,976 --> 0:08:22,986
与此同时

208
00:08:23,056 --> 0:08:24,926
你必须记得使用

209
00:08:25,096 --> 0:08:27,036
Private 存储模式

210
00:08:27,036 --> 0:08:29,286
这一纹理仅能通过将其创建出来的

211
00:08:29,706 --> 0:08:33,126
图形处理器获得

212
00:08:33,876 --> 0:08:35,996
现在我们可以看到一个代码片段

213
00:08:36,456 --> 0:08:38,546
向我们展示了以前我们的 VR

214
00:08:38,546 --> 0:08:41,416
App 会如何将 IOSurface

215
00:08:41,556 --> 0:08:44,186
发送到 VR 生成器

216
00:08:44,186 --> 0:08:45,526
我们现在来看看这个代码片段

217
00:08:45,526 --> 0:08:47,656
看看需要做出哪些改变

218
00:08:47,746 --> 0:08:50,676
从而可以从使用 IOSurface 

219
00:08:50,676 --> 0:08:53,516
转变为共享的 Metal 纹理

220
00:08:54,976 --> 0:08:56,166
所以我们无须再使用这两个

221
00:08:56,166 --> 0:08:59,366
IOSurface 而且由它们

222
00:08:59,426 --> 0:09:01,006
支持的两种纹理

223
00:08:59,426 --> 0:09:01,006
支持的两种纹理

224
00:09:01,006 --> 0:09:03,256
现在可以被替换为

225
00:09:03,256 --> 0:09:05,686
单一可共享 Metal 纹理

226
00:09:05,976 --> 0:09:08,246
这就是目前的 2D 阵列纹理

227
00:09:09,236 --> 0:09:11,956
然后我们会将这一纹理分配给

228
00:09:12,146 --> 0:09:15,136
来自开放式 VRSDK

229
00:09:15,176 --> 0:09:19,116
的两个纹理描述器 并将它的类型

230
00:09:19,526 --> 0:09:21,416
从 IOSurface 改变为 Metal

231
00:09:21,526 --> 0:09:25,076
在完成这几项改变之后

232
00:09:25,836 --> 0:09:27,826
我们可以将针对

233
00:09:27,826 --> 0:09:31,606
左眼和右眼的图像 提交至生成器

234
00:09:32,346 --> 0:09:35,666
然后生成器就会知道 我们已经传递了

235
00:09:35,666 --> 0:09:37,446
拥有高级布局的 Metal 纹理

236
00:09:37,686 --> 0:09:40,366
而非 IOSurface 而且当我们

237
00:09:40,366 --> 0:09:42,526
查看的时候 如果它的类型是 2D 阵列纹理

238
00:09:42,856 --> 0:09:44,596
或者 2D 多样本阵列纹理

239
00:09:45,246 --> 0:09:47,336
如果是这样 那么生成器将

240
00:09:47,416 --> 0:09:49,736
自动认定

241
00:09:49,736 --> 0:09:51,546
对于左眼的图像存储于

242
00:09:51,546 --> 0:09:54,266
切片 0 之中 对于右眼的图像

243
00:09:54,266 --> 0:09:55,876
存储于 切片 1 之中

244
00:09:56,536 --> 0:09:57,916
这样你的 App 就无须

245
00:09:57,966 --> 0:09:59,396
再对此做任何其他操作

246
00:09:59,396 --> 0:10:03,326
当然 在 App

247
00:09:59,396 --> 0:10:03,326
当然 在 App

248
00:10:03,326 --> 0:10:05,266
和生成器之间

249
00:10:05,266 --> 0:10:06,806
共享 Metal

250
00:10:06,856 --> 0:10:08,636
并非是 Metal 纹理的唯一用法

251
00:10:09,436 --> 0:10:11,126
这里有几个简单的例子

252
00:10:11,126 --> 0:10:12,506
展现了你可以如何

253
00:10:12,506 --> 0:10:14,156
在任意两个进程之间

254
00:10:14,156 --> 0:10:14,956
传递 Metal 纹理

255
00:10:15,816 --> 0:10:17,766
那么我们完全按照同样的方式开始

256
00:10:18,046 --> 0:10:19,326
我们创建我们的可共享 Metal 纹理

257
00:10:19,326 --> 0:10:23,206
但如今我们从这一纹理中

258
00:10:23,286 --> 0:10:25,136
创建出了可以在

259
00:10:25,286 --> 0:10:27,456
进程空间之间传递的

260
00:10:27,456 --> 0:10:29,726
特殊共享纹理句柄

261
00:10:30,136 --> 0:10:31,176
可以通过跨进程

262
00:10:31,246 --> 0:10:32,556
通信连接

263
00:10:33,236 --> 0:10:36,056
一旦这一句柄被传递至

264
00:10:36,056 --> 0:10:39,306
其他进程 它就可以用于

265
00:10:39,306 --> 0:10:41,496
重新创建纹理对象

266
00:10:42,346 --> 0:10:44,906
但在做此的同时 你必须

267
00:10:45,006 --> 0:10:46,936
记得在与其他进程空间中

268
00:10:47,016 --> 0:10:49,096
进行创建时

269
00:10:49,096 --> 0:10:51,616
所使用的相同设备上

270
00:10:51,666 --> 0:10:53,326
重新创建你的纹理对象

271
00:10:53,896 --> 0:10:56,176
因为这一纹理不能脱离

272
00:10:56,176 --> 0:10:57,666
图形处理器的范围

273
00:10:58,266 --> 0:11:02,476
现在我们再回过来看我们的管线

274
00:10:58,266 --> 0:11:02,476
现在我们再回过来看我们的管线

275
00:11:02,716 --> 0:11:05,576
看看会发生什么变化

276
00:11:05,606 --> 0:11:07,806
现在 App 可以

277
00:11:07,806 --> 0:11:10,466
用一个 2D 阵列纹理

278
00:11:10,466 --> 0:11:13,096
替换那些分离的 IOSurface

279
00:11:13,096 --> 0:11:14,256
将针对双眼的图像存储起来

280
00:11:15,346 --> 0:11:17,406
这能够促成进一步的优化

281
00:11:18,026 --> 0:11:20,166
因为原始的 2D 多样本

282
00:11:20,166 --> 0:11:21,876
阵列纹理现在也可以

283
00:11:21,876 --> 0:11:24,236
在一个通道中加以解决

284
00:11:24,606 --> 0:11:25,906
只需通过阵列纹理

285
00:11:25,906 --> 0:11:26,736
将其创建成可共享的类型即可

286
00:11:27,706 --> 0:11:28,716
而且不止如此

287
00:11:29,486 --> 0:11:30,786
让我们来看一下生成器

288
00:11:32,286 --> 0:11:33,196
一旦我们在 App 上

289
00:11:33,196 --> 0:11:35,006
完成了渲染部件的简化

290
00:11:35,006 --> 0:11:36,596
就没有什么

291
00:11:36,716 --> 0:11:38,176
可以阻止生成器

292
00:11:38,406 --> 0:11:40,596
从这些新特性中获益

293
00:11:41,246 --> 0:11:45,056
所以生成器现在可以使用

294
00:11:45,126 --> 0:11:47,826
这些即将发布的 2D 阵列纹理

295
00:11:47,826 --> 0:11:50,086
并能在单一渲染通道中

296
00:11:50,086 --> 0:11:51,576
针对双眼执行操作

297
00:11:51,736 --> 0:11:54,836
正如你所见 我们刚刚完成了

298
00:11:54,836 --> 0:11:56,396
整条管线的简化

299
00:11:57,816 --> 0:11:59,246
那么让我们来总结一下

300
00:11:59,246 --> 0:11:59,766
我们刚刚了解到的内容

301
00:12:01,776 --> 0:12:03,266
我们刚刚描述了两种新的

302
00:12:03,266 --> 0:12:04,236
Metal 纹理

303
00:12:04,576 --> 0:12:07,846
可共享 Metal 纹理以及

304
00:12:07,846 --> 0:12:09,746
2D 多样本阵列纹理

305
00:12:09,746 --> 0:12:12,356
以及用他们来

306
00:12:12,406 --> 0:12:14,246
进一步优化你的渲染管线

307
00:12:14,326 --> 0:12:14,856
的方式

308
00:12:16,026 --> 0:12:17,406
这两种纹理马上就会

309
00:12:17,406 --> 0:12:19,326
在即将推出的 SteamVR

310
00:12:19,326 --> 0:12:20,836
Runtime 更新中获得支持

311
00:12:22,016 --> 0:12:23,686
那么现在让我们把注意力集中在

312
00:12:23,686 --> 0:12:25,166
那些可以将你 App 的

313
00:12:25,166 --> 0:12:27,376
中央处理器和图形处理器的使用

314
00:12:27,376 --> 0:12:28,736
最大化的技术之上

315
00:12:29,796 --> 0:12:32,276
这一部分我们会分为

316
00:12:32,366 --> 0:12:34,696
两个小节 先进的帧同步技术

317
00:12:34,696 --> 0:12:36,656
以及不断降低的空闲率

318
00:12:38,386 --> 0:12:40,436
我们先来讲讲帧同步技术

319
00:12:41,276 --> 0:12:43,426
在这一小节中

320
00:12:43,426 --> 0:12:45,446
我们将分析 App 的帧同步技术

321
00:12:45,536 --> 0:12:47,266
以及如何为了 VR 优化帧同步技术

322
00:12:48,306 --> 0:12:49,936
那么我们先从简单的

323
00:12:50,146 --> 0:12:52,096
单线程 App 入手

324
00:12:52,096 --> 0:12:53,646
它们在执行所有操作时都会

325
00:12:53,646 --> 0:12:54,476
采取串口监视的方式

326
00:12:55,406 --> 0:12:57,336
这样的 App 会通过调用 WaitGet 停顿

327
00:12:57,336 --> 0:12:59,816
开始处理其中的画面

328
00:13:00,866 --> 0:13:03,256
从而接收停顿

329
00:13:03,256 --> 0:13:05,866
并将其执行情况同步到

330
00:13:05,866 --> 0:13:07,256
头戴式设备的帧率之中

331
00:13:09,026 --> 0:13:11,506
Vive 和 Vive Pro 都拥有

332
00:13:11,506 --> 0:13:13,286
每秒 90 帧的刷新率

333
00:13:13,286 --> 0:13:14,936
这就意味着

334
00:13:14,986 --> 0:13:17,096
App 只需要 11.1

335
00:13:17,096 --> 0:13:19,316
毫秒就能处理一帧

336
00:13:20,086 --> 0:13:22,496
对比之下 眨一下眼

337
00:13:22,746 --> 0:13:24,756
大约需要 300 毫秒

338
00:13:25,536 --> 0:13:27,286
那么在这一时间里

339
00:13:27,286 --> 0:13:28,666
App 就能渲染 50 帧画面

340
00:13:30,326 --> 0:13:32,436
所以一旦 App 收到了

341
00:13:32,616 --> 0:13:34,736
来自 WaitGet 停顿的停顿

342
00:13:34,806 --> 0:13:37,636
它就能开始模拟你的试验

343
00:13:38,816 --> 0:13:39,886
一旦完成模拟

344
00:13:39,956 --> 0:13:41,676
也就知道了

345
00:13:41,676 --> 0:13:43,756
所有对象的状态

346
00:13:43,756 --> 0:13:46,076
App 就能继续对

347
00:13:46,206 --> 0:13:48,286
命令缓冲区进行编码

348
00:13:48,286 --> 0:13:50,386
然后将其发送至图形处理器 以实现执行目的

349
00:13:51,886 --> 0:13:54,786
一旦图形处理器完成操作

350
00:13:54,786 --> 0:13:57,416
针对双眼的图像 也就渲染完成了

351
00:13:57,416 --> 0:13:59,906
它可以被发送至 VR 生成器

352
00:13:59,906 --> 0:14:01,426
进行我们在前几张幻灯片中所讲的

353
00:13:59,906 --> 0:14:01,426
进行我们在前几张幻灯片中所讲的

354
00:14:01,516 --> 0:14:02,706
最终后期处理

355
00:14:02,706 --> 0:14:07,316
然后再从存储器中

356
00:14:07,646 --> 0:14:09,466
将各帧图像扫描到 头戴式设备的面板中

357
00:14:09,596 --> 0:14:12,266
这一传输需要额外的帧

358
00:14:12,266 --> 0:14:15,226
因为在呈现图像之前

359
00:14:15,376 --> 0:14:17,986
所有像素必须完成更新

360
00:14:19,296 --> 0:14:23,436
一旦所有像素完成更新

361
00:14:23,566 --> 0:14:25,686
头戴式设备的面板中和用户 可以看到

362
00:14:25,686 --> 0:14:26,106
一帧图像

363
00:14:27,246 --> 0:14:28,346
所以你可以看到

364
00:14:28,346 --> 0:14:29,846
从 App 收到停顿的那一刻起

365
00:14:29,926 --> 0:14:32,036
到图像真正投射出来

366
00:14:32,036 --> 0:14:35,896
的那一刻为止 一共历时 25 毫秒

367
00:14:35,976 --> 0:14:39,556
这就是为什么 App 要接收

368
00:14:39,686 --> 0:14:41,346
已经预测到

369
00:14:41,346 --> 0:14:43,296
会在未来发生的停顿

370
00:14:43,546 --> 0:14:45,116
到了发射光子的那一刻

371
00:14:45,116 --> 0:14:47,806
就可以使被渲染的

372
00:14:47,896 --> 0:14:49,946
图像可以和用户的停顿相匹配

373
00:14:50,066 --> 0:14:54,336
而这一连串

374
00:14:54,416 --> 0:14:56,046
与上一帧以及下一帧

375
00:14:56,046 --> 0:14:58,486
重叠的事件创建了我们的

376
00:14:58,516 --> 0:14:59,436
帧基础图

377
00:14:59,436 --> 0:15:02,096
如你所见

378
00:14:59,436 --> 0:15:02,096
如你所见

379
00:15:02,096 --> 0:15:04,966
在单线程 App 中 图形处理器

380
00:15:04,966 --> 0:15:06,446
在大部分时间中都是空闲的

381
00:15:07,826 --> 0:15:08,816
那就让我们来看看

382
00:15:08,816 --> 0:15:10,346
是否可以对此做些什么

383
00:15:11,776 --> 0:15:13,606
我们现在切换到了

384
00:15:13,606 --> 0:15:15,216
多线程 App

385
00:15:15,716 --> 0:15:17,746
它将视觉环境的模拟

386
00:15:17,776 --> 0:15:20,416
和针对图形处理器的编码操作

387
00:15:20,446 --> 0:15:22,656
分离开来

388
00:15:23,496 --> 0:15:24,996
对于这些操作的编码

389
00:15:24,996 --> 0:15:26,596
现在会在独立的

390
00:15:26,596 --> 0:15:27,356
渲染线程中进行

391
00:15:28,796 --> 0:15:29,766
因为我们已将模拟

392
00:15:29,866 --> 0:15:31,216
和编码分离开来

393
00:15:31,766 --> 0:15:33,596
所以对于帧的模拟

394
00:15:33,696 --> 0:15:36,786
可与图形处理器操作

395
00:15:36,786 --> 0:15:38,636
的上一帧编码

396
00:15:38,636 --> 0:15:39,336
同时进行

397
00:15:40,636 --> 0:15:43,316
这意味着编码现在

398
00:15:43,316 --> 0:15:45,746
已经在时间上发生了变化

399
00:15:45,796 --> 0:15:47,596
在我们收到预测的停顿之后

400
00:15:47,706 --> 0:15:48,656
编码会立即开始

401
00:15:49,216 --> 0:15:50,846
这意味着你的 App

402
00:15:50,846 --> 0:15:52,436
现在可以有更多时间

403
00:15:52,436 --> 0:15:54,736
对图形处理器进行编码

404
00:15:54,736 --> 0:15:56,666
并且图形处理器也可以有更多时间

405
00:15:56,746 --> 0:15:57,406
来处理它

406
00:15:57,406 --> 0:16:00,436
这样一来 你的 App 可以拥有更好的

407
00:15:57,406 --> 0:16:00,436
这样一来 你的 App 可以拥有更好的

408
00:16:00,436 --> 0:16:01,096
视觉化效果

409
00:16:02,856 --> 0:16:04,216
但这里有一点要注意

410
00:16:05,436 --> 0:16:07,386
因为现在模拟

411
00:16:07,386 --> 0:16:09,256
会在上一帧就开始

412
00:16:09,956 --> 0:16:12,196
所以需要独立的一组

413
00:16:12,286 --> 0:16:13,326
预测停顿

414
00:16:14,066 --> 0:16:16,586
这一组可以预测到

415
00:16:16,586 --> 0:16:18,956
未来的 56 毫秒

416
00:16:18,956 --> 0:16:20,276
这样就能和针对渲染线程

417
00:16:20,366 --> 0:16:21,886
进行预测的小组相匹配

418
00:16:22,416 --> 0:16:24,176
而且这两组会

419
00:16:24,206 --> 0:16:25,266
和发射光子的时刻相匹配

420
00:16:27,126 --> 0:16:28,646
这张图从中央处理器来看

421
00:16:28,646 --> 0:16:31,056
已经很不错了 正如我们所见

422
00:16:31,056 --> 0:16:32,276
App 在中央处理器中

423
00:16:32,276 --> 0:16:35,236
很好的分配了它的工作 但是

424
00:16:36,236 --> 0:16:37,566
让我们把重点放在图形处理器上

425
00:16:38,446 --> 0:16:43,596
如你所见 我们例子中的 App

426
00:16:43,596 --> 0:16:46,696
现在正在对所有这些图形处理器

427
00:16:46,696 --> 0:16:48,576
所有工作流程进行编码

428
00:16:48,746 --> 0:16:51,286
从而使一帧进入单一的公用缓冲区

429
00:16:51,286 --> 0:16:54,016
因此除非这一公用缓冲区已完成

430
00:16:54,016 --> 0:16:56,466
否则图形处理器就会

431
00:16:56,466 --> 0:16:57,316
处于空闲的等待状态

432
00:16:58,836 --> 0:17:00,306
不过 值得注意的是

433
00:16:58,836 --> 0:17:00,306
不过 值得注意的是

434
00:17:00,546 --> 0:17:02,676
在中央处理器上 对图形处理器的操作

435
00:17:02,676 --> 0:17:05,336
进行编码所花费的时间

436
00:17:05,586 --> 0:17:06,796
比在图形处理器上处理这些操作

437
00:17:06,796 --> 0:17:08,165
所花费的时间要少很多

438
00:17:08,986 --> 0:17:10,336
因此我们可以利用这一事实

439
00:17:10,336 --> 0:17:13,935
并将我们的编码操作

440
00:17:13,935 --> 0:17:15,656
分解成为几个公用缓冲区

441
00:17:15,656 --> 0:17:17,876
而几个公用缓冲区

442
00:17:17,876 --> 0:17:19,276
可以进行快速编码

443
00:17:19,276 --> 0:17:21,266
仅需几步操作而已

444
00:17:21,776 --> 0:17:23,715
并尽快将其提交至

445
00:17:23,786 --> 0:17:24,336
图形处理器

446
00:17:25,626 --> 0:17:30,426
这样一来 我们就能

447
00:17:30,486 --> 0:17:33,016
在图形处理器已经处理帧的同时

448
00:17:33,016 --> 0:17:34,626
进行我们的编码

449
00:17:35,086 --> 0:17:36,826
而且如你所见

450
00:17:36,826 --> 0:17:39,926
在图形处理器进行处理的时候

451
00:17:40,036 --> 0:17:43,456
我们延长了时间

452
00:17:43,456 --> 0:17:45,216
作为结果 这样进一步增加了

453
00:17:45,216 --> 0:17:46,706
你可以在一帧中提交的工作量

454
00:17:48,156 --> 0:17:49,226
现在让我们回到我们的图表

455
00:17:49,266 --> 0:17:50,826
看一下全部放在一起

456
00:17:50,826 --> 0:17:51,906
看起来会如何

457
00:17:53,446 --> 0:17:55,636
如你所见 现在中央处理器

458
00:17:55,636 --> 0:17:57,766
和图形处理器都被完全利用起来了

459
00:17:58,746 --> 0:18:00,056
那么这样的 App 已经

460
00:17:58,746 --> 0:18:00,056
那么这样的 App 已经

461
00:18:00,056 --> 0:18:01,846
为你的 App 提供了

462
00:18:01,846 --> 0:18:03,966
很好的示范

463
00:18:03,966 --> 0:18:05,446
但我们仍有提升的空间

464
00:18:07,196 --> 0:18:09,396
你可能会注意到

465
00:18:09,506 --> 0:18:11,626
在收到预测停顿之前

466
00:18:11,696 --> 0:18:13,786
当对任何种类的图形处理器 进行编码时

467
00:18:14,306 --> 0:18:16,876
渲染线程仍然处于等待状态

468
00:18:17,566 --> 0:18:19,186
但是并非一帧里的所有工作流程

469
00:18:19,186 --> 0:18:21,486
都需要这些停顿

470
00:18:22,536 --> 0:18:24,766
那么让我们进行更加细致的分析

471
00:18:24,886 --> 0:18:26,086
来选择帧的工作负荷

472
00:18:27,486 --> 0:18:29,956
在这里 你可以看到

473
00:18:30,006 --> 0:18:32,916
工作负荷列表 它们可能会在每一帧中被执行

474
00:18:34,056 --> 0:18:35,656
其中一部分在屏幕空间中进行

475
00:18:35,656 --> 0:18:37,696
或者需要了解

476
00:18:37,696 --> 0:18:39,766
与为了渲染帧所产生的停顿

477
00:18:39,766 --> 0:18:40,736
有关的总体信息

478
00:18:41,496 --> 0:18:42,726
我们将这样的工作负荷

479
00:18:42,846 --> 0:18:44,116
称为停顿依赖性工作负荷

480
00:18:44,986 --> 0:18:46,506
与此同时

481
00:18:46,506 --> 0:18:48,746
还有一般性的

482
00:18:48,746 --> 0:18:50,056
无需与停顿有关的信息

483
00:18:50,096 --> 0:18:51,996
就能立即执行的工作负荷

484
00:18:53,096 --> 0:18:54,886
我们将这些工作负荷称为

485
00:18:54,886 --> 0:18:55,886
非停顿依赖性工作负荷

486
00:18:56,496 --> 0:18:59,306
那么现在 我们的 App 

487
00:18:59,306 --> 0:19:01,346
正在等待停顿

488
00:18:59,306 --> 0:19:01,346
正在等待停顿

489
00:19:01,346 --> 0:19:02,996
以对图形处理器的任何工作进行编码

490
00:19:03,626 --> 0:19:05,336
但如果我们将这些工作负荷平分开来

491
00:19:05,336 --> 0:19:08,636
我们就能立即

492
00:19:08,636 --> 0:19:09,676
对非停顿依赖性工作负荷编码

493
00:19:09,766 --> 0:19:11,936
然后等待停顿

494
00:19:12,026 --> 0:19:15,156
以继续对停顿依赖性工作负荷编码

495
00:19:16,126 --> 0:19:19,456
在这张幻灯片中 我们已经

496
00:19:19,456 --> 0:19:21,076
将非停顿依赖性工作负荷

497
00:19:21,076 --> 0:19:23,006
与停顿依赖性工作负荷

498
00:19:23,036 --> 0:19:23,346
区分来开

499
00:19:24,516 --> 0:19:26,096
非停顿依赖性工作负荷

500
00:19:26,096 --> 0:19:27,346
现在已经在公用缓冲区

501
00:19:27,496 --> 0:19:29,096
被编码 如果将它和后面的停顿依赖性

502
00:19:29,446 --> 0:19:31,066
工作负荷比较的话

503
00:19:31,276 --> 0:19:32,746
它被标记地

504
00:19:32,746 --> 0:19:33,446
要更暗一些

505
00:19:34,336 --> 0:19:35,666
因为停顿依赖性工作负荷

506
00:19:35,666 --> 0:19:36,886
可以被立即编码

507
00:19:36,886 --> 0:19:39,146
所以我们就会

508
00:19:39,146 --> 0:19:39,376
采取如下操作

509
00:19:39,966 --> 0:19:41,526
我们会在

510
00:19:41,636 --> 0:19:42,796
上一帧工作负荷编码完成后

511
00:19:42,796 --> 0:19:43,286
立即对其编码

512
00:19:44,766 --> 0:19:46,866
这给了你的中央处理器更多时间

513
00:19:46,866 --> 0:19:49,246
以对图形处理器工作进行编码

514
00:19:49,416 --> 0:19:51,646
更重要的是 这确保了

515
00:19:51,646 --> 0:19:54,196
这一图形处理器工作

516
00:19:54,196 --> 0:19:56,556
已在图形处理器上等待被执行

517
00:19:56,556 --> 0:19:59,336
因此图形处理器就没有

518
00:19:59,336 --> 0:20:00,576
任何空闲时间

519
00:19:59,336 --> 0:20:00,576
任何空闲时间

520
00:20:00,636 --> 0:20:01,846
只要上一帧完成之后

521
00:20:01,846 --> 0:20:04,086
图形处理器就会立即开始

522
00:20:04,626 --> 0:20:06,766
下一帧处理

523
00:20:06,896 --> 0:20:09,376
最后一个小节就是

524
00:20:09,376 --> 0:20:11,306
多图形处理器工作负荷的分配

525
00:20:13,226 --> 0:20:15,666
我们可以在多个图形处理器之间

526
00:20:15,666 --> 0:20:16,386
分配工作负荷

527
00:20:16,386 --> 0:20:19,226
当前的 Mac Book Pro 目前共有两个图形处理器

528
00:20:19,306 --> 0:20:21,166
虽然它们具有

529
00:20:21,166 --> 0:20:22,056
不同的性能特点

530
00:20:22,116 --> 0:20:23,616
但是我们可以

531
00:20:23,616 --> 0:20:25,366
畅通无阻地使用它们

532
00:20:26,036 --> 0:20:27,926
类似地 如果每个图形处理器相互连接起来

533
00:20:27,986 --> 0:20:29,906
那么 App 就能用它

534
00:20:29,906 --> 0:20:31,756
对头戴式设备进行渲染

535
00:20:32,096 --> 0:20:34,866
并同时使用 Mac 的主图形处理器

536
00:20:34,896 --> 0:20:35,936
对一些工作进行分流

537
00:20:39,066 --> 0:20:40,516
所以我们将

538
00:20:40,666 --> 0:20:43,286
停顿依赖性工作分离出来

539
00:20:43,566 --> 0:20:45,256
并将它移动至次图形处理器上

540
00:20:45,796 --> 0:20:48,436
我们这样做是因为这些工作

541
00:20:48,436 --> 0:20:52,046
在很久之前的帧中就已经

542
00:20:52,046 --> 0:20:53,576
完成编码 而且现在

543
00:20:53,666 --> 0:20:55,866
停顿依赖性工作负荷

544
00:20:55,866 --> 0:20:57,516
在执行上一帧

545
00:20:57,616 --> 0:20:59,746
停顿依赖性工作负荷的同时 被执行

546
00:21:00,196 --> 0:21:01,706
因此 我们进一步

547
00:21:01,706 --> 0:21:03,596
增加了你在帧方面拥有的

548
00:21:03,676 --> 0:21:04,916
图形处理器时间量

549
00:21:07,546 --> 0:21:09,856
但是 通过将这一工作分给

550
00:21:09,856 --> 0:21:13,146
多个图形处理器 我们现在到达了

551
00:21:13,256 --> 0:21:14,926
这么一种情况 我们需要一种方式

552
00:21:14,926 --> 0:21:16,886
来将这些工作负荷

553
00:21:16,886 --> 0:21:17,446
同步起来

554
00:21:22,676 --> 0:21:24,426
所以我们今天要介绍新的

555
00:21:24,426 --> 0:21:26,006
同步参数

556
00:21:26,066 --> 0:21:28,086
来处理这样的情况

557
00:21:28,816 --> 0:21:31,196
MTL Event 现在可以用于

558
00:21:31,196 --> 0:21:33,616
在不同 Metal 线索之间

559
00:21:33,616 --> 0:21:35,566
同步单个图形处理器范围内的

560
00:21:35,626 --> 0:21:38,826
图形处理器工作 而 MTL Shared Event

561
00:21:39,276 --> 0:21:41,436
拓展了这一功能

562
00:21:41,436 --> 0:21:42,886
使其可以同步

563
00:21:42,886 --> 0:21:44,816
不同图形处理器之间

564
00:21:44,986 --> 0:21:46,796
甚至不同进程之间的工作负荷

565
00:21:49,136 --> 0:21:50,996
那么在这里 我们来看看这个

566
00:21:51,106 --> 0:21:52,426
简单的代码示例

567
00:21:53,546 --> 0:21:55,406
我们的 Mac 拥有

568
00:21:55,406 --> 0:21:57,486
外置图形处理器 它通过 Thunderbolt 3 接口

569
00:21:57,486 --> 0:21:58,166
进行连接

570
00:21:58,266 --> 0:22:00,936
这一外置图形处理器将成为我们的

571
00:21:58,266 --> 0:22:00,936
这一外置图形处理器将成为我们的

572
00:22:00,936 --> 0:22:04,396
主图形处理器 用于驱动头戴式设备

573
00:22:04,396 --> 0:22:06,576
这样我们就能使用 Mac 中

574
00:22:06,576 --> 0:22:08,676
已有的图形处理器作为辅助的

575
00:22:08,676 --> 0:22:09,136
次图形处理器

576
00:22:10,496 --> 0:22:12,766
然后我们会使用共享事件来

577
00:22:12,766 --> 0:22:16,896
同步两个图形处理器中的

578
00:22:18,486 --> 0:22:18,716
工作负荷

579
00:22:19,206 --> 0:22:21,816
事件的初始值为 0

580
00:22:21,816 --> 0:22:22,996
因此有必要

581
00:22:22,996 --> 0:22:25,526
从 1 开始启动同步计数器

582
00:22:26,176 --> 0:22:27,516
这是因为当我们

583
00:22:27,516 --> 0:22:30,096
在初始化事件中等待之时

584
00:22:30,276 --> 0:22:32,476
如果事件的计数器显示为 0

585
00:22:32,476 --> 0:22:34,696
事件就会立刻恢复原状

586
00:22:34,696 --> 0:22:35,976
所以就无法实现同步

587
00:22:37,786 --> 0:22:39,276
那么我们的渲染线程现在

588
00:22:39,276 --> 0:22:41,826
立即开始了针对辅助图形处理器

589
00:22:41,826 --> 0:22:43,836
的编码工作

590
00:22:44,536 --> 0:22:46,426
它会对停顿依赖性工作

591
00:22:46,426 --> 0:22:48,796
进行编码 这会发生在我们的

592
00:22:48,796 --> 0:22:50,996
次图形处理器上

593
00:22:51,026 --> 0:22:53,426
一旦这一工作完成

594
00:22:53,426 --> 0:22:55,496
结果将会存储在

595
00:22:55,646 --> 0:22:56,156
锁定存储器之中

596
00:22:56,796 --> 0:22:59,146
这就是为什么我们采用

597
00:22:59,146 --> 0:23:01,396
编码简单操作

598
00:22:59,146 --> 0:23:01,396
编码简单操作

599
00:23:01,396 --> 0:23:03,736
将这些结果传输到

600
00:23:03,736 --> 0:23:05,806
对两个图形处理器都可见

601
00:23:05,806 --> 0:23:06,676
的系统内存中

602
00:23:07,426 --> 0:23:08,786
一旦传输完成

603
00:23:08,786 --> 0:23:12,436
我们的次图形处理器就能

604
00:23:12,906 --> 0:23:15,216
安全地向我们的共享事件发出信号

605
00:23:15,866 --> 0:23:18,256
这一信号会告诉外置图形处理器

606
00:23:18,316 --> 0:23:20,236
现在接受这些结果是安全的

607
00:23:21,496 --> 0:23:23,536
所以我们的渲染线程

608
00:23:23,536 --> 0:23:24,576
执行这一些

609
00:23:24,576 --> 0:23:26,886
共用缓冲区 并且辅助图形处理器

610
00:23:26,916 --> 0:23:29,246
已经在处理这一工作

611
00:23:30,016 --> 0:23:32,336
与此同时 我们可以开始

612
00:23:32,336 --> 0:23:34,086
对驱动头戴式设备的

613
00:23:34,166 --> 0:23:36,486
主图形处理器的命令缓冲区进行编码

614
00:23:37,676 --> 0:23:39,356
在这一命令缓冲区中

615
00:23:39,356 --> 0:23:41,626
我们一开始会等待我们的

616
00:23:41,626 --> 0:23:43,446
共享事件 确保数据存储在

617
00:23:43,446 --> 0:23:45,516
在系统内存里

618
00:23:45,516 --> 0:23:47,426
只要它在那里  并且共享事件

619
00:23:47,426 --> 0:23:50,066
收到信号 那么我们可以执行一个

620
00:23:50,066 --> 0:23:51,306
简单操作

621
00:23:51,306 --> 0:23:52,516
它会通过 Thunderbolt 3 接口

622
00:23:52,516 --> 0:23:54,826
将这一数据传回

623
00:23:55,096 --> 0:23:57,856
我们的外部图形处理器中

624
00:23:57,956 --> 0:23:59,856
一旦传输完成

625
00:23:59,856 --> 0:24:01,936
执行停顿依赖性工作就会变得安全

626
00:23:59,856 --> 0:24:01,936
执行停顿依赖性工作就会变得安全

627
00:24:01,966 --> 0:24:05,246
因此第二个命令缓冲区

628
00:24:05,556 --> 0:24:08,206
就会发出封锁事件的信号

629
00:24:08,356 --> 0:24:10,166
让停顿依赖性工作知道

630
00:24:10,166 --> 0:24:11,546
它可以开始执行操作了

631
00:24:12,366 --> 0:24:14,346
在将这两个命令缓冲区

632
00:24:14,416 --> 0:24:15,776
编码并提交之后

633
00:24:16,386 --> 0:24:18,436
渲染线程可以向往常一样继续

634
00:24:18,436 --> 0:24:20,566
等待停顿

635
00:24:20,816 --> 0:24:21,826
并在之后

636
00:24:21,916 --> 0:24:26,076
对停顿依赖性工作进行编码

637
00:24:26,296 --> 0:24:28,296
那么现在我们就有了一个

638
00:24:28,296 --> 0:24:30,306
同步不同图形处理器间

639
00:24:30,306 --> 0:24:31,146
不同工作负荷的机制

640
00:24:31,146 --> 0:24:35,156
但是你可以看到

641
00:24:35,156 --> 0:24:37,426
我们的次图形处理器仍然

642
00:24:37,426 --> 0:24:38,176
有些空闲

643
00:24:38,226 --> 0:24:40,506
这是因为在这个例子里

644
00:24:40,926 --> 0:24:43,886
我们想要设法完成

645
00:24:44,316 --> 0:24:45,846
停顿依赖性工作负荷

646
00:24:45,846 --> 0:24:47,396
即那些拥有依赖于

647
00:24:47,396 --> 0:24:48,856
停顿依赖性的工作

648
00:24:49,346 --> 0:24:49,786
抱歉

649
00:24:50,796 --> 0:24:52,156
不过 当然也有一些

650
00:24:52,206 --> 0:24:53,396
工作负荷不具

651
00:24:53,396 --> 0:24:55,086
依赖性 它们可以

652
00:24:55,216 --> 0:24:57,496
在较低频率中发生

653
00:24:57,496 --> 0:24:58,806
也就是头戴式设备的频率

654
00:24:59,576 --> 0:25:01,076
这样的工作负荷

655
00:24:59,576 --> 0:25:01,076
这样的工作负荷

656
00:25:01,196 --> 0:25:03,456
比如可以是

657
00:25:03,456 --> 0:25:05,076
基于物理的精准

658
00:25:05,076 --> 0:25:07,076
异常值的模拟

659
00:25:07,766 --> 0:25:11,236
或者需要大量更新时间

660
00:25:11,976 --> 0:25:12,826
的任何东西

661
00:25:13,326 --> 0:25:15,846
这样的工作负荷可以发生在

662
00:25:15,846 --> 0:25:17,316
背景中 完全

663
00:25:17,316 --> 0:25:18,846
和渲染画面不同步

664
00:25:18,846 --> 0:25:20,596
而且在它每次

665
00:25:20,596 --> 0:25:23,336
准备完成后 它的结果就会被发送至

666
00:25:23,456 --> 0:25:24,536
主图形处理器

667
00:25:25,316 --> 0:25:27,296
这里灰色的标记

668
00:25:27,626 --> 0:25:28,996
是用来表示它

669
00:25:28,996 --> 0:25:31,036
和任何特定一帧无关

670
00:25:32,516 --> 0:25:33,616
那么 当然会有

671
00:25:33,616 --> 0:25:36,016
具有不同性能特点的

672
00:25:36,066 --> 0:25:38,086
不同图形处理器 而且

673
00:25:38,086 --> 0:25:38,976
它们会具有不同

674
00:25:38,976 --> 0:25:40,146
带宽的连接

675
00:25:40,606 --> 0:25:42,966
而且你的 App 将会

676
00:25:43,086 --> 0:25:44,976
在一帧中拥有不同的工作负荷

677
00:25:44,976 --> 0:25:47,876
它们之间分别具有不同的关系

678
00:25:48,986 --> 0:25:51,676
因此你需要设计出一种方式

679
00:25:51,786 --> 0:25:53,446
让你能分配这一工作负荷

680
00:25:53,446 --> 0:25:56,406
但是说了这么多

681
00:25:56,406 --> 0:25:58,166
开始考虑

682
00:25:58,166 --> 0:26:00,076
这一图形处理器工作负荷的分配

683
00:25:58,166 --> 0:26:00,076
这一图形处理器工作负荷的分配

684
00:26:00,116 --> 0:26:02,106
非常重要

685
00:26:02,106 --> 0:26:04,026
因为多图形处理器配置如今

686
00:26:04,136 --> 0:26:05,956
在 Apple 应用平台上十分常见

687
00:26:07,956 --> 0:26:10,266
那么让我们来总结一下

688
00:26:10,266 --> 0:26:11,326
我们在这一节中学到的

689
00:26:11,416 --> 0:26:11,866
所有内容

690
00:26:12,496 --> 0:26:13,426
我们展示了多线程 App

691
00:26:13,426 --> 0:26:15,986
来充分利用

692
00:26:16,076 --> 0:26:17,396
所有的中央处理器代码

693
00:26:17,466 --> 0:26:20,556
并分离了命令缓冲区

694
00:26:20,786 --> 0:26:22,666
确保图形处理器没有处于空闲状态

695
00:26:23,756 --> 0:26:25,776
在这一过程中 在可能的条件下

696
00:26:26,066 --> 0:26:26,916
我们尽量将

697
00:26:27,046 --> 0:26:28,396
非停顿依赖性工作负荷

698
00:26:28,466 --> 0:26:31,036
与停顿依赖性工作负荷划分开来

699
00:26:31,036 --> 0:26:32,946
从而尽快对这一工作进行编码

700
00:26:32,946 --> 0:26:35,746
除此之外

701
00:26:36,206 --> 0:26:38,086
我们还根据更新频率划分工作负荷

702
00:26:38,086 --> 0:26:41,126
所以如果你的 App

703
00:26:41,126 --> 0:26:42,586
会在多图形处理器配置下执行

704
00:26:42,586 --> 0:26:44,486
你可以轻松地

705
00:26:44,486 --> 0:26:47,576
在那些图形处理器中对其进行分配

706
00:26:48,126 --> 0:26:50,726
而且在这一过程中

707
00:26:51,136 --> 0:26:53,296
确保你驱动各个图形处理器时

708
00:26:53,296 --> 0:26:55,566
使用了独立的渲染线程

709
00:26:55,566 --> 0:26:57,446
从而确保它们在执行时

710
00:26:57,446 --> 0:26:58,206
是不同步的

711
00:26:59,116 --> 0:27:01,766
现在 你来到了降低填充率的部分

712
00:26:59,116 --> 0:27:01,766
现在 你来到了降低填充率的部分

713
00:27:03,186 --> 0:27:04,986
Vive Pro

714
00:27:05,046 --> 0:27:07,466
为 VR App 的开发者带来了新挑战

715
00:27:08,026 --> 0:27:09,516
为了更好地认识到

716
00:27:09,516 --> 0:27:11,186
问题的严重性 我们将比较

717
00:27:11,186 --> 0:27:12,676
不同的媒介填充率

718
00:27:12,676 --> 0:27:15,756
例如

719
00:27:15,756 --> 0:27:18,556
按默认缩放比例

720
00:27:18,616 --> 0:27:21,966
对 Vive 头戴式设备进行渲染的 App 

721
00:27:22,266 --> 0:27:27,776
每秒可产生 4.36 亿像素

722
00:27:27,776 --> 0:27:29,766
而对于目前便宜的高清屏幕相比于

723
00:27:30,236 --> 0:27:32,776
最先进驱动的屏幕

724
00:27:32,776 --> 0:27:39,546
拥有每秒 4.75 亿像素

725
00:27:39,606 --> 0:27:40,156
的填充率

726
00:27:40,916 --> 0:27:43,806
这些数据已经过于大了

727
00:27:44,136 --> 0:27:45,416
以至于游戏开发者

728
00:27:45,476 --> 0:27:47,486
做出了不同的改进 来降低这一填充率

729
00:27:48,246 --> 0:27:49,856
接下来让我们看看 Vive Pro

730
00:27:49,856 --> 0:27:51,226
在这些数据上的对比情况

731
00:27:53,046 --> 0:27:55,116
Vive Pro 拥有正常的填充率

732
00:27:55,116 --> 0:27:58,676
为每秒 7.75 亿像素

733
00:27:59,146 --> 0:28:00,826
如果你增加

734
00:27:59,146 --> 0:28:00,826
如果你增加

735
00:28:00,826 --> 0:28:02,976
4 倍多样本抗锯齿

736
00:28:03,206 --> 0:28:05,186
或者更大的缩放率

737
00:28:05,186 --> 0:28:06,486
这一数据就会变得更大

738
00:28:06,486 --> 0:28:09,786
这就是降低填充率

739
00:28:09,786 --> 0:28:11,206
为何如此重要

740
00:28:12,146 --> 0:28:13,406
现在已经有多种技术

741
00:28:13,406 --> 0:28:14,956
而且每一天都会

742
00:28:14,956 --> 0:28:15,826
产生新的技术

743
00:28:16,316 --> 0:28:19,046
所以我建议你们 把它们都尝试一遍

744
00:28:19,046 --> 0:28:22,106
但是今天我们

745
00:28:22,106 --> 0:28:24,506
只关注其中的一小部分 因为它们

746
00:28:24,506 --> 0:28:27,746
执行起来最为简单

747
00:28:27,746 --> 0:28:29,836
并能带来不错的性能提升

748
00:28:30,356 --> 0:28:31,986
那么我们先讲讲裁剪

749
00:28:31,986 --> 0:28:33,056
不可见的像素

750
00:28:33,946 --> 0:28:36,186
这里 你可以看到渲染的图像

751
00:28:36,186 --> 0:28:37,076
它针对的是左眼

752
00:28:38,526 --> 0:28:40,566
但是因为

753
00:28:40,566 --> 0:28:44,766
镜头的性质 大约 20% 的

754
00:28:44,896 --> 0:28:47,646
像素会在生成器

755
00:28:47,726 --> 0:28:50,156
执行失真校正后丢失

756
00:28:50,786 --> 0:28:52,166
在右侧 你可以看到

757
00:28:52,216 --> 0:28:53,796
将在通过镜头之前

758
00:28:53,796 --> 0:28:55,746
展示在头戴式设备面板上

759
00:28:55,746 --> 0:28:56,706
的图像

760
00:28:58,746 --> 0:29:00,896
所以 最简单的

761
00:28:58,746 --> 0:29:00,896
所以 最简单的

762
00:29:00,896 --> 0:29:03,836
降低填充率的方式就是防止我们的

763
00:29:03,836 --> 0:29:05,426
App 渲染那些

764
00:29:05,486 --> 0:29:07,066
完全不可见的像素

765
00:29:07,066 --> 0:29:09,616
你可以

766
00:29:09,616 --> 0:29:12,176
通过使用 SteamVR Stencil Mask

767
00:29:12,176 --> 0:29:12,946
轻松实现

768
00:29:14,416 --> 0:29:18,836
那么我们刚刚降低了百分之 20 的

769
00:29:18,836 --> 0:29:20,406
填充率 借助了这一

770
00:29:20,406 --> 0:29:22,626
简单的遮罩 并将我们 Vive

771
00:29:22,966 --> 0:29:26,806
Pro 的填充率降至 6.2 亿像素

772
00:29:29,286 --> 0:29:32,236
现在我们来分析一下

773
00:29:32,276 --> 0:29:33,776
执行这一镜头失真校正

774
00:29:33,776 --> 0:29:35,326
的更多细节

775
00:29:36,336 --> 0:29:40,836
我们可以将我们的视场

776
00:29:40,836 --> 0:29:42,936
分为九个区域

777
00:29:43,886 --> 0:29:45,986
中心区域的视野

778
00:29:45,986 --> 0:29:48,396
水平为 80 度

779
00:29:48,456 --> 0:29:51,276
垂直为 80 度

780
00:29:51,276 --> 0:29:53,206
周围区域

781
00:29:53,266 --> 0:29:54,396
位于边缘和角落里

782
00:29:55,306 --> 0:29:57,596
我们为它们上了色

783
00:29:57,596 --> 0:29:58,956
从而可以更好地看到

784
00:29:58,956 --> 0:30:00,726
它们对最终图像的影响

785
00:29:58,956 --> 0:30:00,726
它们对最终图像的影响

786
00:30:01,306 --> 0:30:05,196
正如你所见

787
00:30:05,196 --> 0:30:08,236
角落几乎完全不可见

788
00:30:08,506 --> 0:30:11,786
和原来的相比

789
00:30:11,786 --> 0:30:13,596
边缘对图像的影响

790
00:30:13,626 --> 0:30:14,696
会更小

791
00:30:15,486 --> 0:30:17,996
事实上 如果你

792
00:30:17,996 --> 0:30:19,996
在头戴式设备中看这幅图像

793
00:30:20,066 --> 0:30:22,616
你是无法直接看到红色

794
00:30:22,726 --> 0:30:23,346
区域的

795
00:30:24,126 --> 0:30:25,846
可以看到这些图像的唯一方式

796
00:30:25,846 --> 0:30:27,366
就是使用你的周边视觉

797
00:30:28,886 --> 0:30:31,666
这就给了我们很大的启发

798
00:30:33,306 --> 0:30:35,186
我们可以通过较低的填充率

799
00:30:35,236 --> 0:30:37,626
渲染这些边角区域

800
00:30:37,626 --> 0:30:40,086
因为不管怎么说

801
00:30:40,086 --> 0:30:41,046
它们几乎不可见

802
00:30:42,276 --> 0:30:45,056
我们渲染了中心区域

803
00:30:45,056 --> 0:30:45,956
如同之前一样

804
00:30:47,296 --> 0:30:49,046
但之后在渲染垂直边缘时

805
00:30:49,046 --> 0:30:51,856
我们会将宽度减半

806
00:30:51,906 --> 0:30:53,946
对于水平区域

807
00:30:53,976 --> 0:30:54,686
则将高度减半

808
00:30:54,686 --> 0:30:56,966
最后 在渲染角落区域时

809
00:30:57,026 --> 0:31:00,306
我们会将分辨率降至

810
00:30:57,026 --> 0:31:00,306
我们会将分辨率降至

811
00:31:00,306 --> 0:31:01,066
四分之一

812
00:31:03,076 --> 0:31:05,166
当我们完成昂贵的

813
00:31:05,246 --> 0:31:06,976
渲染通道之后 我们会

814
00:31:06,976 --> 0:31:09,606
执行廉价的放大通道

815
00:31:09,606 --> 0:31:11,416
让这些区域

816
00:31:11,646 --> 0:31:13,276
拉伸至

817
00:31:13,276 --> 0:31:15,356
需要提交给生成器的分辨率

818
00:31:16,386 --> 0:31:18,186
那么你可能会好奇

819
00:31:18,226 --> 0:31:20,166
这样我们可以获得多少提升

820
00:31:21,316 --> 0:31:23,576
对于 80x80 度

821
00:31:23,576 --> 0:31:25,546
的中央区域 我们将我们的

822
00:31:25,546 --> 0:31:27,556
填充率一下子降到了

823
00:31:27,556 --> 0:31:30,586
每秒 4.91 亿像素

824
00:31:31,736 --> 0:31:32,936
但是你应该记得我们刚刚

825
00:31:32,996 --> 0:31:34,666
提到了裁剪不可见像素

826
00:31:34,666 --> 0:31:36,866
所以让我们

827
00:31:36,946 --> 0:31:38,036
将这两个技术结合起来

828
00:31:40,016 --> 0:31:42,456
通过将像素裁剪

829
00:31:42,456 --> 0:31:44,016
和多分辨率变化结合起来

830
00:31:44,016 --> 0:31:45,696
你甚至可以进一步将填充率

831
00:31:45,696 --> 0:31:48,796
降至每秒 4.56 亿像素

832
00:31:48,796 --> 0:31:50,996
这并不是一个随机数字

833
00:31:51,696 --> 0:31:54,196
事实上这是

834
00:31:54,196 --> 0:31:57,456
Vive 头戴式设备的默认填充率

835
00:31:57,456 --> 0:31:59,176
所以仅仅通过使用这两项优化技术

836
00:31:59,176 --> 0:32:01,246
你的 App 就可以

837
00:31:59,176 --> 0:32:01,246
你的 App 就可以

838
00:32:01,246 --> 0:32:03,536
使用与渲染 Vive 头戴式设备时

839
00:32:03,536 --> 0:32:05,796
所使用的相同图形处理器

840
00:32:05,796 --> 0:32:08,386
而得到更高的分辨率

841
00:32:08,386 --> 0:32:09,796
对 Vive Pro 进行渲染

842
00:32:10,816 --> 0:32:12,486
当然 你也可以

843
00:32:12,556 --> 0:32:13,626
在对 Vive 进行渲染时

844
00:32:13,626 --> 0:32:15,346
使用这些技术

845
00:32:15,346 --> 0:32:17,306
这能让你 App 的视觉化效果

846
00:32:17,566 --> 0:32:19,386
更加突出

847
00:32:20,106 --> 0:32:21,046
更加美观

848
00:32:21,626 --> 0:32:25,306
这里要提醒一下

849
00:32:25,676 --> 0:32:27,166
多分辨率变化

850
00:32:27,296 --> 0:32:30,356
需要一些新的渲染通道

851
00:32:30,356 --> 0:32:34,006
所以它会在几何管线上

852
00:32:34,126 --> 0:32:36,356
增加你的工作负荷

853
00:32:36,356 --> 0:32:38,466
但你可以轻松缓解这一问题

854
00:32:38,516 --> 0:32:39,996
只需将你的中心区域

855
00:32:39,996 --> 0:32:41,746
降低几度

856
00:32:42,556 --> 0:32:44,036
这里 仅将我们的中心视野

857
00:32:44,036 --> 0:32:45,996
降低了 10 度

858
00:32:46,486 --> 0:32:48,026
我们就将填充率一下子降低到了

859
00:32:48,026 --> 0:32:50,826
每秒 3.82 亿像素

860
00:32:51,546 --> 0:32:53,956
而且如果你的几何图形的工作负荷

861
00:32:53,956 --> 0:32:56,606
非常高 你可以更进一步

862
00:32:56,696 --> 0:32:59,146
尝试更低的填充率

863
00:32:59,146 --> 0:33:02,116
更低的区域

864
00:32:59,146 --> 0:33:02,116
更低的区域

865
00:33:02,446 --> 0:33:03,966
这会将填充率降得更低

866
00:33:04,846 --> 0:33:07,206
对于 55x55 度的

867
00:33:07,206 --> 0:33:10,446
中心区域 你百分之 80 的

868
00:33:11,266 --> 0:33:12,536
眼部动作仍然会

869
00:33:12,536 --> 0:33:15,546
位于这一区域之中 但是

870
00:33:15,546 --> 0:33:17,426
我们将我们的填充率

871
00:33:17,426 --> 0:33:20,016
减少了一大半

872
00:33:20,146 --> 0:33:23,476
降至每秒 3.6 亿像素

873
00:33:23,696 --> 0:33:25,116
当然 还有其他

874
00:33:25,116 --> 0:33:26,316
方法可以实现

875
00:33:26,366 --> 0:33:29,446
多分辨率变化

876
00:33:30,466 --> 0:33:32,326
而且你会从中获得

877
00:33:32,416 --> 0:33:34,626
不同的性能提升

878
00:33:34,816 --> 0:33:36,366
所以我建议大家

879
00:33:36,366 --> 0:33:37,966
尝试这一技术

880
00:33:38,006 --> 0:33:39,446
看看什么最适合你

881
00:33:41,546 --> 0:33:42,926
下面让我们来总结一下

882
00:33:42,926 --> 0:33:46,986
我们在本次会议中 学到的所有内容

883
00:33:47,086 --> 0:33:48,676
我们刚刚公布了针对 Vive Pro 头戴式设备

884
00:33:48,716 --> 0:33:50,446
的即插即用支持

885
00:33:50,486 --> 0:33:53,526
并且介绍了

886
00:33:53,526 --> 0:33:55,256
Metal 2 的新特性 它们能使你

887
00:33:55,256 --> 0:33:57,306
开发更多的

888
00:33:57,306 --> 0:33:58,916
先进的 VR App

889
00:33:59,726 --> 0:34:01,486
然后我建议大家

890
00:33:59,726 --> 0:34:01,486
然后我建议大家

891
00:34:01,486 --> 0:34:03,246
利用多图形处理器配置

892
00:34:03,246 --> 0:34:05,006
因为它们现在

893
00:34:05,006 --> 0:34:07,416
在 Apple 平台上变得越来越常见

894
00:34:08,076 --> 0:34:12,136
你可以通过这个链接

895
00:34:12,136 --> 0:34:14,106
了解有关本次会议的更多内容

896
00:34:14,106 --> 0:34:16,335
我想邀请大家

897
00:34:16,525 --> 0:34:17,606
在 Metal 4 VR 实验室里

898
00:34:17,606 --> 0:34:19,616
和我以及我的同事见面

899
00:34:19,616 --> 0:34:21,766
时间就定在今天

900
00:34:21,766 --> 0:34:24,136
中午 12 点 地点在 6 号

901
00:34:24,136 --> 0:34:24,536
科技实验室

902
00:34:24,626 --> 0:34:26,976
非常感谢大家

903
00:34:27,516 --> 0:34:30,500
[ 掌声 ]
