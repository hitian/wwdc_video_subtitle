1
00:00:17,017 --> 0:00:22,923
（Core ML新特性

2
00:00:27,261 --> 0:00:28,161
早上好

3
00:00:28,762 --> 0:00:29,596
欢迎大家

4
00:00:29,930 --> 0:00:32,131
我是Michael

5
00:00:32,198 --> 0:00:33,967
Core ML中的新特性

6
00:00:35,569 --> 0:00:40,707
一年前推出的Core ML

7
00:00:40,774 --> 0:00:44,044
将机器学习模型整合到app中的过程

8
00:00:45,312 --> 0:00:48,415
看到它在过去一年能被广泛使用

9
00:00:49,883 --> 0:00:52,152
我们希望它让能所有人思考

10
00:00:52,219 --> 0:00:57,791
如果你的app有能力做到以下这些

11
00:00:57,858 --> 0:01:00,894
比如理解图片的内容

12
00:00:57,858 --> 0:01:00,894
比如理解图片的内容

13
00:01:02,629 --> 0:01:06,099
或者分析一些文本

14
00:01:06,166 --> 0:01:08,635
（Cate 你的工作很优秀

15
00:01:08,702 --> 0:01:13,740
如果你的app可以理解音频或音乐

16
00:01:15,242 --> 0:01:18,579
或根据用户的动作解释用户的行为

17
00:01:19,913 --> 0:01:23,083
甚至可以对其转换或生成新的内容

18
00:01:24,384 --> 0:01:28,455
所有这些 以及更多其它的功能

19
00:01:28,989 --> 0:01:31,225
这是因为这种类型的功能

20
00:01:31,458 --> 0:01:33,460
都可在Core ML模型中编码

21
00:01:35,095 --> 0:01:37,431
现在 如果我们窥视其内部

22
00:01:37,998 --> 0:01:39,733
我们可能会找到一个神经网络

23
00:01:40,067 --> 0:01:42,503
集成树或其他的模型体系结构

24
00:01:43,637 --> 0:01:45,873
它们可能有数百万个参数

25
00:01:45,939 --> 0:01:48,809
其值是从大量的数据中学习到的

26
00:01:50,544 --> 0:01:53,580
但是对于你来说

27
00:01:54,281 --> 0:01:57,317
你可以专注于它提供的功能

28
00:01:57,384 --> 0:02:01,455
及其带来的体验

29
00:01:57,384 --> 0:02:01,455
及其带来的体验

30
00:02:04,758 --> 0:02:06,894
将Core ML模型添加到

31
00:02:06,960 --> 0:02:09,896
只需将该文件添加到

32
00:02:11,131 --> 0:02:14,968
Xcode会显示一个简单的视图

33
00:02:15,035 --> 0:02:18,939
根据其输入及输出来描述它的功能

34
00:02:20,073 --> 0:02:23,544
Xcode还能更进一步

35
00:02:24,811 --> 0:02:27,748
这样只需几行代码就可以

36
00:02:28,782 --> 0:02:30,250
一行用来加载模型

37
00:02:31,318 --> 0:02:32,586
一行进行预测

38
00:02:33,687 --> 0:02:36,857
有时可以再加一行代码

39
00:02:37,991 --> 0:02:40,694
注意在某些情况下

40
00:02:40,761 --> 0:02:43,764
因为Core ML与我们的一些

41
00:02:43,830 --> 0:02:47,434
若你为它们提供Core ML模型

42
00:02:48,101 --> 0:02:51,839
在Vision中 这通过

43
00:02:51,905 --> 0:02:53,574
新Natural Language框架中

44
00:02:53,640 --> 0:02:56,677
你可以从Core ML模型中

45
00:02:59,513 --> 0:03:01,014
这即Core ML的简介

46
00:02:59,513 --> 0:03:01,014
这即Core ML的简介

47
00:03:01,615 --> 0:03:03,183
但我们这次要谈论有何新鲜东西

48
00:03:04,284 --> 0:03:07,788
我们在过去的一年中

49
00:03:07,855 --> 0:03:11,124
并在Core ML 2中

50
00:03:12,626 --> 0:03:15,028
我们将分两次演讲讨论这些问题

51
00:03:15,696 --> 0:03:17,965
在第一次演讲中

52
00:03:18,031 --> 0:03:21,001
我们将从你的app的角度

53
00:03:21,835 --> 0:03:24,471
在第二个演讲中

54
00:03:24,538 --> 0:03:26,640
在上午10点开始的那个演讲

55
00:03:27,674 --> 0:03:29,109
我们将讨论一些工具

56
00:03:29,176 --> 0:03:31,378
以及如何更新和转换模型

57
00:03:31,445 --> 0:03:33,747
来充分利用

58
00:03:36,884 --> 0:03:39,987
当涉及到你的app时

59
00:03:40,687 --> 0:03:45,726
首先是你如何在

60
00:03:45,792 --> 0:03:47,694
减小app中模型的大小和数量

61
00:03:48,862 --> 0:03:52,533
然后 我们将看看

62
00:03:54,101 --> 0:03:56,670
接着我们将总结

63
00:03:56,737 --> 0:03:58,906
可以让你跟上发展迅速的

64
00:03:58,972 --> 0:04:01,341
机器学习领域的最新进展

65
00:03:58,972 --> 0:04:01,341
机器学习领域的最新进展

66
00:04:02,276 --> 0:04:04,511
我们首先从讨论模型大小开始

67
00:04:04,578 --> 0:04:06,146
我将把这个话题

68
00:04:10,450 --> 0:04:11,351
谢谢Michael

69
00:04:12,753 --> 0:04:13,587
大家好

70
00:04:14,254 --> 0:04:18,091
任何减小Core ML

71
00:04:18,591 --> 0:04:20,459
我是Francesco

72
00:04:20,527 --> 0:04:22,362
量化和弹性形状

73
00:04:22,963 --> 0:04:26,366
它们是在Core ML 2中

74
00:04:28,235 --> 0:04:29,203
所以…

75
00:04:29,269 --> 0:04:31,872
Core ML是一种在设备上

76
00:04:33,607 --> 0:04:37,144
与在云中运行app相比

77
00:04:37,711 --> 0:04:38,545
首先

78
00:04:38,912 --> 0:04:40,480
用户隐私得到充分尊重

79
00:04:41,048 --> 0:04:43,116
通过在设备上运行机器学习模型

80
00:04:43,851 --> 0:04:46,854
我们保证数据

81
00:04:47,988 --> 0:04:50,824
其次 它可以帮助你实现实时性能

82
00:04:52,025 --> 0:04:56,196
Apple设备对运行

83
00:04:57,097 --> 0:05:00,434
此外 你不必维护互联网服务器

84
00:04:57,097 --> 0:05:00,434
此外 你不必维护互联网服务器

85
00:05:01,335 --> 0:05:05,005
最后 Core ML的推理过程

86
00:05:05,539 --> 0:05:07,241
而不需考虑连接问题

87
00:05:07,941 --> 0:05:09,843
所有这些好处都伴随着这个事实

88
00:05:10,077 --> 0:05:13,180
即你现在需要将机器学习模型

89
00:05:14,014 --> 0:05:17,751
如果机器学习模型很大

90
00:05:17,818 --> 0:05:19,119
你的app的大小

91
00:05:19,786 --> 0:05:24,024
假设你有一个很棒的app

92
00:05:24,391 --> 0:05:26,393
你的用户非常喜欢这个app

93
00:05:26,860 --> 0:05:29,630
现在你想利用设备上的机器学习

94
00:05:29,696 --> 0:05:31,999
所提供的新机会

95
00:05:32,065 --> 0:05:34,368
来为你的app添加超酷的新功能

96
00:05:34,902 --> 0:05:37,437
那么你怎么做呢

97
00:05:37,504 --> 0:05:38,772
然后将它们添加到你的app中

98
00:05:39,773 --> 0:05:42,309
这意味着 你的app变得更棒了

99
00:05:42,376 --> 0:05:43,977
并且你的用户也更加开心

100
00:05:45,145 --> 0:05:46,680
但其中一些用户可能会注意到

101
00:05:47,014 --> 0:05:49,349
你的app大小有所增加

102
00:05:49,917 --> 0:05:52,152
app在添加机器学习能力之后

103
00:05:52,219 --> 0:05:54,621
变大数十或数百兆字节

104
00:05:54,688 --> 0:05:56,290
并不罕见

105
00:05:57,491 --> 0:06:00,127
随着你不断向app

106
00:05:57,491 --> 0:06:00,127
随着你不断向app

107
00:06:00,928 --> 0:06:03,363
你的app大小可能会失控

108
00:06:04,665 --> 0:06:06,667
如果这些机器学习模型

109
00:06:06,967 --> 0:06:09,069
正在支持你的app的某些附加功能

110
00:06:09,136 --> 0:06:11,004
你首先可以做的是

111
00:06:11,638 --> 0:06:14,074
就是将它们保存在

112
00:06:15,242 --> 0:06:17,878
然后当用户使用这些附加功能时

113
00:06:17,945 --> 0:06:21,114
你可以根据需要下载它们

114
00:06:21,782 --> 0:06:24,284
因此在这种情况下

115
00:06:24,351 --> 0:06:26,887
因为安装大小不变

116
00:06:27,221 --> 0:06:31,191
但由于用户在你的app中下载

117
00:06:31,959 --> 0:06:35,295
最终你的app大小仍然很大

118
00:06:36,230 --> 0:06:38,732
那么如果我们采用另一种方法

119
00:06:39,900 --> 0:06:41,368
即缩小模型大小本身

120
00:06:42,469 --> 0:06:44,605
这不是更好吗？

121
00:06:46,306 --> 0:06:50,010
如果我们在app内部自带模型

122
00:06:51,311 --> 0:06:52,980
而如果我们按需下载模型

123
00:06:53,480 --> 0:06:56,183
这可以带来更快 更小的下载文件

124
00:06:57,084 --> 0:07:00,587
无论如何 你的app将有

125
00:06:57,084 --> 0:07:00,587
无论如何 你的app将有

126
00:07:00,654 --> 0:07:03,891
使用较少的存储空间

127
00:07:03,957 --> 0:07:05,659
也对整个系统大有所益

128
00:07:06,927 --> 0:07:09,863
所以让我们看看如何将

129
00:07:09,930 --> 0:07:11,932
分解成更小的因素

130
00:07:13,367 --> 0:07:14,801
首先是模型的数量

131
00:07:14,868 --> 0:07:18,672
这取决于你的app

132
00:07:19,139 --> 0:07:20,707
然后是权重的数量

133
00:07:21,441 --> 0:07:24,411
权重的数量取决于

134
00:07:24,478 --> 0:07:25,846
你所选择的体系结构

135
00:07:26,513 --> 0:07:27,814
如Michael提到的

136
00:07:28,882 --> 0:07:32,352
权重是机器学习模型存储

137
00:07:32,719 --> 0:07:35,689
它在训练期间所学习的信息的地方

138
00:07:36,290 --> 0:07:40,661
因此如果它被训练

139
00:07:40,727 --> 0:07:43,864
这样的一个模型需要数千万个权重

140
00:07:45,499 --> 0:07:47,167
最后是每个权重的大小

141
00:07:47,367 --> 0:07:50,704
我们如何存储我们在训练期间

142
00:07:51,738 --> 0:07:53,240
我们首先关注这个因素

143
00:07:54,441 --> 0:07:56,510
对于神经网络 我们有几种选择

144
00:07:56,577 --> 0:07:58,245
来表示和存储权重

145
00:07:59,947 --> 0:08:02,649
在iOS 11的

146
00:07:59,947 --> 0:08:02,649
在iOS 11的

147
00:08:03,450 --> 0:08:07,955
神经网络使用浮点32位权重存储

148
00:08:09,923 --> 0:08:12,893
在iOS 11.2中

149
00:08:12,960 --> 0:08:16,396
并且引入了半精度浮点16位权重

150
00:08:16,630 --> 0:08:21,735
这在为app提供相同准确度的基础上

151
00:08:22,236 --> 0:08:24,938
但今年 我们想更进一步

152
00:08:25,472 --> 0:08:27,574
我们推出了量化权重

153
00:08:28,575 --> 0:08:30,611
通过使用量化权重

154
00:08:30,677 --> 0:08:33,981
只能使用浮点32位或浮点16位值

155
00:08:34,047 --> 0:08:37,951
神经网络可以使用8位 4位

156
00:08:38,452 --> 0:08:40,621
一直到1位来进行编码

157
00:08:42,188 --> 0:08:45,325
现在我们来看看这里的量化是什么

158
00:08:46,360 --> 0:08:50,097
这里我们想要表示我们的

159
00:08:50,497 --> 0:08:54,635
正如我们所看到的

160
00:08:55,502 --> 0:08:58,038
这意味着在理论上

161
00:08:58,105 --> 0:09:00,641
每个权重的取值具有无限可能

162
00:08:58,105 --> 0:09:00,641
每个权重的取值具有无限可能

163
00:09:01,041 --> 0:09:07,681
因此在神经网络中

164
00:09:08,048 --> 0:09:10,784
这意味着这个权重

165
00:09:10,851 --> 0:09:14,087
以更好地表现它们的连续性

166
00:09:14,555 --> 0:09:18,926
但事实上神经网络也可以

167
00:09:19,927 --> 0:09:24,064
量化是将不连续值的取值限制在

168
00:09:24,464 --> 0:09:30,704
这个子集非常小并且离散

169
00:09:31,171 --> 0:09:35,342
例如 这里的量化过程

170
00:09:36,310 --> 0:09:39,213
只有256个可能取值的子集

171
00:09:39,546 --> 0:09:43,016
所以在量化之前

172
00:09:43,350 --> 0:09:46,987
量化后 它们只有256种可能取值

173
00:09:47,955 --> 0:09:51,692
现在 由于它的权重可以

174
00:09:52,559 --> 0:09:55,796
因此Core ML现在只需要8位

175
00:09:56,830 --> 0:10:00,267
但还不止如此 我们可以走得更远

176
00:09:56,830 --> 0:10:00,267
但还不止如此 我们可以走得更远

177
00:10:00,767 --> 0:10:04,171
比如我们可以限制网络

178
00:10:04,238 --> 0:10:08,141
只能取8种值 而不是256种

179
00:10:09,610 --> 0:10:11,845
既然现在我们只有8种可能

180
00:10:12,513 --> 0:10:16,350
Core ML中每个权重将需要

181
00:10:17,518 --> 0:10:18,919
这里有一些细节

182
00:10:19,353 --> 0:10:21,154
关于我们如何选择这些值

183
00:10:21,221 --> 0:10:22,489
来表示其权重

184
00:10:22,756 --> 0:10:26,026
它们可以在取值范围内均匀分布

185
00:10:26,093 --> 0:10:28,295
在这种情况下 它是一个线性量化

186
00:10:29,296 --> 0:10:31,431
然而如果是查找表量化

187
00:10:33,333 --> 0:10:37,204
我们可以任意的方式

188
00:10:37,738 --> 0:10:42,009
现在我们来看看

189
00:10:42,342 --> 0:10:44,912
在这个例子中

190
00:10:45,212 --> 0:10:47,748
这是许多app用来

191
00:10:47,814 --> 0:10:49,016
常见体系结构

192
00:10:49,983 --> 0:10:52,853
它包含2500万个训练参数

193
00:10:53,587 --> 0:10:56,990
这意味着如果你使用

194
00:10:57,925 --> 0:11:00,694
那么总模型大小超过100兆字节

195
00:10:57,925 --> 0:11:00,694
那么总模型大小超过100兆字节

196
00:11:02,396 --> 0:11:06,133
如果我们将它量化为8位

197
00:11:06,200 --> 0:11:09,002
我们仍然有2500万个参数

198
00:11:09,503 --> 0:11:11,738
但我们现在只使用一个字节

199
00:11:12,573 --> 0:11:13,974
来存储单个权重

200
00:11:14,041 --> 0:11:16,977
这意味着模型大小减少了4倍

201
00:11:17,277 --> 0:11:20,547
现在只需要26兆字节

202
00:11:20,881 --> 0:11:22,249
我们还可以更进一步

203
00:11:22,316 --> 0:11:24,051
我们可以在这个模型中使用

204
00:11:24,117 --> 0:11:26,753
4位来表示每个权重的量化表示

205
00:11:27,254 --> 0:11:29,223
并最终得到一个更小的模型

206
00:11:36,463 --> 0:11:40,234
Core ML支持所有的量化模式

207
00:11:40,300 --> 0:11:42,436
直到只需1位

208
00:11:44,271 --> 0:11:45,105
现在…

209
00:11:45,639 --> 0:11:47,508
量化是一项强大的技术

210
00:11:47,975 --> 0:11:51,044
它可以采取现有的体系结构

211
00:11:51,345 --> 0:11:52,980
但是你如何获得量化模型呢？

212
00:11:54,781 --> 0:11:58,151
如果你有Core ML格式的

213
00:11:58,218 --> 0:12:01,622
你可以使用Core ML工具

214
00:11:58,218 --> 0:12:01,622
你可以使用Core ML工具

215
00:12:01,688 --> 0:12:04,291
Core ML工具会自动替你量化

216
00:12:05,492 --> 0:12:07,928
或者你可以直接训练量化模型

217
00:12:09,263 --> 0:12:11,732
你可以使用量化约束

218
00:12:11,798 --> 0:12:15,402
或者用量化约束重新训练现有模型

219
00:12:16,403 --> 0:12:17,971
在你获得量化模型和训练工具后

220
00:12:18,038 --> 0:12:19,973
你可以像平常一样

221
00:12:20,040 --> 0:12:21,608
将其转换为Core ML

222
00:12:22,209 --> 0:12:25,012
在app中

223
00:12:25,579 --> 0:12:27,447
在模型中

224
00:12:27,514 --> 0:12:29,483
数字将以不同的精度进行存储

225
00:12:29,550 --> 0:12:33,120
但使用该模型的接口完全不会改变

226
00:12:35,489 --> 0:12:38,559
但我们总是需要考虑到

227
00:12:38,959 --> 0:12:40,727
只是原始浮点模型的

228
00:12:40,794 --> 0:12:43,597
较低精度的近似

229
00:12:44,231 --> 0:12:45,933
这意味着量化模型

230
00:12:45,999 --> 0:12:48,902
具有精确性与模型大小的折衷

231
00:12:49,703 --> 0:12:53,073
这种折衷取决于模型和用例

232
00:12:53,740 --> 0:12:55,943
这也是一个非常活跃的研究领域

233
00:12:56,410 --> 0:12:59,613
因此总是建议检查量化模型的准确性

234
00:13:00,047 --> 0:13:03,417
并将其与原来的浮点数版本进行比较

235
00:13:04,017 --> 0:13:07,855
你应在检查中使用相关的测试数据

236
00:13:08,956 --> 0:13:11,792
现在让我们看一个如何采用量化模型

237
00:13:12,259 --> 0:13:15,062
来减小app大小的演示

238
00:13:25,172 --> 0:13:27,174
我想向你展示一款风格转换app

239
00:13:28,075 --> 0:13:32,579
在风格转换app中 有一个训练好的

240
00:13:32,646 --> 0:13:36,149
该网络使用通过观看绘画或其他图像

241
00:13:36,550 --> 0:13:37,618
首先加载app

242
00:13:39,186 --> 0:13:40,287
我们可以看到

243
00:13:40,587 --> 0:13:42,656
我的app中内置了四种风格

244
00:13:42,723 --> 0:13:45,259
城市 玻璃 油画和波浪

245
00:13:45,626 --> 0:13:49,296
然后我可以从用户的照片库中

246
00:13:49,863 --> 0:13:53,400
然后通过在设备上

247
00:13:53,934 --> 0:13:57,838
这是原始图像

248
00:13:59,940 --> 0:14:01,008
玻璃风格

249
00:13:59,940 --> 0:14:01,008
玻璃风格

250
00:14:02,309 --> 0:14:03,143
油画风格

251
00:14:04,845 --> 0:14:05,679
和波浪风格

252
00:14:07,414 --> 0:14:09,583
看看该app

253
00:14:10,951 --> 0:14:15,422
这个app使用Core ML

254
00:14:16,223 --> 0:14:19,993
如我们所见 我们在Xcode中

255
00:14:20,360 --> 0:14:23,497
城市、玻璃、油画和波浪

256
00:14:24,431 --> 0:14:28,335
我们可以检视这个模型

257
00:14:28,402 --> 0:14:31,905
所以这些模型中的每一个

258
00:14:33,040 --> 0:14:35,843
我们看到模型的输入

259
00:14:36,543 --> 0:14:39,813
并生成一个名为Stylized的

260
00:14:40,981 --> 0:14:45,052
现在我们想知道

261
00:14:45,118 --> 0:14:48,255
节省多少存储空间和内存空间

262
00:14:48,622 --> 0:14:50,457
我已使用

263
00:14:51,525 --> 0:14:55,395
获得了所有这些模型的量化表示

264
00:14:56,163 --> 0:14:58,599
有关如何获取这些模型的教程

265
00:14:58,999 --> 0:15:03,403
参见稍后第二部分 其将详细介绍

266
00:14:58,999 --> 0:15:03,403
参见稍后第二部分 其将详细介绍

267
00:15:04,104 --> 0:15:06,173
我想先关注玻璃风格

268
00:15:06,874 --> 0:15:09,576
并查看不同的量化版本

269
00:15:09,643 --> 0:15:10,911
对这些风格的效果影响如何

270
00:15:11,845 --> 0:15:15,782
我所要做的就是

271
00:15:17,951 --> 0:15:20,921
并重新运行该app

272
00:15:22,523 --> 0:15:25,826
首先我们可以看到app大小

273
00:15:25,893 --> 0:15:29,997
例如 8位版本已经

274
00:15:30,063 --> 0:15:31,665
缩小到1.7兆字节

275
00:15:37,037 --> 0:15:39,306
在4位版本中 我们可以节省更多

276
00:15:39,373 --> 0:15:41,441
现在模型少于1兆字节

277
00:15:41,875 --> 0:15:46,046
在3位版本中 它是649千字节

278
00:15:46,980 --> 0:15:48,749
现在让我们回到app

279
00:15:51,151 --> 0:15:53,287
让我们选择相同的图像作为参考

280
00:15:53,520 --> 0:15:56,390
并在原始版本中应用玻璃风格

281
00:15:57,124 --> 0:15:58,325
仍然像以前一样

282
00:15:58,959 --> 0:16:01,762
现在我们可以将它

283
00:15:58,959 --> 0:16:01,762
现在我们可以将它

284
00:16:04,331 --> 0:16:06,366
你可以看到没有任何改变

285
00:16:06,767 --> 0:16:09,670
这是因为8位量化方法非常稳定

286
00:16:10,771 --> 0:16:15,375
我们还可以进一步尝试

287
00:16:16,944 --> 0:16:18,612
哇 结果仍然很好

288
00:16:20,180 --> 0:16:21,982
现在让我们试试3位版本

289
00:16:24,852 --> 0:16:27,621
我们看到第一次颜色偏移

290
00:16:27,688 --> 0:16:30,190
因此 我们最好去和设计师核对一下

291
00:16:30,257 --> 0:16:32,526
这种效果是否仍然可以接受

292
00:16:33,227 --> 0:16:35,128
现在 当我们看到2位版本时

293
00:16:36,330 --> 0:16:37,865
这不是我们所期待的

294
00:16:37,931 --> 0:16:39,700
也许我们会将它保存为一恐怖app

295
00:16:39,766 --> 0:16:41,602
但我不打算向设计师展示这个

296
00:16:46,473 --> 0:16:48,675
让我们回到4位版本并隐藏这个版本

297
00:16:49,142 --> 0:16:51,945
这只是在提醒我们

298
00:16:52,513 --> 0:16:54,515
量化模型是原始模型的一个近似

299
00:16:55,182 --> 0:16:58,752
因此你最好检查它们

300
00:16:59,052 --> 0:17:01,755
现在 对于每种模型和量化技术

301
00:16:59,052 --> 0:17:01,755
现在 对于每种模型和量化技术

302
00:17:01,822 --> 0:17:04,391
事情总会从某点开始变得不太匹配

303
00:17:06,492 --> 0:17:08,962
在与设计师进行了一些讨论

304
00:17:09,029 --> 0:17:12,332
并对许多图像进行了广泛的评估之后

305
00:17:12,398 --> 0:17:15,702
这个模型的4位版本

306
00:17:16,936 --> 0:17:19,406
让我们删除app中占了大量空间的

307
00:17:19,473 --> 0:17:22,442
所有的浮点版本模型

308
00:17:23,443 --> 0:17:26,113
并将其替换为4位版本

309
00:17:31,018 --> 0:17:33,120
现在让我们最后一次运行app

310
00:17:40,427 --> 0:17:42,095
我们再次选择相同的图像

311
00:17:45,132 --> 0:17:46,333
并显示所有风格

312
00:17:48,702 --> 0:17:49,703
这是这个城市风格

313
00:17:50,838 --> 0:17:51,672
玻璃风格

314
00:17:53,740 --> 0:17:54,575
油画风格

315
00:17:56,310 --> 0:17:57,177
和大波浪风格

316
00:18:00,214 --> 0:18:05,185
在这个演示中

317
00:18:05,252 --> 0:18:08,856
其总app大小为27兆字节

318
00:18:09,389 --> 0:18:12,659
然后我们评估质量并切换到4位模型

319
00:18:12,993 --> 0:18:16,563
我们app的总大小一路降到

320
00:18:17,598 --> 0:18:18,432
现在…

321
00:18:23,136 --> 0:18:25,639
这在质量方面没有任何缩水

322
00:18:26,139 --> 0:18:30,110
因为所有这些量化版本

323
00:18:30,177 --> 0:18:32,145
质量仍然令人满意

324
00:18:34,481 --> 0:18:37,885
我们看到了量化如何

325
00:18:37,951 --> 0:18:41,121
来帮助我们缩小app的大小

326
00:18:42,089 --> 0:18:46,226
现在让我们看看

327
00:18:47,728 --> 0:18:49,363
在最简单的情况下

328
00:18:50,063 --> 0:18:53,233
如果你的app有三种机器学习功能

329
00:18:53,300 --> 0:18:55,602
那么你需要三种不同的机器学习模型

330
00:18:56,036 --> 0:19:01,341
但在某些情况下

331
00:18:56,036 --> 0:19:01,341
但在某些情况下

332
00:19:01,408 --> 0:19:03,744
来支持两种不同的功能

333
00:19:04,378 --> 0:19:07,080
例如 你可以训练一个多任务模型

334
00:19:07,514 --> 0:19:11,685
多任务模型被训练成

335
00:19:12,352 --> 0:19:14,121
Turi Create演讲中

336
00:19:14,188 --> 0:19:16,356
涉及到多任务模型

337
00:19:16,823 --> 0:19:18,325
或者 在某些情况下

338
00:19:18,692 --> 0:19:21,061
你可以在Core ML中使用一个

339
00:19:21,128 --> 0:19:23,063
被称为“弹性形状和尺寸”的新特性

340
00:19:24,298 --> 0:19:27,801
让我们回到风格转换演示

341
00:19:28,135 --> 0:19:32,339
在Xcode中

342
00:19:32,840 --> 0:19:36,076
被编码到模型的部分定义中

343
00:19:36,777 --> 0:19:40,414
但如果我们想在不同的图像分辨率下

344
00:19:41,014 --> 0:19:45,385
如果我们想在不同的图像尺寸上

345
00:19:46,787 --> 0:19:47,821
例如

346
00:19:48,121 --> 0:19:51,258
用户可能希望看到

347
00:19:51,792 --> 0:19:55,095
所以他们给我们一个高清图像

348
00:19:55,596 --> 0:19:59,233
现在如果我们的Core ML模型

349
00:20:00,000 --> 0:20:05,472
作为开发者我们能做的只有

350
00:20:06,106 --> 0:20:10,410
然后再将其放大

351
00:20:11,778 --> 0:20:13,113
即便在过去

352
00:20:14,014 --> 0:20:16,917
我们也可使用Corel ML Tools

353
00:20:16,984 --> 0:20:18,819
并让它接受任何分辨率的图像

354
00:20:19,486 --> 0:20:21,889
特别是高分辨率图像

355
00:20:23,223 --> 0:20:27,027
因此即使在过去

356
00:20:27,094 --> 0:20:29,596
并将高分辨率图像

357
00:20:29,830 --> 0:20:31,798
然后产生一个高分辨率的结果

358
00:20:33,534 --> 0:20:37,037
这是因为我们想要在风格化中

359
00:20:37,104 --> 0:20:41,708
并有更精细的笔触

360
00:20:41,775 --> 0:20:44,645
因为它们在最终图像中

361
00:20:46,513 --> 0:20:49,416
过去我们的确可以做到

362
00:20:49,483 --> 0:20:52,753
复制模型并创建两个不同的版本

363
00:20:53,053 --> 0:20:56,089
一个用于标准画质

364
00:20:56,490 --> 0:21:00,327
这当然意味着我们的app大小

365
00:20:56,490 --> 0:21:00,327
这当然意味着我们的app大小

366
00:21:00,394 --> 0:21:01,695
尽管这个网络

367
00:21:01,762 --> 0:21:03,830
是被训练为处理任何分辨率的

368
00:21:04,498 --> 0:21:07,401
现在不再是这样了

369
00:21:07,768 --> 0:21:11,505
通过使用弹性形状

370
00:21:11,772 --> 0:21:14,508
来处理更多的分辨率种类

371
00:21:15,609 --> 0:21:16,743
现在在Xcode中…

372
00:21:21,348 --> 0:21:23,517
在Xcode中 你会看到

373
00:21:24,284 --> 0:21:26,687
输入仍然是图像

374
00:21:27,187 --> 0:21:31,959
但除了默认分辨率

375
00:21:32,025 --> 0:21:35,362
在这个简单的例子中

376
00:21:36,330 --> 0:21:38,832
这意味着现在你只需安装一个模型

377
00:21:40,400 --> 0:21:42,302
你不必写任何冗余代码

378
00:21:43,270 --> 0:21:46,306
如果你需要在标清和高清之间切换

379
00:21:46,373 --> 0:21:48,408
其速度非常快 因为我们不需要

380
00:21:48,475 --> 0:21:51,044
重新加载模型

381
00:21:52,513 --> 0:21:55,716
你有两种方法来指定模型的弹性

382
00:21:56,984 --> 0:21:59,286
你可以为其维度定义一个范围

383
00:21:59,586 --> 0:22:01,722
你可以定义一个最小的宽度和高度

384
00:21:59,586 --> 0:22:01,722
你可以定义一个最小的宽度和高度

385
00:22:01,788 --> 0:22:03,156
以及一个最大的宽度和高度

386
00:22:03,590 --> 0:22:06,193
然后在推理过程中

387
00:22:07,094 --> 0:22:08,295
但也有另一种方法

388
00:22:08,562 --> 0:22:11,365
你可以枚举你要使用的所有形状

389
00:22:11,732 --> 0:22:13,934
例如 所有不同的宽高比

390
00:22:14,001 --> 0:22:17,304
所有不同的分辨率

391
00:22:17,704 --> 0:22:20,174
Core ML更早地了解你的用例

392
00:22:20,541 --> 0:22:24,111
因此它有机会进行更多的优化

393
00:22:24,978 --> 0:22:27,814
这也为你的app提供了更小的测试面

394
00:22:29,249 --> 0:22:30,884
那哪些模型是弹性的呢？

395
00:22:30,951 --> 0:22:34,655
哪些模型能被训练

396
00:22:36,223 --> 0:22:40,827
完全卷积神经网络

397
00:22:40,894 --> 0:22:45,499
如风格转换 图像增强

398
00:22:45,999 --> 0:22:47,935
它还被用来实现一些对象检测架构

399
00:22:48,402 --> 0:22:52,806
Core ML工具可以替

400
00:22:54,208 --> 0:22:57,778
我们看到了如何使用弹性大小

401
00:22:57,845 --> 0:23:00,380
以及权重的大小可以通过量化来缩小

402
00:22:57,845 --> 0:23:00,380
以及权重的大小可以通过量化来缩小

403
00:23:00,647 --> 0:23:02,249
那权重的数量呢？

404
00:23:03,183 --> 0:23:04,017
Core ML

405
00:23:04,484 --> 0:23:05,886
考虑到它支持

406
00:23:05,953 --> 0:23:08,422
许多不同的架构和训练框架

407
00:23:08,922 --> 0:23:12,860
它一直帮助你为你的机器学习问题

408
00:23:12,926 --> 0:23:14,161
选择合适大小的模型

409
00:23:14,595 --> 0:23:18,098
因此 Core ML可以同时使用

410
00:23:18,432 --> 0:23:21,134
来帮助你解决你的app大小的问题

411
00:23:21,502 --> 0:23:24,204
在任何情况下

412
00:23:24,738 --> 0:23:28,041
为了介绍在性能和定制化中

413
00:23:28,108 --> 0:23:30,210
让我们欢迎Bill March

414
00:23:37,951 --> 0:23:38,785
谢谢

415
00:23:39,786 --> 0:23:43,190
Core ML

416
00:23:43,257 --> 0:23:46,426
就是它应该为你的app

417
00:23:46,727 --> 0:23:50,163
为了达到这个目标 我想强调一下

418
00:23:50,230 --> 0:23:53,500
以帮助你的app能够

419
00:23:54,801 --> 0:23:56,703
我们来看看

420
00:23:56,770 --> 0:23:58,238
风格转换示例

421
00:23:58,305 --> 0:23:59,606
从你的app的角度来看

422
00:24:00,040 --> 0:24:03,911
它需要一个输入的图像

423
00:24:04,344 --> 0:24:07,047
有两个关键组件可以实现这一点

424
00:24:07,414 --> 0:24:11,618
第一个是MLModel文件

425
00:24:11,685 --> 0:24:13,053
应用此风格所需的特定参数

426
00:24:13,453 --> 0:24:15,656
第二个是推理引擎

427
00:24:15,722 --> 0:24:18,058
它摄入MLModel和图像

428
00:24:18,125 --> 0:24:21,061
并执行必要的计算以生成结果

429
00:24:21,862 --> 0:24:24,464
让我们来看看这个推理引擎的底层

430
00:24:24,531 --> 0:24:28,502
以及我们如何利用Apple

431
00:24:30,170 --> 0:24:32,439
这个模型是一个神经网络的例子

432
00:24:32,506 --> 0:24:35,976
它由一系列称为层的数学运算组成

433
00:24:36,376 --> 0:24:39,179
每个层都会对图像进行一些转换

434
00:24:39,246 --> 0:24:41,748
最终产生风格化输出

435
00:24:42,616 --> 0:24:45,352
模型存储了每个层的权重

436
00:24:45,419 --> 0:24:48,622
这些权重决定了特定的转换

437
00:24:49,523 --> 0:24:51,558
Core ML神经网络推理引擎

438
00:24:51,625 --> 0:24:54,862
为这些层中的每一层

439
00:24:55,128 --> 0:24:57,364
在GPU上 我们使用MTL着色器

440
00:24:57,431 --> 0:25:00,767
在CPU上 我们可以使用

441
00:24:57,431 --> 0:25:00,767
在CPU上 我们可以使用

442
00:25:01,301 --> 0:25:03,637
并且我们可以进行调度

443
00:25:03,704 --> 0:25:07,074
根据模型 设备状态和其它因素

444
00:25:07,140 --> 0:25:09,176
动态地分配给不同的硬件

445
00:25:11,144 --> 0:25:14,281
我们也可以找到

446
00:25:14,348 --> 0:25:17,284
这会减少所需的整体计算

447
00:25:18,785 --> 0:25:22,122
我们能够在这里进行优化

448
00:25:22,189 --> 0:25:23,824
我们知道模型的细节

449
00:25:23,891 --> 0:25:26,760
它们包含在你提供给我们的

450
00:25:26,827 --> 0:25:30,063
我们知道推理引擎和设备的细节

451
00:25:30,130 --> 0:25:31,231
因为我们设计了它们

452
00:25:32,299 --> 0:25:35,369
我们可以为你处理所有这些优化

453
00:25:35,435 --> 0:25:38,872
以使你可以专注于

454
00:25:40,274 --> 0:25:41,708
但是你的工作载荷呢？

455
00:25:42,409 --> 0:25:46,313
特别是 如果你需要进行多重预测

456
00:25:47,147 --> 0:25:50,684
如果Core ML不知道它

457
00:25:51,485 --> 0:25:54,288
因此在过去

458
00:25:55,455 --> 0:25:57,157
你需要做这样的事情：

459
00:25:57,224 --> 0:26:01,562
一个简单的for循环 环绕着

460
00:25:57,224 --> 0:26:01,562
一个简单的for循环 环绕着

461
00:26:01,762 --> 0:26:05,499
你可以遍历一个输入数组

462
00:26:06,834 --> 0:26:11,371
让我们仔细看看

463
00:26:12,139 --> 0:26:15,409
对于每张图片

464
00:26:15,642 --> 0:26:18,378
如果没有别的要做了

465
00:26:19,046 --> 0:26:21,415
一旦我们完成这些

466
00:26:21,481 --> 0:26:24,785
并生成输出图像

467
00:26:25,085 --> 0:26:28,555
我们需要从GPU中拿回数据

468
00:26:29,823 --> 0:26:31,725
改善这张图片的关键

469
00:26:31,792 --> 0:26:34,528
是消除GPU管道中的气泡

470
00:26:35,829 --> 0:26:38,866
出于两个主要原因

471
00:26:38,932 --> 0:26:41,602
首先 由于GPU不曾空闲

472
00:26:41,668 --> 0:26:43,637
整体计算时间得到了缩短

473
00:26:44,037 --> 0:26:47,608
第二 由于GPU持续工作

474
00:26:47,674 --> 0:26:50,310
它能够以更高的性能状态运行

475
00:26:50,377 --> 0:26:54,348
并减少计算每个特定输出所需的时间

476
00:26:55,582 --> 0:26:58,218
但Core ML的魅力在于

477
00:26:58,285 --> 0:27:01,822
这其中的任何细节

478
00:26:58,285 --> 0:27:01,822
这其中的任何细节

479
00:27:01,889 --> 0:27:03,524
你需要关心的仅仅是

480
00:27:03,924 --> 0:27:07,060
用户得到结果的时间变短了

481
00:27:07,728 --> 0:27:11,198
所以今年我们推出了

482
00:27:11,265 --> 0:27:13,100
可以让你做到这一点

483
00:27:14,067 --> 0:27:15,969
之前你需要循环遍历输入

484
00:27:16,036 --> 0:27:19,273
并调用它们各自的预测

485
00:27:20,407 --> 0:27:22,276
单行预测代码

486
00:27:22,342 --> 0:27:26,847
它会摄入一个输入数组

487
00:27:26,914 --> 0:27:28,515
Core ML将负责其余部分

488
00:27:34,721 --> 0:27:35,889
让我们看看它的实践

489
00:27:36,423 --> 0:27:39,626
继续我们的风格转换示例

490
00:27:39,693 --> 0:27:42,095
让我们看看我们想要为整个照片库

491
00:27:42,162 --> 0:27:44,998
应用风格转换的情况

492
00:27:45,065 --> 0:27:49,169
就是用来做这件事的

493
00:27:49,236 --> 0:27:51,505
在左边 你们的左边

494
00:27:51,939 --> 0:27:55,809
这是在for循环中

495
00:27:55,876 --> 0:27:58,478
在右侧

496
00:27:58,545 --> 0:27:59,513
让我们开始吧

497
00:28:00,414 --> 0:28:01,315
我们开始了

498
00:28:03,784 --> 0:28:05,319
我们可以看到新API已完成

499
00:28:05,719 --> 0:28:07,621
我们等一下去年的技术

500
00:28:08,589 --> 0:28:09,423
好了

501
00:28:15,262 --> 0:28:17,698
在这个例子中

502
00:28:17,764 --> 0:28:19,066
明显的改进

503
00:28:19,132 --> 0:28:22,803
一般来说 你在app中看到的改进

504
00:28:22,870 --> 0:28:24,838
以及设备和工作载荷

505
00:28:24,905 --> 0:28:28,475
但若你有大量prediction

506
00:28:28,542 --> 0:28:31,845
并为Core ML

507
00:28:35,649 --> 0:28:39,553
当然 世界上性能最好的app

508
00:28:39,620 --> 0:28:42,489
你想为你的用户提供的体验

509
00:28:43,590 --> 0:28:46,460
我们希望确保无论该体验是什么

510
00:28:46,527 --> 0:28:48,195
或将来是什么样的

511
00:28:48,262 --> 0:28:51,431
Core ML的性能

512
00:28:52,366 --> 0:28:54,835
但机器学习领域正在迅速发展

513
00:28:55,135 --> 0:28:57,938
我们将如何跟上呢？

514
00:28:58,005 --> 0:29:00,908
让我告诉你一个跟这个问题有关的

515
00:28:58,005 --> 0:29:00,908
让我告诉你一个跟这个问题有关的

516
00:29:02,843 --> 0:29:04,945
让我们看一个

517
00:29:05,012 --> 0:29:06,713
看似简单的问题

518
00:29:07,648 --> 0:29:11,752
给出一张图片 我想知道

519
00:29:12,519 --> 0:29:14,555
我想我听到一两声笑了

520
00:29:14,621 --> 0:29:16,723
也许这是一个愚蠢的挑战问题

521
00:29:16,790 --> 0:29:18,992
顺便说一句 小孩儿都好这口

522
00:29:19,059 --> 0:29:24,064
很久很久以前

523
00:29:24,131 --> 0:29:27,134
我当时正在考虑这个问题

524
00:29:27,501 --> 0:29:29,970
我对这个问题的看法像下面这样

525
00:29:30,904 --> 0:29:34,842
“我不知道 似乎很难

526
00:29:35,876 --> 0:29:40,247
几年过去了 我变老了

527
00:29:40,314 --> 0:29:42,749
但是这个领域非常迅速地发展

528
00:29:43,083 --> 0:29:45,052
因这时开始出现很多

529
00:29:45,118 --> 0:29:46,687
得到的令人兴奋的新结果

530
00:29:47,688 --> 0:29:50,023
就这样 我对这个问题的看法

531
00:29:50,090 --> 0:29:53,260
突然间 哇 原来这些先进的研究

532
00:29:53,327 --> 0:29:55,229
电脑现在可以赶上小孩子

533
00:29:55,295 --> 0:29:58,332
和马识别技术了

534
00:30:00,267 --> 0:30:02,402
又经过了几年

535
00:30:02,469 --> 0:30:05,939
现在我在Apple工作

536
00:30:06,373 --> 0:30:10,544
现在只需要使用Create ML

537
00:30:10,611 --> 0:30:12,613
你将在几分钟内拥有一个马分类器

538
00:30:13,313 --> 0:30:15,916
所以 你知道

539
00:30:15,983 --> 0:30:17,918
且正在看这个 你可能会想

540
00:30:17,985 --> 0:30:19,086
不知道他在说什么

541
00:30:19,152 --> 0:30:21,355
在2007年我就知道

542
00:30:21,421 --> 0:30:23,790
到2012年我已解决它一百次了”

543
00:30:24,224 --> 0:30:25,325
这不是重点

544
00:30:25,659 --> 0:30:30,264
如果你是一个关心

545
00:30:30,330 --> 0:30:32,599
这会让你感到紧张

546
00:30:32,666 --> 0:30:35,135
我们看到这个问题的环境

547
00:30:36,203 --> 0:30:38,472
所以我们看看

548
00:30:38,539 --> 0:30:40,340
来让你将悬着的心放下

549
00:30:41,542 --> 0:30:44,678
为了做到这一点

550
00:30:44,745 --> 0:30:48,982
这个新的马匹识别模型

551
00:30:49,750 --> 0:30:51,185
如前所述

552
00:30:51,251 --> 0:30:54,655
神经网络由一系列层组成

553
00:30:54,721 --> 0:30:57,824
我们在推理引擎中对其中每一层

554
00:30:57,891 --> 0:30:59,993
都有高度优化的实现

555
00:31:00,827 --> 0:31:03,830
我们支持的操作列表很庞大

556
00:31:04,264 --> 0:31:06,633
试图跟上这一领域的新发展

557
00:31:07,668 --> 0:31:10,737
但是如果在Core ML中

558
00:31:12,272 --> 0:31:13,173
过去

559
00:31:13,707 --> 0:31:16,643
你要么等待

560
00:31:17,411 --> 0:31:20,747
但如果这层是关键的马匹识别层呢？

561
00:31:21,048 --> 0:31:23,684
这是你的马匹识别app

562
00:31:23,984 --> 0:31:24,985
你等得起吗？

563
00:31:26,687 --> 0:31:29,590
鉴于机器学习的发展速度

564
00:31:31,191 --> 0:31:34,695
因此 我们为神经网络模型

565
00:31:35,028 --> 0:31:39,499
现在 如果缺少某个神经网络层

566
00:31:39,566 --> 0:31:43,237
它将与Core ML

567
00:31:44,004 --> 0:31:47,941
在模型中

568
00:31:48,008 --> 0:31:50,277
在这里是

569
00:31:51,078 --> 0:31:54,248
实现类在推理引擎中

570
00:31:54,314 --> 0:31:55,516
充当所缺失实现的角色

571
00:31:55,849 --> 0:31:57,885
就像这个层

572
00:31:57,951 --> 0:32:01,455
这里提供的实现应该是通用的

573
00:31:57,951 --> 0:32:01,455
这里提供的实现应该是通用的

574
00:32:01,522 --> 0:32:02,956
并适用于新层的任何实例

575
00:32:04,691 --> 0:32:07,394
它只需要在运行时

576
00:32:07,661 --> 0:32:09,963
然后这个特定层的参数

577
00:32:10,030 --> 0:32:12,032
和其他有关该模型的信息

578
00:32:12,099 --> 0:32:14,201
将一同被封装在MLModel中

579
00:32:15,969 --> 0:32:20,240
实现一个自定义层很简单

580
00:32:20,507 --> 0:32:22,809
你只需根据存储在

581
00:32:22,876 --> 0:32:24,945
提供用来初始化层的方法

582
00:32:26,046 --> 0:32:28,949
你需要提供一个方法

583
00:32:29,016 --> 0:32:30,384
分配多少空间

584
00:32:31,118 --> 0:32:32,853
然后是执行计算的方法

585
00:32:34,955 --> 0:32:37,124
另外 你可以添加这种灵活性

586
00:32:37,191 --> 0:32:40,060
而不牺牲整个模型的性能

587
00:32:41,061 --> 0:32:43,864
该协议包含一个可选的方法

588
00:32:43,931 --> 0:32:47,501
一个该层的MTL着色器的实现

589
00:32:48,302 --> 0:32:50,671
如果你给我们这个 那么它可以在

590
00:32:50,737 --> 0:32:53,707
与其它Core ML计算所在的

591
00:32:53,774 --> 0:32:56,009
所以这里没额外的开销

592
00:32:56,076 --> 0:32:57,845
还是多次往返GPU产生的开销

593
00:32:58,412 --> 0:33:00,581
如果你不提供这个

594
00:32:58,412 --> 0:33:00,581
如果你不提供这个

595
00:33:00,647 --> 0:33:03,116
在CPU上进行计算

596
00:33:04,952 --> 0:33:08,121
因此 不管神经网络模型的进展

597
00:33:08,188 --> 0:33:09,923
你都有办法跟上Core ML

598
00:33:10,490 --> 0:33:11,892
但有一些限制

599
00:33:12,826 --> 0:33:15,162
自定义层仅适用于神经网络模型

600
00:33:15,229 --> 0:33:18,232
他们只能处理

601
00:33:19,032 --> 0:33:21,368
这是一种与神经网络交互的自然方式

602
00:33:21,668 --> 0:33:23,871
但机器学习领域几乎不会限制

603
00:33:23,937 --> 0:33:25,639
只在这个领域前进

604
00:33:26,607 --> 0:33:28,942
实际上 当我第一次学习图像识别时

605
00:33:29,009 --> 0:33:32,613
几乎没有人在谈论将神经网络

606
00:33:32,980 --> 0:33:35,315
今天你可以看到

607
00:33:37,251 --> 0:33:40,587
并不难想象具有机器学习功能的app

608
00:33:40,654 --> 0:33:42,556
可能会导致有些自定义层根本不适用

609
00:33:43,023 --> 0:33:46,627
例如 机器学习app

610
00:33:46,693 --> 0:33:50,130
来向某个相似空间中嵌入图像

611
00:33:50,197 --> 0:33:53,166
或局部敏感哈希法

612
00:33:53,233 --> 0:33:54,735
来查找相似的图像

613
00:33:56,837 --> 0:33:59,339
模型可能会结合

614
00:33:59,406 --> 0:34:02,809
给那些并不总能完成跑步目标的人

615
00:33:59,406 --> 0:34:02,809
给那些并不总能完成跑步目标的人

616
00:34:04,878 --> 0:34:08,447
甚至是一种我们甚至还没有想到的

617
00:34:08,514 --> 0:34:10,583
全新模型类型

618
00:34:10,984 --> 0:34:12,452
在所有这些情况下

619
00:34:12,518 --> 0:34:15,222
如果我们可以拥有Core ML的

620
00:34:15,656 --> 0:34:19,226
而不必牺牲灵活性来跟上领域的发展

621
00:34:20,827 --> 0:34:22,529
所以我们推出了自定义模型

622
00:34:23,496 --> 0:34:26,699
Core ML自定义模型允许你

623
00:34:26,766 --> 0:34:29,735
封装Core ML中缺少的

624
00:34:30,404 --> 0:34:31,871
就像自定义层一样

625
00:34:31,938 --> 0:34:34,440
该模型存储了实现类的名称

626
00:34:34,975 --> 0:34:37,244
这个类则充当了这类模型的

627
00:34:37,311 --> 0:34:38,645
通用推理引擎的角色

628
00:34:39,079 --> 0:34:42,748
而参数像以前一样

629
00:34:43,550 --> 0:34:46,219
这允许将模型

630
00:34:46,286 --> 0:34:47,754
而无需接触代码

631
00:34:50,424 --> 0:34:52,659
并且实现自定义模型也很简单

632
00:34:52,726 --> 0:34:55,094
我们暴露了一个协议

633
00:34:55,429 --> 0:34:59,099
你根据存储在MLModel中

634
00:35:00,100 --> 0:35:02,736
再提供一个

635
00:35:03,303 --> 0:35:05,973
如果有机会在这个特定的模型类型中

636
00:35:06,039 --> 0:35:08,475
我们还有一个可选的方法

637
00:35:08,542 --> 0:35:10,043
来提供批处理实现

638
00:35:10,277 --> 0:35:12,679
如果没有

639
00:35:14,615 --> 0:35:16,316
在你的app中使用自定义模型

640
00:35:16,383 --> 0:35:19,086
与使用其他任何Core ML模型

641
00:35:19,653 --> 0:35:22,556
在Xcode中

642
00:35:22,623 --> 0:35:26,493
将有一个依赖项部分

643
00:35:26,560 --> 0:35:27,928
以及简短的描述

644
00:35:28,562 --> 0:35:30,864
只需将其包含在你的app中

645
00:35:31,665 --> 0:35:35,736
原来的prediction API没有改变

646
00:35:38,205 --> 0:35:41,375
因此 自定义层和自定义模型允许你

647
00:35:41,441 --> 0:35:45,045
使用Core ML的强大能力

648
00:35:45,112 --> 0:35:47,648
这种灵活性对跟上

649
00:35:48,582 --> 0:35:52,352
对于新的神经网络层 自定义层

650
00:35:52,419 --> 0:35:54,188
神经网络推理引擎中

651
00:35:54,254 --> 0:35:56,523
已经存在的诸多优化

652
00:35:57,057 --> 0:36:01,461
自定义模型对于类型和功能更加灵活

653
00:35:57,057 --> 0:36:01,461
自定义模型对于类型和功能更加灵活

654
00:36:01,528 --> 0:36:04,031
但他们的确需要你做更多的实现工作

655
00:36:05,766 --> 0:36:09,403
这两种自定义形式都允许你

656
00:36:09,469 --> 0:36:13,073
使得模型可移植且代码更简单

657
00:36:15,976 --> 0:36:19,580
我们只接触到Core ML 2中的

658
00:36:20,047 --> 0:36:23,116
请下载测试版 自己尝试一下

659
00:36:27,020 --> 0:36:30,357
Core ML具有许多优秀新特性

660
00:36:30,424 --> 0:36:33,760
提高性能 确保灵活性

661
00:36:33,827 --> 0:36:35,729
并兼容机器学习的最新进展

662
00:36:36,496 --> 0:36:40,567
我们向你展示了量化如何

663
00:36:40,634 --> 0:36:44,872
可以实现更高效的处理

664
00:36:44,938 --> 0:36:47,674
如何帮助你将先进机器学习技术

665
00:36:48,275 --> 0:36:51,745
结合我们在Create ML中

666
00:36:51,812 --> 0:36:55,249
将机器学习功能添加到你的app中

667
00:36:55,315 --> 0:36:57,851
的方式比以往任何时候都多

668
00:36:59,853 --> 0:37:01,121
短暂休息后

669
00:36:59,853 --> 0:37:01,121
短暂休息后

670
00:37:01,188 --> 0:37:04,791
我们会回到这里

671
00:37:04,858 --> 0:37:08,395
特别是 我们将向你展示如何使用

672
00:37:08,462 --> 0:37:12,132
来缩小模型大小并使用

673
00:37:12,199 --> 0:37:14,268
谢谢
