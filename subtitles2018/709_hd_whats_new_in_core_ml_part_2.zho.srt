1
00:00:17,017 --> 0:00:23,457
（Core ML新特性

2
00:00:24,858 --> 0:00:25,726
大家好

3
00:00:31,398 --> 0:00:33,700
欢迎来到Core ML

4
00:00:34,368 --> 0:00:37,971
我是Aseem

5
00:00:40,774 --> 0:00:43,243
众所周知

6
00:00:43,544 --> 0:00:46,413
用于设备上推理的机器学习框架

7
00:00:48,348 --> 0:00:50,717
而我最喜欢Core ML的原因

8
00:00:50,884 --> 0:00:53,754
是它在所有Apple硬件上

9
00:00:55,422 --> 0:00:56,657
过去一年中

10
00:00:57,324 --> 0:01:02,429
我们在所有Apple平台上看到了

11
00:00:57,324 --> 0:01:02,429
我们在所有Apple平台上看到了

12
00:01:03,096 --> 0:01:04,464
所以这真的很令人兴奋

13
00:01:05,232 --> 0:01:07,034
而我们对今年推出的新功能

14
00:01:07,601 --> 0:01:09,803
甚至更加兴奋

15
00:01:10,604 --> 0:01:11,438
现在

16
00:01:12,039 --> 0:01:15,108
你可以大幅缩减app的大小

17
00:01:16,577 --> 0:01:21,415
通过使用新的批处理预测API

18
00:01:23,050 --> 0:01:27,588
并且你可以轻松将最先进的研究成果

19
00:01:27,754 --> 0:01:29,990
通过自定义机制整合到你的app中

20
00:01:31,725 --> 0:01:33,961
这些是对第一次演讲的回顾

21
00:01:34,394 --> 0:01:35,662
如果你错过了那次演讲

22
00:01:36,163 --> 0:01:38,932
我强烈建议你回去看一下幻灯片

23
00:01:41,435 --> 0:01:43,837
在这次演讲中 我们将会看到

24
00:01:44,238 --> 0:01:47,040
如何实际使用这些特性

25
00:01:47,941 --> 0:01:51,211
更具体地说

26
00:01:51,678 --> 0:01:55,148
你如何通过简单的几步

27
00:01:55,682 --> 0:01:59,953
使用Core ML Tools

28
00:02:00,220 --> 0:02:02,856
以及你如何在模型中使用自定义特性

29
00:02:04,591 --> 0:02:06,126
这是这次演讲的议程

30
00:02:07,060 --> 0:02:10,764
我们从Core ML Tools

31
00:02:11,732 --> 0:02:17,304
然后我们将深入并演示

32
00:02:18,038 --> 0:02:19,640
让我们先从生态系统开始

33
00:02:23,277 --> 0:02:25,312
你如何得到一个ML模型呢？

34
00:02:26,046 --> 0:02:28,048
最简单的是 如果你…

35
00:02:29,449 --> 0:02:30,384
如果你可以…

36
00:02:32,286 --> 0:02:35,022
如果你能在网上找到它

37
00:02:36,023 --> 0:02:39,393
一个下载ML模型的好地方

38
00:02:39,459 --> 0:02:42,362
是Apple机器学习着陆页

39
00:02:42,696 --> 0:02:44,264
那上面有许多模型

40
00:02:45,465 --> 0:02:48,468
现在让我们假设你想

41
00:02:49,036 --> 0:02:51,104
在这种情况下 你可以使用

42
00:02:52,739 --> 0:02:53,774
Create ML

43
00:02:53,941 --> 0:02:56,977
这是我们今年刚刚发布的一个新框架

44
00:02:57,845 --> 0:03:00,848
你无需成为机器学习专家即可使用它

45
00:02:57,845 --> 0:03:00,848
你无需成为机器学习专家即可使用它

46
00:03:01,315 --> 0:03:03,784
它非常易于使用

47
00:03:04,451 --> 0:03:06,920
所以去试试吧

48
00:03:08,488 --> 0:03:13,126
你们中的一些人已经熟悉了

49
00:03:13,193 --> 0:03:15,529
令人惊叹的机器学习工具

50
00:03:16,029 --> 0:03:22,002
为此我们去年发布了一个Python包

51
00:03:22,536 --> 0:03:26,773
此外我们还发布了一些转换器

52
00:03:28,375 --> 0:03:32,246
去年这个领域有许多活动

53
00:03:32,946 --> 0:03:34,915
这就是现在的样子

54
00:03:37,451 --> 0:03:42,422
正如你所看到的 还有更多的转换器

55
00:03:42,890 --> 0:03:47,160
现在确实有很多不同的

56
00:03:48,695 --> 0:03:52,533
所有这些转换器都建立在

57
00:03:55,369 --> 0:03:59,072
现在 我想在这里强调

58
00:04:01,175 --> 0:04:06,346
去年我们与Google合作

59
00:04:07,414 --> 0:04:08,715
这很令人兴奋

60
00:04:10,651 --> 0:04:15,322
如你所知 TensorFlow

61
00:04:15,656 --> 0:04:19,625
所以我们最近在转换器中添加了

62
00:04:21,128 --> 0:04:25,832
最近TensorFlow发布了

63
00:04:26,200 --> 0:04:28,602
这种支持是通过

64
00:04:29,102 --> 0:04:31,438
这个特性很快就会添加到转换器中

65
00:04:33,173 --> 0:04:37,811
另一个令人兴奋的是

66
00:04:38,312 --> 0:04:40,881
这些合作的成果就是ONNX转换器

67
00:04:42,182 --> 0:04:43,951
ONNX的优势在于

68
00:04:45,652 --> 0:04:49,857
现在你可以使用许多不同的训练库了

69
00:04:50,290 --> 0:04:54,361
通过使用新的ONNX转换器

70
00:04:56,230 --> 0:05:00,434
这是对Core ML Tools

71
00:04:56,230 --> 0:05:00,434
这是对Core ML Tools

72
00:05:00,834 --> 0:05:02,569
为了讨论量化

73
00:05:02,636 --> 0:05:05,472
我想邀请我的朋友

74
00:05:14,147 --> 0:05:16,116
大家早上好

75
00:05:16,183 --> 0:05:17,985
我是Core ML团队的工程师

76
00:05:18,051 --> 0:05:21,321
今天 我们将看看

77
00:05:21,388 --> 0:05:22,990
新的量化功能

78
00:05:28,095 --> 0:05:29,763
Core ML Tools 2.0支持

79
00:05:29,830 --> 0:05:32,432
最新的Core ML模型格式规范

80
00:05:32,733 --> 0:05:33,867
它也有一些实用工具

81
00:05:33,934 --> 0:05:36,904
使你可以轻松地添加

82
00:05:37,204 --> 0:05:39,740
到你的神经网络机器学习模型中

83
00:05:40,240 --> 0:05:42,309
在Core ML中

84
00:05:42,376 --> 0:05:45,279
你不仅可以缩减模型的大小

85
00:05:45,546 --> 0:05:48,949
还可以减少app中模型的数量

86
00:05:50,350 --> 0:05:53,320
现在 我们先看一下量化

87
00:05:54,821 --> 0:05:57,257
Core ML Tools

88
00:05:57,658 --> 0:06:00,194
我们从Core ML

89
00:05:57,658 --> 0:06:00,194
我们从Core ML

90
00:06:00,594 --> 0:06:03,330
它具有32位浮点权重参数

91
00:06:03,730 --> 0:06:07,467
我们用Core ML Tools

92
00:06:08,101 --> 0:06:10,037
生成的模型体积较小

93
00:06:10,771 --> 0:06:13,340
模型大小的缩减直接依赖于

94
00:06:13,407 --> 0:06:15,876
我们量化模型的位数

95
00:06:17,811 --> 0:06:21,048
现在 我们中的很多人可能会想

96
00:06:21,281 --> 0:06:23,317
它如何缩减模型的大小

97
00:06:23,984 --> 0:06:26,253
让我们窥视一下幕后所发生的事情

98
00:06:30,357 --> 0:06:32,426
神经网络由层组成

99
00:06:32,726 --> 0:06:35,495
这些层可以被视为数学函数

100
00:06:36,063 --> 0:06:39,233
这些数学函数有参数 称为权重

101
00:06:39,700 --> 0:06:42,803
这些权重通常存储为32位浮点数

102
00:06:44,304 --> 0:06:47,074
在我们之前的演讲中

103
00:06:47,641 --> 0:06:49,142
这是一种流行的机器学习模型

104
00:06:49,209 --> 0:06:52,045
可以用于图像分类等等

105
00:06:52,446 --> 0:06:56,283
这个模型拥有

106
00:06:57,050 --> 0:07:00,320
所以你可以想象

107
00:06:57,050 --> 0:07:00,320
所以你可以想象

108
00:07:00,521 --> 0:07:02,723
来表示这些参数

109
00:07:03,090 --> 0:07:05,325
我们就可以大大缩减这个模型的大小

110
00:07:06,927 --> 0:07:09,730
实际上 这个过程被称为量化

111
00:07:10,464 --> 0:07:13,267
在量化过程中 我们将

112
00:07:13,600 --> 0:07:16,003
在最小值和最大值之间的层的权重

113
00:07:16,537 --> 0:07:17,638
映射为

114
00:07:18,605 --> 0:07:19,773
无符号整数

115
00:07:20,908 --> 0:07:22,576
对于APIC量化

116
00:07:22,643 --> 0:07:26,680
我们将这些值映射到0到55的范围

117
00:07:27,114 --> 0:07:28,382
对于7位量化

118
00:07:28,448 --> 0:07:32,553
我们将它们映射到0到127

119
00:07:32,786 --> 0:07:35,489
即将这些权重映射为0或1

120
00:07:36,223 --> 0:07:37,491
由于我们使用更少的位数

121
00:07:37,558 --> 0:07:40,594
来表示相同的信息

122
00:07:42,362 --> 0:07:43,197
真棒

123
00:07:43,530 --> 0:07:47,334
你们中许多人可能已经注意到

124
00:07:48,202 --> 0:07:51,171
你可能已经得出结论 在这种映射中

125
00:07:51,638 --> 0:07:53,841
可能会有一些精确度损失 这是对的

126
00:07:54,675 --> 0:07:55,642
经验法则是

127
00:07:55,976 --> 0:07:58,278
你用来量化模型的位数越少

128
00:07:58,545 --> 0:08:00,914
我们的模型在准确性方面

129
00:07:58,545 --> 0:08:00,914
我们的模型在准确性方面

130
00:08:01,048 --> 0:08:02,683
我们稍后还会谈到这一点

131
00:08:03,884 --> 0:08:05,619
以上是对量化的概述

132
00:08:05,986 --> 0:08:08,755
但问题依然存在

133
00:08:09,489 --> 0:08:11,258
有很多流行的算法

134
00:08:11,325 --> 0:08:13,694
和技术能帮助你做到这一点

135
00:08:13,760 --> 0:08:16,530
Core ML支持

136
00:08:17,130 --> 0:08:19,700
线性量化和查找表量化

137
00:08:20,634 --> 0:08:22,002
让我们简要介绍一下

138
00:08:26,273 --> 0:08:28,008
线性量化是一种

139
00:08:28,075 --> 0:08:31,778
以均匀的方式映射参数的算法

140
00:08:32,880 --> 0:08:37,150
这种量化是通过比例系数和偏差值

141
00:08:37,217 --> 0:08:39,186
这些值是通过计算得到的

142
00:08:39,553 --> 0:08:42,389
该计算基于我们正在量化的层的参数

143
00:08:43,023 --> 0:08:46,393
了解这种映射工作原理

144
00:08:46,727 --> 0:08:48,195
是我们退后一步

145
00:08:48,262 --> 0:08:50,497
看看我们如何从位于底部的量化权重

146
00:08:50,564 --> 0:08:53,267
恢复到原来的浮点数权重

147
00:08:53,834 --> 0:08:57,571
在线性量化中

148
00:08:57,804 --> 0:08:59,973
乘以比例系数再加上偏差

149
00:09:02,075 --> 0:09:04,778
Core ML支持的

150
00:09:05,012 --> 0:09:06,513
是查找表量化

151
00:09:07,147 --> 0:09:09,383
顾名思义

152
00:09:09,683 --> 0:09:11,018
我们构造一个查找表

153
00:09:11,952 --> 0:09:14,588
再想象一下我们如何从量化后的权重

154
00:09:14,655 --> 0:09:17,024
得到原来的权重

155
00:09:17,257 --> 0:09:20,294
在这种情况下 量化权重只是

156
00:09:20,594 --> 0:09:22,763
查找表中的一些索引

157
00:09:24,031 --> 0:09:26,233
现在 如果你注意到

158
00:09:26,300 --> 0:09:29,603
我们现在可以自由移动

159
00:09:29,670 --> 0:09:32,039
它们不必以线性方式间隔开

160
00:09:33,874 --> 0:09:37,811
回顾一下

161
00:09:38,612 --> 0:09:40,781
线性量化和查找表量化

162
00:09:40,848 --> 0:09:42,850
我们从一个全精度神经网络模型开始

163
00:09:42,916 --> 0:09:45,652
并使用这些工具来量化该模型的权重

164
00:09:46,220 --> 0:09:47,654
现在你可能在想

165
00:09:47,988 --> 0:09:50,290
太好了

166
00:09:50,824 --> 0:09:53,961
但该如何找出量化的参数呢？

167
00:09:54,761 --> 0:09:57,965
如果我正进行线性量化

168
00:09:58,365 --> 0:10:02,035
如果我正在执行查找表量化

169
00:09:58,365 --> 0:10:02,035
如果我正在执行查找表量化

170
00:10:03,036 --> 0:10:06,206
我在这里告诉你

171
00:10:06,940 --> 0:10:10,611
你所要做的就是决定

172
00:10:10,844 --> 0:10:12,746
并决定要使用的算法

173
00:10:13,046 --> 0:10:15,215
剩下的工作交给

174
00:10:16,083 --> 0:10:16,984
事实上…

175
00:10:17,985 --> 0:10:18,819
谢谢大家

176
00:10:22,656 --> 0:10:26,994
事实上 量化一个

177
00:10:27,394 --> 0:10:29,796
以至于我们可在几行

178
00:10:30,397 --> 0:10:33,400
既然我们可以在这里演示

179
00:10:40,507 --> 0:10:42,676
为了演示

180
00:10:42,743 --> 0:10:46,013
我需要一个

181
00:10:46,580 --> 0:10:48,248
正如我的同事Aseem所说

182
00:10:48,315 --> 0:10:51,752
Core ML机器学习主页是一个

183
00:10:52,052 --> 0:10:55,189
我已经提前下载了该页面中的

184
00:10:55,522 --> 0:10:58,358
这个模型叫做SqueezeNet

185
00:11:00,627 --> 0:11:03,230
正如我们所看到的

186
00:11:03,597 --> 0:11:08,268
它有一个输入

187
00:11:08,669 --> 0:11:12,105
它有两个输出

188
00:11:12,639 --> 0:11:16,243
由一个字符串表示

189
00:11:16,610 --> 0:11:17,644
属于的标签

190
00:11:17,711 --> 0:11:21,215
第二个输出是这些字符串对应的概率

191
00:11:21,615 --> 0:11:23,951
鉴于此 如果我们传入图像

192
00:11:24,017 --> 0:11:27,020
我们会得到这个图像

193
00:11:28,789 --> 0:11:30,457
现在让我们开始量化这个模型

194
00:11:31,458 --> 0:11:34,761
我首先要做的是

195
00:11:34,928 --> 0:11:35,896
我比较喜欢

196
00:11:35,963 --> 0:11:37,831
Jupyter Notebook

197
00:11:38,098 --> 0:11:39,766
现在我们打开它

198
00:11:46,673 --> 0:11:50,110
让我们打开一个新的笔记本并放大

199
00:11:51,311 --> 0:11:54,915
我们先导入

200
00:11:58,886 --> 0:12:01,221
让我们来运行它

201
00:11:58,886 --> 0:12:01,221
让我们来运行它

202
00:12:01,288 --> 0:12:03,724
导入所有

203
00:12:03,790 --> 0:12:07,261
新量化工具

204
00:12:16,170 --> 0:12:19,106
现在我们需要加载想要量化的模型

205
00:12:19,173 --> 0:12:21,175
即我们刚看到的

206
00:12:21,241 --> 0:12:23,343
我们需要获取该模型的一个实例

207
00:12:32,786 --> 0:12:34,288
将参数设置为我的桌面

208
00:12:37,991 --> 0:12:38,825
很好

209
00:12:39,026 --> 0:12:43,063
现在 为了量化这个模型

210
00:12:43,463 --> 0:12:47,267
让我们尝试使用线性量化

211
00:12:51,572 --> 0:12:54,408
它的API名称很简单

212
00:12:54,808 --> 0:12:56,510
我们传入的第一个参数

213
00:12:56,877 --> 0:12:59,079
是你刚加载的原始模型

214
00:12:59,546 --> 0:13:02,149
然后是我们想要量化模型的位数

215
00:12:59,546 --> 0:13:02,149
然后是我们想要量化模型的位数

216
00:13:02,216 --> 0:13:03,550
这里我们将其设为8

217
00:13:04,685 --> 0:13:06,887
以及我们想要使用的量化算法

218
00:13:07,054 --> 0:13:08,689
让我们试试线性量化

219
00:13:10,157 --> 0:13:11,158
现在所发生的事情是

220
00:13:11,225 --> 0:13:14,995
这些工具会遍历线性网络的所有层

221
00:13:15,062 --> 0:13:17,731
并量化这些层中的所有权重

222
00:13:18,165 --> 0:13:19,099
我们完成了

223
00:13:20,467 --> 0:13:22,269
如果你还记得

224
00:13:22,603 --> 0:13:25,272
几分钟前我提到量化我们的模型

225
00:13:25,339 --> 0:13:27,274
会造成精确度上的损失

226
00:13:27,941 --> 0:13:31,345
所以我们想知道我们的量化模型

227
00:13:32,179 --> 0:13:35,883
这样做的最简单方法是

228
00:13:36,383 --> 0:13:39,953
并使用我们的原始模型推理该数据

229
00:13:40,554 --> 0:13:42,956
再使用我们的量化模型

230
00:13:43,023 --> 0:13:46,426
对相同的数据进行相同的推理

231
00:13:47,094 --> 0:13:48,595
来看看它们的一致程度

232
00:13:49,029 --> 0:13:51,465
Core ML Tools

233
00:13:51,532 --> 0:13:55,636
我们可以通过调用这个

234
00:13:56,236 --> 0:13:57,971
我们传入全精度模型

235
00:13:58,472 --> 0:14:01,141
然后是我们刚刚量化过的模型

236
00:13:58,472 --> 0:14:01,141
然后是我们刚刚量化过的模型

237
00:14:01,942 --> 0:14:03,710
由于这个模型是一个简单的

238
00:14:04,778 --> 0:14:07,381
图像分类器 它只有一个图像输入

239
00:14:08,081 --> 0:14:09,416
我们有一个方便的工具

240
00:14:09,483 --> 0:14:12,753
我们只需传入一个

241
00:14:13,120 --> 0:14:14,221
在我的桌面上

242
00:14:14,288 --> 0:14:17,824
我有一个文件夹

243
00:14:18,158 --> 0:14:23,063
因此我将这个文件夹的路径

244
00:14:27,968 --> 0:14:28,836
很好

245
00:14:28,902 --> 0:14:31,805
现在我们看到我们正在分析

246
00:14:31,872 --> 0:14:34,174
我们正在推理…

247
00:14:34,241 --> 0:14:36,577
我们先使用全精度模型

248
00:14:36,643 --> 0:14:38,512
然后再用量化模型进行推理

249
00:14:38,579 --> 0:14:40,380
最后比较这两个预测

250
00:14:41,348 --> 0:14:42,749
我们似乎已经完成了

251
00:14:43,750 --> 0:14:46,954
你可以看到我们的Top 1

252
00:14:47,721 --> 0:14:51,058
看起来不错 这个Top 1

253
00:14:51,558 --> 0:14:53,894
这意味着当我向原始模型输入

254
00:14:54,494 --> 0:14:56,763
比如一只狗的图像时

255
00:14:57,297 --> 0:14:59,132
它会预测这张图片是一只狗

256
00:14:59,199 --> 0:15:00,767
而我的量化模型也作出同样预测

257
00:14:59,199 --> 0:15:00,767
而我的量化模型也作出同样预测

258
00:15:01,034 --> 0:15:04,137
这种情况发生在

259
00:15:05,839 --> 0:15:08,275
我可以在我的app中使用此模型

260
00:15:08,675 --> 0:15:09,943
但我想看看

261
00:15:10,177 --> 0:15:12,779
其他量化技术

262
00:15:13,480 --> 0:15:16,917
正如我所提到的

263
00:15:17,084 --> 0:15:19,553
线性量化和查找表量化

264
00:15:19,887 --> 0:15:21,188
所以让我们继续尝试

265
00:15:21,488 --> 0:15:24,124
使用查找表量化来量化此模型

266
00:15:30,931 --> 0:15:32,466
我们再次传入原始模型

267
00:15:32,766 --> 0:15:35,102
和我们想要量化模型的位数

268
00:15:35,669 --> 0:15:37,404
以及我们的量化技术

269
00:15:39,306 --> 0:15:40,474
哎呀 这里有个错误

270
00:15:48,916 --> 0:15:50,217
让我们运行它

271
00:15:50,651 --> 0:15:53,720
K-means是一种

272
00:15:53,787 --> 0:15:56,356
能够逼近我们的权重分布

273
00:15:56,657 --> 0:15:58,192
使用这种分布

274
00:15:58,392 --> 0:16:02,062
我们可以为我们的权重构建查找表

275
00:15:58,392 --> 0:16:02,062
我们可以为我们的权重构建查找表

276
00:16:02,529 --> 0:16:04,097
我们在这里做的是

277
00:16:04,164 --> 0:16:07,000
我们遍历神经网络中的所有层

278
00:16:07,267 --> 0:16:09,736
对其执行量化过程

279
00:16:09,970 --> 0:16:11,438
并为那个特顶层计算查找表

280
00:16:12,206 --> 0:16:15,409
如果你是一位专家

281
00:16:15,576 --> 0:16:16,944
你也知道你的模型架构

282
00:16:17,211 --> 0:16:19,580
而且你知道K-means

283
00:16:19,813 --> 0:16:22,049
你可以灵活地传入

284
00:16:22,216 --> 0:16:23,483
你自己的自定义函数

285
00:16:24,585 --> 0:16:26,954
而不是这里的这个算法

286
00:16:27,020 --> 0:16:29,790
你的自定义函数来为你构造查找表

287
00:16:30,824 --> 0:16:34,661
我们使用查找表方法

288
00:16:35,062 --> 0:16:38,298
现在让我们看看这个模型

289
00:16:38,632 --> 0:16:41,468
所以我们再次调用

290
00:16:42,236 --> 0:16:46,373
我们传入原始模型

291
00:16:46,974 --> 0:16:48,909
我们再次传入

292
00:16:50,511 --> 0:16:51,645
示例数据文件夹

293
00:16:54,681 --> 0:16:58,619
我们再次使用原始模型和量化模型

294
00:16:59,586 --> 0:17:01,388
对所有图像进行推理

295
00:16:59,586 --> 0:17:01,388
对所有图像进行推理

296
00:17:01,688 --> 0:17:02,723
我们看到这一次

297
00:17:02,789 --> 0:17:05,791
我们得到了一个更好一点的

298
00:17:06,193 --> 0:17:07,261
对于这个模型

299
00:17:07,694 --> 0:17:09,963
我们看到查找表是正确的选择

300
00:17:10,364 --> 0:17:12,866
但是这与模型有关 对于其他模型

301
00:17:13,066 --> 0:17:14,067
可能是线性量化效果更好

302
00:17:14,635 --> 0:17:17,905
现在我们对这个结果感到高兴

303
00:17:17,971 --> 0:17:20,773
已经够好了

304
00:17:23,410 --> 0:17:25,546
我们通过调用save函数来保存

305
00:17:30,417 --> 0:17:34,254
再给它起个有创意的名字

306
00:17:41,161 --> 0:17:43,263
可以了

307
00:17:43,964 --> 0:17:47,634
这是一个原始模型

308
00:17:48,168 --> 0:17:50,037
让我们打开我们的量化模型

309
00:17:52,606 --> 0:17:54,274
我们立即注意到的第一件事

310
00:17:54,341 --> 0:17:57,544
是这个模型的大小只有1.3兆字节

311
00:18:04,117 --> 0:18:05,285
如果你注意一下会发现

312
00:18:05,986 --> 0:18:10,858
有关量化模型的所有细节

313
00:18:11,225 --> 0:18:14,561
它仍然需要一个图像输入

314
00:18:15,229 --> 0:18:18,131
若我有一个使用此模型的app

315
00:18:18,198 --> 0:18:19,633
如我们在演示中看到的那样

316
00:18:20,000 --> 0:18:22,536
将这个量化模型直接

317
00:18:22,603 --> 0:18:23,937
并开始使用它

318
00:18:24,137 --> 0:18:26,440
只需这样 我们就缩减了

319
00:18:32,379 --> 0:18:34,915
这就是使用

320
00:18:38,652 --> 0:18:43,590
回顾一下 我们看到使用Core ML Tools

321
00:18:44,291 --> 0:18:48,328
使用一个简单的API

322
00:18:48,795 --> 0:18:51,231
我们想要量化模型的位数

323
00:18:51,498 --> 0:18:53,667
和我们想要使用的量化算法

324
00:18:54,201 --> 0:18:56,436
我们也看到Core ML Tools中

325
00:18:56,703 --> 0:18:59,039
来帮助我们比较量化模型

326
00:18:59,373 --> 0:19:01,808
从而了解它与我们的

327
00:18:59,373 --> 0:19:01,808
从而了解它与我们的

328
00:19:03,510 --> 0:19:05,345
正如我们在演示中看到的那样

329
00:19:05,712 --> 0:19:08,882
量化我们的模型会导致

330
00:19:09,816 --> 0:19:10,817
这个…

331
00:19:11,151 --> 0:19:13,754
这种精度损失高度依赖于模型和数据

332
00:19:14,621 --> 0:19:18,759
一些模型在量化之后

333
00:19:19,359 --> 0:19:20,994
作为一般经验法则

334
00:19:21,161 --> 0:19:23,697
我们量化模型的位数越少

335
00:19:24,364 --> 0:19:26,033
我们精度所受的影响就越大

336
00:19:26,567 --> 0:19:28,235
在演示中我们看到

337
00:19:28,669 --> 0:19:31,705
我们能使用Core ML Tools中的

338
00:19:31,772 --> 0:19:34,575
来比较我们的量化模型

339
00:19:35,442 --> 0:19:36,810
但你必须弄清楚

340
00:19:37,411 --> 0:19:40,147
你的模型和用例的

341
00:19:40,214 --> 0:19:42,850
并验证你的量化模型是可接受的

342
00:19:44,017 --> 0:19:47,421
在之前的演讲中

343
00:19:48,155 --> 0:19:50,757
这个网络输入一幅图像

344
00:19:51,158 --> 0:19:54,494
然后输出一个风格化的图像

345
00:19:55,329 --> 0:19:57,297
让我们来看看这个模型

346
00:19:57,364 --> 0:19:59,233
在不同的量化级别下表现如何

347
00:20:00,133 --> 0:20:04,271
在左上角

348
00:20:04,771 --> 0:20:10,210
我们看到原始模型是32位

349
00:20:10,677 --> 0:20:14,448
我们的8位线性量化模型

350
00:20:14,781 --> 0:20:17,451
而且我们发现 从视觉上来看

351
00:20:17,518 --> 0:20:19,753
该效果对于我的风格转换演示来说

352
00:20:20,687 --> 0:20:23,924
我们还可以看到 即使低至4位

353
00:20:24,024 --> 0:20:26,193
我们也不会在效果方面损失太多

354
00:20:26,593 --> 0:20:27,961
我甚至可能会说

355
00:20:28,028 --> 0:20:30,163
对于我的app来说

356
00:20:30,664 --> 0:20:33,967
从2位开始我们可以看到

357
00:20:34,401 --> 0:20:36,436
这个模型可能不适合我们

358
00:20:38,906 --> 0:20:41,175
以上就是如何使用

359
00:20:41,975 --> 0:20:43,510
接下来我将话筒交回给Aseem

360
00:20:43,577 --> 0:20:45,612
他将会谈论自定义转换

361
00:20:45,779 --> 0:20:46,613
谢谢

362
00:20:52,352 --> 0:20:53,387
谢谢Sohaib

363
00:20:55,155 --> 0:20:58,659
我想谈一下一个非常重要的特性

364
00:20:58,725 --> 0:21:01,728
它让我们能够跟上

365
00:20:58,725 --> 0:21:01,728
它让我们能够跟上

366
00:21:02,329 --> 0:21:03,397
大家都知道

367
00:21:04,064 --> 0:21:07,134
机器学习领域正在迅速发展

368
00:21:07,768 --> 0:21:10,304
因此 为你提供必要的软件工具

369
00:21:10,771 --> 0:21:14,374
对于我们Core ML团队来说

370
00:21:15,876 --> 0:21:17,077
现在举一个例子

371
00:21:17,911 --> 0:21:20,781
假设你正在尝试一个

372
00:21:20,848 --> 0:21:22,349
Core ML尚不支持的新模型

373
00:21:22,649 --> 0:21:27,321
或者假设你有一个

374
00:21:27,387 --> 0:21:31,792
但是也许其中有一两层

375
00:21:32,893 --> 0:21:38,432
在这种情况下 你希望仍然能够使用

376
00:21:39,333 --> 0:21:41,134
对这个问题的回答是

377
00:21:41,668 --> 0:21:44,938
自定义机制将帮助你达到这点

378
00:21:46,173 --> 0:21:47,274
在接下来的几分钟内

379
00:21:47,474 --> 0:21:50,644
我想重点关注当我们有一个

380
00:21:50,711 --> 0:21:53,514
新的神经网络层的情况

381
00:21:53,881 --> 0:21:56,984
然后向你展示

382
00:21:57,284 --> 0:21:59,486
以及如何在你的app中实现它

383
00:22:00,854 --> 0:22:02,956
让我们先来看看模型转换

384
00:22:03,957 --> 0:22:07,261
如果你使用过我们的转换器

385
00:22:07,661 --> 0:22:10,697
它是一个非常简单的API

386
00:22:12,065 --> 0:22:15,068
这是Keras转换器的样子

387
00:22:15,469 --> 0:22:17,638
它与ONNX转换器

388
00:22:17,704 --> 0:22:20,440
都很相似

389
00:22:21,742 --> 0:22:25,612
当你调用这个函数时

390
00:22:25,946 --> 0:22:29,149
但有时你可能会得到

391
00:22:30,751 --> 0:22:34,354
它可能会说

392
00:22:35,088 --> 0:22:36,957
如果这件事发生在你身上

393
00:22:37,291 --> 0:22:40,894
你只需要多做一点事

394
00:22:41,628 --> 0:22:42,796
更具体地说

395
00:22:42,963 --> 0:22:47,668
这样的错误信息表明

396
00:22:48,969 --> 0:22:50,170
在我向你展示

397
00:22:50,237 --> 0:22:53,407
你需要做点什么才能成功转换之前

398
00:22:54,241 --> 0:22:57,778
让我们先看几个

399
00:23:01,315 --> 0:23:05,853
假设你有一个图像分类器

400
00:23:06,220 --> 0:23:08,589
这是一些关于该模型的高级描述

401
00:23:08,889 --> 0:23:12,593
如果你能看到它的内部

402
00:23:13,026 --> 0:23:16,063
而且很可能是一个卷积神经网络

403
00:23:16,129 --> 0:23:19,399
所以它会有很多层

404
00:23:20,367 --> 0:23:21,635
现在可能会发生这种情况

405
00:23:21,702 --> 0:23:23,971
即有一个新的激活层出现

406
00:23:24,037 --> 0:23:25,472
而Core ML还不支持它

407
00:23:25,772 --> 0:23:26,607
并且…

408
00:23:27,341 --> 0:23:30,277
就像在每次机器学习会议上一样

409
00:23:30,344 --> 0:23:32,713
研究人员总是在提出新的层

410
00:23:32,779 --> 0:23:34,214
所以这是一个很常见的情况

411
00:23:35,048 --> 0:23:36,216
如果发生这种情况

412
00:23:36,483 --> 0:23:40,888
你只需要使用这个新层的自定义实现

413
00:23:41,321 --> 0:23:44,258
然后你就准备好了

414
00:23:44,324 --> 0:23:47,327
唯一的区别是在底部的

415
00:23:47,394 --> 0:23:48,495
这个依赖部分

416
00:23:49,363 --> 0:23:50,364
其中…

417
00:23:51,431 --> 0:23:54,601
具有这个模型所包含的

418
00:23:55,169 --> 0:23:56,837
我们来看看另一个例子

419
00:23:57,004 --> 0:23:59,940
假设我们有一个非常简单的

420
00:24:01,175 --> 0:24:02,342
最近

421
00:24:02,943 --> 0:24:06,980
我看到了一篇研究论文

422
00:24:07,548 --> 0:24:09,416
它所做的事情是这样的

423
00:24:10,017 --> 0:24:13,687
它在数字之后插入一个神经网络

424
00:24:14,154 --> 0:24:16,523
用来定位数字的位置

425
00:24:17,291 --> 0:24:19,860
然后将其传入一个网格采样器层

426
00:24:20,260 --> 0:24:22,229
这会重新渲染这个数字

427
00:24:22,296 --> 0:24:25,265
但这次它已经能够定位在数字本身上

428
00:24:25,566 --> 0:24:28,068
然后你将它传递给你的旧分类方法

429
00:24:28,969 --> 0:24:32,339
我们不关心这里的细节

430
00:24:32,406 --> 0:24:35,008
但要注意的一点是

431
00:24:35,275 --> 0:24:36,944
绿色部分是Core ML支持的

432
00:24:37,344 --> 0:24:40,581
而红色部分是新的网格采样器层

433
00:24:40,948 --> 0:24:43,750
是Core ML不支持的新实验层

434
00:24:44,418 --> 0:24:46,887
我想通过这个特定模型的例子

435
00:24:47,354 --> 0:24:51,325
来向你展示如何使用

436
00:24:51,959 --> 0:24:53,327
现在我们来演示一下

437
00:25:00,000 --> 0:25:01,768
我希望能够一次成功

438
00:25:03,504 --> 0:25:05,005
好的

439
00:25:05,973 --> 0:25:06,974
好

440
00:25:07,508 --> 0:25:09,977
我先关闭这些窗口

441
00:25:14,648 --> 0:25:17,584
让我清除这个

442
00:25:18,085 --> 0:25:22,856
我也将使用

443
00:25:29,930 --> 0:25:33,300
导航到我的预训练网络的文件夹

444
00:25:34,334 --> 0:25:39,439
你可以在这里看到我的

445
00:25:39,506 --> 0:25:41,441
这是一个预训练的Keras模型

446
00:25:42,743 --> 0:25:46,380
如果你想知道

447
00:25:48,182 --> 0:25:49,483
基本上我做的是…

448
00:25:50,050 --> 0:25:51,418
我可以轻松找到

449
00:25:51,485 --> 0:25:54,021
空间变换器的开源实现

450
00:25:54,087 --> 0:25:57,057
我刚在Keras中执行了该脚本

451
00:25:58,158 --> 0:26:02,429
除此以外 我还有这个

452
00:25:58,158 --> 0:26:02,429
除此以外 我还有这个

453
00:26:03,197 --> 0:26:05,866
我正在谈论的这个网格采样器层

454
00:26:06,266 --> 0:26:08,669
在Keras中也没有原生支持

455
00:26:09,303 --> 0:26:11,805
所以我在网上找到的这个实现

456
00:26:12,105 --> 0:26:15,676
使用Keras自定义层来实现该层

457
00:26:16,376 --> 0:26:20,614
正如你所见 自定义概念

458
00:26:20,914 --> 0:26:24,418
实际上 在大多数机器学习框架中

459
00:26:24,751 --> 0:26:27,087
这就是人们在新层中进行实验的方法

460
00:26:27,955 --> 0:26:30,624
好的 到目前为止

461
00:26:30,824 --> 0:26:33,660
现在我想专注于

462
00:26:34,361 --> 0:26:36,230
所以我将打开…

463
00:26:38,131 --> 0:26:39,099
让我们看看…

464
00:26:40,000 --> 0:26:42,336
在这里 让我启动一个

465
00:26:44,137 --> 0:26:46,874
我将从在Python环境中

466
00:26:46,940 --> 0:26:48,242
导入Keras模型开始

467
00:26:51,879 --> 0:26:54,248
先导入Keras

468
00:26:55,315 --> 0:26:57,751
再导入我们的Keras自定义层

469
00:26:58,285 --> 0:27:00,921
现在我将在Keras中加载模型

470
00:26:58,285 --> 0:27:00,921
现在我将在Keras中加载模型

471
00:27:02,689 --> 0:27:04,658
这就是你如何加载Keras模型

472
00:27:05,526 --> 0:27:07,494
你将该部分提供给模型

473
00:27:07,561 --> 0:27:10,030
如果有一个自定义层

474
00:27:10,998 --> 0:27:14,468
好的 现在我们有了这个模型

475
00:27:15,669 --> 0:27:17,638
我要先导入coremltools

476
00:27:18,372 --> 0:27:19,373
执行它

477
00:27:19,907 --> 0:27:22,476
现在 正如我之前展示给你的那样

478
00:27:22,543 --> 0:27:25,679
只需要调用一个函数来转换它

479
00:27:26,079 --> 0:27:27,114
我们来试试

480
00:27:28,415 --> 0:27:32,085
这是我的调用

481
00:27:33,520 --> 0:27:35,822
Python喜欢抛出

482
00:27:36,123 --> 0:27:40,027
但是我们真正关心的是最后一行

483
00:27:40,427 --> 0:27:41,361
让我…

484
00:27:46,733 --> 0:27:49,002
正如我们在这最后一行所看到的那样

485
00:27:49,269 --> 0:27:51,338
采样器层不受支持

486
00:27:51,839 --> 0:27:55,142
现在我们看看怎样才能解决这个问题

487
00:27:55,742 --> 0:27:57,778
我关掉这些以便你可以看到

488
00:27:58,445 --> 0:28:00,948
现在我稍微改一下我的转换器调用

489
00:27:58,445 --> 0:28:00,948
现在我稍微改一下我的转换器调用

490
00:28:01,181 --> 0:28:03,050
这是我的Core ML模型

491
00:28:06,019 --> 0:28:08,956
现在我要传递一个额外的参数

492
00:28:09,223 --> 0:28:15,229
它被称为

493
00:28:19,399 --> 0:28:20,801
这是一个字典类型

494
00:28:21,401 --> 0:28:25,839
它是从层的名称到一个

495
00:28:26,139 --> 0:28:27,774
将其命名为

496
00:28:27,841 --> 0:28:30,511
让我退后一步并解释这里发生的事情

497
00:28:30,577 --> 0:28:34,214
转换器的工作方式是

498
00:28:34,281 --> 0:28:35,682
它会遍历每个Keras层

499
00:28:36,817 --> 0:28:38,452
先进入第一层

500
00:28:38,519 --> 0:28:40,754
将其参数转换为Core ML

501
00:28:40,821 --> 0:28:43,857
然后转到第二层继续转换它的参数

502
00:28:44,625 --> 0:28:47,427
当它碰到这个自定义层时

503
00:28:47,761 --> 0:28:51,398
所以我传入的这个函数

504
00:28:51,965 --> 0:28:54,268
将帮助我的转换器做到这一点

505
00:28:54,868 --> 0:28:57,171
我们来看看这个函数长什么样

506
00:29:00,974 --> 0:29:01,975
就是这个函数

507
00:29:02,843 --> 0:29:06,280
这里有几行代码

508
00:29:07,481 --> 0:29:11,318
首先 它给出了一个类的名称

509
00:29:11,985 --> 0:29:13,353
正如我们注意到的那样

510
00:29:13,420 --> 0:29:15,556
该层的实现不在这里

511
00:29:15,889 --> 0:29:18,192
实现将稍后在app中出现

512
00:29:18,725 --> 0:29:20,861
它将被封装在一个类中

513
00:29:21,261 --> 0:29:24,431
这是我们稍后将实现的类的名称

514
00:29:24,498 --> 0:29:27,768
在转换过程中

515
00:29:28,068 --> 0:29:28,936
就这么简单

516
00:29:29,136 --> 0:29:30,604
然后设置其描述

517
00:29:30,804 --> 0:29:32,639
你应该提供它

518
00:29:32,706 --> 0:29:34,541
如果有其他人…

519
00:29:34,741 --> 0:29:38,278
以便如果有人正在看你的模型

520
00:29:39,246 --> 0:29:40,347
第三件事基本上就是

521
00:29:40,414 --> 0:29:44,451
将Keras层的任何参数

522
00:29:45,052 --> 0:29:47,221
对于这个特定的层

523
00:29:47,287 --> 0:29:51,091
输出高度和输出权重

524
00:29:51,792 --> 0:29:54,161
如果你的自定义层没有任何参数

525
00:29:54,228 --> 0:29:57,631
那么你不需要这样做

526
00:29:58,332 --> 0:30:01,401
如果你的层有很多参数

527
00:29:58,332 --> 0:30:01,401
如果你的层有很多参数

528
00:30:01,468 --> 0:30:05,072
并且被封装在Core ML模型中

529
00:30:06,240 --> 0:30:08,509
你可能已经注意到了

530
00:30:08,575 --> 0:30:11,478
与你定义类的方式非常相似 对吗？

531
00:30:11,745 --> 0:30:13,614
你给出一个类名 可能有一个描述

532
00:30:13,680 --> 0:30:16,817
也许还有些参数

533
00:30:19,853 --> 0:30:22,923
现在我们看到转换进行得很顺利

534
00:30:25,692 --> 0:30:28,095
让我……

535
00:30:28,929 --> 0:30:31,632
不知道为什么 这里有点奇怪

536
00:30:35,769 --> 0:30:38,672
如果你不介意 我把这些都删了

537
00:30:40,541 --> 0:30:42,409
现在让我可视化这个模型

538
00:30:42,676 --> 0:30:47,147
你可以简单的调用

539
00:30:47,581 --> 0:30:49,082
这个函数叫

540
00:30:50,751 --> 0:30:54,254
这里你可以看到该模型的可视化效果

541
00:30:54,588 --> 0:30:58,458
正如我们所看到的那样

542
00:30:58,792 --> 0:31:00,494
这是我们的自定义层

543
00:30:58,792 --> 0:31:00,494
这是我们的自定义层

544
00:31:00,561 --> 0:31:03,130
如果我点击它

545
00:31:03,197 --> 0:31:05,699
这是我给它的类名

546
00:31:06,700 --> 0:31:09,036
这些是我设置的参数

547
00:31:10,037 --> 0:31:12,606
可视化你的Core ML模型

548
00:31:13,240 --> 0:31:16,043
在拖放之前 检查一下一切是否正常

549
00:31:17,277 --> 0:31:18,111
好

550
00:31:19,613 --> 0:31:23,417
不是这个笔记本

551
00:31:31,158 --> 0:31:32,759
现在我们来看看这个模型

552
00:31:34,094 --> 0:31:35,829
让我关闭它

553
00:31:37,297 --> 0:31:38,298
好的

554
00:31:42,669 --> 0:31:45,372
让我导航到

555
00:31:46,807 --> 0:31:48,108
这个目录

556
00:31:51,845 --> 0:31:54,348
我的模型在这里

557
00:31:54,414 --> 0:31:58,352
看看它是什么样的

558
00:31:59,119 --> 0:32:00,487
一个自定义网格描述

559
00:31:59,119 --> 0:32:00,487
一个自定义网格描述

560
00:32:01,522 --> 0:32:03,457
让我们回到幻灯片

561
00:32:10,297 --> 0:32:14,768
我们刚刚看到的是

562
00:32:14,835 --> 0:32:17,538
我们就可以轻松将函数

563
00:32:17,804 --> 0:32:19,973
这过程和你用TensorFlow

564
00:32:20,374 --> 0:32:23,944
的过程几乎是一样的

565
00:32:25,245 --> 0:32:27,447
左边是我们的模型

566
00:32:28,248 --> 0:32:30,083
带参数的自定义层模型

567
00:32:30,484 --> 0:32:32,753
当你将此模型拖放到Xcode中时

568
00:32:33,453 --> 0:32:36,023
你需要在一个文件中提供该类的实现

569
00:32:36,423 --> 0:32:39,726
比如gridSampler.swift

570
00:32:40,260 --> 0:32:45,599
这就是你的类 它有一个初始化函数

571
00:32:46,033 --> 0:32:47,100
它将会

572
00:32:47,167 --> 0:32:50,103
初始化模型中的任何参数

573
00:32:50,804 --> 0:32:52,840
这个类的主要函数

574
00:32:54,741 --> 0:32:55,909
是evaluate函数

575
00:32:58,111 --> 0:33:01,515
这是该层需要执行的数学运算的

576
00:32:58,111 --> 0:33:01,515
这是该层需要执行的数学运算的

577
00:33:01,582 --> 0:33:04,384
真正实现部分

578
00:33:05,185 --> 0:33:06,320
还有另一个函数也会被调用

579
00:33:06,386 --> 0:33:08,088
这个outputShapes

580
00:33:08,155 --> 0:33:10,891
它会指定该层产生的

581
00:33:10,958 --> 0:33:12,159
输出区域的大小

582
00:33:12,526 --> 0:33:16,296
这有助于Core ML在加载时

583
00:33:16,930 --> 0:33:19,633
以便你的app在运行时更高效

584
00:33:21,969 --> 0:33:26,507
我们刚刚看到你将如何处理

585
00:33:27,174 --> 0:33:30,177
有一个非常类似于自定义层的概念

586
00:33:30,244 --> 0:33:32,513
它被称为自定义模型

587
00:33:33,280 --> 0:33:36,750
它们的原理差不多 但它更具通用性

588
00:33:37,217 --> 0:33:41,555
对于自定义模型

589
00:33:41,755 --> 0:33:44,858
它不一定是一个神经网络

590
00:33:45,292 --> 0:33:48,662
并且在整体上能给你更多的灵活性

591
00:33:50,564 --> 0:33:53,300
让我总结一下这次演讲

592
00:33:54,601 --> 0:33:58,939
Core ML Tools的

593
00:33:59,006 --> 0:34:00,340
这对你们来说很棒

594
00:33:59,006 --> 0:34:00,340
这对你们来说很棒

595
00:34:00,407 --> 0:34:03,810
因为现在你有更多的选择

596
00:34:04,478 --> 0:34:06,747
我们看到量化Core ML模型

597
00:34:08,215 --> 0:34:12,485
我们还看到只需几行代码

598
00:34:13,920 --> 0:34:18,257
我们就可以很轻松地在模型中

599
00:34:20,726 --> 0:34:23,429
你可以在我们的文档页面

600
00:34:23,597 --> 0:34:25,632
欢迎来实验室并与我们交谈

601
00:34:26,166 --> 0:34:27,201
好的 谢谢
